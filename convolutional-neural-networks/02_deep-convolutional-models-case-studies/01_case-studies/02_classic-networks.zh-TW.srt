1
00:00:00,000 --> 00:00:02,470
在這段影片中, 你將開始學習一些

2
00:00:02,470 --> 00:00:05,418
經典的神經網路架構，從 LeNet-5

3
00:00:05,418 --> 00:00:10,122
到 AlexNet, 然後是 VGGNet, 我們來看看

4
00:00:10,122 --> 00:00:12,935
這個是 LeNet-5 架構

5
00:00:12,935 --> 00:00:15,700
您從一個影像開始

6
00:00:15,700 --> 00:00:17,540
32乘32乘1

7
00:00:17,540 --> 00:00:21,520
這個LeNet-5 的目標是辨識手寫數字

8
00:00:21,520 --> 00:00:25,490
或許是一個數字影像像這樣

9
00:00:25,490 --> 00:00:28,815
而 LeNet-5 訓練在灰階的影像上

10
00:00:28,815 --> 00:00:32,180
也就是為什麼 32乘32乘1

11
00:00:32,180 --> 00:00:34,400
這個神經網路架構實際上

12
00:00:34,400 --> 00:00:38,315
相當類似於您上個禮拜看過的例子

13
00:00:38,315 --> 00:00:39,847
第一步

14
00:00:39,847 --> 00:00:41,765
您用一組六個

15
00:00:41,765 --> 00:00:45,220
5乘5 過濾器，跨步為 1, 因為您用了

16
00:00:45,220 --> 00:00:50,218
6 個過濾器，您最終會有 28乘28乘6 的輸出

17
00:00:50,218 --> 00:00:52,730
而跨步 1, 沒有填充

18
00:00:52,730 --> 00:00:58,640
影像維度會從 32乘32 降為 28乘28

19
00:00:58,640 --> 00:01:02,295
然後 LeNet 神經網路應用池層

20
00:01:02,295 --> 00:01:04,970
回到這份論文寫作時

21
00:01:04,970 --> 00:01:07,576
人們大多使用平均池層

22
00:01:07,576 --> 00:01:09,290
如果您在現在建置

23
00:01:09,290 --> 00:01:12,145
您或許會使用最大池化

24
00:01:12,145 --> 00:01:13,360
不過在這例子

25
00:01:13,360 --> 00:01:17,825
您使用平均池層，過濾器的寬度為 2, 跨步為 2

26
00:01:17,825 --> 00:01:20,780
這樣您會降低維度

27
00:01:20,780 --> 00:01:22,730
高度跟寬度都減半

28
00:01:22,730 --> 00:01:28,784
我們現在會是 14乘14乘6 容積

29
00:01:28,784 --> 00:01:32,180
我猜我畫的高度跟寬度不符合比例原則

30
00:01:32,180 --> 00:01:35,210
技術上而言，如果您畫的容積符合比例

31
00:01:35,210 --> 00:01:38,150
高度跟寬度應該要減半

32
00:01:38,150 --> 00:01:41,180
接下來，您應用另一個卷積層

33
00:01:41,180 --> 00:01:44,070
這一次，您用了一組 16 個過濾器

34
00:01:44,070 --> 00:01:48,515
5乘5 ，您最終會有 16 個通道在下一個容積

35
00:01:48,515 --> 00:01:52,355
回到這篇論文寫作的時間 1998 年

36
00:01:52,355 --> 00:01:57,200
人們實際上不用填充，或者說人們都用有效卷積

37
00:01:57,200 --> 00:01:59,635
也就是每次您應用卷積層

38
00:01:59,635 --> 00:02:01,965
高度跟寬度都會縮水

39
00:02:01,965 --> 00:02:03,380
所以這是為什麼，這裡

40
00:02:03,380 --> 00:02:06,393
您從 14乘14 降為 10乘10

41
00:02:06,393 --> 00:02:08,580
然後加入另一個池層

42
00:02:08,580 --> 00:02:11,060
因此將高度跟寬度減半

43
00:02:11,060 --> 00:02:13,715
最終輸出是 5乘5

44
00:02:13,715 --> 00:02:16,640
而如果您將所有的 5乘5乘16 乘起來

45
00:02:16,640 --> 00:02:20,375
這個乘積是 400

46
00:02:20,375 --> 00:02:24,020
25乘 16 是 400

47
00:02:24,020 --> 00:02:29,900
然後下一層是全連結層，連結所有

48
00:02:29,900 --> 00:02:36,840
這些 400 個節點跟這 120 個節點

49
00:02:36,840 --> 00:02:38,385
所以這是一個全連結層

50
00:02:38,385 --> 00:02:41,955
有時候會另外畫

51
00:02:41,955 --> 00:02:46,080
一層有 400 個節點，我跳過這個步驟

52
00:02:46,080 --> 00:02:49,590
這是一個全連結層，然後另一個全連結層

53
00:02:49,590 --> 00:02:51,690
最後的步驟是使用

54
00:02:51,690 --> 00:02:57,280
這些是基本的 84 個特徵，用來估算一個輸出

55
00:02:57,280 --> 00:03:01,375
我猜您可以畫另一個節點在這裡來做 y-hat 的預估

56
00:03:01,375 --> 00:03:04,560
而 y-hat 有 10 個可能值

57
00:03:04,560 --> 00:03:09,090
對應辨識從 0 到 9 的每一個數字

58
00:03:09,090 --> 00:03:11,100
一個現代的神經網路版本

59
00:03:11,100 --> 00:03:17,300
我們會使用  softmax 層有 10 個分類輸出

60
00:03:17,300 --> 00:03:23,385
雖然回到當初，
 LeNet-5 實際上使用不同的分類器在輸出層

61
00:03:23,385 --> 00:03:25,633
現在已經不用了

62
00:03:25,633 --> 00:03:29,220
這個神經網路
依現在的標準來看算小的

63
00:03:29,220 --> 00:03:32,645
有大約 60,000 個參數

64
00:03:32,645 --> 00:03:35,934
在今天，您通常看到的神經網路

65
00:03:35,934 --> 00:03:39,690
可能從一千萬到一億個參數

66
00:03:39,690 --> 00:03:41,850
也不是不常看到那樣的網路

67
00:03:41,850 --> 00:03:45,295
真的是千倍於這個網路

68
00:03:45,295 --> 00:03:49,600
但當您進入深層網路時您會見到

69
00:03:49,600 --> 00:03:51,790
當您從左到右

70
00:03:51,790 --> 00:03:55,360
高度跟寬度趨向於降低

71
00:03:55,360 --> 00:03:57,690
所以您從 32乘32 到 28 到 14

72
00:03:57,690 --> 00:04:03,100
到 10 到 5，而通道數目則一直增加

73
00:04:03,100 --> 00:04:11,250
它從 1 到 6 到 16 當您進入深層的網路時

74
00:04:11,250 --> 00:04:15,400
另一個模式即使在今天的神經網路
也依然重複著的是

75
00:04:15,400 --> 00:04:20,500
您或許有一個或多個卷積層接著一個池層

76
00:04:20,500 --> 00:04:25,758
然後一個或多個卷積層接著一個池層

77
00:04:25,758 --> 00:04:29,940
然後一些全連結層然後是輸出層

78
00:04:29,940 --> 00:04:34,090
這樣網路層的安排是很常見的

79
00:04:34,090 --> 00:04:39,515
最後這或許只針對於那些想讀論文的人

80
00:04:39,515 --> 00:04:41,880
有一些東西是不同的

81
00:04:41,880 --> 00:04:43,690
這張投影片的其餘部分

82
00:04:43,690 --> 00:04:47,065
我將做一些進階的註解

83
00:04:47,065 --> 00:04:52,265
只針對那些想讀經典論文的人

84
00:04:52,265 --> 00:04:54,903
所有用紅色字寫的

85
00:04:54,903 --> 00:04:57,490
您可以安全地跳過

86
00:04:57,490 --> 00:05:00,520
或許是一個有趣的歷史註解

87
00:05:00,520 --> 00:05:04,350
如果您跟不上也沒關係

88
00:05:04,350 --> 00:05:07,990
實際上如果您讀原來的論文，那時

89
00:05:07,990 --> 00:05:12,453
人們使用 S 形函數跟  Tanh 非線性函數

90
00:05:12,453 --> 00:05:16,330
人們那時候還沒有使用 ReLU 非線性函數

91
00:05:16,330 --> 00:05:20,065
所以如果您看論文的話，
您會看到 s形函數 跟 tanh 被引用

92
00:05:20,065 --> 00:05:23,260
然後也有一些有趣的方式有關

93
00:05:23,260 --> 00:05:26,835
這些網路如何連結，用現在的標準來看

94
00:05:26,835 --> 00:05:33,775
舉個例，您見到如果您有  nh 乘 nw 乘 nc 網路

95
00:05:33,775 --> 00:05:40,985
有 nc 個通道，您會使用  f乘f乘nc 維度的過濾器

96
00:05:40,985 --> 00:05:44,480
每一個過濾器都看著所有的通道

97
00:05:44,480 --> 00:05:47,195
但那時，電腦相對比較慢

98
00:05:47,195 --> 00:05:50,230
為了節省計算跟一些參數

99
00:05:50,230 --> 00:05:53,785
原本 LeNet-5 有一些瘋狂複雜的方式

100
00:05:53,785 --> 00:05:58,040
不同的過濾器看管不同的輸入通道

101
00:05:58,040 --> 00:06:00,343
論文裡談到了有關這些的細節

102
00:06:00,343 --> 00:06:07,090
但在現在的建置中已經不需要這樣的複雜

103
00:06:07,090 --> 00:06:12,280
最後一件事我猜那時並沒有作對的一件事

104
00:06:12,280 --> 00:06:19,705
就是原本的 LeNet-5 在池層後應用非線性

105
00:06:19,705 --> 00:06:25,005
我想它實際上使用非線性  S 型函數在池層之後

106
00:06:25,005 --> 00:06:27,130
如果您讀這份論文

107
00:06:27,130 --> 00:06:29,345
這個應該算是難的一份比起

108
00:06:29,345 --> 00:06:32,100
下幾個影片要談的

109
00:06:32,100 --> 00:06:34,670
下一個應該比較容易開始

110
00:06:34,670 --> 00:06:40,135
這張投影片大部分的觀念
我用的是論文的第二跟第三節

111
00:06:40,135 --> 00:06:44,485
論文後面幾節談到其他觀念

112
00:06:44,485 --> 00:06:47,260
它談論到有關圖形轉換網路

113
00:06:47,260 --> 00:06:49,215
在今日不常用到

114
00:06:49,215 --> 00:06:50,935
如果您試著讀這份論文

115
00:06:50,935 --> 00:06:55,660
我建議您聚焦在第二節談到有關架構部分

116
00:06:55,660 --> 00:06:58,165
或許很快看過第三節

117
00:06:58,165 --> 00:07:01,720
有一些實驗跟結果，還相當有趣

118
00:07:01,720 --> 00:07:06,155
第二個神經網路的例子我要展示的是 AlexNet

119
00:07:06,155 --> 00:07:12,510
以 Alex Krizhevsky 為名，
是第一位作者論文描述這種方式

120
00:07:12,510 --> 00:07:13,725
其他的作者是 Ilya Sutskever 跟 Geoffrey Hinton

121
00:07:13,725 --> 00:07:21,048
所以 AlexNet 的輸入是 227乘227乘3 影像

122
00:07:21,048 --> 00:07:22,525
如果您讀論文的話

123
00:07:22,525 --> 00:07:27,010
論文指的是 224乘224乘3 影像

124
00:07:27,010 --> 00:07:28,120
但如果您看這些數字

125
00:07:28,120 --> 00:07:33,100
我想這些數字應該是 227乘277 才有道理

126
00:07:33,100 --> 00:07:40,230
然後第一層使用一組 96 個
11乘11 的過濾器，跨步為 4

127
00:07:40,230 --> 00:07:42,740
因為用了大的跨步 4

128
00:07:42,740 --> 00:07:45,574
維度降低到了 55乘55

129
00:07:45,574 --> 00:07:50,930
大約，降低了將近四分之一，因為大的跨步

130
00:07:50,930 --> 00:07:55,110
然後應用了一個最大化池層 3乘3 過濾器

131
00:07:55,110 --> 00:07:57,925
所以 f 等於 3 跨步為 2

132
00:07:57,925 --> 00:08:04,570
這個降低容積到 27乘27乘96

133
00:08:04,570 --> 00:08:08,530
然後做一個 5乘5 相同卷積

134
00:08:08,530 --> 00:08:14,730
一些填充，所以最終是 27乘27乘276 (應該是 256)

135
00:08:14,730 --> 00:08:20,025
再一次最大池化，降低高度跟寬度到 13

136
00:08:20,025 --> 00:08:23,860
然後另外一個相同卷積，所以相同填充

137
00:08:23,860 --> 00:08:29,805
所以是 13乘13乘384 過濾器

138
00:08:29,805 --> 00:08:35,275
然後再一次 3乘3 相同卷積，給您這個

139
00:08:35,275 --> 00:08:39,680
然後再一次 3乘3 相同卷積，給您這個

140
00:08:39,680 --> 00:08:45,285
再一個最大池化，降低到  6乘6乘256

141
00:08:45,285 --> 00:08:52,020
如果您將這些數字乘起來 6乘6乘 256 會是 9216

142
00:08:52,020 --> 00:08:56,947
所以我們會攤平這些成為 9216 個節點

143
00:08:56,947 --> 00:09:00,790
然後最後，會有一些全連結層

144
00:09:00,790 --> 00:09:04,250
最後，使用 softmax 來輸出

145
00:09:04,250 --> 00:09:09,515
也就是 1000 種分類之一

146
00:09:09,515 --> 00:09:16,920
這個神經網路實際上跟 LeNet 有很多的相似性

147
00:09:16,920 --> 00:09:20,210
但是大很多

148
00:09:20,210 --> 00:09:27,740
儘管前面投影片的 LeNet-5 有大約 60,000 個參數

149
00:09:27,740 --> 00:09:31,935
這個 AlexNet 大約有 6 千萬個參數

150
00:09:31,935 --> 00:09:34,024
實際上它們可以

151
00:09:34,024 --> 00:09:36,925
用相當類似的建構基石是因為

152
00:09:36,925 --> 00:09:40,270
它用了相當多的隱藏單元跟訓練在大量的資料上

153
00:09:40,270 --> 00:09:42,820
它們使用 ImageNet 的資料集

154
00:09:42,820 --> 00:09:46,255
讓它可以有很好的績效

155
00:09:46,255 --> 00:09:49,810
另外一方面這個架構讓它比

156
00:09:49,810 --> 00:09:53,575
LeNet 更好是因為用了 ReLU 啟動函數

157
00:09:53,575 --> 00:09:56,425
再提醒一次，如果您讀了這份論文

158
00:09:56,425 --> 00:09:59,020
會有一些進階的細節

159
00:09:59,020 --> 00:10:01,840
如果您不讀這些論文的話您不用擔心，一個是

160
00:10:01,840 --> 00:10:03,445
當這份論文寫作時

161
00:10:03,445 --> 00:10:06,197
GPU 還比較慢

162
00:10:06,197 --> 00:10:11,135
它用了複雜的方式在兩顆 GPU 上訓練

163
00:10:11,135 --> 00:10:13,310
基本的觀念是

164
00:10:13,310 --> 00:10:18,250
很多層實際上拆開來在不同的  ＧＰＵ 上，有一些

165
00:10:18,250 --> 00:10:23,497
考慮到當兩顆 GPU 互相溝通的方式

166
00:10:23,497 --> 00:10:25,360
論文也同時

167
00:10:25,360 --> 00:10:29,650
在原本 AlexNet 架構同時也用了一些其他種的層

168
00:10:29,650 --> 00:10:34,125
稱為 區域反應正規化 (Local Response Nomalization)

169
00:10:34,125 --> 00:10:36,820
這類的網路層不常使用

170
00:10:36,820 --> 00:10:38,830
所以我並沒有提到

171
00:10:38,830 --> 00:10:42,220
但區域反應正規化(LRN)基本觀念是

172
00:10:42,220 --> 00:10:44,845
如果看一個建構基石

173
00:10:44,845 --> 00:10:46,940
上面的其中一個容積

174
00:10:46,940 --> 00:10:49,360
為了討論方便起見，用這個

175
00:10:49,360 --> 00:10:52,380
13乘13乘256

176
00:10:52,380 --> 00:10:54,765
區域反應正規化

177
00:10:54,765 --> 00:10:57,805
做的是，當您看一個位置

178
00:10:57,805 --> 00:10:59,570
一個同一高度跟寬度的位置

179
00:10:59,570 --> 00:11:02,935
看穿所有的通道

180
00:11:02,935 --> 00:11:07,195
看這些 256 個數字，正規化它們

181
00:11:07,195 --> 00:11:10,750
區域反應正規化的動機在於

182
00:11:10,750 --> 00:11:14,934
在這 13乘13 影像中的每一個位置

183
00:11:14,934 --> 00:11:20,123
或許您不要太多的神經元有太高的啟動值

184
00:11:20,123 --> 00:11:25,730
但後來，很多研究學者發現
這樣做並沒有太大幫助

185
00:11:25,730 --> 00:11:27,995
這是為什麼我用紅色來標這個想法

186
00:11:27,995 --> 00:11:31,880
因為對您而言這個較不重要

187
00:11:31,880 --> 00:11:33,940
實際上，我也不會使用

188
00:11:33,940 --> 00:11:38,760
區域反應正規化在神經網路上

189
00:11:38,760 --> 00:11:41,380
如果您對深度學習的歷史有興趣

190
00:11:41,380 --> 00:11:43,395
我想即使在 AlexNet 之前

191
00:11:43,395 --> 00:11:48,978
深度學習開始在語音辨識及其他區域獲得青睞

192
00:11:48,978 --> 00:11:52,690
但真的從這份論文開始，說服很多

193
00:11:52,690 --> 00:11:56,350
電腦視覺社群認真地看待

194
00:11:56,350 --> 00:12:00,280
深度學習，說服他們
深度學習的確可以在電腦視覺成功

195
00:12:00,280 --> 00:12:02,710
然後長大茁壯不只影響到

196
00:12:02,710 --> 00:12:05,508
電腦視覺，更超乎電腦視覺

197
00:12:05,508 --> 00:12:08,170
而如果您試著自己讀這些論文

198
00:12:08,170 --> 00:12:11,635
這個課程並不要求這樣做

199
00:12:11,635 --> 00:12:14,200
但如果您想自己讀這些論文

200
00:12:14,200 --> 00:12:19,354
這份論文算是容易的，或許可以看一下

201
00:12:19,354 --> 00:12:23,257
既然 AlexNet 有相對複雜的架構

202
00:12:23,257 --> 00:12:25,585
就會有很多的超參數，對吧？

203
00:12:25,585 --> 00:12:28,255
您要所有這些數字

204
00:12:28,255 --> 00:12:33,240
Alex Krizenvsky 跟其他作者要能提供

205
00:12:33,240 --> 00:12:39,765
讓我來展示第三種，這影片的最後一個例子
稱為 VGG 或者 VGG-16 網路

206
00:12:39,765 --> 00:12:44,820
VGG-16 值得注意的是，他們說

207
00:12:44,820 --> 00:12:46,966
與其使用這麼多的超參數

208
00:12:46,966 --> 00:12:52,495
我們用簡單許多的網路，您只要聚焦在卷積層

209
00:12:52,495 --> 00:12:58,690
就只是 3乘3 過濾器，
跨步為 1, 都使用相同填充

210
00:12:58,690 --> 00:13:03,640
讓您所有的最大池層都是 2乘2，跨步為 2

211
00:13:03,640 --> 00:13:06,250
所以，一件很棒的事在

212
00:13:06,250 --> 00:13:12,224
 VGG 網路是真的簡化了神經網路的架構

213
00:13:12,224 --> 00:13:14,494
讓我們看看這個架構

214
00:13:14,494 --> 00:13:19,660
您開始一個影像，然後前兩層是卷積層

215
00:13:19,660 --> 00:13:24,315
也就是這些 3乘3 過濾器

216
00:13:24,315 --> 00:13:27,930
而在前兩層用 64 個過濾器

217
00:13:27,930 --> 00:13:35,830
您最終會有 224乘224 
因為使用了相同卷積，然後有 64 個通道

218
00:13:35,830 --> 00:13:39,345
因為 VGG-16 相對於言是比較深的深層網路

219
00:13:39,345 --> 00:13:42,335
我們就不畫所有的容積

220
00:13:42,335 --> 00:13:46,270
所以這小張圖，描述的是我們先前

221
00:13:46,270 --> 00:13:50,890
畫的 224乘224乘3 

222
00:13:50,890 --> 00:13:55,362
然後卷積結果，我猜會是 

223
00:13:55,362 --> 00:14:00,535
224乘224乘64 畫成這樣的深度容積

224
00:14:00,535 --> 00:14:07,227
然後另一層的結果是 224乘224乘64

225
00:14:07,227 --> 00:14:15,730
所以這個 conv64 乘 2 指的是
您使用兩個卷積層有 64 個過濾器

226
00:14:15,730 --> 00:14:17,380
就像我之前提過的

227
00:14:17,380 --> 00:14:20,555
過濾器永遠都是 3乘3

228
00:14:20,555 --> 00:14:24,455
 跨步為 1，都是使用相同卷積

229
00:14:24,455 --> 00:14:26,395
所以與其畫出所有容積

230
00:14:26,395 --> 00:14:28,400
我只用文字來代表這個網路

231
00:14:28,400 --> 00:14:31,413
接下來，用一個池層

232
00:14:31,413 --> 00:14:33,580
所以池層會降低

233
00:14:33,580 --> 00:14:36,725
我想從 224乘224 降到多少？

234
00:14:36,725 --> 00:14:40,755
降到 112乘112乘64

235
00:14:40,755 --> 00:14:44,339
然後有一些卷積層

236
00:14:44,339 --> 00:14:50,426
這個代表它使用 128 個過濾器，因為是相同卷積

237
00:14:50,426 --> 00:14:52,365
我們來看看新的維度是？

238
00:14:52,365 --> 00:14:57,020
它會是 112乘112乘128

239
00:14:57,020 --> 00:15:02,205
然後是池層，您可以發現到新的維度是這樣

240
00:15:02,205 --> 00:15:07,210
然後三個卷積層

241
00:15:07,210 --> 00:15:14,300
256 過濾器，到池層，然後一些卷積層

242
00:15:14,300 --> 00:15:18,945
池層，一些卷積層，池層

243
00:15:18,945 --> 00:15:26,345
然後它用最後這個 7乘7乘512 到全連結層

244
00:15:26,345 --> 00:15:30,230
這全連結層有 4,096 個

245
00:15:30,230 --> 00:15:36,080
單元，然後用 softmax 輸出一千個類別

246
00:15:36,080 --> 00:15:39,875
順道提一下， VGG-16 的 16

247
00:15:39,875 --> 00:15:45,080
指的是這裡有 16 層裡有權重

248
00:15:45,080 --> 00:15:47,470
這是相當大的網路

249
00:15:47,470 --> 00:15:52,415
這個網路全部有 一億三千八百萬個參數

250
00:15:52,415 --> 00:15:55,615
而即使在今天也是很大的網路

251
00:15:55,615 --> 00:16:00,673
但 VGG-16 的簡單架構讓它很吸引人

252
00:16:00,673 --> 00:16:03,935
您可以看出來它的架構很一致

253
00:16:03,935 --> 00:16:07,130
一些卷積層接著一個池層

254
00:16:07,130 --> 00:16:09,590
來降低高度跟寬度

255
00:16:09,590 --> 00:16:13,396
池層用來降低高度跟寬度

256
00:16:13,396 --> 00:16:15,570
您看到一些這種型態

257
00:16:15,570 --> 00:16:20,260
同時，如果您看卷積層的過濾器個數

258
00:16:20,260 --> 00:16:28,675
這裡是64個過濾器，然後加倍到 128，
加倍到 256，加倍到 512

259
00:16:28,675 --> 00:16:33,160
而我猜作者想說 512 已經足夠大，沒有再加倍

260
00:16:33,160 --> 00:16:36,410
但這樣大約每次加倍

261
00:16:36,410 --> 00:16:39,915
或者說每次卷積層加倍的方式

262
00:16:39,915 --> 00:16:45,040
在設計這個網路架構時
是另一個簡單的規則

263
00:16:45,040 --> 00:16:48,230
所以我想這種相對一致

264
00:16:48,230 --> 00:16:52,460
的架構對於研究人員很具有吸引力

265
00:16:52,460 --> 00:16:54,680
最主要的缺點是它

266
00:16:54,680 --> 00:16:58,910
是相當大的網路，如果說您需要訓練這麼多的參數

267
00:16:58,910 --> 00:17:00,995
而如果您讀論文的話

268
00:17:00,995 --> 00:17:04,700
有時候您會見到人們談 VGG-19

269
00:17:04,700 --> 00:17:08,600
比這個網路還要大

270
00:17:08,600 --> 00:17:11,780
您可以在論文的細節看到在

271
00:17:11,780 --> 00:17:16,595
底端被 Karen Simonyan 跟 Andrew Zisserman 引用

272
00:17:16,595 --> 00:17:20,875
但因為 VGG-16 幾乎跟 VGG-19 一樣好

273
00:17:20,875 --> 00:17:23,570
很多人會使用 VGG-16

274
00:17:23,570 --> 00:17:26,090
我最喜歡的一件事是

275
00:17:26,090 --> 00:17:28,540
這種模式

276
00:17:28,540 --> 00:17:31,100
當您網路越深，高度跟寬度越低

277
00:17:31,100 --> 00:17:33,540
它每次降低一半在

278
00:17:33,540 --> 00:17:36,890
池層，而通道的數目增加

279
00:17:36,890 --> 00:17:42,855
這裡幾乎是一倍的增加
每次您用一組新的卷積層

280
00:17:42,855 --> 00:17:49,155
所以很系統化地讓這個比率降低，同時讓這個增加

281
00:17:49,155 --> 00:17:54,410
我想這份論文從這個觀點看很吸引人

282
00:17:54,410 --> 00:17:57,845
所以這就是經典的三個架構

283
00:17:57,845 --> 00:18:00,931
如果要的話，您可以讀這一下這些論文

284
00:18:00,931 --> 00:18:05,270
我建議從  AlexNet 開始，然後是  VGG net 論文

285
00:18:05,270 --> 00:18:07,460
然後 LeNet 論文有點難讀

286
00:18:07,460 --> 00:18:09,984
但是是只要您讀過，會是相當經典

287
00:18:09,984 --> 00:18:14,725
接下來，超越這些經典網路，看一些更進階的

288
00:18:14,725 --> 00:18:18,040
更強大的神經網路架構，我們繼續前進