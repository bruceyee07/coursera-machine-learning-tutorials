前回の動画では、 Inception ネットワークの 全ての基本構成要素を見てきた このビデオでは どのように これらの構成要素を一緒にして Inception ネットワークを作るか 理解しよう Inception モジュールは 前の層からの 活性 もしくは 出力を 入力として取る 議論のため 28 x 28 x 192 としよう 前のビデオと同じにね ここで扱う例は 1 x 1 層 に引き続き 5 x 5 層 だ 1 x 1 は 16チャンネルとしよう 5 x 5 は 28 x 28 x 32 チャンネルを出力することにしよう これは 前のビデオのスライドでやった例だ それから 3 x 3 の畳み込みを同じようにここでやり この 3 x 3 は 28 x 28 x 128 を出力する それから 1 x 1 畳み込みも 入れたいかもしれない 1 x 1 畳み込みは 別の 1 x 1 に続ける必要はない だから １ステップだけで 28 x 28 x 64 を出力させよう そして最後は プーリング層だ ここでは ちょっと変なことをやる 最後に これら全ての出力を結合するため Sameタイプのパディングを プーリングに使う よって 出力の高さと幅は 28 x 28 のままとなる そうやって これと これらの出力を結合できる でも 気を付けて欲しいのは
Sameパディングで 最大プーリングを行う時は 3 x 3 のフィルターを ストライド１で使うことだ ここの出力は 28 x 28 x 192 これは 同じチャンネル数 ここの入力と同じ深さを持つ ここには たくさんのチャンネルがあるようだ そこで もう一層 1 x 1 畳み込み層を追加して 1 x 1 畳み込みのビデオで見たように チャンネル数を減らす そうしたら 28 x 28 x 32 になる ここでやった 32個のフィルターを使い 1 x 1 x 192 次元にかけた だから 出力次元が 縮小した 32 のチャンネル数となった プーリング層で終わりにせずに 全てのチャンネルが 最終出力に取り出された そして 最後に これらのブロック全てを取り チャンネル結合する 結合するだけだ この 64 + 128 + 32 + 32
これを足し合わせて 28 x 28 x 256 次元の出力になる チャンネル結合は 前のビデオで見たように ブロックを結合することだ これが Inception モジュール１個だ
Inception ネットワークでは 多かれ少なかれ これらのモジュールを沢山まとめて使う これが Szegedy らの論文にある Inception ネットワークの絵だ これには 沢山の繰り返しブロックがあることに気付くだろう この絵は 本当に複雑に見えるかもしれない しかし ブロックの1つを見れば そのブロックは基本的に 前のスライドで見た Inception モジュールだ 細部までは議論しないが
これは 別の Inception ブロックで これが 別の Inception ブロックで そして なにか追加の最大プーリングがあり 次元数を変更する 高さと幅を これも 別の Inception ブロック ここに 別の最大プーリングがあって 高さと幅を変える 基本的には 別の Inception ブロックだ でも Inception ネットワークは 今学んだ これらのブロックが 沢山あるだけだ ネットワークの異なる場所に繰り返して 前のスライドで Inception ブロックを理解したらなら Inception ネットワークも理解するだろう オリジナルの研究論文を読めば Inception ネットワークには もつ1つだけ詳細があるのが分かる それは 今追加した これら追加の分岐だ これらは 何をするのか？ ネットワークの最後の数層は 全結合層だ 続けて ソフトマックス層で予測を出す これらの分岐では いくつかの隠れ層から 予測を試みる これは 実際はソフトマックス出力だ これも同様 そして この分岐では また 隠れ層を 全結合層のような層を数個持つ それから ソフトマックスで 出力ラベルが何になるか予測する これは もう一つの細部に過ぎない Inception ネットワークの しかし こうすることは 特徴の計算を助けることになる 隠れ層に於いても 中間層に於いてもね これらは 画像の出力クラスを予測するのに悪くない働きをする これは Inceptionネットワークに対し 正則化の効果があると考えられており このネットワークが過学習するのを防ぐ ところで この特別の Inceptionネットワークは Googleの人たちによって開発された 彼らは これを GoogLeNet と呼んだ
こう綴るんだけど LeNet ネットワークのオマージュになっている LeNet は 前のビデオで学んだよね これは とても素晴らしいことだと思うんだ
ディープラーニング コミュニティが とても 協力し合っているのは そして このような お互いの仕事に対する 強く健全な尊敬の念が ディープラーニング コミュニティにはある 最後に １つ変なことを Inception ネットワークという名前は どこから来たのか？ Inception 論文では 実は この意味は ”We need to go deeper” だと述べている そして このURLが Inception論文で実際に触れているものだ この画像のリンクだ もし The Inception というタイトルの映画を見たことが有るなら 多分 この意味が分かるだろう 論文の著者たちは 実際 このリンクを次の動機を持つものとして引用している それは より深いニューラルネットワークが必要という動機だ だから Inception構造を思いついたと 研究者が インターネット文化の類を 引用欄に引用するのは そうあることでは ないだろう でも この場合は 非常にうまく行っていると思う じゃあ 纏めよう
Inceptionモジュールを理解したなら Inception ネットワークも理解するだろう それは ネットワークを通じて 何度も繰り返される 巨大なInceptionモジュールだ オリジナルのInceptionモジュールの開発では 著者や他の人たちが 他のバージョンも思い付いている 他の 新しい Inceptionアルゴリズムのバージョンの論文もある そして 時には これらの後発のバージョンを見ることもあるだろう この版と同様に Inceptino V2, Inception V3, Inception V4 を Inception にはバージョンがある これは ResNet のスキップコネクションのアイデアを組み合わせたもので よりうまく 動く場合がある でも これら全ての変種は 今学んだ基本アイデアの上に成り立っている Inceptionモジュールが初めに来て それらを たくさん積み重ねる それから これらのビデオで あなたは 読むことができ そして 理解できるはずだ
Inception論文や 後発の変種についての論文も 以上だ とても多くの特別なニューラルネットワーク構造を見てきたね 次のビデオでは より実践的なアドバイスをしておきたい 実際に どのようにして
これらのアルゴリズムを使って 自分のコンピューター ビジョン システムを 作るか 次のビデオに進みましょう