컨텐츠 아키텍처 설계에 있어서, 정말 도움되는 방안은 1 x 1 컨볼루션을 사용하는 것입니다. 이제, 궁금하실 텐데요, 1 x 1 컨볼루션은 무엇일까요? 그냥 숫자를 곱하는 거 아닐까요? 재미있어 보이는데요, 사실 그렇진 않은 것 같죠. 한 번 보시죠. 한번 자세히 살펴볼까요. 1 x 1 필터가 있습니다. 숫자 2가 여기 들어가있습니다. 그리고 6 x 6 이미지, 즉, 6 x 6 x 1 이미지를 1 x 1 x 1 필터와 컨벌브하면, 이미지를 취해서 여기에 2를 곱하면 됩니다. 따라서 1, 2, 3 은 2, 4, 6 이렇게 되겠죠. 따라서, 1 x 1필터의 컨볼루션은 특별히 유용해 보이지는 않습니다. 그냥 어떤 숫자로 곱하기를 하는것 뿐이죠. 하지만 이건 6 x 6 x1 채널 이미지의 경우입니다. 6 x 6 에 32 대신 1을 곱하면 1 x 1 필터를 가진 컨볼루션이 훨씬 의미 있는 일을 할 수 있게 됩니다. 특히 1 x 1 컨볼루션이 수행 할 작업은 여기에 있는 36 가지 위치를 각각 살펴보고 왼쪽의 32 개 숫자와 필터의 32 개 숫자 사이에 요소 간 곱셈을 하는 것 입니다. 그리고 나서 여기에 ReLU 비선형성을 적용하십시오. 36 가지 위치 중 하나, 즉, 아마도 이 볼륨을 통과하는 하나의 조각을 살펴보기 위해서는 이 36개 숫자들을 취한 후, 이렇게 이 볼륨을 통과하는 조각 하나를 곱해줍니다. 그러면 여러분은 마지막에 이런 아웃풋 중의 하나로 표시되는 실제 숫자를 얻게 됩니다. 사실, 1 x 1 x 32 필터 안에 들어갈 32개 숫자에 대해 생각하는 한 가지 방법은 이는 마치 인풋을 받아들이는 뉴런을 여러분이 가지고 있는 것과 같은 건데요, 32 개 숫자, 같은 위치에서 높이를 지닌 한 조각 안에 있는 32개의 숫자들 각각을 이 32개의 다른 채널과 곱하고, 즉, 32 가중치로 곱하는 것입니다. 그리고 나서 ReLU 비선형성을 적용한 후 대응되는 것을 이쪽에 아웃풋하면 되는 거죠. 더 일반적으로, 필터가 하나가 아니라 필터가 여러 개인 경우 하나의 유닛이 아닌, 여러 개의 유닛을 가진 것과 같습니다. 이는 하나의 조각에 모든 숫자를 인풋한 다음 6 x 6 x필터의 개수 의 아웃풋으로 이것들을 만들어내면 되는 것이죠. 따라서 1 x 1 컨볼루션에 대해 생각해볼 수 있는 한가지 방법은 기본적으로 완전 연결 신경망을 사용하여 62 개의 서로 다른 위치에 적용하는 것입니다 완전 연결 신경망은 무엇을 할까요? 인풋이 32개고 아웃풋은 필터의 개수이죠 따라서 수식으로 보면 이게 다음 레이어라면 nc(l + 1) 이 됩니다. 각각의 36개의 위치, 즉 각각 6 x 6 위치에서 이렇게 함으로서 6 x 6 x 필터의 개수 인 아웃풋을 만들어낼 수 있습니다. 그리고 이것은 여러분의 인풋 볼륨에 대해 아주 단순한 계산을 수행할 수 있습니다. 이런 아이디어를 바로 1 x 1 컨볼루션 이라고 부릅니다. 어떤 때에는 Min Lin, Qiang Chen, and Schuicheng Yan 이라는 저자들이 쓴 논문에 설명된 바와 같이 ‘Network in Network’라고 부르기도 합니다. 논문에 나오는 아키텍쳐의 세부적인 사항들이 아직 널리 사용되고 있지는 않지만 1 x 1 컨볼루션이라는 방안이나 이 Network in Network 방안은 매우 영향력이 있어서, 많은 다른 신경망 아키텍쳐에 영향을 미치고 있습니다. 다음 강의에서 보게 될 인셉션 네트워크 또한 포함해서 영향을 주는 것이죠. 1 x 1 컨볼루션이 유용하게 쓰이는 예시를 하나 들어보자면, 여기 하나가 있습니다. 28 x 28 x 192 볼륨이라고 가정해보죠. 높이와 넓이를 줄이고 싶다면 pooling 레이어를 사용하면 됩니다. 우린 이걸 하는 방법을 알고 있죠. 많은 채널 중의 하나가 과하게 커서 이걸 줄이고 싶다면, 28 x 28 x 32 차원 볼륨으로 어떻게 줄일 수 있을까요? 1 x 1인 32 개의 필터를 사용하는 것입니다. 기술적으로 각각의 필터는 1 x 1 x 192입니다. 필터안에 있는 채널의 수는 여러분의 인풋 볼륨에 있는 채널의 숫자와 매치가 되야 하기 때문입니다. 하지만 32개의 필터를 사용하면, 이 과정의 아웃풋이 28 x 28 x 32볼륨이 되는 겁니다. 따라서 이것이 nc 또한 줄일 수 있는 방법입니다. 반면 pooling 레이어는 nH 와 nW 를 줄이려고 사용했었죠. 이것은 이 볼륨의 높이(H)와 넓이(W)를 가리키는 것입니다. 1 x 1 컨볼루션이 어떻게 채널의 수를 줄이는 것을 가능하게 해주는 지는 다음 강의에서 볼 것입니다. 따라서, 네트워크에서는 연산은 좀 아껴두기로 하죠. 하지만 물론, 채널 수를 192로 유지하고자 한다면, 그것도 괜찮습니다. 그리고 1 x 1 컨볼루션의 효과는 비선형성을 추가하는 것입니다. 이렇게 하면 28 x 28 x 192 인풋을 주고, 28 x 28 x 192 를 아웃풋하는 또 다른 레이어를 추가하여 네트워크의 더 복잡한 기능을 배울 수 있게 해줍니다. 자, 이게 어떻게 1 x 1 컨볼루션 레이어가 실제로 아주 단순하지 않은 작업을 수행하는 방법입니다. 신경망에 비선형성을 추가하여 원하는 경우 볼륨의 채널 수를 줄이거나 그대로 유지하거나 아니면 늘리는 것도 가능합니다. 다음으로, 이것이 사실상 초기 네트워크 구축에 매우 유용하다는 것을 알 수 있습니다. 다음 강의에서는 그걸 보도록 하죠. 자, 이제까지 1 x 1 컨볼루션 연산이 어떻게 실제로 그리 단순하지 않은 연산을 수행하는지 살펴보았습니다. 이는 여러분의 볼륨에서 채널의 수를 줄일 수도 있고 같게 유지하거나 심지어 늘릴 수 있습니다. 다음 강의에서는, 다음 비디오에서는 이것이 인셉션 네트워크를 구축하기 위해 사용되는 것을 볼 수 있습니다. 다음 강의로 가시죠.