1
00:00:00,380 --> 00:00:01,980
嗨,歡迎回來.

2
00:00:01,980 --> 00:00:06,560
本周我們要做的第一件事
是給你看一些案例研究

3
00:00:06,560 --> 00:00:08,570
有關於卷積神經網路

4
00:00:08,570 --> 00:00:10,330
那麼, 為什麼要看案例研究呢？

5
00:00:10,330 --> 00:00:13,480
上周, 我們瞭解了基本的概念, 如卷積

6
00:00:13,480 --> 00:00:17,220
層, 池層和全連接層的卷積網路。

7
00:00:17,220 --> 00:00:21,320
事實證明, 過去幾年的電腦視覺研究一直在

8
00:00:21,320 --> 00:00:23,910
如何把這些建構基石放在一起

9
00:00:23,910 --> 00:00:26,770
來形成有效的卷積神經網路。

10
00:00:26,770 --> 00:00:27,990
其中, 讓你自己獲得直覺, 最好的方式之一

11
00:00:27,990 --> 00:00:32,220
就是看看這些例子

12
00:00:32,220 --> 00:00:36,753
我想, 正如你們中的許多人
可能已經通過閱讀其他人寫的程式, 
而學會了如何寫程式

13
00:00:36,753 --> 00:00:41,210
我認為,
 一個好的方法來理解如何建構卷積網路

14
00:00:41,210 --> 00:00:46,140
就是閱讀, 或是透過看到其他有效的卷積網路的例子

15
00:00:46,140 --> 00:00:50,270
我們發現, 
能在一個電腦視覺任務上良好運行的網路神經結構

16
00:00:50,270 --> 00:00:54,740
通常在其他任務上也能良好運行

17
00:00:54,740 --> 00:00:55,750
例如像是你的任務

18
00:00:55,750 --> 00:00:59,530
所以如果有人在訓練神經網路

19
00:00:59,530 --> 00:01:03,012
它非常善於識別貓狗和人

20
00:01:03,012 --> 00:01:06,792
但是你有一個不同的電腦視覺任務, 
像是你試圖做自動

21
00:01:06,792 --> 00:01:07,900
無人駕駛車。

22
00:01:07,900 --> 00:01:11,867
你能夠應用其他人的神經網路結構

23
00:01:11,867 --> 00:01:14,070
然後應用至你的問題上。

24
00:01:14,070 --> 00:01:18,130
在接下來的影片中
你將閱讀到

25
00:01:18,130 --> 00:01:21,630
戲劇電腦視覺領域相關的研究論文

26
00:01:21,630 --> 00:01:24,515
我希望你也能感到滿意。

27
00:01:24,515 --> 00:01:28,545
作為一堂課, 
你不必閱讀這些論文, 
但我希望你會滿足於

28
00:01:28,545 --> 00:01:32,141
能夠閱讀一些影響重大的電腦視覺研究論文
而且

29
00:01:32,141 --> 00:01:34,191
發現自己能理解他們。

30
00:01:34,191 --> 00:01:36,634
所以，我們開始吧

31
00:01:36,634 --> 00:01:40,711
我們將在接下來的幾個影片中

32
00:01:40,711 --> 00:01:44,256
向你展示一些經典的神經網路。

33
00:01:44,256 --> 00:01:48,663
LeNEt-5 網路, 源於1980年代,

34
00:01:48,663 --> 00:01:52,108
AlexNet 經常被引用
還有 VGG 網路

35
00:01:52,108 --> 00:01:56,050
這些都是相當有效的神經網路的例子

36
00:01:56,050 --> 00:02:00,550
這些網路中的一些想法
為現代電腦視覺奠定了基礎

37
00:02:00,550 --> 00:02:05,640
在這些論文中看到的想法可能對你自己有幫助

38
00:02:06,820 --> 00:02:10,340
這些想法, 也可能對你的工作

39
00:02:10,340 --> 00:02:12,520
是有幫助的

40
00:02:12,520 --> 00:02:17,960
然後, 我想和你展示深度殘差網路(ResNet)或卷積殘差網路(conv residual network )

41
00:02:17,960 --> 00:02:21,190
你可能聽說過神經網路的層數越來越深了。

42
00:02:21,190 --> 00:02:23,698
深度殘差網路訓練了一個非常

43
00:02:23,698 --> 00:02:28,439
非常深的152層神經網路, 有一些非常有趣的技巧,

44
00:02:28,439 --> 00:02:32,070
以及有趣的想法如何有效地做到這一點。

45
00:02:32,070 --> 00:02:38,720
最後, 您還可以看到一個「(Inception neural network)」的案例研究

46
00:02:38,720 --> 00:02:43,436
看完這些神經網路後, 
我認為你對如何建立卷積神經網路

47
00:02:43,436 --> 00:02:46,745
有更好的理解

48
00:02:46,745 --> 00:02:49,947
即使你自己也不從事電腦視覺的工作

49
00:02:49,947 --> 00:02:53,295
我想你會從這些例子中找到了很多想法

50
00:02:53,295 --> 00:02:57,665
例如ResNet， Inception network, 
這些想法多是具啟發性的

51
00:02:57,665 --> 00:03:00,105
使它們也能應用於其他學科。

52
00:03:00,105 --> 00:03:03,715
即使你最終沒有建立自己的電腦視覺應用程式, 我

53
00:03:03,715 --> 00:03:06,925
認為你會發現這些想法非常有趣
, 它們對你的工作有幫助