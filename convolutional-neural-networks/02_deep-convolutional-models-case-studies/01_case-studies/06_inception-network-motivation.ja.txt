ConvNet の層を設計する場合 選ばなくてはならない 1 x 3 フィルターにしたいか？ それとも 3 x 3 か？  5 x 5 か？ プーリング層を入れたいか？ Inception ネットワークは こう言っている 全部やれば？ これは ネットワーク構造をより複雑にする だが 著しくうまく動く これが実際にどう作用するのかを見てみましょう。 例として 入力に 28 x 28 x 192 次元ボリュームがあるとする Inceptionネットワーク Inception層が 言っているのは 畳み込み層に 欲しいサイズを選ぶ代わりに さらに 畳み込み層なのか プーリング層なのか ということまで含めて 全てやってしまおう ということだ
もし 1 x 1 畳み込みを使えたら 28 x 28 x いくつか の出力になる 28 x 28 x 64 としよう ここに ボリュームを得た さらに 3 x 3 をやれば 28 x 28 x 128 を得る それから この２番目のボリュームを 最初のボリュームに積み重ねる 次元数を合わせるために これを Same畳み込みとする よって 出力の次元は 28 x 28 のままだ 高さと幅においては 入力の次元と同じだ ただし 28 x 28 x この例では128 多分 あなたは 私が賭けを分散したいと 思っているでしょ もしかしたら 5 x 5 フィルターの方がいいかも それもやってみよう そうしたら 28 x 28 x 32 の出力になった それから 次元数を保つために Same畳み込みを また使う また もしかしたら 畳み込み層は 欲しくないかもしれない プーリングを入れよう
もう１つの出力を得るので 同じように積み重ねる このプーリングは 28 x 28 x 32 を出力する さて 全ての次元数を合わせるために 最大プーリングにパディングが必要になる これは 通常の正式なプーリングではない なぜなら 28 x 28 の入力を得て 出力を 他の全ての次元を 28 x 28 に合わせるから よって Sameパディングで 且つ ストライド１のプーリングを使う必要がある この詳細は 今は ちょっと変に思えるかもしれない でも このまま続けよう 後で これら全てを 動かすよ このような Inceptionモジュールでは あるボリュームを入力して ある出力をする この例では これらの数を全て足せば 32 + 32 + 128 + 64 これは 256 だ つまり 1つの Inception モジュールは 28 x 28 x 129 の入力を 28 x 28 x 256 の出力にする そして これが Inception モジュールの心臓部で これは Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke そして Andrew Rabinovich の功績だ 基本的なアイデアは これらのフィルターサイズの1つや プーリング を選んで それに委ねるのではなく 全てを行い 全ての出力を結合する そして ネットワークに学ばせる
どんなパラメータ値がいいのか どんなフィルターサイズの組み合わせがいいのか を ここで ひとつ問題がある ここで説明した Inception層のだ それは 計算コストだ 次のスライドでは ここにある 5 x 5 フィルターの計算コストが どうなるのか 明らかにしよう 前のスライドの 5 x 5 の塊りに注目しよう 入力は 28 x 28 x 192 ブロックだ 5 x 5  32フィルターのSame畳み込みで 28 x 28 x 32 を出力する 前のスライドでは これは 紫の薄い切れ端になっていた ここでは より通常の形の 青いブロックで描く それじゃ この 28 x 28 x 32 の計算コストを見てみよう 出力が 32チャンネルなので 32フィルターだ 各フィルターは 5 x 5 x 192 になる 出力サイズは 28 x 28 x 32 なので 28 x 28 x 32 の数を計算する必要がある ここのそれぞれに対し この多くの掛け算を行う必要がある いいかい？ 5 x 5 x 192 よって 掛け算の総数は 出力値のそれぞれに必要な計算数 掛ける 出力数だ そして これらの数を全て掛ければ １億２千万だ 現在のコンピューターなら １億２千万の掛け算を行うことはできるが それでも かなり高くつく 次のスライドでは 1 x 1 畳み込みを使い 前のビデオで見たよね 計算コストを 大体10倍くらい減らすことができる １億２千万回の掛け算を 約10分の１にする 120(M)という数値を覚えておいて 次のスライドで見るのと比較するから １億２千万ね 代わりの構造はこうだ この 28 x 28 x 192 入力と 28 x 28 x 32 出力の 代わりはこう 入力ボリュームがあり 1 x 1 畳み込みを使い 192チャンネルを 16チャンネルに減らす それから このとても小さくしたボリュームに 5 x 5 畳み込みを掛けて 最終出力を得る 入力と出力の次元数は 同じままだ 入力は 28 x 28 x 192 で 出力は 28 x 28 x 32 だ 前のスライドと同じ でも 今やったのは 左にある 非常に大きなボリュームを この とても小さい中間のボリュームに縮めた それは 192チャンネルではなく 16しか持っていない 時々 これは ボトルネック層と呼ばれる ボトルネックとは 通常 何か一番小さい部分のことだからね こんな風なガラス瓶があるだろう ここには コルクが来るよね そして ボトルネックとは この瓶の一番小さい部分だ 同様に ボトルネック層とは このネットワークの一番小さい部分だ 大きさを再び増やす前に 表現を縮小した それじゃ ここに含まれる計算コストを見てみよう 1 x 1 畳み込みを適用するには 16フィルターがあるから 各フィルターは 1 x 1 x 192 となり この 192 は この 192 と合う 28 x 28 x 16 ボリュームの 計算コストは これだけの出力が必要で そのそれぞれには 192回の掛け算が要る 1 x 1 x 192 って書いてもいいけど いいね？ それは これだしね
そして 掛け算すると これは 240万だ 約240万だ じゃ ２番目は？ これは 最初の畳み込み層のコストだ ２番目の畳み込み層のコストは これだけ多くの出力があるので 28 x 28 x 32 の出力がある この出力の各々に 5 x 5 x 16 次元のフィルターを適用しなければならない よって x 5 x 5 x 16 そして 掛け算すると 10.0
(訳注: 単位をMとして話しているので 10.0M = １千万) よって 計算数の合計は これらを合わせて 1,240万 だ じゃ 前のスライドの値と比べよう １億２千万回の掛け算の計算コストが 約10分の１に減って 1,240万回の掛け算になった 必要な足し算の数は 必要な掛け算の数に比べて 非常に小さい だから 掛け算の数だけ数えた 纏めると ニューラルネットワークの層を作る場合 決める必要は無い 1 x 1 か 3 x 3 か 5 x 5 か それとも プーリング層か Inception モジュールが それらを全部やらせてくれる 結果を結合してくれて それから 計算コストの問題に対処した ここで見たのは どのように 1 x 1 畳み込み層を使うかだ このボトルネック層を作成して 計算コストを著しく減らすことができる もしかしたら 疑問に思っているかもしれない 表現のサイズを そんなに劇的に縮めて ニューラルネットワークの性能を損ねないのか？と この理由でボトルネック層を実装する限りにおいては 表現のサイズを極端に減らすことができ 性能を損ねないことが 分かっている そして 計算を節約できる これらが Inception モジュールのキーとなるアイデアだ 次のビデオでは これらを 合わせて フル Inception ネットワークがどんなだか 見てみよう