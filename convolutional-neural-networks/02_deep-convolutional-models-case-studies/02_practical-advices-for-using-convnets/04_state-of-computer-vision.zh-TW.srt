1
00:00:00,000 --> 00:00:01,650
深度學習已經成功地

2
00:00:01,650 --> 00:00:03,850
應用在電腦視覺，自然語言處理

3
00:00:03,850 --> 00:00:05,990
語音辨識，線上廣告

4
00:00:05,990 --> 00:00:08,550
物流，很多很多問題

5
00:00:08,550 --> 00:00:10,470
有一些東西是很獨特的在

6
00:00:10,470 --> 00:00:12,990
深度學習的電腦視覺應用上

7
00:00:12,990 --> 00:00:15,570
有關電腦視覺的狀況

8
00:00:15,570 --> 00:00:20,160
這段影片中，我將跟您分享一些有關深度學習的

9
00:00:20,160 --> 00:00:25,335
電腦視覺的觀察，我希望會幫助您瀏覽一些論文

10
00:00:25,335 --> 00:00:27,270
跟那裡的一些觀念

11
00:00:27,270 --> 00:00:31,880
跟您如何建置您自己的電腦視覺系統

12
00:00:31,880 --> 00:00:38,180
您可以想像大部分的機器學習問題落在

13
00:00:38,180 --> 00:00:40,730
這個光譜內，介於相對少的資料

14
00:00:40,730 --> 00:00:45,585
到您有很多資料

15
00:00:45,585 --> 00:00:50,840
舉例來說，我想今日我們有相當多量的

16
00:00:50,840 --> 00:00:57,230
語音辨識資料，相對於這個問題的複雜度而言、

17
00:00:57,230 --> 00:00:59,540
即使有

18
00:00:59,540 --> 00:01:05,315
合理大小的資料集在於影像辨識或者影像分類

19
00:01:05,315 --> 00:01:07,460
因為影像辨識

20
00:01:07,460 --> 00:01:11,222
就是一個複雜的問題，看所有的像素來找出它是什麼

21
00:01:11,222 --> 00:01:16,250
似乎線上資料集相當大，超過一百萬個影像

22
00:01:16,250 --> 00:01:20,098
感覺似乎我們要更多的資料

23
00:01:20,098 --> 00:01:28,006
而有一些問題像是物件偵測
我們擁有很少的資料

24
00:01:28,006 --> 00:01:31,340
提醒一下，影像辨識的問題是

25
00:01:31,340 --> 00:01:34,912
看這一張照片然後告訴您是不是一隻貓

26
00:01:34,912 --> 00:01:39,590
而物件偵測是看著照片，實際上您要放一個

27
00:01:39,590 --> 00:01:41,948
邊緣框告訴您

28
00:01:41,948 --> 00:01:44,935
照片中的物件在哪裡

29
00:01:44,935 --> 00:01:46,760
而因為要做

30
00:01:46,760 --> 00:01:52,470
邊緣框的成本也就是要標籤物件跟邊緣框很貴

31
00:01:52,470 --> 00:01:57,905
所以我們往往在物件偵測的資料
比影像辨識的資料少

32
00:01:57,905 --> 00:02:02,083
而我們會在下週討論物件偵測

33
00:02:02,083 --> 00:02:06,605
所以如果您看一下機器學習問題的光譜

34
00:02:06,605 --> 00:02:12,095
您看到平均而言，有很多的資料的部分，發現人們

35
00:02:12,095 --> 00:02:18,300
會使用較簡單的演算法，跟比較少的手工工程

36
00:02:18,300 --> 00:02:23,480
因此，比較不需要小心地設計問題的特徵

37
00:02:23,480 --> 00:02:25,910
但取而代之，您可以使用大的神經網路

38
00:02:25,910 --> 00:02:28,507
即使簡單的架構，使用神經網路

39
00:02:28,507 --> 00:02:32,415
就會學習我們要的學習，因為我們有很多的資料

40
00:02:32,415 --> 00:02:36,560
而相對的，當我們沒有那麼多資料，

41
00:02:36,560 --> 00:02:41,713
平均而言，人們會從事更多的手工工程

42
00:02:41,713 --> 00:02:46,660
而如果您不客氣說的話，
您可以說用了很多駭客手法

43
00:02:46,660 --> 00:02:49,880
但我想當您沒有很多資料，那

44
00:02:49,880 --> 00:02:54,809
手工工程實際上是最佳的方式
來獲得最好的績效

45
00:02:54,809 --> 00:02:59,435
所以，當我看一個機器學習的應用時

46
00:02:59,435 --> 00:03:04,595
我想通常我們有的學習演算法
有兩種知識來源

47
00:03:04,595 --> 00:03:07,430
一個知識來源是標籤的資料

48
00:03:07,430 --> 00:03:11,525
實際上的 (x,y) 讓您用來做監督式學習

49
00:03:11,525 --> 00:03:14,652
而第二種知識來源是手工工程

50
00:03:14,652 --> 00:03:17,045
而有很多種方式來做手工工程系統

51
00:03:17,045 --> 00:03:20,435
可以小心的手工設計這些特徵

52
00:03:20,435 --> 00:03:22,281
小心地手工設計

53
00:03:22,281 --> 00:03:26,485
網路架構，或許系統上其他的元件

54
00:03:26,485 --> 00:03:28,880
所以當您沒有太多的標籤資料

55
00:03:28,880 --> 00:03:32,270
您就只能多依賴手工工程

56
00:03:32,270 --> 00:03:38,165
因此，我想電腦視覺試著學習相當複雜的函數

57
00:03:38,165 --> 00:03:42,815
而通常我們覺得我們
沒有足夠的資料來做電腦視覺

58
00:03:42,815 --> 00:03:45,362
即使資料集越來越大

59
00:03:45,362 --> 00:03:48,845
通常我們就是沒有足夠所需的資料

60
00:03:48,845 --> 00:03:52,100
而這是為什麼電腦視覺歷史上

61
00:03:52,100 --> 00:03:57,178
即使在今天都非常依賴手工工程

62
00:03:57,178 --> 00:04:00,425
我想這也是為什麼電腦視覺

63
00:04:00,425 --> 00:04:05,040
開發一些相當複雜的網路架構

64
00:04:05,040 --> 00:04:08,720
正是因為缺少很多資料

65
00:04:08,720 --> 00:04:13,400
為獲取更佳的績效，要花比較多的時間在架構上

66
00:04:13,400 --> 00:04:17,130
或者在網路架構上鬼混

67
00:04:17,130 --> 00:04:19,340
如果您認為我在

68
00:04:19,340 --> 00:04:23,525
貶低手工工程，這不是我的原意

69
00:04:23,525 --> 00:04:27,830
當您沒有足夠的資料，手工工程是一個很難

70
00:04:27,830 --> 00:04:32,135
很有技術，需要很多洞察力的

71
00:04:32,135 --> 00:04:36,875
而有人有此洞見在手工工程的話，
會獲得較好的績效

72
00:04:36,875 --> 00:04:39,590
會在這個專案上有很大的貢獻

73
00:04:39,590 --> 00:04:43,085
做手工工程，當您沒有足夠的資料時

74
00:04:43,085 --> 00:04:47,150
如果您有很多資料的話，我就不會花時間在做手工工程

75
00:04:47,150 --> 00:04:52,588
我會花時間來建立學習系統

76
00:04:52,588 --> 00:04:57,610
但我想從歷史來看，電腦視覺領域使用相當少的資料集

77
00:04:57,610 --> 00:04:59,965
所以傳統的電腦視覺的論文

78
00:04:59,965 --> 00:05:02,700
相當依賴很多的手工工程

79
00:05:02,700 --> 00:05:06,640
即使在幾年前，資料的數量 

80
00:05:06,640 --> 00:05:10,540
在電腦視覺的任務中急遽的增加

81
00:05:10,540 --> 00:05:12,580
我想已經造成

82
00:05:12,580 --> 00:05:17,185
手工工程數量明顯減少很多

83
00:05:17,185 --> 00:05:21,480
但還是有很多的手工工程的網路架構在電腦視覺

84
00:05:21,480 --> 00:05:26,890
這也是為什麼您會見到
很複雜的超參數選擇在電腦視覺上

85
00:05:26,890 --> 00:05:31,294
比起其他的領域更複雜

86
00:05:31,294 --> 00:05:33,550
實際上，因為您通常有

87
00:05:33,550 --> 00:05:38,050
較少的物件偵測資料集
比起影像辨識資料集而言

88
00:05:38,050 --> 00:05:43,360
當我們下個禮拜談到物件偵測這個任務

89
00:05:43,360 --> 00:05:48,280
您會看到的演算法

90
00:05:48,280 --> 00:05:54,040
變得相當複雜，使用甚至於更特定的元件

91
00:05:54,040 --> 00:06:00,100
幸運地，有一件事對於少資料有很大的幫助，那就是轉移學習

92
00:06:00,100 --> 00:06:10,395
我會說從前面的投影片中的例子， Tigger,

93
00:06:10,395 --> 00:06:13,850
Misty 或兩者皆不是的偵測問題

94
00:06:13,850 --> 00:06:18,666
您只有很少資料，而轉移學習有相當的幫助

95
00:06:18,666 --> 00:06:21,120
所以這是另一種常常使用的技術

96
00:06:21,120 --> 00:06:24,255
當您只有相對少的資料

97
00:06:24,255 --> 00:06:27,100
如果您看電腦視覺論文

98
00:06:27,100 --> 00:06:29,243
看那裡的一些觀念

99
00:06:29,243 --> 00:06:32,293
您也會見到人們很熱衷於

100
00:06:32,293 --> 00:06:34,800
他們真的做得很好在

101
00:06:34,800 --> 00:06:38,730
標準的基準資料集上，然後贏了比賽

102
00:06:38,730 --> 00:06:41,925
而對於電腦視覺研究者而言，如果您在

103
00:06:41,925 --> 00:06:45,395
基準資料做得很棒的話，很容易讓這些論文發表

104
00:06:45,395 --> 00:06:49,155
所以有很多的注意力想
在這些基準資料上做得更好

105
00:06:49,155 --> 00:06:51,615
正面來說

106
00:06:51,615 --> 00:06:56,125
它幫助了整個社群來發現最佳的演算法

107
00:06:56,125 --> 00:07:02,475
但您也會見到一些論文，人們做的讓您在基準資料上做得很好

108
00:07:02,475 --> 00:07:04,310
但您不會真的用在

109
00:07:04,310 --> 00:07:08,665
上線的系統，
或者部署一個這樣的系統在真正的應用上

110
00:07:08,665 --> 00:07:11,379
所以這裡有一些建議
讓您在基準資料上做得很棒

111
00:07:11,379 --> 00:07:15,960
然而這些東西我並不會真的用

112
00:07:15,960 --> 00:07:20,940
在實際服務客戶的系統上

113
00:07:20,940 --> 00:07:23,105
一種方式是總效果 (ensembling)

114
00:07:23,105 --> 00:07:24,870
這個的意思是

115
00:07:24,870 --> 00:07:27,410
在你找到你想要的神經網路之後

116
00:07:27,410 --> 00:07:33,120
獨立訓練多個神經網路並將輸出做平均

117
00:07:33,120 --> 00:07:35,610
所以，隨機初始 3, 5

118
00:07:35,610 --> 00:07:40,095
或 7 個神經網路，然後訓練這些神經網路

119
00:07:40,095 --> 00:07:41,890
然後將他們的輸出平均

120
00:07:41,890 --> 00:07:44,943
順道提一下，平均他們的輸出 y-hat 是很重要的

121
00:07:44,943 --> 00:07:47,660
不要平均他們的權重，這不可行

122
00:07:47,660 --> 00:07:50,410
看著您的假設 7 個神經網路

123
00:07:50,410 --> 00:07:53,348
有 7 個不同的預測，將他們平均

124
00:07:53,348 --> 00:07:57,725
而這會讓您或許 1% 更好，或者  2% 更好

125
00:07:57,725 --> 00:08:02,015
所以會做得好一點點
在一些基準資料上

126
00:08:02,015 --> 00:08:04,569
而這樣做會讓您做得好一點點

127
00:08:04,569 --> 00:08:11,544
或許有時候達到 1%  或者 2% 這會幫助您贏得比賽

128
00:08:11,544 --> 00:08:15,200
但因為總效果的意思是在每個影像做測試

129
00:08:15,200 --> 00:08:17,810
您或許需要跑一個影像經過

130
00:08:17,810 --> 00:08:21,965
可能 3 到 15 個不同的網路，這相當常見

131
00:08:21,965 --> 00:08:25,570
這會減低您的執行時間變成 3 到 15 倍

132
00:08:25,570 --> 00:08:26,885
有時候更長

133
00:08:26,885 --> 00:08:29,655
所以總效果是一個秘訣讓人們

134
00:08:29,655 --> 00:08:33,111
在基準上做得很好來贏得比賽

135
00:08:33,111 --> 00:08:38,275
但我想幾乎不會用在實際應用上來服務客戶

136
00:08:38,275 --> 00:08:41,400
我猜除非您有去大的計算預算，不

137
00:08:41,400 --> 00:08:44,996
擔心燒錢在每個客戶的影像上

138
00:08:44,996 --> 00:08:50,195
另一件事您在論文中見到的
真的會幫助在基準資料上

139
00:08:50,195 --> 00:08:52,690
是多重剪裁在測試時

140
00:08:52,690 --> 00:08:58,055
我的意思是您已經見過資料擴增

141
00:08:58,055 --> 00:09:04,910
而多重剪裁是一種應用資料擴增的方式
在您的測試影像上

142
00:09:04,910 --> 00:09:07,470
舉例來說，假設看到一隻貓的影像

143
00:09:07,470 --> 00:09:12,155
只是將他們複製四次，包含兩次鏡射的版本

144
00:09:12,155 --> 00:09:14,585
有一種技巧稱為 10-剪裁

145
00:09:14,585 --> 00:09:19,460
基本上是假設您拿中間的區域然後剪裁

146
00:09:19,460 --> 00:09:22,097
然後用它跑在分類器中

147
00:09:22,097 --> 00:09:24,830
然後拿左上角的剪裁，跑在分類器中

148
00:09:24,830 --> 00:09:27,145
右上角用綠色顯示

149
00:09:27,145 --> 00:09:30,980
左下角用黃色顯示

150
00:09:30,980 --> 00:09:33,162
右下角用橘色顯示

151
00:09:33,162 --> 00:09:34,950
將他們跑進分類器中

152
00:09:34,950 --> 00:09:37,060
然後在鏡射影像中做同樣的事

153
00:09:37,060 --> 00:09:38,743
是的，我會拿中間剪裁

154
00:09:38,743 --> 00:09:41,670
然後拿四個角落的剪裁

155
00:09:41,670 --> 00:09:44,165
所以，這個是中間剪裁在這裡跟這裡

156
00:09:44,165 --> 00:09:46,210
這裡有四個角落的剪裁在這裡跟這裡

157
00:09:46,210 --> 00:09:49,540
如果您將這些加總，總共會有提過的 10 個剪裁

158
00:09:49,540 --> 00:09:51,600
所以名為  10-剪裁

159
00:09:51,600 --> 00:09:54,980
所以您要做的是，您將這 10  個影像經過

160
00:09:54,980 --> 00:09:59,360
您的分類器然後將結果平均

161
00:09:59,360 --> 00:10:02,660
所以如果您有足夠的計算預算，您可以這樣做

162
00:10:02,660 --> 00:10:04,530
或許不需要到 10-剪裁這麼多

163
00:10:04,530 --> 00:10:05,900
您可以使用一些剪裁

164
00:10:05,900 --> 00:10:10,960
而這或許會給您一些好一點的績效
在真正上線的系統上

165
00:10:10,960 --> 00:10:16,190
上線的系統指的是
您部署到真正客戶手上的系統

166
00:10:16,190 --> 00:10:19,760
但這是另一種技巧用在很多在基準上

167
00:10:19,760 --> 00:10:24,110
作用得很好而不是在上線的系統上

168
00:10:24,110 --> 00:10:27,550
總效果的一個大問題是

169
00:10:27,550 --> 00:10:30,575
您需要保持所有這些不同的網路

170
00:10:30,575 --> 00:10:33,835
所以就是會佔用很多電腦記憶體

171
00:10:33,835 --> 00:10:37,600
對於多重剪裁，至少您只保留一個網路

172
00:10:37,600 --> 00:10:41,155
所以它並不會吃太多的記憶體

173
00:10:41,155 --> 00:10:46,235
但它還是會讓您的執行時間慢很多

174
00:10:46,235 --> 00:10:52,240
所以這些是您看到的技巧，
而在研究論文中也會引用的技巧

175
00:10:52,240 --> 00:10:56,940
但我自己並不會用這些方法在

176
00:10:56,940 --> 00:10:59,535
上線的系統上，即使它們在

177
00:10:59,535 --> 00:11:03,205
基準上做得很好，用來贏得比賽

178
00:11:03,205 --> 00:11:08,345
因為很多的電腦視覺問題是在小的資料區域

179
00:11:08,345 --> 00:11:12,620
其他人也做了很多的手工工程
在網路的架構方面

180
00:11:12,620 --> 00:11:17,400
而一個神經網路在一種視覺問題上作用得很好，或許令人驚訝的

181
00:11:17,400 --> 00:11:21,010
它們在另一種視覺問題上也可以作用

182
00:11:21,010 --> 00:11:25,295
所以，要建立一個實作的系統，通常您會

183
00:11:25,295 --> 00:11:29,796
開始於別人的神經網路架構

184
00:11:29,796 --> 00:11:32,810
可能的話，您可以使用開源建置

185
00:11:32,810 --> 00:11:35,770
因為開源建置或許已經找出

186
00:11:35,770 --> 00:11:39,120
所有挑剔的細節，像是學習率

187
00:11:39,120 --> 00:11:42,478
（聽不清楚） 跟其他超參數

188
00:11:42,478 --> 00:11:46,350
最後，別人或許已經花幾個星期來訓練一個模型

189
00:11:46,350 --> 00:11:51,926
在半打的 GPU 上，用了上百萬個影像

190
00:11:51,926 --> 00:11:56,565
所以使用別人預先訓練的模型，微調在您的資料集上

191
00:11:56,565 --> 00:12:00,610
您通常可以讓一個應用進展更快速

192
00:12:00,610 --> 00:12:05,048
但當然如果您有計算資源跟志趣

193
00:12:05,048 --> 00:12:09,840
不要讓我阻止您從頭開始訓練

194
00:12:09,840 --> 00:12:14,326
實際上，如果您想發明
您自己的電腦視覺演算法

195
00:12:14,326 --> 00:12:16,840
這樣做可能是必需的

196
00:12:16,840 --> 00:12:18,920
所以，這個星期到此結束

197
00:12:18,920 --> 00:12:20,960
我希望看過一些

198
00:12:20,960 --> 00:12:24,605
電腦視覺的架構，幫助您了解哪些是可行的

199
00:12:24,605 --> 00:12:28,055
在這個禮拜的練習，您實際上會學到

200
00:12:28,055 --> 00:12:32,740
另一種程式框架，使用它來建置殘差網路

201
00:12:32,740 --> 00:12:37,970
我希望您享受那個練習，我期待下週與您相見