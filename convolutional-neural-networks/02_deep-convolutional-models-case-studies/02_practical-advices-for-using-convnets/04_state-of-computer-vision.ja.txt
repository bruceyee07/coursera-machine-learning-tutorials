ディープラーニングは成功裏に適用されてきた コンピュータ ビジョンや 自然言語処理や 音声認識 オンライン広告 物流 その他多くの 問題に コンピュータビジョンに対する ディープラーニングのアプリケーションには 独自のものがいくつかあるけど このビデオでは コンピュータビジョンに対するディープラーニングについての 私の観察のいくつかを共有したい
そうすることで 文献や そこで出てきたアイデアや コンピュータ ビジョンのシステムを自分自身でどのように作るか等を より良く探索する助けにしてほしい では 殆どの機械学習問題は この分布のどこかにあると考えることができる 比較的 少ないデータがある場合と 沢山データがある場合の間だ 例えば 今日 かなり多くの音声認識のデータがある それは 問題の複雑さに対して ということだけど でも 今日 画像認識や画像分類に対しては それなりの大きさのデータセットだ なぜなら 画像認識は 全てのピクセルを見て 何かを当てるという複雑な問題だから オンラインのデータセットは 百万以上にもなる とても巨大なものだけど まだ もっと多くのデータが欲しいように感じる そして 物体検出のような問題では まだデータが少ない 思い出して欲しいけど 画像認識は 写真を見て 猫かどうか判断する問題だ 一方 物体検出は 写真の中を見て 境界の箱を置いて 写真の中のどこに 車のような物体があるか知らせる 境界の箱を得るためのコストは 本当に高く付いて 物体や境界の箱をラベル付けするんだ だから 画像認識よりも 物体検出に対して データが少ない傾向がある そして 物体検出については 次週 議論する 機械学習問題の幅広い分布図を通して見れば 平均的に見れば
沢山データがあれば 人々は 比較的単純なアルゴリズムを使わず 手作業での調整も少なくするのが 分かる 注意深く 問題に対する特徴を設計する必要が 少なくなるからだ しかし その代わりに 巨大なニューラルネットワークを持つだろう 単純な構造であっても ニューラルネットワークに 学ばせたいものが何であれ 沢山のデータがあればね 一方 対照的に それほど沢山のデータが無い場合は 平均的には 人々は より手作業での調整を多く行っているのが分かるだろう あなたは そうしたくないだろうから 「何かコツがあるんでしょう」 と言うでしょう でも 沢山データが無い場合は 手作業での調整が 実際 良い性能を得るための一番の方法なんだ 私が 機械学習アプリケーションを見ると 通常 学習アルゴリズムが ２つの知識を使っていると思う １つの知識は ラベル付けしたデータで 教師あり学習で使う (x, y) ペアだ ２番目の知識は 手作業での調整だ システムを手作業で調整するには 沢山の方法がある 特徴量を注意深く設計することから 注意深くネットワーク構造を設計することまで システムの他の要素のことまでかもしれない 沢山のラベル付けしたデータが無い場合は より多く 手作業での調整をしなければならない そして コンピュータ ビジョンは 本当に複雑な関数を学ぼうとする そして コンピュータ ビジョンには 十分なデータが無いと 感じることがよくある データセットが どんどん大きくなってきても しばしば 必要な量のデータが無い これが コンピュータ ビジョンが 歴史的にも 今日でも 手作業での調整に多く頼る理由だ さらに コンピュータ ビジョンが より複雑なネットワーク構造を発展させてきた理由は より多くのデータが無い中で 良い性能を得るための方法が ネットワーク構造を 設計し 工夫を凝らすのに より多くの時間をかけること だからだ 手作業での調整を 蔑視し 自分の目指すものではない と思う場合は 十分なデータが無い場合は 手作業での調整はとても難しく 多くの知見が要求される とても巧みなタスクになる そして 手作業での調整についての知見のある者が より良い性能を得て プロジェクトへ大きな貢献をするだろう 十分なデータが無い場合に 手作業で調整をすることに対してね 手作業での調整に時間を使わないのは データが沢山ある場合のみだ 代わりに 学習システムの構築に時間を掛ける でも 歴史的には コンピュータ ビジョンの分野では とても小さいデータセットを使ってきた だから コンピュータ ビジョンの文献は 歴史的に 沢山の手作業での調整に頼ってきた この数年は 適切なコンピュータ ビジョン タスクの データ量は 劇的に増加したが それが 手作業による調整を 著しく減らしたと思われる しかし まだ コンピュータ ビジョンにおけるネットワーク構造の手作業による調整はある それだから コンピュータ ビジョンでは とても複雑なハイパーパラメータの選択を見かけるのだ それは 多くの他の分野より 複雑だ 事実 通常は 画像認識データセットより 物体検出データセットの方が少ない 物体検出は こんなタスクのことで 次週 話すけど そのアルゴリズムは より複雑になって より特化した部品を持っているのが分かるよ 有難いことに 少ないデータしか無い場合に役に立つのに 転移学習がある 例えば 前のスライドの Tigger, Misty, どちらでも無い 識別問題では 少ないデータしか無いので 転移学習がとても役に立つ これが 比較的少ないデータしか無い場合に よく使われる 別の技術だ コンピュータ ビジョン文献を見ると そこにある 何かしらのアイデアを見ると 人々が 本当に情熱的であることに 気付くだろう 彼らは 標準化されたベンチマーク データセットで 本当にうまくやっているし
コンペティションでいい成績を収めている そして コンピュータ ビジョン研究者は ベンチマークでうまくいけば 簡単に 論文を出せる だから これらのベンチマークでうまくやることに 多くの目が向けられている これの良い点は コミュニティ全体で 最も効果的なアルゴリズムが何か 見つけ出すのを 促すことだ ただし 人々が論文でやったことを見て ベンチマークでうまくいけたとしても でも 実際には使わないかもしれない 実際に本番運用するシステムでは ベンチマークで うまくやるためのコツは いくつかある 私が 実際に顧客へ本番システムを提供する場合は あまり多くは使わないものもある しかし １つはアンサンブルすることだ それが意味するのは どんなニューラルネットワークが欲しいか分かったら 数個のニューラルネットワークを訓練して それらの出力の平均を取る ということだ そうだな ニューラルネットワークを ３個 または ５個 または ７個 ランダムに初期化して 訓練する それから それらの平均を取る ところで 出力 yハット を平均するのに重要なのは うまく働かない重みは平均しないことだ ７個のニューラルネットワークがあるとしよう ７つの異なる予測を 平均する 多分 これで １％とか２％とか 良くなる 何かのベンチマークで 少し良くなる これで 少しだけ 改善するだろう おそらく 時には １や２％の大きさは コンペティションでは 本当に助けになる しかし アンサンブルするということは
各画像をテストするのに 典型的には ３～１５の異なるネットワーク全てに 画像を通さなくてならない ということだ これは 実行時間を３～１５倍遅くする 時にはそれ以上だ だから アンサンブルは
ベンチマークでうまくやり コンペティションに勝つためのコツの１つで 実際に顧客に提供する場合は 決して使わないと思う 巨額のコンピュータ予算を持っていない限り 顧客の画像毎に より多く燃やそうとか 気にかけないほうがいいだろう ベンチマークで助けになる論文を見て分かる別のことに テスト時の Muti-crop (複数切り抜き) がある 何が言いたいかというと
Data Augmentation をどうできるかを見てきたでしょ Multi-crop は テスト画像にも Data Augmentation を行うことなんだ 例えば 猫の画像を見てみよう ４回コピーして ２つのバージョンにした 10-crop と呼ばれる技術がある それは この中央の領域を切り抜くとすると それを 全てに一斉に行うんだ そして 左上角を切り抜く場合 一斉にやる 右上角を切り抜く場合は 緑で示す 左下は 黄色 右下は オレンジ そして 一斉にやる 反転した画像にも 同じことをやる そう 中央を切り抜き それから ４つの角を切り抜く よって １つの中央の切り抜きは ここと ここに ４つ角の切り抜きが ここと ここ それらを足し合わせれば さっき言った 10個の異なる切り抜きになる だから 10-crop という名前になっている それから 行なうのは これらの一斉処理で得た10個の画像を 実行して 結果の平均を取ることだ コンピュータ予算があるなら これができるだろう 10個の数の切り抜きは不要かもしれない もっと少ない切り抜きでやることもできる これは 本番システムで 少しだけ良い性能をもたらすだろう 本番とは 実際のユーザに提供するシステムのことだ ただし これは 実際の本番システムよりも ベンチマークで うまくやるために より多く使われている技術だけどね アンサンブルの大きな問題は これらの異なるネットワークを保持しておく必要があることだ それにより とても多くのコンピュータメモリが使われる Multi-crop では 最低１つのネットワークだけを保持する だから それは 多くのメモリを吸い上げたりしない ただし 実行時間は かなり遅くなる これらがコツだ 研究論文も これらのコツに言及している しかし 私は 個人的には 本番システムでは これらの手法を使おうとはしない
例えそれらが ベンチマークや コンペティションで勝つのに 素晴らしくてもね なぜなら 多くのコンピュータ ビジョン問題は 小さなデータ枠内のもので 他の人が 沢山の手作業による調整をした ネットワーク構造があるからだ そして ある画像問題でうまくいったニューラルネットワークは しばしば
驚くことかもしれないけど 他の画像問題でも 上手くいくことが多い だから 実際のシステムを作る場合は 他の誰かのニューラルネットワーク構造から初めて できれば オープンソース実装を使って なぜなら オープンソース実装は 学習率減衰計画や 他のハイパーパラメータの 込み入った詳細が 全て解明されていてるからだ 最後に 他の誰かが モデルの訓練に 半ダースのGPUと 百万個の画像を使って 何週間も費やしていたかもしれない だから 他の誰かが 事前訓練したモデルを使い 自分のデータセットで微調整の訓練をすれば アプリケーションは とても速く進捗できる ただし もちろん コンピュータ資源があって そうしたいなら スクラッチで自分自身のネットワークを訓練するのを 止めないよ 事実 自分自身のコンピュータ ビジョン アルゴリズムを 発明しようとしているのなら それは やらなくちゃいけないことだもの これで 今週は終わり 多くの コンピュータ ビジョン 構造を 見ることが 何がうまくいくかという 感覚を得る助けになるといいな 今週のプログラミング演習では 別のプログラミング フレームワークを学び それを使って ResNet を実装する 演習を楽しんでほしい
次週 あなたに会うのが楽しみだ