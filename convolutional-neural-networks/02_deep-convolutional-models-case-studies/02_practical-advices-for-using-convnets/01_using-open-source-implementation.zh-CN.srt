1
00:00:01,040 --> 00:00:05,360
大家现在已经学习了几种高效的神经网络

2
00:00:05,360 --> 00:00:07,750
还有ConvNet结构

3
00:00:07,750 --> 00:00:12,040
在接下来的几个小节中，我想给大家分享关于如何

4
00:00:12,040 --> 00:00:17,056
使用它们的实用的建议，让我们先看看如何使用开源的实现

5
00:00:17,056 --> 00:00:21,870
事实证明许多神经网络都很难复现

6
00:00:21,870 --> 00:00:26,660
因为许多关于调整hyperparameters的细节

7
00:00:26,660 --> 00:00:31,430
例如学习率衰减还有其他许多细节都会给最终效果带来影响

8
00:00:31,430 --> 00:00:34,890
此外我还发现对于博士生甚至在顶尖大学就读的博士生来说

9
00:00:34,890 --> 00:00:40,140
有时候仅仅通过阅读论文来复现其他人的成果

10
00:00:40,140 --> 00:00:45,130
还是有难度的

11
00:00:45,130 --> 00:00:47,860
幸运的是, 许多深度学习的研究人员

12
00:00:47,860 --> 00:00:52,880
都会习惯地将他们的成果开源并且放在网上,例如GitHub

13
00:00:52,880 --> 00:00:55,680
同时对于你自己的成果，我当然也鼓励你

14
00:00:55,680 --> 00:01:00,420
考虑将你自己的代码贡献给开源社区

15
00:01:00,420 --> 00:01:04,930
如果你看到一篇论文并想实现它

16
00:01:04,930 --> 00:01:06,500
你需要考虑的是

17
00:01:06,500 --> 00:01:11,770
我也经常会这样做的是,去上网寻找一个开源的实现

18
00:01:11,770 --> 00:01:16,284
因为如果你可以得到作者的实现,你通常可以

19
00:01:16,284 --> 00:01:20,000
比你从头实现更节省时间

20
00:01:20,000 --> 00:01:23,414
尽管有时候从头实现一次

21
00:01:23,414 --> 00:01:24,350
也是很好的锻炼

22
00:01:24,350 --> 00:01:27,800
如果你对于如何使用Github已经很熟悉

23
00:01:27,800 --> 00:01:32,080
这段视频也许就没这么重要

24
00:01:32,080 --> 00:01:35,960
但如果你对于如何从Github下载开放的源代码并不熟练

25
00:01:35,960 --> 00:01:38,300
让我快速演示一遍怎么使用

26
00:01:42,589 --> 00:01:46,270
加入你对残差网络很感兴趣 想要使用它

27
00:01:46,270 --> 00:01:49,700
我们首先输入resnets github这对关键词进行搜索

28
00:01:50,880 --> 00:01:55,870
你可以看到关于残差网络的很多不同的实现

29
00:01:55,870 --> 00:01:58,840
我们可以看一下第一个链接

30
00:01:58,840 --> 00:02:02,760
这是一个关于残差网络的实现

31
00:02:02,760 --> 00:02:06,346
往下翻页面你可以看到

32
00:02:06,346 --> 00:02:09,840
关于代码实现的一些描述

33
00:02:09,840 --> 00:02:13,980
这个库的作者是

34
00:02:13,980 --> 00:02:19,090
ResNet的论文原作者

35
00:02:19,090 --> 00:02:22,940
这个代码是按照MIT 开源许可协议开发的

36
00:02:22,940 --> 00:02:27,110
可以通过点击这个按钮来快速浏览一下许可

37
00:02:27,110 --> 00:02:29,454
MIT 开发许可协议是最宽松的

38
00:02:29,454 --> 00:02:32,420
开源协议之一

39
00:02:32,420 --> 00:02:37,650
现在我要下载这些代码 点击这个链接

40
00:02:37,650 --> 00:02:41,327
这是下载代码的链接

41
00:02:41,327 --> 00:02:45,455
这个按钮可以复制下载链接

42
00:02:45,455 --> 00:02:46,527
然后在现在这个界面

43
00:02:46,527 --> 00:02:53,100
你只需要输入 git clone 然后粘贴刚才复制的链接 然后点击回车

44
00:02:53,100 --> 00:02:55,450
几秒钟代码就可以下载好

45
00:02:55,450 --> 00:02:58,726
这样我们把上面的代码库克隆到了本地电脑硬盘

46
00:02:58,726 --> 00:03:03,290
下面我们去具体目录下看一看

47
00:03:03,290 --> 00:03:09,900
我一般用mac系统 比 window 系统多 我们来看看prototxt

48
00:03:09,900 --> 00:03:15,450
这个应该是关于实现残差网络的一些相关文件

49
00:03:15,450 --> 00:03:21,722
这个文件很长 包含了很多细节

50
00:03:21,722 --> 00:03:28,030
有很多关于ResNet的详细配置 有101 层 对吧

51
00:03:28,030 --> 00:03:32,640
如果我没有记错的话 这个实现看起来

52
00:03:32,640 --> 00:03:36,830
应用了开源架构Caffe的框架

53
00:03:39,112 --> 00:03:42,516
如果你想要使用其他代码框架的代码实现的话

54
00:03:42,516 --> 00:03:45,930
你也可以找到相应的代码

55
00:03:48,198 --> 00:03:51,752
现在 你已经开始开发一个计算机视觉图像应用

56
00:03:51,752 --> 00:03:56,030
在这个过程中最常见的流程从选取一个你喜欢的框架开始

57
00:03:56,030 --> 00:03:59,405
比如一些我们在这个课程中学到的框架

58
00:03:59,405 --> 00:04:03,415
或者你从其他地方听到见到的框架

59
00:04:03,415 --> 00:04:06,035
然后去找一个开源的代码实现

60
00:04:06,035 --> 00:04:09,655
去github上下载好 然后可以在下载好的代码上开发

61
00:04:09,655 --> 00:04:14,300
这样做的好处之一是

62
00:04:14,300 --> 00:04:18,380
这些网络可能需要很长的时间来训练 也许有人已经用多个GPU

63
00:04:18,380 --> 00:04:22,110
和大数据集训练好了

64
00:04:22,110 --> 00:04:25,410
这样你就可以直接对这些网络使用迁移学习

65
00:04:25,410 --> 00:04:28,930
关于迁移学习 我们在下一个视频中会讲

66
00:04:28,930 --> 00:04:33,679
当然 如果你是一个计算机视觉的研究者 你可能需要

67
00:04:33,679 --> 00:04:36,623
从头开始构建这个神经网络框架 这样的话工作流程就会不同

68
00:04:36,623 --> 00:04:37,615
如果你从头构建的话

69
00:04:37,615 --> 00:04:40,969
不要忘记了把你的代码贡献到开源社区

70
00:04:40,969 --> 00:04:46,037
因为很多的计算机视觉研究者都做了很多的工作来实现这些

71
00:04:46,037 --> 00:04:51,183
架构 我个人认为对一个项目来说

72
00:04:51,183 --> 00:04:55,820
找一个适合的开源代码 是一个比较好也比较块的开始