コンピュータ ビジョン アプリケーションを構築する場合 スクラッチで ランダム初期化で 学習するよりも もっと速く進められる
もし 誰か他の人が 既に学習を行った ニューラルネットワークをダウンロードし それを 事前学習済みのものとして使い 自分が興味を持っている新しいタスクに転移させるなら コンピュータ ビジョン研究コミュニティでは 非常に沢山の データセットをインターネットに投稿してきた
ImageNet や MS COCO もしくは Pascal のようなデータセットのことを聞いたことが有るなら これらは 人々がオンライン投稿してきた異なるデータセットの名前で 多くのコンピュータ ビジョン研究者が 自分のアルゴリズムの訓練に使ってきた 時折 このような訓練は数週間かかったり とても多くのGPUを使ったりする 他の誰かが これを行い 痛みを伴う 高性能の研究過程を経てきた ということは 他の誰かが 見つけ出すのに 何週間も 何か月もかかった オープンソースの重みを ダウンロードできて それを使うことができる ということだ 自分自身のニューラルネットワークの非常に良い初期化として そして 転移学習 を使うんだ
これらの巨大なパブリックデータセットから 自分自身の問題へ 知識を転移させるんだ どうやるのか 深く見ていこう 例から始めよう 自分のペットの猫を認識する 猫検出器を作っているとしよう インターネットによれば Tigger は よくある猫の名前だ
Misty も また よくある猫の名前だ あなたの猫は Tigger と Misty だとする どちらでも無い場合もある ３つの場合がある 分類問題だ この写真は Tigger か Misty か それとも どちらでも無いか？ それに 両方の猫が 写真に写っている場合がある さて あなたは 多分 Tigger の写真を たくさんは持っていないだろう Misty のもね
つまり あなたの学習セットは 小さい 何ができるだろう？ 私が勧めるのは こうだ
オンラインで、いくつかの ニューラルネットワークのオープン ソース実装のダウンロードする コードだけではなく 重み もダウンロードするんだ たくさんの訓練済みのネットワークをダウンロードできる 例えば ImageNet データセットには 1000個のことなクラスがあって だから ネットワークは ソフトマックスで 1000の内の1つのクラスを出力するだろう できるのは 最後のソフトマックス層を取り除き Tigger か Misty か それ以外かを 出力する自分のソフトマックスユニットを作ることだ ネットワークの方では これらの全ての層は 固定されたものと考えるとよい つまり ネットワークのこの全ての層では パラメータが固定され それから ソフトマックス層に関係するパラメータだけを訓練するんだ これは ３つの出力が有り得るソフトマックス層だ Tigger, Misty, もしくは どちらでも無い 他の誰かの 無料の学習済み重み を使うことで 小さなデータセットでも とても良い性能を得ることだろう 幸運なことに 多くのディープラーニング フレームワークは この処理を行うモードを備えている
実際に フレームワークにもよるが trainableParameter = 0 とすることで そうできたりする これらを もっと前の方の層にセットするかもしれない こう言うためにだよ "これらの重みを訓練するな"
または パラメータは freeze = 1 とするかもしれない 異なるディープラーニング プログラミング フレームワークでは 異なるやり方で 特定の層の重みの 訓練可否を指定する この例では ソフトマックス層の重みのみ訓練し それより前の層の重みは全て固定する 実装によっては役に立つ 別の巧みなトリックがある これらの前の方の層は 全て固定されているので これは 固定された関数であって 変更できないので これは訓練されずに 入力画像 x を取り この層で ある活性に割り付けする 学習速度を上げるトリックの1つは この層を事前に計算しておくことだ この層の活性化された特徴量を計算しておき ディスクに保存しておく 今やったのは この固定関数を使い このニューラルネットワークの最初の部分を使い 入力画像 x から 特徴ベクトルを計算して それから その特徴ベクトルで 薄いソフトマックス モデルを訓練した
予測を行うためにね 計算を助ける１ステップは これらの層の活性を事前計算し 学習セットの全てのサンプルについて行い ディスクに保存し それから それらを使って ソフトマックス識別器の訓練だけを行うことだ ディスクに保存しておく利点は 事前計算してディスクに保存しておく利点は 毎回 これらの活性を 再計算をしなくてよいことだ エポックの度に 訓練セットを通さなくてよい 自分のタスクに とても少ない学習セットしか持っていない場合は こうすればいい もっと沢山の学習セットを持っていたら どうだろうか？ 一つの指針は もし 多くのデータセットがあり
そう TiggerとMisty の写真を山ほどもっているかもしれない 同じく ２つが移っていないのも沢山あるだろう できることの一つは より少ない層を固定することだ ここの層だけを固定し この後の方の層を訓練する ただし 出力層に 異なるクラスを持つ場合は "Tigger, Misty, 何れでも無い" となる 何らかの方法の 自分の出力ユニットが必要だ これを行うには いくつかのやり方がある 終わりの方の何層かの 重みは初期化に使い それから勾配降下法を始めることができる もしくは ここの終わりの何層かを消してしまい 自分自身の新しい隠れ層と 自分自身の最終ソフトマックス出力にもできる どちらも やってみる価値がある ただし もし より多くのデータを持っているなら 固定する層の数を より少なくし 訓練する先頭の層の数を より大きくするだろう 考え方はこうだ
もし 大きなデータセットがあるなら 十分なデータがあるなら
ソフトマックス１つだけを訓練するのではなく ニューラルネットワークのより多くの層を訓練する 最終的に使うネットワークの最後の数層を 最後に もし とても多くのデータがあるなら 行なうであろうことは このオープンソースのネットワークと重みを 全て 初期化にだけ使い ネットワーク全体を訓練することだ でも また言うけど 1000のソフトマックスだった場合は ３つの出力しかしないのだから 自分のソフトマックス出力が必要だよ その出力ラベルは 自分が扱おうとしているものにしてね より多くのデータがあるなら Tigger, Misty, その他 の写真がもっとあるなら より多くの層を訓練できる そして究極では ダウンロードした重みを 初期化としてのみ使い ランダム初期化の代わりでね
そして 勾配降下法を使って ネットワークの 全ての重み 全ての層を 訓練 更新できる これが ConvNet を訓練するための 転移学習だ 実際 インターネット上のオープン データセットは膨大で ダウンロードできる重みは 誰かが 数週間かけて 非常に沢山のデータで訓練したものなので 多くのコンピュータ ビジョン アプリケーション用のが見つかるし とても上手く行く
もし 自身の問題のため 他の誰かの オープンソース重みを ダウンロードして 初期化に使うならね あらゆる分野において あらゆる種類のディープラーニングアプリケーションにおいて コンピュータ ビジョンには 転移学習を 常に行うべきだ 格別に大きなデータセットを持っていて 自分自身で スクラッチで全てを訓練する場合を除いて 転移学習は 真剣に検討する価値が 本当にある 自分自身で スクラッチで 全てを訓練するための 特別に巨大なデータセットと 巨大なコンピュータ予算がある場合を除いてね