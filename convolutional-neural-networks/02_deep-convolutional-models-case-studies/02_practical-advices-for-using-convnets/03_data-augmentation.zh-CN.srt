1
00:00:00,000 --> 00:00:03,836
大多数的计算机视觉工作能用到很多数据.

2
00:00:03,836 --> 00:00:07,350
因此数据增强是其中一种常用技术

3
00:00:07,350 --> 00:00:11,995
用于来改善计算机视觉系统的性能.

4
00:00:11,995 --> 00:00:15,535
我认为, 计算机视觉是一件十分复杂的工作.

5
00:00:15,535 --> 00:00:16,745
你必须要输入这个图像,

6
00:00:16,745 --> 00:00:21,870
包括所有的像素, 并试着弄清楚图像中内容.

7
00:00:21,870 --> 00:00:26,615
貌似你需要训练出一个相当复杂的函数来做这件事.

8
00:00:26,615 --> 00:00:32,160
事实上, 更多的数据对几乎所有的计算机视觉工作都有好处

9
00:00:32,160 --> 00:00:36,580
这和其他一些领域不一样. 只要获得了足够的数据,

10
00:00:36,580 --> 00:00:39,610
那些领域并不需要获得了更多数据了.

11
00:00:39,610 --> 00:00:42,428
但是我认为如今, 计算机视觉的状态是

12
00:00:42,428 --> 00:00:44,655
对于绝大多数的问题,

13
00:00:44,655 --> 00:00:47,655
我们总是不能获得足够的数据.

14
00:00:47,655 --> 00:00:50,783
这点对机器学习应用来说并不成立,

15
00:00:50,783 --> 00:00:53,490
但对计算机视觉来说是成立的

16
00:00:53,490 --> 00:00:57,120
那么, 这就意味着, 当你在训练计算机视觉模型时,

17
00:00:57,120 --> 00:00:59,880
数据增强常常会有所帮助.

18
00:00:59,880 --> 00:01:02,520
无论你是用迁移学习还是

19
00:01:02,520 --> 00:01:05,720
其他人预先训练好的模型来开头,

20
00:01:05,720 --> 00:01:09,055
或者你试着从零开始训练你自己的模型, 这点都是成立的

21
00:01:09,055 --> 00:01:13,755
让我们看一下计算机视觉中常见的数据增强方法

22
00:01:13,755 --> 00:01:19,920
最简单的数据增强方式应该是(对图片)做垂直镜像.

23
00:01:19,920 --> 00:01:22,995
假设这是你训练集中的一个例子,

24
00:01:22,995 --> 00:01:27,045
通过水平翻转你获得了右边图像.

25
00:01:27,045 --> 00:01:29,300
对大部分计算机视觉工作来说,

26
00:01:29,300 --> 00:01:33,475
如果左边的图片是一只猫, 那镜像后仍然是一只猫.

27
00:01:33,475 --> 00:01:35,610
如果镜像操作

28
00:01:35,610 --> 00:01:38,890
保留了你试着识别的任何图像内容,

29
00:01:38,890 --> 00:01:43,395
这将是一种很好用的数据增强技术.

30
00:01:43,395 --> 00:01:47,035
另一种常用技术是随机裁剪.

31
00:01:47,035 --> 00:01:48,725
就拿这个数据集来说,

32
00:01:48,725 --> 00:01:50,190
让我们来做一些随机裁剪.

33
00:01:50,190 --> 00:01:51,536
你也许会选取那块,

34
00:01:51,536 --> 00:01:56,442
裁剪下来,或者你会选另一块裁剪下来,

35
00:01:56,442 --> 00:01:59,460
或选这块图像,裁剪下来.

36
00:01:59,460 --> 00:02:02,508
这样就获得了不同的示例来扩充你的训练集,

37
00:02:02,508 --> 00:02:04,350
对数据集的不同随机裁剪.

38
00:02:04,350 --> 00:02:08,310
但是随机裁剪并不是一种完美的数据增强方式.

39
00:02:08,310 --> 00:02:14,760
假如你随机裁剪下那块看起来不像猫的一片

40
00:02:14,760 --> 00:02:18,110
但是实际随机裁剪效果还不错

41
00:02:18,110 --> 00:02:21,920
只要随机裁剪的部分占原图片的相当大一部分.

42
00:02:21,920 --> 00:02:26,700
因此,我们经常使用镜像和随机裁剪, 而且理论上,

43
00:02:26,700 --> 00:02:29,580
你还可以用其他方式例如旋转,

44
00:02:29,580 --> 00:02:31,086
剪切图像,

45
00:02:31,086 --> 00:02:34,233
例如你这样处理图片,

46
00:02:34,233 --> 00:02:35,883
使其变形,

47
00:02:35,883 --> 00:02:39,130
引入不同类型的局部弯曲等.

48
00:02:39,130 --> 00:02:42,253
尝试所有这些方式也没有什么坏处,

49
00:02:42,253 --> 00:02:45,805
虽然实践中这些方法不那么常用,

50
00:02:45,805 --> 00:02:48,159
也可能是因为他们的复杂程度.

51
00:02:48,159 --> 00:02:58,345
第二类常用的数据增强方式是色彩变化.

52
00:02:58,345 --> 00:03:01,080
以这个图片为例,

53
00:03:01,080 --> 00:03:04,950
让我们在R(红)G(绿)B(蓝)通道

54
00:03:04,950 --> 00:03:09,783
加入不同的扰动.

55
00:03:09,783 --> 00:03:12,260
在这里示例中,我们

56
00:03:12,260 --> 00:03:16,410
增加了红和蓝色通道的值, 减小了绿色通道值.

57
00:03:16,410 --> 00:03:20,320
红色混蓝色是紫色.

58
00:03:20,320 --> 00:03:23,360
所以这使得整个图片颜色偏紫

59
00:03:23,360 --> 00:03:27,080
这样就给训练集增加了一个干扰后图像.

60
00:03:27,080 --> 00:03:29,435
为了起到展示效果, 我将

61
00:03:29,435 --> 00:03:32,775
对色彩做一些明显的改变,

62
00:03:32,775 --> 00:03:39,720
事实上你在红绿蓝通道上做的干扰也可以非常小.

63
00:03:39,720 --> 00:03:43,608
你要做的是采取不同的红绿蓝数值,

64
00:03:43,608 --> 00:03:46,410
来干扰不同颜色通道.

65
00:03:46,410 --> 00:03:48,480
所以,在第二个示例中,

66
00:03:48,480 --> 00:03:50,695
我们减少红色的值,

67
00:03:50,695 --> 00:03:52,415
增加绿色和蓝色的值,

68
00:03:52,415 --> 00:03:57,109
所以图片变得有点偏黄.

69
00:03:57,109 --> 00:04:01,407
在这个图片里, 我们多增加点蓝色的值,

70
00:04:01,407 --> 00:04:03,155
和一点点红色的值.

71
00:04:03,155 --> 00:04:04,868
在实践中, 红绿蓝的数值

72
00:04:04,868 --> 00:04:09,465
是通过些概率分布来获得的.

73
00:04:09,465 --> 00:04:15,370
这样做的出发点是有时候日光有点偏黄,

74
00:04:15,370 --> 00:04:20,187
或者室内的照明有点偏黄色,

75
00:04:20,187 --> 00:04:23,730
这些都会很轻松的改变图片的颜色,

76
00:04:23,730 --> 00:04:27,745
但是猫的身份或者说内容的身份

77
00:04:27,745 --> 00:04:30,840
标记 y, 应该保持不变.

78
00:04:30,840 --> 00:04:35,798
因此, 通过引入颜色干扰或是色彩变化, 使得

79
00:04:35,798 --> 00:04:46,435
你的学习算法在应对图像色彩变化时健壮性更好.

80
00:04:46,435 --> 00:04:54,880
这里给这个课程的高阶学生们一个建议,

81
00:04:54,880 --> 00:04:59,997
如果你不懂我接下来红笔写的内容也没有关系.

82
00:04:59,997 --> 00:05:04,280
有不同的方式来采样红绿蓝通道值.

83
00:05:04,280 --> 00:05:08,790
其中一种色彩干扰的算法被称为PCA.

84
00:05:08,790 --> 00:05:11,465
即主成成分分析

85
00:05:11,465 --> 00:05:14,345
我在ml-cross.org

86
00:05:14,345 --> 00:05:22,750
机器学习课程中有谈到.

87
00:05:22,750 --> 00:05:29,080
但此算法的细节在AlexNet论文中有描述,

88
00:05:29,080 --> 00:05:36,080
有时也被称为PCA色彩增强.

89
00:05:36,080 --> 00:05:41,585
但那时被称为PCA色彩增强的大致想法是这样的,

90
00:05:41,585 --> 00:05:44,160
如果你的图像主要呈紫色,

91
00:05:44,160 --> 00:05:47,540
即主要是红色和蓝色,

92
00:05:47,540 --> 00:05:49,010
带一点点绿色,

93
00:05:49,010 --> 00:05:52,399
那么PCA色彩增强

94
00:05:52,399 --> 00:05:55,120
会增加和减少许多红色和蓝色值,

95
00:05:55,120 --> 00:05:56,510
却对绿色值做很小修改,

96
00:05:56,510 --> 00:06:01,770
因此来保持整体和之前相同的着色.

97
00:06:01,770 --> 00:06:05,390
如果你不理解上述内容,不用担心.

98
00:06:05,390 --> 00:06:09,677
但是如果你愿意,可以在网上搜索一下,

99
00:06:09,677 --> 00:06:13,905
了解下AlextNet论文中关于此算法的细节,

100
00:06:13,905 --> 00:06:18,500
而且你也可以找到一些关于PCA色彩增强的开源实现,

101
00:06:18,500 --> 00:06:21,685
直接用即可.

102
00:06:21,685 --> 00:06:30,010
你也许将训练样本存在一个硬盘上,

103
00:06:30,010 --> 00:06:33,705
这里用这个圆筒来代表你的硬盘.

104
00:06:33,705 --> 00:06:36,000
如果你有一个小的训练集合,

105
00:06:36,000 --> 00:06:38,336
你可以做任何事情,都没有问题.

106
00:06:38,336 --> 00:06:42,785
但是如果是非常大训练集合, 这是一个很常见的情况

107
00:06:42,785 --> 00:06:52,705
这里你也许会有一个CPU进程, 不断的从硬盘中加载图像.

108
00:06:52,705 --> 00:07:00,235
那么从你的硬盘中有这个图片流进来.

109
00:07:00,235 --> 00:07:08,535
你能做的是用一个CPU进程来实现失真,

110
00:07:08,535 --> 00:07:11,000
可以是随机裁剪,

111
00:07:11,000 --> 00:07:13,795
或色彩变换, 或镜像,

112
00:07:13,795 --> 00:07:16,710
对于每个图像,

113
00:07:16,710 --> 00:07:21,000
你会得到一些它的失真的版本.

114
00:07:21,000 --> 00:07:22,950
这里我们看下这个图片,

115
00:07:22,950 --> 00:07:28,310
我会对它做镜像,或者再做下色彩失真处理等.

116
00:07:28,310 --> 00:07:35,120
而这个图像也许做些色彩变换,

117
00:07:35,120 --> 00:07:41,470
这样你就获得了一些不同色彩的猫图片.

118
00:07:41,470 --> 00:07:48,395
这里你的CPU线程不断的加载数据并做

119
00:07:48,395 --> 00:07:56,810
一些必要的失真处理, 来形成一批或几小批数据.

120
00:07:56,810 --> 00:08:05,045
这些数据会不断的传给其他线程或进程

121
00:08:05,045 --> 00:08:08,815
来实现训练学习, 这些可以在CPU或者GPU上实现,

122
00:08:08,815 --> 00:08:14,075
如果要训练一个大的神经网络, 后者越来越多被用到.

123
00:08:14,075 --> 00:08:17,710
因此, 一种常见的数据增强方法是

124
00:08:17,710 --> 00:08:22,235
通过一个线程,

125
00:08:22,235 --> 00:08:26,540
几乎是四个线程,

126
00:08:26,540 --> 00:08:30,635
用来加载数据并做失真处理,

127
00:08:30,635 --> 00:08:32,840
然后传递给其他线程或

128
00:08:32,840 --> 00:08:35,935
进程来做深度学习训练.

129
00:08:35,935 --> 00:08:38,435
通常,这部分和这部分,

130
00:08:38,435 --> 00:08:39,650
可以并行.

131
00:08:39,650 --> 00:08:46,121
以上, 这就是数据增强.

132
00:08:46,121 --> 00:08:49,970
同其他训练深度神经网络的模块一样,

133
00:08:49,970 --> 00:08:55,250
数据增强也有一些超参数,例如需要实现多大

134
00:08:55,250 --> 00:09:00,965
程度的色彩变化和具体用什么参数来做随机裁剪?

135
00:09:00,965 --> 00:09:03,500
所以, 同计算机视觉的其他部分一样,

136
00:09:03,500 --> 00:09:06,335
直接用其他人用到的数据增强的开源实现

137
00:09:06,335 --> 00:09:10,920
也许是一个很好的开始.

138
00:09:10,920 --> 00:09:15,640
当然,如果你想捕捉到更多细节变化,

139
00:09:15,640 --> 00:09:19,235
并且你认为其他人的开源实现并没有做到这点,

140
00:09:19,235 --> 00:09:24,230
你自己来调整超参数也是有合理的.

141
00:09:24,230 --> 00:09:27,980
以上, 我希望通过数据增强,

142
00:09:27,980 --> 00:09:31,250
可以让你的计算机视觉应用更好的工作.