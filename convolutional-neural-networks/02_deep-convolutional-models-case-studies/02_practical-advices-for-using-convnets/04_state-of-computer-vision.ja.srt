1
00:00:00,000 --> 00:00:01,650
ディープラーニングは成功裏に適用されてきた

2
00:00:01,650 --> 00:00:03,850
コンピュータ ビジョンや 自然言語処理や

3
00:00:03,850 --> 00:00:05,990
音声認識 オンライン広告

4
00:00:05,990 --> 00:00:08,550
物流 その他多くの 問題に

5
00:00:08,550 --> 00:00:10,470
コンピュータビジョンに対する 

6
00:00:10,470 --> 00:00:12,990
ディープラーニングのアプリケーションには

7
00:00:12,990 --> 00:00:15,570
独自のものがいくつかあるけど

8
00:00:15,570 --> 00:00:20,160
このビデオでは コンピュータビジョンに対するディープラーニングについての

9
00:00:20,160 --> 00:00:25,335
私の観察のいくつかを共有したい
そうすることで 文献や そこで出てきたアイデアや

10
00:00:25,335 --> 00:00:27,270
コンピュータ ビジョンのシステムを自分自身でどのように作るか等を

11
00:00:27,270 --> 00:00:31,880
より良く探索する助けにしてほしい

12
00:00:31,880 --> 00:00:38,180
では 殆どの機械学習問題は この分布のどこかにあると考えることができる

13
00:00:38,180 --> 00:00:40,730
比較的 少ないデータがある場合と

14
00:00:40,730 --> 00:00:45,585
沢山データがある場合の間だ

15
00:00:45,585 --> 00:00:50,840
例えば 今日 かなり多くの音声認識のデータがある

16
00:00:50,840 --> 00:00:57,230
それは 問題の複雑さに対して ということだけど

17
00:00:57,230 --> 00:00:59,540
でも 今日

18
00:00:59,540 --> 00:01:05,315
画像認識や画像分類に対しては それなりの大きさのデータセットだ

19
00:01:05,315 --> 00:01:07,460
なぜなら 画像認識は

20
00:01:07,460 --> 00:01:11,222
全てのピクセルを見て 何かを当てるという複雑な問題だから

21
00:01:11,222 --> 00:01:16,250
オンラインのデータセットは 百万以上にもなる とても巨大なものだけど

22
00:01:16,250 --> 00:01:20,098
まだ もっと多くのデータが欲しいように感じる

23
00:01:20,098 --> 00:01:28,006
そして 物体検出のような問題では まだデータが少ない

24
00:01:28,006 --> 00:01:31,340
思い出して欲しいけど 画像認識は

25
00:01:31,340 --> 00:01:34,912
写真を見て 猫かどうか判断する問題だ

26
00:01:34,912 --> 00:01:39,590
一方 物体検出は 写真の中を見て

27
00:01:39,590 --> 00:01:41,948
境界の箱を置いて 写真の中のどこに

28
00:01:41,948 --> 00:01:44,935
車のような物体があるか知らせる

29
00:01:44,935 --> 00:01:46,760
境界の箱を得るためのコストは

30
00:01:46,760 --> 00:01:52,470
本当に高く付いて 物体や境界の箱をラベル付けするんだ

31
00:01:52,470 --> 00:01:57,905
だから 画像認識よりも 物体検出に対して データが少ない傾向がある

32
00:01:57,905 --> 00:02:02,083
そして 物体検出については 次週 議論する

33
00:02:02,083 --> 00:02:06,605
機械学習問題の幅広い分布図を通して見れば

34
00:02:06,605 --> 00:02:12,095
平均的に見れば
沢山データがあれば 人々は

35
00:02:12,095 --> 00:02:18,300
比較的単純なアルゴリズムを使わず 手作業での調整も少なくするのが 分かる

36
00:02:18,300 --> 00:02:23,480
注意深く 問題に対する特徴を設計する必要が 少なくなるからだ

37
00:02:23,480 --> 00:02:25,910
しかし その代わりに 巨大なニューラルネットワークを持つだろう

38
00:02:25,910 --> 00:02:28,507
単純な構造であっても ニューラルネットワークに

39
00:02:28,507 --> 00:02:32,415
学ばせたいものが何であれ 沢山のデータがあればね

40
00:02:32,415 --> 00:02:36,560
一方 対照的に それほど沢山のデータが無い場合は

41
00:02:36,560 --> 00:02:41,713
平均的には 人々は より手作業での調整を多く行っているのが分かるだろう

42
00:02:41,713 --> 00:02:46,660
あなたは そうしたくないだろうから 「何かコツがあるんでしょう」 と言うでしょう

43
00:02:46,660 --> 00:02:49,880
でも 沢山データが無い場合は

44
00:02:49,880 --> 00:02:54,809
手作業での調整が 実際 良い性能を得るための一番の方法なんだ

45
00:02:54,809 --> 00:02:59,435
私が 機械学習アプリケーションを見ると

46
00:02:59,435 --> 00:03:04,595
通常 学習アルゴリズムが ２つの知識を使っていると思う

47
00:03:04,595 --> 00:03:07,430
１つの知識は ラベル付けしたデータで

48
00:03:07,430 --> 00:03:11,525
教師あり学習で使う (x, y) ペアだ

49
00:03:11,525 --> 00:03:14,652
２番目の知識は 手作業での調整だ

50
00:03:14,652 --> 00:03:17,045
システムを手作業で調整するには 沢山の方法がある

51
00:03:17,045 --> 00:03:20,435
特徴量を注意深く設計することから

52
00:03:20,435 --> 00:03:22,281
注意深くネットワーク構造を設計することまで

53
00:03:22,281 --> 00:03:26,485
システムの他の要素のことまでかもしれない

54
00:03:26,485 --> 00:03:28,880
沢山のラベル付けしたデータが無い場合は

55
00:03:28,880 --> 00:03:32,270
より多く 手作業での調整をしなければならない

56
00:03:32,270 --> 00:03:38,165
そして コンピュータ ビジョンは 本当に複雑な関数を学ぼうとする

57
00:03:38,165 --> 00:03:42,815
そして コンピュータ ビジョンには 十分なデータが無いと 感じることがよくある

58
00:03:42,815 --> 00:03:45,362
データセットが どんどん大きくなってきても

59
00:03:45,362 --> 00:03:48,845
しばしば 必要な量のデータが無い

60
00:03:48,845 --> 00:03:52,100
これが コンピュータ ビジョンが 歴史的にも

61
00:03:52,100 --> 00:03:57,178
今日でも 手作業での調整に多く頼る理由だ

62
00:03:57,178 --> 00:04:00,425
さらに コンピュータ ビジョンが

63
00:04:00,425 --> 00:04:05,040
より複雑なネットワーク構造を発展させてきた理由は

64
00:04:05,040 --> 00:04:08,720
より多くのデータが無い中で

65
00:04:08,720 --> 00:04:13,400
良い性能を得るための方法が ネットワーク構造を

66
00:04:13,400 --> 00:04:17,130
設計し 工夫を凝らすのに より多くの時間をかけること だからだ

67
00:04:17,130 --> 00:04:19,340
手作業での調整を

68
00:04:19,340 --> 00:04:23,525
蔑視し 自分の目指すものではない と思う場合は

69
00:04:23,525 --> 00:04:27,830
十分なデータが無い場合は 手作業での調整はとても難しく

70
00:04:27,830 --> 00:04:32,135
多くの知見が要求される とても巧みなタスクになる

71
00:04:32,135 --> 00:04:36,875
そして 手作業での調整についての知見のある者が より良い性能を得て

72
00:04:36,875 --> 00:04:39,590
プロジェクトへ大きな貢献をするだろう

73
00:04:39,590 --> 00:04:43,085
十分なデータが無い場合に 手作業で調整をすることに対してね

74
00:04:43,085 --> 00:04:47,150
手作業での調整に時間を使わないのは データが沢山ある場合のみだ

75
00:04:47,150 --> 00:04:52,588
代わりに 学習システムの構築に時間を掛ける

76
00:04:52,588 --> 00:04:57,610
でも 歴史的には コンピュータ ビジョンの分野では とても小さいデータセットを使ってきた

77
00:04:57,610 --> 00:04:59,965
だから コンピュータ ビジョンの文献は 歴史的に

78
00:04:59,965 --> 00:05:02,700
沢山の手作業での調整に頼ってきた

79
00:05:02,700 --> 00:05:06,640
この数年は 適切なコンピュータ ビジョン タスクの

80
00:05:06,640 --> 00:05:10,540
データ量は 劇的に増加したが

81
00:05:10,540 --> 00:05:12,580
それが

82
00:05:12,580 --> 00:05:17,185
手作業による調整を 著しく減らしたと思われる

83
00:05:17,185 --> 00:05:21,480
しかし まだ コンピュータ ビジョンにおけるネットワーク構造の手作業による調整はある

84
00:05:21,480 --> 00:05:26,890
それだから コンピュータ ビジョンでは とても複雑なハイパーパラメータの選択を見かけるのだ

85
00:05:26,890 --> 00:05:31,294
それは 多くの他の分野より 複雑だ

86
00:05:31,294 --> 00:05:33,550
事実 通常は

87
00:05:33,550 --> 00:05:38,050
画像認識データセットより 物体検出データセットの方が少ない

88
00:05:38,050 --> 00:05:43,360
物体検出は こんなタスクのことで 次週 話すけど

89
00:05:43,360 --> 00:05:48,280
そのアルゴリズムは

90
00:05:48,280 --> 00:05:54,040
より複雑になって より特化した部品を持っているのが分かるよ

91
00:05:54,040 --> 00:06:00,100
有難いことに 少ないデータしか無い場合に役に立つのに 転移学習がある

92
00:06:00,100 --> 00:06:10,395
例えば 前のスライドの

93
00:06:10,395 --> 00:06:13,850
Tigger, Misty, どちらでも無い 識別問題では

94
00:06:13,850 --> 00:06:18,666
少ないデータしか無いので 転移学習がとても役に立つ

95
00:06:18,666 --> 00:06:21,120
これが 比較的少ないデータしか無い場合に

96
00:06:21,120 --> 00:06:24,255
よく使われる 別の技術だ

97
00:06:24,255 --> 00:06:27,100
コンピュータ ビジョン文献を見ると

98
00:06:27,100 --> 00:06:29,243
そこにある 何かしらのアイデアを見ると

99
00:06:29,243 --> 00:06:32,293
人々が 本当に情熱的であることに 気付くだろう

100
00:06:32,293 --> 00:06:34,800
彼らは 標準化されたベンチマーク データセットで

101
00:06:34,800 --> 00:06:38,730
本当にうまくやっているし
コンペティションでいい成績を収めている

102
00:06:38,730 --> 00:06:41,925
そして コンピュータ ビジョン研究者は

103
00:06:41,925 --> 00:06:45,395
ベンチマークでうまくいけば 簡単に 論文を出せる

104
00:06:45,395 --> 00:06:49,155
だから これらのベンチマークでうまくやることに 多くの目が向けられている

105
00:06:49,155 --> 00:06:51,615
これの良い点は

106
00:06:51,615 --> 00:06:56,125
コミュニティ全体で 最も効果的なアルゴリズムが何か 見つけ出すのを 促すことだ

107
00:06:56,125 --> 00:07:02,475
ただし 人々が論文でやったことを見て ベンチマークでうまくいけたとしても

108
00:07:02,475 --> 00:07:04,310
でも 実際には使わないかもしれない

109
00:07:04,310 --> 00:07:08,665
実際に本番運用するシステムでは

110
00:07:08,665 --> 00:07:11,379
ベンチマークで うまくやるためのコツは いくつかある

111
00:07:11,379 --> 00:07:15,960
私が 実際に顧客へ本番システムを提供する場合は

112
00:07:15,960 --> 00:07:20,940
あまり多くは使わないものもある

113
00:07:20,940 --> 00:07:23,105
しかし １つはアンサンブルすることだ

114
00:07:23,105 --> 00:07:24,870
それが意味するのは

115
00:07:24,870 --> 00:07:27,410
どんなニューラルネットワークが欲しいか分かったら

116
00:07:27,410 --> 00:07:33,120
数個のニューラルネットワークを訓練して それらの出力の平均を取る ということだ

117
00:07:33,120 --> 00:07:35,610
そうだな ニューラルネットワークを

118
00:07:35,610 --> 00:07:40,095
３個 または ５個 または ７個 ランダムに初期化して 訓練する

119
00:07:40,095 --> 00:07:41,890
それから それらの平均を取る

120
00:07:41,890 --> 00:07:44,943
ところで 出力 yハット を平均するのに重要なのは

121
00:07:44,943 --> 00:07:47,660
うまく働かない重みは平均しないことだ

122
00:07:47,660 --> 00:07:50,410
７個のニューラルネットワークがあるとしよう

123
00:07:50,410 --> 00:07:53,348
７つの異なる予測を 平均する

124
00:07:53,348 --> 00:07:57,725
多分 これで １％とか２％とか 良くなる

125
00:07:57,725 --> 00:08:02,015
何かのベンチマークで 少し良くなる

126
00:08:02,015 --> 00:08:04,569
これで 少しだけ 改善するだろう

127
00:08:04,569 --> 00:08:11,544
おそらく 時には １や２％の大きさは コンペティションでは 本当に助けになる

128
00:08:11,544 --> 00:08:15,200
しかし アンサンブルするということは
各画像をテストするのに

129
00:08:15,200 --> 00:08:17,810
典型的には ３～１５の異なるネットワーク全てに

130
00:08:17,810 --> 00:08:21,965
画像を通さなくてならない ということだ

131
00:08:21,965 --> 00:08:25,570
これは 実行時間を３～１５倍遅くする

132
00:08:25,570 --> 00:08:26,885
時にはそれ以上だ

133
00:08:26,885 --> 00:08:29,655
だから アンサンブルは
ベンチマークでうまくやり

134
00:08:29,655 --> 00:08:33,111
コンペティションに勝つためのコツの１つで

135
00:08:33,111 --> 00:08:38,275
実際に顧客に提供する場合は 決して使わないと思う

136
00:08:38,275 --> 00:08:41,400
巨額のコンピュータ予算を持っていない限り

137
00:08:41,400 --> 00:08:44,996
顧客の画像毎に より多く燃やそうとか 気にかけないほうがいいだろう

138
00:08:44,996 --> 00:08:50,195
ベンチマークで助けになる論文を見て分かる別のことに

139
00:08:50,195 --> 00:08:52,690
テスト時の Muti-crop (複数切り抜き) がある

140
00:08:52,690 --> 00:08:58,055
何が言いたいかというと
Data Augmentation をどうできるかを見てきたでしょ

141
00:08:58,055 --> 00:09:04,910
Multi-crop は テスト画像にも Data Augmentation を行うことなんだ

142
00:09:04,910 --> 00:09:07,470
例えば 猫の画像を見てみよう

143
00:09:07,470 --> 00:09:12,155
４回コピーして ２つのバージョンにした

144
00:09:12,155 --> 00:09:14,585
10-crop と呼ばれる技術がある

145
00:09:14,585 --> 00:09:19,460
それは この中央の領域を切り抜くとすると

146
00:09:19,460 --> 00:09:22,097
それを 全てに一斉に行うんだ

147
00:09:22,097 --> 00:09:24,830
そして 左上角を切り抜く場合 一斉にやる

148
00:09:24,830 --> 00:09:27,145
右上角を切り抜く場合は 緑で示す

149
00:09:27,145 --> 00:09:30,980
左下は 黄色

150
00:09:30,980 --> 00:09:33,162
右下は オレンジ

151
00:09:33,162 --> 00:09:34,950
そして 一斉にやる

152
00:09:34,950 --> 00:09:37,060
反転した画像にも 同じことをやる

153
00:09:37,060 --> 00:09:38,743
そう 中央を切り抜き

154
00:09:38,743 --> 00:09:41,670
それから ４つの角を切り抜く

155
00:09:41,670 --> 00:09:44,165
よって １つの中央の切り抜きは ここと ここに

156
00:09:44,165 --> 00:09:46,210
４つ角の切り抜きが ここと ここ

157
00:09:46,210 --> 00:09:49,540
それらを足し合わせれば さっき言った 10個の異なる切り抜きになる

158
00:09:49,540 --> 00:09:51,600
だから 10-crop という名前になっている

159
00:09:51,600 --> 00:09:54,980
それから 行なうのは これらの一斉処理で得た10個の画像を

160
00:09:54,980 --> 00:09:59,360
実行して 結果の平均を取ることだ

161
00:09:59,360 --> 00:10:02,660
コンピュータ予算があるなら これができるだろう

162
00:10:02,660 --> 00:10:04,530
10個の数の切り抜きは不要かもしれない

163
00:10:04,530 --> 00:10:05,900
もっと少ない切り抜きでやることもできる

164
00:10:05,900 --> 00:10:10,960
これは 本番システムで 少しだけ良い性能をもたらすだろう

165
00:10:10,960 --> 00:10:16,190
本番とは 実際のユーザに提供するシステムのことだ

166
00:10:16,190 --> 00:10:19,760
ただし これは 実際の本番システムよりも ベンチマークで

167
00:10:19,760 --> 00:10:24,110
うまくやるために より多く使われている技術だけどね

168
00:10:24,110 --> 00:10:27,550
アンサンブルの大きな問題は

169
00:10:27,550 --> 00:10:30,575
これらの異なるネットワークを保持しておく必要があることだ

170
00:10:30,575 --> 00:10:33,835
それにより とても多くのコンピュータメモリが使われる

171
00:10:33,835 --> 00:10:37,600
Multi-crop では 最低１つのネットワークだけを保持する

172
00:10:37,600 --> 00:10:41,155
だから それは 多くのメモリを吸い上げたりしない

173
00:10:41,155 --> 00:10:46,235
ただし 実行時間は かなり遅くなる

174
00:10:46,235 --> 00:10:52,240
これらがコツだ 研究論文も これらのコツに言及している

175
00:10:52,240 --> 00:10:56,940
しかし 私は 個人的には 本番システムでは

176
00:10:56,940 --> 00:10:59,535
これらの手法を使おうとはしない
例えそれらが ベンチマークや

177
00:10:59,535 --> 00:11:03,205
コンペティションで勝つのに 素晴らしくてもね

178
00:11:03,205 --> 00:11:08,345
なぜなら 多くのコンピュータ ビジョン問題は 小さなデータ枠内のもので

179
00:11:08,345 --> 00:11:12,620
他の人が 沢山の手作業による調整をした ネットワーク構造があるからだ

180
00:11:12,620 --> 00:11:17,400
そして ある画像問題でうまくいったニューラルネットワークは しばしば
驚くことかもしれないけど

181
00:11:17,400 --> 00:11:21,010
他の画像問題でも 上手くいくことが多い

182
00:11:21,010 --> 00:11:25,295
だから 実際のシステムを作る場合は

183
00:11:25,295 --> 00:11:29,796
他の誰かのニューラルネットワーク構造から初めて

184
00:11:29,796 --> 00:11:32,810
できれば オープンソース実装を使って

185
00:11:32,810 --> 00:11:35,770
なぜなら オープンソース実装は 学習率減衰計画や

186
00:11:35,770 --> 00:11:39,120
他のハイパーパラメータの

187
00:11:39,120 --> 00:11:42,478
込み入った詳細が 全て解明されていてるからだ

188
00:11:42,478 --> 00:11:46,350
最後に 他の誰かが モデルの訓練に

189
00:11:46,350 --> 00:11:51,926
半ダースのGPUと 百万個の画像を使って 何週間も費やしていたかもしれない

190
00:11:51,926 --> 00:11:56,565
だから 他の誰かが 事前訓練したモデルを使い 自分のデータセットで微調整の訓練をすれば

191
00:11:56,565 --> 00:12:00,610
アプリケーションは とても速く進捗できる

192
00:12:00,610 --> 00:12:05,048
ただし もちろん コンピュータ資源があって そうしたいなら

193
00:12:05,048 --> 00:12:09,840
スクラッチで自分自身のネットワークを訓練するのを 止めないよ

194
00:12:09,840 --> 00:12:14,326
事実 自分自身のコンピュータ ビジョン アルゴリズムを 発明しようとしているのなら

195
00:12:14,326 --> 00:12:16,840
それは やらなくちゃいけないことだもの

196
00:12:16,840 --> 00:12:18,920
これで 今週は終わり

197
00:12:18,920 --> 00:12:20,960
多くの コンピュータ ビジョン 構造を

198
00:12:20,960 --> 00:12:24,605
見ることが 何がうまくいくかという 感覚を得る助けになるといいな

199
00:12:24,605 --> 00:12:28,055
今週のプログラミング演習では

200
00:12:28,055 --> 00:12:32,740
別のプログラミング フレームワークを学び それを使って ResNet を実装する

201
00:12:32,740 --> 00:12:37,970
演習を楽しんでほしい
次週 あなたに会うのが楽しみだ