1
00:00:00,000 --> 00:00:01,650
딥 러닝은 

2
00:00:01,650 --> 00:00:03,850
컴퓨터 비전, 자연 언어 처리,

3
00:00:03,850 --> 00:00:05,990
음성 인식, 온라인 광고, 

4
00:00:05,990 --> 00:00:08,550
물류, 많은, 많은, 많은 문제에 성공적으로 적용되어왔습니다. 

5
00:00:08,550 --> 00:00:10,470
컴퓨터 비전에 상태에 대한 

6
00:00:10,470 --> 00:00:12,990
딥 러닝의 응용 어플리케이션에 대해

7
00:00:12,990 --> 00:00:15,570
고유 한 몇 가지 사항이 있습니다. 

8
00:00:15,570 --> 00:00:20,160
이 강의에서는 컴퓨터 비전에 대한 심층적인 학습에 대해 제가 한 관찰 내용을 여러분과 함께 나누며,

9
00:00:20,160 --> 00:00:25,335
이 문헌을 더 잘 읽어가고

10
00:00:25,335 --> 00:00:27,270
아이디어의 탐색을 돕고 

11
00:00:27,270 --> 00:00:31,880
컴퓨터 비전을 위해 이 시스템을 직접 구축하는 방법에 도움이 되기를 바랍니다. 

12
00:00:31,880 --> 00:00:38,180
따라서 대부분의 머신 러닝 문제는

13
00:00:38,180 --> 00:00:40,730
데이터가 비교적 적은 곳과 많은 데이터가있는 곳 사이의

14
00:00:40,730 --> 00:00:45,585
스펙트럼에 어딘가에 떨어지는 것으로 생각할 수 있습니다. 

15
00:00:45,585 --> 00:00:50,840
예를 들어, 오늘날 우리는 음성 인식을 위한 상당한 양의 데이터를 보유하고 있으며 

16
00:00:50,840 --> 00:00:57,230
이는 문제의 복잡성에 비례한다고 생각합니다. 

17
00:00:57,230 --> 00:00:59,540
그리고 오늘날

18
00:00:59,540 --> 00:01:05,315
이미지 인식이나 이미지 분류를 위한 합리적인 규모의 데이터 세트가 있다 해도

19
00:01:05,315 --> 00:01:07,460
이미지 인식은 

20
00:01:07,460 --> 00:01:11,222
모든 픽셀을 보고 이게 무엇인지 파악해야 하는 복잡한 문제이기 때문입니다. 

21
00:01:11,222 --> 00:01:16,250
온라인 데이터 세트가 백만 개 이상의 이미지처럼 상당히 큰 경우에도

22
00:01:16,250 --> 00:01:20,098
우리는 더 많은 데이터가 필요하다고 느끼는 것처럼 느껴집니다. 

23
00:01:20,098 --> 00:01:28,006
또한 더 적은 데이터를 가진 객체 감지와 같은 몇 가지 문제점들이 있습니다. 

24
00:01:28,006 --> 00:01:31,340
따라서, 기억하셔야 할 점은 이미지 인식은

25
00:01:31,340 --> 00:01:34,912
사진을 보고 이것이 가축인지 아닌지를 말해주는 문제라는 점입니다. 

26
00:01:34,912 --> 00:01:39,590
반면, 객체 감지는 사진을 보고, 

27
00:01:39,590 --> 00:01:41,948
바운딩 박스를 두어

28
00:01:41,948 --> 00:01:44,935
사진 안 어디에 자동차와 같은 객체들이 있는지를 알려주는 것입니다. 

29
00:01:44,935 --> 00:01:46,760
바운딩 박스를 가져 오는 비용이

30
00:01:46,760 --> 00:01:52,470
객체와 바운딩 박스에 레이블을 지정하는 것보다 비용이 많이 듭니다.

31
00:01:52,470 --> 00:01:57,905
따라서 우리는 이미지 인식보다 객체 감지를 위한 데이터가 적은 경향이 있습니다. 

32
00:01:57,905 --> 00:02:02,083
그리고 객체 감지는 다음 주에 논의 할 내용입니다. 

33
00:02:02,083 --> 00:02:06,605
광범위한 머신 러닝 문제를 살펴보면 

34
00:02:06,605 --> 00:02:12,095
평균적으로 많은 데이터가있을 때 단순한 알고리즘과 적은 수작업을 사용하여

35
00:02:12,095 --> 00:02:18,300
사람들이 빠져 나가는 경향이 있다는 것을 알 수 있습니다.

36
00:02:18,300 --> 00:02:23,480
따라서, 문제에 대한 피처들을 조심스럽게 설계할 필요는 없지만, 

37
00:02:23,480 --> 00:02:25,910
대신, 거대한 신경망, 

38
00:02:25,910 --> 00:02:28,507
더 단순한 아키텍처와 신경망을 가질 수 있습니다. 

39
00:02:28,507 --> 00:02:32,415
그저 데이터가 많이 있는지에 대해 이것이 학습하고 싶어하는지를 알아두십시오

40
00:02:32,415 --> 00:02:36,560
반대로 많은 양의 데이터가 없을 때는 

41
00:02:36,560 --> 00:02:41,713
평균적으로보다 더 많은 핸드 엔지니어링에 참여하는 사람들을 볼 수 있습니다.

42
00:02:41,713 --> 00:02:46,660
그리고 여러분이 인색하게 하고 싶으면, 사람이 너무 많다고 말할 수도 있습니다.

43
00:02:46,660 --> 00:02:49,880
하지만 데이터가 많지 않을 때에는

44
00:02:49,880 --> 00:02:54,809
핸드 엔지니어링이 실제로 좋은 성능을 얻는 가장 좋은 방법이라고 생각합니다. 

45
00:02:54,809 --> 00:02:59,435
머신 러닝 응용 프로그램들을 보면

46
00:02:59,435 --> 00:03:04,595
보통 학습 알고리즘에 두 가지 지식의 원천이 있다고 생각한다고 생각합니다. 

47
00:03:04,595 --> 00:03:07,430
지식의 한 가지 소스는 레이블이 지정된 데이터,

48
00:03:07,430 --> 00:03:11,525
즉 실제로 감독 학습(supervised learning)에 사용하는 (x, y) 쌍입니다. 

49
00:03:11,525 --> 00:03:14,652
그리고 지식의 두 번째 소스는 핸드 엔지니어링입니다

50
00:03:14,652 --> 00:03:17,045
시스템을 손으로 조작하는 데는 여러 가지 방법이 있습니다. 

51
00:03:17,045 --> 00:03:20,435
신중하게 손으로 디자인하여 피처를 설계하는 것으로부터

52
00:03:20,435 --> 00:03:22,281
신중하게 손으로 디자인하여 네트워크 아키텍처와 

53
00:03:22,281 --> 00:03:26,485
시스템의 다른 구성요소들을 설계하는 것까지 가능합니다. 

54
00:03:26,485 --> 00:03:28,880
따라서 레이블이 많은 데이터가 없으면

55
00:03:28,880 --> 00:03:32,270
직접 손으로 엔지니어링해야합니다. 

56
00:03:32,270 --> 00:03:38,165
그래서 저는 컴퓨터 비전이 정말로 복잡한 함수를 배우려고 노력하고 있다고 생각합니다.

57
00:03:38,165 --> 00:03:42,815
어떨때에는, 컴퓨터 비전을위한 충분한 데이터가 없는 것처럼 느껴집니다

58
00:03:42,815 --> 00:03:45,362
데이터 세트가 점점 더 커지더라도

59
00:03:45,362 --> 00:03:48,845
필요한만큼의 데이터를 확보하지 못하는 경우가 많습니다. 

60
00:03:48,845 --> 00:03:52,100
이것이 바로 이 데이터 컴퓨터 비전이 역사적으로

61
00:03:52,100 --> 00:03:57,178
심지어 오늘날에도 핸드 엔지니어링에 더 많이 의존한 이유입니다. 

62
00:03:57,178 --> 00:04:00,425
그리고 저는 이것이 어느 컴퓨터 비전이

63
00:04:00,425 --> 00:04:05,040
다소 복잡한 네트워크 아키텍처를 개발한 이유라고 생각합니다. 

64
00:04:05,040 --> 00:04:08,720
더 많은 데이터가없는 상황에서 

65
00:04:08,720 --> 00:04:13,400
좋은 성능을 얻는 방법은 아키텍팅에 더 많은 시간을 할애하고

66
00:04:13,400 --> 00:04:17,130
네트워크 아키텍처와 더 많이 작업해보는 것입니다. 

67
00:04:17,130 --> 00:04:19,340
그리고 제가 핸드엔지니어링을 낮춰보고 있다고 생각하신다면,

68
00:04:19,340 --> 00:04:23,525
그건 제 의도가 아님을 말씀드립니다. 

69
00:04:23,525 --> 00:04:27,830
충분한 데이터가 없을 때, 핸드 엔지니어링은

70
00:04:27,830 --> 00:04:32,135
많은 통찰력을 필요로 하는 매우 어렵고 매우 숙련된 작업입니다.

71
00:04:32,135 --> 00:04:36,875
그리고 핸드 엔지니어링에 대해 통찰력을 가진 사람은 더 나은 결과를 얻을 수 있으며, 

72
00:04:36,875 --> 00:04:39,590
충분한 데이터가 없을 때 

73
00:04:39,590 --> 00:04:43,085
그 핸드 엔지니어링을 수행하는 프로젝트에 큰 기여를 합니다. 

74
00:04:43,085 --> 00:04:47,150
많은 양의 데이터를 가지고 있을 때, 저라면 핸드 엔지니어링에 시간을 낭비하지 않고 

75
00:04:47,150 --> 00:04:52,588
대신 학습 시스템을 구축하는 데 시간을 할애 할 것입니다. 

76
00:04:52,588 --> 00:04:57,610
그러나 역사적으로 컴퓨터 비전이 가진 두려움은 매우 작은 데이터 세트를 사용해왔고,

77
00:04:57,610 --> 00:04:59,965
역사적으로 컴퓨터 비전 문헌은

78
00:04:59,965 --> 00:05:02,700
많은 핸드 엔지니어링에 의존해 왔다는 것입니다. 

79
00:05:02,700 --> 00:05:06,640
지난 몇 년 동안 올바른 컴퓨터 비전 작업을 

80
00:05:06,640 --> 00:05:10,540
수행하는 데이터의 양이 급격히 증가했지만, 

81
00:05:10,540 --> 00:05:12,580
그 결과로 수행되는 

82
00:05:12,580 --> 00:05:17,185
핸드 엔지니어링의 양이 크게 줄어 들었습니다. 

83
00:05:17,185 --> 00:05:21,480
그러나 네트워크 아키텍처와 컴퓨터 비전에 대한 Hand Engineering 여전히 많이 있습니다. 

84
00:05:21,480 --> 00:05:26,890
이것이 컴퓨터 비전에서 매우 복잡한 과도한 선택을 보게되고 

85
00:05:26,890 --> 00:05:31,294
다른 많은 분야에서 하는 것보다 더 복잡한 이유입니다. 

86
00:05:31,294 --> 00:05:33,550
그리고 사실, 이미지 인식 데이터 세트보다 

87
00:05:33,550 --> 00:05:38,050
더 작은 객체 감지 데이터 세트를 가지고 있기 때문에, 

88
00:05:38,050 --> 00:05:43,360
다음 주에 보시게 될 객체 감지에 대해 말하자면, 

89
00:05:43,360 --> 00:05:48,280
여러분은 이 알고리즘이

90
00:05:48,280 --> 00:05:54,040
훨씬 더 많이 복잡해지고 훨씬 더 전문화된 구성요소를 가지고 있다는 걸 보시게 될 겁니다. 

91
00:05:54,040 --> 00:06:00,100
다행히도 데이터가 거의 없을 때 도움이되는 것은 전이 학습입니다. 

92
00:06:00,100 --> 00:06:10,395
그리고 이전의 tigger, misty, detection 이전 슬라이드에 있었던, 

93
00:06:10,395 --> 00:06:13,850
문제의 예제에서, 

94
00:06:13,850 --> 00:06:18,666
전이 학습이 도와 줄 해결 가능한 데이터를 가지고 있습니다. 

95
00:06:18,666 --> 00:06:21,120
그리고 이것은 상대적으로 적은 데이터가있을 때 

96
00:06:21,120 --> 00:06:24,255
많이 사용되는 또 다른 기술입니다. 

97
00:06:24,255 --> 00:06:27,100
컴퓨터 시각 자료를 보고, 

98
00:06:27,100 --> 00:06:29,243
거기에있는 아이디어를 살펴 본다면

99
00:06:29,243 --> 00:06:32,293
사람들이 정말로 열정적이라는 것을 알 수 있습니다. 

100
00:06:32,293 --> 00:06:34,800
그들은 표준화 된 벤치 마크 데이터 세트와 

101
00:06:34,800 --> 00:06:38,730
경쟁에서 우위를 차지하는 것에서 정말 잘 하고 있습니다.

102
00:06:38,730 --> 00:06:41,925
컴퓨터 비전 연구의 경우, 여러분이 잘 수행하면

103
00:06:41,925 --> 00:06:45,395
벤치 마크 결과를 쉽게 얻을 수 있습니다.

104
00:06:45,395 --> 00:06:49,155
따라서 이러한 벤치 마크에서 잘 수행하는 데 많은 주의를 기울여야 합니다.

105
00:06:49,155 --> 00:06:51,615
그리고 이것의 긍정적인면은

106
00:06:51,615 --> 00:06:56,125
이것이 전체 커뮤니티가 가장 효과적인 알고리즘이 무엇인지 파악하는 데 도움이 된다는 것입니다.

107
00:06:56,125 --> 00:07:02,475
하지만 사람들은 여러분이 벤치 마크에서 잘 할 수있게 해주는 일들을 수행하지만

108
00:07:02,475 --> 00:07:04,310
실제 응용 프로그램에 배포하는 프로덕션이나 시스템에서는

109
00:07:04,310 --> 00:07:08,665
사용하지 않을 것이라는 것을 논문들에서 볼 수 있습니다.

110
00:07:08,665 --> 00:07:11,379
벤치마킹에 대한 몇 가지 팁이 있습니다.

111
00:07:11,379 --> 00:07:15,960
실제로 고객에게 서비스를 제공하는 시스템을 생산한다면

112
00:07:15,960 --> 00:07:20,940
이것들은 제가 많이 사용하지 않을 것들입니다.

113
00:07:20,940 --> 00:07:23,105
하나는 앙상블입니다.

114
00:07:23,105 --> 00:07:24,870
이것이 의미하는 바는,

115
00:07:24,870 --> 00:07:27,410
여러분이 원하는 신경망을 알아 낸 후에

116
00:07:27,410 --> 00:07:33,120
여러 신경망을 독립적으로 훈련시키고 아웃풋을 평균화하는 것입니다.

117
00:07:33,120 --> 00:07:35,610
그래서 3,5,또는 7 신경망을 무작위로 초기화하고

118
00:07:35,610 --> 00:07:40,095
이러한 신경망을 모두 훈련시킨 다음

119
00:07:40,095 --> 00:07:41,890
아웃풋을 평균냅니다.

120
00:07:41,890 --> 00:07:44,943
그리고 그 방법으로 출력 y 모자를 평균하는 것이 중요합니다.

121
00:07:44,943 --> 00:07:47,660
작동하지 않을 가중치를 평균화하지 마십시오.

122
00:07:47,660 --> 00:07:50,410
7 가지 다른 예측을 가진 7가지 신경망을 가지고

123
00:07:50,410 --> 00:07:53,348
평균을 내십시오.

124
00:07:53,348 --> 00:07:57,725
그리고 이것으로 1 % 또는 2 % 더 나아지게 할 것입니다.

125
00:07:57,725 --> 00:08:02,015
이렇게 하면 몇몇 벤치 마크에서 조금 나아지죠.

126
00:08:02,015 --> 00:08:04,569
그리고 이것은 여러분이 조금 더 잘하도록 도와 줄 것입니다.

127
00:08:04,569 --> 00:08:11,544
때로는 1 ~ 2 % 정도가 경쟁에서이기는 데 도움이 될 수 있습니다.

128
00:08:11,544 --> 00:08:15,200
그러나 앙상블이란 각 이미지를 테스트하는 것을 의미하므로,

129
00:08:15,200 --> 00:08:17,810
보통 3 ~ 15 개의 다른 네트워크에서

130
00:08:17,810 --> 00:08:21,965
이미지를 실행해야 할 수도 있습니다.

131
00:08:21,965 --> 00:08:25,570
이렇게하면 실행 시간이 3-15 배나

132
00:08:25,570 --> 00:08:26,885
때로는 더 빨라집니다.

133
00:08:26,885 --> 00:08:29,655
그래서 앙상블은 사람들이 벤치 마크에서 잘하고

134
00:08:29,655 --> 00:08:33,111
경쟁에서 이기는 데 사용하는 팁 중 하나입니다.

135
00:08:33,111 --> 00:08:38,275
그러나 저는 실제 고객에게 서비스를 제공하기 위한 프로덕션에는 거의 사용하지 않는다고 생각합니다.

136
00:08:38,275 --> 00:08:41,400
여러분이 계산 예산을 엄청나게 많이 가지고 있고

137
00:08:41,400 --> 00:08:44,996
고객 이미지 당 더 많은 예산을 낭비하지 않는 한

138
00:08:44,996 --> 00:08:50,195
제 생각에.벤치 마크에서 실제로 도움이 되는 논문에서 볼 수있는 또 다른 사항은

139
00:08:50,195 --> 00:08:52,690
테스트 시에 하는 다중 크롭(multi-crop)입니다.

140
00:08:52,690 --> 00:08:58,055
그래서, 데이터 증강을 어떻게 할 수 있는지 여러분은 보셨습니다.

141
00:08:58,055 --> 00:09:04,910
멀티 크롭은 여러분의 테스트 이미지에 데이터 증강을 적용하는 한 가지 형태입니다.

142
00:09:04,910 --> 00:09:07,470
그래서, 예를 들어 , 고양이 이미지를보고

143
00:09:07,470 --> 00:09:12,155
두 개의 버전을 더해, 네 번 복사하십시오.

144
00:09:12,155 --> 00:09:14,585
10 -크롭 이라는 기술이 있는데요,

145
00:09:14,585 --> 00:09:19,460
이는 기본적으로 말하자면,이 가운데 영역을 자르고,

146
00:09:19,460 --> 00:09:22,097
크로스파이어로 실행하는 것입니다.

147
00:09:22,097 --> 00:09:24,830
그리고 나서 녹색으로 표시된 왼쪽 상단 모서리에 크로스파이어를 실행하고,

148
00:09:24,830 --> 00:09:27,145
초록색으로 된 오른쪽 코너를,

149
00:09:27,145 --> 00:09:30,980
노란색으로 된 왼쪽 하단을,

150
00:09:30,980 --> 00:09:33,162
오렌지색으로 된 오른쪽 하단을 취해서

151
00:09:33,162 --> 00:09:34,950
크로스파이어를 통해 그것을 실행합니다.

152
00:09:34,950 --> 00:09:37,060
그리고 나서 미러링된 이미지를 가지고 같은 것을 하시면 됩니다.

153
00:09:37,060 --> 00:09:38,743
자, 제가 이 중앙 크롭을 가지고 와서

154
00:09:38,743 --> 00:09:41,670
네 코너를 크롭하겠습니다.

155
00:09:41,670 --> 00:09:44,165
여기 여기는 가운데 크롭 하나씩,

156
00:09:44,165 --> 00:09:46,210
여기랑 여기는 네 모서리 크롭합니다.

157
00:09:46,210 --> 00:09:49,540
이것을 다 더하면,10 개의 다른 크롭이 되죠.

158
00:09:49,540 --> 00:09:51,600
이렇게 해서 이름이 10-크롭인 것입니다.

159
00:09:51,600 --> 00:09:54,980
그리고 이제 여러분이 하실 일은 크로스파이어를 통해 10 개의 이미지를 실행 한 다음

160
00:09:54,980 --> 00:09:59,360
결과를 평균화하는 것입니다.

161
00:09:59,360 --> 00:10:02,660
만약 계산 예산이 있다면 그렇게 할 수 있습니다.

162
00:10:02,660 --> 00:10:04,530
어쩌면 10 크롭만큼이나 필요하지 않을 수도 있습니다.

163
00:10:04,530 --> 00:10:05,900
몇 크롭만을 사용할 수도 있습니다.

164
00:10:05,900 --> 00:10:10,960
그리고 이렇게 하면 프로덕션 시스템에서 좀 더 나은 성능을 얻을 수 있습니다.

165
00:10:10,960 --> 00:10:16,190
프로덕션이란 실제 사용자를 위해 배포하는 시스템을 의미합니다.

166
00:10:16,190 --> 00:10:19,760
그러나 이것은 실제 프로덕션 시스템보다

167
00:10:19,760 --> 00:10:24,110
벤치 마크에서 잘 수행하는 데 사용되는 또 다른 기술입니다.

168
00:10:24,110 --> 00:10:27,550
앙상블의 가장 큰 문제점 중 하나는

169
00:10:27,550 --> 00:10:30,575
이러한 모든 서로 다른 네트워크를 유지해야한다는 것입니다.

170
00:10:30,575 --> 00:10:33,835
그래서 컴퓨터 메모리가 더 많이 필요합니다.

171
00:10:33,835 --> 00:10:37,600
멀티 크롭의 경우,최소한 하나의 네트워크만 유지하면됩니다.

172
00:10:37,600 --> 00:10:41,155
따라서 이것이 많은 메모리를 낭비하지는 않지만,

173
00:10:41,155 --> 00:10:46,235
실행 시간은 상당히 느려집니다.

174
00:10:46,235 --> 00:10:52,240
자,이것들은 팁이고,연구 논문들도 이 조언들을 언급하고 있습니다.

175
00:10:52,240 --> 00:10:56,940
하지만 제 개인적으로는 프로덕션 시스템을 만들 때,

176
00:10:56,940 --> 00:10:59,535
이런 방법들을 사용할 의향은 없습니다.이것들이 벤치마크에서나

177
00:10:59,535 --> 00:11:03,205
우위를 점하는 경쟁에서 더 잘 수행한다고 해도 말이죠.

178
00:11:03,205 --> 00:11:08,345
많은 컴퓨터 비전 문제가 작은 데이터 영역에 있기 때문에

179
00:11:08,345 --> 00:11:12,620
다른 사람들은 네트워크 아키텍처에 대해 많은 핸드 엔지니어링을 수행했습니다.

180
00:11:12,620 --> 00:11:17,400
그리고 하나의 비전 문제에서 잘 작동하는 신경망은 놀라울 만큼,

181
00:11:17,400 --> 00:11:21,010
그러나 자주 다른 비전 문제들에서도 작동할 것입니다.

182
00:11:21,010 --> 00:11:25,295
따라서 실용적인 시스템을 구축하려면

183
00:11:25,295 --> 00:11:29,796
종종 다른 사람의 신경망 구조로 시작해야합니다.

184
00:11:29,796 --> 00:11:32,810
가능하다면,오픈 소스 구현을 사용할 수 있습니다.

185
00:11:32,810 --> 00:11:35,770
왜냐하면 오픈 소스 도구들이

186
00:11:35,770 --> 00:11:39,120
학습 속도,사례 스케줄러 및 기타 하이퍼 파라미터와 같이

187
00:11:39,120 --> 00:11:42,478
까다로운 세부 사항을 모두 파악했을 수 있기 때문입니다.

188
00:11:42,478 --> 00:11:46,350
그리고 마침내 누군가는 이렇게 수십 개의 GP를 사용하고,백만 가지 이상의 이미지에 대해

189
00:11:46,350 --> 00:11:51,926
모델을 훈련하는 데에 수 주의 시간을 할애했었을 지도 모릅니다.

190
00:11:51,926 --> 00:11:56,565
따라서 다른 사람의 사전 훈련 된 모델을 사용하고 데이터 세트를 미세 조정하면

191
00:11:56,565 --> 00:12:00,610
응용 프로그램에서 훨씬 빠르게 진행될 수 있습니다.

192
00:12:00,610 --> 00:12:05,048
물론 여러분이 컴퓨팅 리소스와 기울기를 가지고 있다면

193
00:12:05,048 --> 00:12:09,840
여러분의 네트워크를 처음부터 교육하는 것을 막을 수는 없습니다

194
00:12:09,840 --> 00:12:14,326
사실 자신의 컴퓨터 비전 알고리즘을 발명하고 싶다면

195
00:12:14,326 --> 00:12:16,840
그렇게해야 할 수도 있습니다.

196
00:12:16,840 --> 00:12:18,920
자,이번 주 강의는 여기까지 입니다.

197
00:12:18,920 --> 00:12:20,960
많은 컴퓨터 비전 아키텍처가

198
00:12:20,960 --> 00:12:24,605
어떤 일을 아닌지 감을 얻어가시기를 바랍니다.

199
00:12:24,605 --> 00:12:28,055
이번 주 연습에서는

200
00:12:28,055 --> 00:12:32,740
실제로 다른 프로그램 프레임 워크를 배우고 공명을 구현하는 데 사용합니다.

201
00:12:32,740 --> 00:12:37,970
자, 연습문제를 즐기시고, 다시 만나뵙길 바랍니다.