1
00:00:00,000 --> 00:00:01,650
深度学习已被成功地应用于

2
00:00:01,650 --> 00:00:03,850
计算机视觉 自然语言处理

3
00:00:03,850 --> 00:00:05,990
语音识别 在线广告 

4
00:00:05,990 --> 00:00:08,550
物流等许多许多问题。

5
00:00:08,550 --> 00:00:10,470
对于深度学习在计算机视觉中的

6
00:00:10,470 --> 00:00:12,990
应用及现状

7
00:00:12,990 --> 00:00:15,570
有几个独特的方面

8
00:00:15,570 --> 00:00:20,160
在这个视频中 我将与大家分享我对深度学习

9
00:00:20,160 --> 00:00:25,335
在计算机视觉中的一些观察 希望可以对你做相关阅读时有所帮助

10
00:00:25,335 --> 00:00:27,270
帮助你了解其中的设计理念

11
00:00:27,270 --> 00:00:31,880
以及你如何搭建用于计算机视觉的系统

12
00:00:31,880 --> 00:00:38,180
你可以认为大多数机器学习问题是

13
00:00:38,180 --> 00:00:40,730
从拥有相对较少数据

14
00:00:40,730 --> 00:00:45,585
到拥有大量数据之间的问题

15
00:00:45,585 --> 00:00:50,840
例如 我认为现在我们已有相当大量的

16
00:00:50,840 --> 00:00:57,230
用于语音识别的数据 相对于问题的复杂程度来说

17
00:00:57,230 --> 00:00:59,540
即便如今有相当数量的数据

18
00:00:59,540 --> 00:01:05,315
可用于图像识别或图像分类

19
00:01:05,315 --> 00:01:07,460
由于图像识别是一个复杂的问题

20
00:01:07,460 --> 00:01:11,222
需要处理所有像素然后弄清楚它是什么

21
00:01:11,222 --> 00:01:16,250
即使在线数据集已然相当大了 有上百万图像

22
00:01:16,250 --> 00:01:20,098
感觉上我们还希望有更多的数据

23
00:01:20,098 --> 00:01:28,006
还有一些问题 比如目标检测 我们只有更少的数据。

24
00:01:28,006 --> 00:01:31,340
给大家一个小提示 图像识别的问题就是

25
00:01:31,340 --> 00:01:34,912
给定一幅画 回答图中是不是一只猫的问题

26
00:01:34,912 --> 00:01:39,590
目标检测 是看图片然后是用

27
00:01:39,590 --> 00:01:41,948
一些矩形框(称作边界框)告诉你

28
00:01:41,948 --> 00:01:44,935
目标(例如汽车)在图片中的什么位置

29
00:01:44,935 --> 00:01:46,760
因此 由于获得这些边框的成本

30
00:01:46,760 --> 00:01:52,470
比标注目标和画出边界框的成本更高

31
00:01:52,470 --> 00:01:57,905
相比于图像识别 我们往往用更少的数据做目标检测

32
00:01:57,905 --> 00:02:02,083
我们会在下周讨论目标检测

33
00:02:02,083 --> 00:02:06,605
如果纵观机器学习问题的谱系

34
00:02:06,605 --> 00:02:12,095
你会看到 一般情况下 当你有很多数据时候 你往往会发现人们

35
00:02:12,095 --> 00:02:18,300
差不多使用比较简单的算法 以及更少的人工设计也就可以了

36
00:02:18,300 --> 00:02:23,480
所以 不太需要针对问题来仔细地设计特征

37
00:02:23,480 --> 00:02:25,910
取而代之 当你有大量数据的时候 你可以用一个巨大的神经网络

38
00:02:25,910 --> 00:02:28,507
甚至更为简单的结构 就让一个神经网络

39
00:02:28,507 --> 00:02:32,415
学习我们想要学习的 

40
00:02:32,415 --> 00:02:36,560
相比之下 当你没有那么多数据时 

41
00:02:36,560 --> 00:02:41,713
通常会看到人们做更多的人工设计 

42
00:02:41,713 --> 00:02:46,660
说得更通俗一点 就是做更多的手工处理

43
00:02:46,660 --> 00:02:49,880
但我认为 当你没有多少数据时

44
00:02:49,880 --> 00:02:54,809
人工设计实际上是获得良好效果的最好方法

45
00:02:54,809 --> 00:02:59,435
所以 当我看机器学习的应用时

46
00:02:59,435 --> 00:03:04,595
我想 通常学习算法有两个知识来源

47
00:03:04,595 --> 00:03:07,430
一个知识来源是标记的数据

48
00:03:07,430 --> 00:03:11,525
实际上就是用于监督学习的 (x, y)

49
00:03:11,525 --> 00:03:14,652
第二个知识来源是人工设计

50
00:03:14,652 --> 00:03:17,045
而且有很多方法可以用来手工设计一个系统

51
00:03:17,045 --> 00:03:20,435
它可以从精心设计特性

52
00:03:20,435 --> 00:03:22,281
到精心设计网络结构

53
00:03:22,281 --> 00:03:26,485
亦或系统的其他组件

54
00:03:26,485 --> 00:03:28,880
所以 当你没有太多的标记好的数据时

55
00:03:28,880 --> 00:03:32,270
就需要在人工设计上多下功夫 

56
00:03:32,270 --> 00:03:38,165
我认为 计算机视觉正试图学习一个非常复杂的函数 

57
00:03:38,165 --> 00:03:42,815
我们经常觉得没有足够的 用于计算机视觉的数据 

58
00:03:42,815 --> 00:03:45,362
尽管数据集正在变得越来越大 

59
00:03:45,362 --> 00:03:48,845
通常 我们还是没有满足需要的那么多的数据

60
00:03:48,845 --> 00:03:52,100
这就是为什么数据计算机视觉一直以来

61
00:03:52,100 --> 00:03:57,178
都更为依赖于人工设计

62
00:03:57,178 --> 00:04:00,425
我认为这也是为什么在计算机视觉领域

63
00:04:00,425 --> 00:04:05,040
要么是开发了相当复杂的网络结构

64
00:04:05,040 --> 00:04:08,720
因为在缺乏更多的数据的情况下

65
00:04:08,720 --> 00:04:13,400
获得良好性能的途径就是花更多时间 去精心设计

66
00:04:13,400 --> 00:04:17,130
或者是胡乱摆弄网络结构

67
00:04:17,130 --> 00:04:19,340
千万不要以为我是在贬损人工设计

68
00:04:19,340 --> 00:04:23,525
那完全不是我的意图

69
00:04:23,525 --> 00:04:27,830
当你没有足够的数据时 人工设计是一项非常难的

70
00:04:27,830 --> 00:04:32,135
且非常需要技巧的工作 它需要很深入的洞察力

71
00:04:32,135 --> 00:04:36,875
那些有对人工设计有深刻见解的人会获得更好的效果

72
00:04:36,875 --> 00:04:39,590
并且 在没有足够数据的情况下

73
00:04:39,590 --> 00:04:43,085
对项目而言这也是一个巨大的贡献

74
00:04:43,085 --> 00:04:47,150
当有很多的数据时 我便不会在人工设计上花时间

75
00:04:47,150 --> 00:04:52,588
而是会把花时间花在建立学习系统上

76
00:04:52,588 --> 00:04:57,610
但从历史的角度看 我认为对于计算机视觉使用非常小的数据集的担忧

77
00:04:57,610 --> 00:04:59,965
以及对一直以来计算机视觉文献

78
00:04:59,965 --> 00:05:02,700
依赖于大量的人工设计的担忧

79
00:05:02,700 --> 00:05:06,640
即使最近几年 数据的量级

80
00:05:06,640 --> 00:05:10,540
伴随着正确的计算机视觉任务的有了显著的增加 

81
00:05:10,540 --> 00:05:12,580
我认为这已经导致

82
00:05:12,580 --> 00:05:17,185
一直以来在做的人工设计的数量有了明显减少 

83
00:05:17,185 --> 00:05:21,480
但仍然有很多网络结构和计算机视觉方面的人工设计

84
00:05:21,480 --> 00:05:26,890
这就是为什么仍能在计算机视觉领域 看到非常复杂的超级疯狂的选择

85
00:05:26,890 --> 00:05:31,294
比在很多其它学科所做的更为复杂

86
00:05:31,294 --> 00:05:33,550
实际上 因为你通常有

87
00:05:33,550 --> 00:05:38,050
比图像识别数据集更小的目标检测数据集

88
00:05:38,050 --> 00:05:43,360
当谈及目标检测时 即下个星期的任务

89
00:05:43,360 --> 00:05:48,280
你会看到算法

90
00:05:48,280 --> 00:05:54,040
变得更为复杂 并具有更为特定化的组件

91
00:05:54,040 --> 00:06:00,100
所幸的是 当只有很少量数据时 有一个能提供很大帮助的东西 就是迁移学习

92
00:06:00,100 --> 00:06:10,395
我想说 之前演讲稿中关于tigger 

93
00:06:10,395 --> 00:06:13,850
misty的例子 这些都不是检测问题 

94
00:06:13,850 --> 00:06:18,666
你只有非常少的数据 迁移学习会有很大帮助

95
00:06:18,666 --> 00:06:21,120
那是另一套技术

96
00:06:21,120 --> 00:06:24,255
被大量使用于只有相对很少数据的情况

97
00:06:24,255 --> 00:06:27,100
如果你看一下计算机视觉文献

98
00:06:27,100 --> 00:06:29,243
看一下那里都有什么思路或者点子

99
00:06:29,243 --> 00:06:32,293
有也会发现 人们真的是充满激情 

100
00:06:32,293 --> 00:06:34,800
他们相当投入 并且在标准化的基准数据集

101
00:06:34,800 --> 00:06:38,730
以及赢得比赛方面确实做得很好

102
00:06:38,730 --> 00:06:41,925
对于计算机视觉的研究者来说 如果你在基准数据上做得很好 

103
00:06:41,925 --> 00:06:45,395
就很容易发表文章

104
00:06:45,395 --> 00:06:49,155
所以 很多人关注于在那些基准数据上得到好的结果

105
00:06:49,155 --> 00:06:51,615
这样做的好处是

106
00:06:51,615 --> 00:06:56,125
它帮助整个学科领域搞清楚那些是最有效的算法

107
00:06:56,125 --> 00:07:02,475
但你也看到 在文章中人们做一些工作 是为了让你在基准数据上获得好结果

108
00:07:02,475 --> 00:07:04,310
但你不会真的把这些算法用于

109
00:07:04,310 --> 00:07:08,665
你现实中要发布的产品或者系统上

110
00:07:08,665 --> 00:07:11,379
因此这儿我有一些对在基准数据上做的好的小建议

111
00:07:11,379 --> 00:07:15,960
如果我要将一个系统放到实际服务客户的产品中

112
00:07:15,960 --> 00:07:20,940
这些东西我自己基本上是不曾也不会用的

113
00:07:20,940 --> 00:07:23,105
但也有例外 一个是 集成

114
00:07:23,105 --> 00:07:24,870
它的意思是

115
00:07:24,870 --> 00:07:27,410
在弄清楚了你要什么神经网络

116
00:07:27,410 --> 00:07:33,120
独立地训练多个神经网络 然后对它们的输出求平均作为结果

117
00:07:33,120 --> 00:07:35,610
随机初始化3个 5个或者

118
00:07:35,610 --> 00:07:40,095
7个神经网络 然后训练所有这些神经网络

119
00:07:40,095 --> 00:07:41,890
然后对它们的输出求平均

120
00:07:41,890 --> 00:07:44,943
顺便说一下 这个非常重要 要对它们的输出 ŷ 求平均，

121
00:07:44,943 --> 00:07:47,660
不要对它们的权重求平均 那样是行不通的

122
00:07:47,660 --> 00:07:50,410
比方 你会说 7个神经网络

123
00:07:50,410 --> 00:07:53,348
给出7个不同的预测，然后对它们求平均。

124
00:07:53,348 --> 00:07:57,725
这个将你的结果提升可能%1或2%

125
00:07:57,725 --> 00:08:02,015
在某些基准数据测试上 有些许更好的结果

126
00:08:02,015 --> 00:08:04,569
这会让你做得稍微好一点儿

127
00:08:04,569 --> 00:08:11,544
有时候或许就是%1或2%的提高 就确实能帮助你赢得一个比赛

128
00:08:11,544 --> 00:08:15,200
但是 因为集成意味着要在每幅图像上进行测试

129
00:08:15,200 --> 00:08:17,810
有或许需要将一幅图像输入到

130
00:08:17,810 --> 00:08:21,965
3到15个不同的神经网络 这很非常典型的情况。

131
00:08:21,965 --> 00:08:25,570
这样会把运行速度降低3到15倍

132
00:08:25,570 --> 00:08:26,885
有时候降低得甚至更多

133
00:08:26,885 --> 00:08:29,655
所以 集成是人们在基准数据测试上获得好成绩

134
00:08:29,655 --> 00:08:33,111
以及赢得比赛的小帖士之一 

135
00:08:33,111 --> 00:08:38,275
但是我认为它从来没有被用到服务真正客户的产品中

136
00:08:38,275 --> 00:08:41,400
我猜测 除非是有巨大的计算资源 并且不在乎

137
00:08:41,400 --> 00:08:44,996
为每一幅客户的图像烧掉更多的钱

138
00:08:44,996 --> 00:08:50,195
另外一个你在文章中看到 真正有助于基准数据测试的东西

139
00:08:50,195 --> 00:08:52,690
是测试时使用多重剪切(multi-crop)

140
00:08:52,690 --> 00:08:58,055
我所说的多重剪切 是你已经看到过的如何做数据增强

141
00:08:58,055 --> 00:09:04,910
多重剪切也就是在你的测试图像上 应用数据增强的一种形式

142
00:09:04,910 --> 00:09:07,470
让我们以一个猫的图像为例

143
00:09:07,470 --> 00:09:12,155
简单地将其拷贝四次 包括附加的两个版本

144
00:09:12,155 --> 00:09:14,585
有一个技术被称为 10次剪切

145
00:09:14,585 --> 00:09:19,460
基本上来说 假设取这个中心区域进行裁剪

146
00:09:19,460 --> 00:09:22,097
然后让它在你的网络中运行

147
00:09:22,097 --> 00:09:24,830
然后 把那个裁剪移到左上角

148
00:09:24,830 --> 00:09:27,145
显示为绿色的右上角

149
00:09:27,145 --> 00:09:30,980
显示为换色的左下角

150
00:09:30,980 --> 00:09:33,162
显示为桔色的右下角

151
00:09:33,162 --> 00:09:34,950
并且把它也在你的网络中运行一下

152
00:09:34,950 --> 00:09:37,060
然后在镜像的图像上做同样的事情

153
00:09:37,060 --> 00:09:38,743
就想这样 我会取这个中心部分剪切

154
00:09:38,743 --> 00:09:41,670
然后去四个角的剪切

155
00:09:41,670 --> 00:09:44,165
于是这里和这里有一个中心部分剪切

156
00:09:44,165 --> 00:09:46,210
这里和这里有四个角的剪切

157
00:09:46,210 --> 00:09:49,540
把它们累加起来 上面提到的有10个不同的剪切

158
00:09:49,540 --> 00:09:51,600
因此这就是 10次剪切 名字的来由

159
00:09:51,600 --> 00:09:54,980
所以你要做的是 把这十幅图像都放入

160
00:09:54,980 --> 00:09:59,360
你的网络中运行 然后对他们的结果求平均

161
00:09:59,360 --> 00:10:02,660
因此如果你有计算资源 就可以这么做

162
00:10:02,660 --> 00:10:04,530
或许你并不需要10次剪切那么多

163
00:10:04,530 --> 00:10:05,900
那么 你可以使用若干次剪切

164
00:10:05,900 --> 00:10:10,960
这也许能为一个产品化的系统带来些许性能提升

165
00:10:10,960 --> 00:10:16,190
产品化的系统，我是说你发布给实际用户的系统

166
00:10:16,190 --> 00:10:19,760
但是这个另一个绝大多数情况下用来

167
00:10:19,760 --> 00:10:24,110
在基准数据上获得良好表现的技术 而不是用于实际的产品化系统中

168
00:10:24,110 --> 00:10:27,550
集成学习的重大问题之一是

169
00:10:27,550 --> 00:10:30,575
你需要保留所有那些不同的网络随时可用

170
00:10:30,575 --> 00:10:33,835
那样会额外占用很多内存

171
00:10:33,835 --> 00:10:37,600
对于多重剪切 你只需要保存一个网络

172
00:10:37,600 --> 00:10:41,155
所以它不会吞噬太多内存

173
00:10:41,155 --> 00:10:46,235
但它仍然会很大程度上降低运行速度

174
00:10:46,235 --> 00:10:52,240
这些建议 你也会在科研论文会中看到

175
00:10:52,240 --> 00:10:56,940
但是 在构建产品化的系统时

176
00:10:56,940 --> 00:10:59,535
我个人不倾向于使用这些方法 尽管对于在基准数据

177
00:10:59,535 --> 00:11:03,205
以及赢得比赛上有更好的效果 它们的结果非常棒

178
00:11:03,205 --> 00:11:08,345
因为很多计算机视觉问题是在拥有少量数据的范畴

179
00:11:08,345 --> 00:11:12,620
前人已经对网络结构做了大量的人工处理

180
00:11:12,620 --> 00:11:17,400
一个神经网络在某个视觉问题上效果很好的网络 通常惊人的是

181
00:11:17,400 --> 00:11:21,010
它们大多在另外的视觉问题上也能用

182
00:11:21,010 --> 00:11:25,295
因此 要搭建一个是用的系统 你一般所要做的是

183
00:11:25,295 --> 00:11:29,796
从别人的神经网络架构作为开始

184
00:11:29,796 --> 00:11:32,810
而且如果可能 你可以用开源实现

185
00:11:32,810 --> 00:11:35,770
因为那个开源实现或许已经搞清楚了

186
00:11:35,770 --> 00:11:39,120
所有繁复细致的细节 比如学习率

187
00:11:39,120 --> 00:11:42,478
调度 以及其它超参数

188
00:11:42,478 --> 00:11:46,350
最后 其他人或许花了好几个星期训练一个模型

189
00:11:46,350 --> 00:11:51,926
用了半打GPU以及上百万的图像

190
00:11:51,926 --> 00:11:56,565
所以 使用别人预先训练的模型 然后在你的数据集上进行微调

191
00:11:56,565 --> 00:12:00,610
你通常可以在你的应用上取得非常快的进展

192
00:12:00,610 --> 00:12:05,048
当然 如果你有计算资源 并且有意愿去做

193
00:12:05,048 --> 00:12:09,840
大可不必因我所言而不去从头开始训练你自己的网络

194
00:12:09,840 --> 00:12:14,326
实际上 如果你想要打造自己的计算机视觉算法

195
00:12:14,326 --> 00:12:16,840
从头训练你自己的网络 或许是不得不去做的事

196
00:12:16,840 --> 00:12:18,920
这就是这周的全部内容

197
00:12:18,920 --> 00:12:20,960
我希望 通过了解一定数量的

198
00:12:20,960 --> 00:12:24,605
计算机视觉架构 能够有助于你对什么网络能奏效的的感觉有一些帮助

199
00:12:24,605 --> 00:12:28,055
这周 从课后练习中你会切实得学到

200
00:12:28,055 --> 00:12:32,740
其它编程体系结构 并用它们去实现你的想法

201
00:12:32,740 --> 00:12:37,970
所以 希望你喜欢这个练习 我们下周见