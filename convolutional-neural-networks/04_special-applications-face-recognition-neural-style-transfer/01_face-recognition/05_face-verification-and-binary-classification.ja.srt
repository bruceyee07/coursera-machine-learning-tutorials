1
00:00:00,000 --> 00:00:02,580
Triplet Loss は 顔認識のための

2
00:00:02,580 --> 00:00:05,950
ConvNet パラメータを学ぶ いいやり方だ

3
00:00:05,950 --> 00:00:08,490
このパラメータを学ぶ 別の方法がある

4
00:00:08,490 --> 00:00:11,475
顔認識がどのようにして

5
00:00:11,475 --> 00:00:15,175
純粋な２項分類の問題なるのかを見てみよう

6
00:00:15,175 --> 00:00:17,085
ニューラルネットワークを訓練する別の方法は

7
00:00:17,085 --> 00:00:19,740
このニューラルネットワークのペアで

8
00:00:19,740 --> 00:00:25,260
シャムネットワークを作り ここを埋める値を どちらも計算する

9
00:00:25,260 --> 00:00:27,255
128次元の値とかだ

10
00:00:27,255 --> 00:00:28,770
もしかしたら もっと高次元かもしれないけど

11
00:00:28,770 --> 00:00:31,530
それから これらを

12
00:00:31,530 --> 00:00:36,375
ロジスティック回帰部に入力して 予測をすればいい

13
00:00:36,375 --> 00:00:42,705
これらが 同じ人なら 目的出力は１となり

14
00:00:42,705 --> 00:00:46,530
異なる人なら ０となる

15
00:00:46,530 --> 00:00:52,960
これが 顔認識を ただの２項分類問題として扱う方法だ

16
00:00:52,960 --> 00:00:58,890
そして これは このようなシステムを訓練する Triplet Loss の代わりになる

17
00:00:58,890 --> 00:01:03,405
では この最後の ロジスティック回帰部は 実際には 何をしているのか？

18
00:01:03,405 --> 00:01:08,400
出力 yハット は シグモイド関数で

19
00:01:08,400 --> 00:01:12,750
ある特徴量のセットが投入される ただし 単に これらの符号を

20
00:01:12,750 --> 00:01:18,690
喰わせるのではなく 符号間の差異を取る

21
00:01:18,690 --> 00:01:20,795
どういうことか 説明しよう

22
00:01:20,795 --> 00:01:30,020
k=１~128で 絶対値の合計を書く

23
00:01:30,020 --> 00:01:35,525
この異なる２つの符号間の要素毎のだ

24
00:01:35,525 --> 00:01:39,930
書き終えたら どいうことか説明するよ

25
00:01:39,930 --> 00:01:45,335
この表記では f(x(i)) は 画像 x(i) を符号化したものだ

26
00:01:45,335 --> 00:01:52,210
添え字の k は このベクトルの k 番目の要素を意味する

27
00:01:52,210 --> 00:01:59,625
これが これら２つの符号の 絶対値での 要素毎の差だ

28
00:01:59,625 --> 00:02:03,240
そして これらの128個の数を

29
00:02:03,240 --> 00:02:07,140
特徴量と見なして ロジスティック回帰に喰わせる

30
00:02:07,140 --> 00:02:11,350
そして 最後のロジスティック回帰では 追加のパラメータ wi

31
00:02:11,350 --> 00:02:16,030
b を 普通のロジスティック回帰と同じように持つ

32
00:02:16,030 --> 00:02:21,990
そして これらの128個の特徴量についての重みを訓練する

33
00:02:21,990 --> 00:02:24,105
そうして

34
00:02:24,105 --> 00:02:28,225
この２つの画像が 同じ人か 違う人か 予測できるようになる

35
00:02:28,225 --> 00:02:31,035
これは とても合理的なやり方だ

36
00:02:31,035 --> 00:02:37,300
０か１か 同じ人か違う人か 予測するための学習だ

37
00:02:37,300 --> 00:02:40,230
この緑の下線の式の計算には

38
00:02:40,230 --> 00:02:44,220
他にも いくつか方法がある

39
00:02:44,220 --> 00:02:51,405
例えば 別の式は これ k - f(x(j))

40
00:02:51,405 --> 00:02:56,220
k の２乗 割るf(x(i))

41
00:02:56,220 --> 00:03:02,980
+ f(x(j))k これは 時々 カイ２乗式と呼ばれる

42
00:03:02,980 --> 00:03:05,700
これは ギリシャ文字の χ(カイ) だ

43
00:03:05,700 --> 00:03:08,874
これは カイ２乗類似度 とも呼ばれる

44
00:03:08,874 --> 00:03:15,810
これと 他のやり方は この DeepFace 論文で探求されている

45
00:03:15,810 --> 00:03:18,015
この論文は 前にも引用したよね

46
00:03:18,015 --> 00:03:20,760
この学習式では

47
00:03:20,760 --> 00:03:23,801
入力は ペア画像で

48
00:03:23,801 --> 00:03:28,920
これが 学習入力 x と y だ

49
00:03:28,920 --> 00:03:32,085
y は ０か１で 入力したペアが

50
00:03:32,085 --> 00:03:35,680
似ているか 似ていないかで決まる

51
00:03:35,680 --> 00:03:37,070
前回のと同様に

52
00:03:37,070 --> 00:03:40,065
シャム ネットワークを訓練して

53
00:03:40,065 --> 00:03:44,035
この上のニューラルネットワークのパラメータが

54
00:03:44,035 --> 00:03:48,455
この下のニューラルネットワークのパラメータと結びつく

55
00:03:48,455 --> 00:03:52,235
このシステムも 同様に とてもうまく機能する

56
00:03:52,235 --> 00:03:53,420
最後に言っておくことがある

57
00:03:53,420 --> 00:03:58,905
実用上 非常に有意義な計算上の工夫がある

58
00:03:58,905 --> 00:04:00,375
もし これが新しい画像の場合

59
00:04:00,375 --> 00:04:03,910
これが 入場ゲートに向かって歩いてる従業員で

60
00:04:03,910 --> 00:04:08,815
ゲートが開くのを期待している そして これが データベースの画像だとすると

61
00:04:08,815 --> 00:04:11,190
計算する代わりに

62
00:04:11,190 --> 00:04:17,520
毎回 ここを埋めるのではなく

63
00:04:17,520 --> 00:04:20,970
これを事前に計算しておくことができる

64
00:04:20,970 --> 00:04:22,970
そして 新しい従業員が歩いてきたら

65
00:04:22,970 --> 00:04:29,500
この上の ConvNet を使って 符号化を計算し

66
00:04:29,500 --> 00:04:31,020
それを 事前計算しておいた符号と

67
00:04:31,020 --> 00:04:36,730
比較できる そして 予測 yハットを生成できる

68
00:04:36,730 --> 00:04:40,770
生の画像を保存しておく必要は無いから

69
00:04:40,770 --> 00:04:44,880
そして とても巨大な従業員データベースがあるなら

70
00:04:44,880 --> 00:04:50,935
毎回 全ての従業員にについて 符号化を計算する必要は無い

71
00:04:50,935 --> 00:04:52,980
計算しないというアイデア

72
00:04:52,980 --> 00:04:56,880
これらの事前符号化で 計算を著しく節約できる

73
00:04:56,880 --> 00:05:00,775
この種の事前計算は

74
00:05:00,775 --> 00:05:02,950
シャム構造を持つようなものに対し 有効だ

75
00:05:02,950 --> 00:05:07,485
２項分類として顔認識を行う場合にも

76
00:05:07,485 --> 00:05:11,160
前のビデオで説明した

77
00:05:11,160 --> 00:05:15,070
Triplet Loss を使った符号化を学習する場合にもね

78
00:05:15,070 --> 00:05:16,760
じゃ まとめると

79
00:05:16,760 --> 00:05:19,530
顔認識を教師有り学習として扱うには

80
00:05:19,530 --> 00:05:23,460
今回は 学習セットを 単なる画像のペアとして作ればよくて

81
00:05:23,460 --> 00:05:28,045
同じ人の写真のペアなら

82
00:05:28,045 --> 00:05:34,366
目的ラベルが１で

83
00:05:34,366 --> 00:05:38,880
違う人なら０

84
00:05:38,880 --> 00:05:40,845
色んなペアを使って

85
00:05:40,845 --> 00:05:45,660
誤差逆伝播を使って ニューラルネットワークを訓練して シャム ネットワークを訓練する

86
00:05:45,660 --> 00:05:49,755
今見た２項分類バージョンは

87
00:05:49,755 --> 00:05:53,918
顔認証をする場合も 拡張した顔認識をする場合も

88
00:05:53,918 --> 00:05:55,645
どちらも とても良く機能する

89
00:05:55,645 --> 00:05:57,645
そんな風に 理解してもらえたらいいな

90
00:05:57,645 --> 00:05:59,490
顔認証を訓練するにせよ

91
00:05:59,490 --> 00:06:05,000
One Shot Learning の顔認識システムを訓練するにせよね