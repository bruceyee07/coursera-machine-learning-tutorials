1
00:00:00,000 --> 00:00:04,650
關於前面提到的神經網路，有個方法可以學出參數

2
00:00:04,650 --> 00:00:07,875
能給你一個良好的人臉照片的編碼

3
00:00:07,875 --> 00:00:11,930
就是定義「三元損失」函數 (triplet loss)，
用他來執行梯度下降法

4
00:00:11,930 --> 00:00:13,425
讓我們來看看這是什麼意思

5
00:00:13,425 --> 00:00:15,341
要利用三元損失 (tripet loss)

6
00:00:15,341 --> 00:00:18,630
你需要比較兩對照片

7
00:00:18,630 --> 00:00:21,365
舉個例子，給定這一張圖

8
00:00:21,365 --> 00:00:24,075
如果要學出這神經網路的參數

9
00:00:24,075 --> 00:00:27,605
你必須同時看過若干張照片

10
00:00:27,605 --> 00:00:29,685
例如，給你這一對照片

11
00:00:29,685 --> 00:00:33,895
你想要讓他們的編碼很接近，因為這兩張是同一個人

12
00:00:33,895 --> 00:00:35,925
而對於這一對照片

13
00:00:35,925 --> 00:00:41,500
你想讓他們的編碼很不一樣，因為這兩張是不同人

14
00:00:41,500 --> 00:00:44,770
在三元損失的術語中

15
00:00:44,770 --> 00:00:49,290
你都會看著一張「錨」照片 (anchor image)

16
00:00:49,290 --> 00:00:53,820
然後你要讓錨照片和「正例」照片之間的距離

17
00:00:53,820 --> 00:00:55,200
— 也就是正面的例子

18
00:00:55,200 --> 00:00:58,025
意思是同一個人 — 變得比較相近

19
00:00:58,025 --> 00:01:01,470
而當錨照片是和反面的例子

20
00:01:01,470 --> 00:01:07,455
做比較的時候，你想要兩者之間的距離比較遠。

21
00:01:07,455 --> 00:01:10,755
所以這就是「三元損失」名字的由來

22
00:01:10,755 --> 00:01:15,145
你每次都要同時觀察三張圖片

23
00:01:15,145 --> 00:01:17,415
你會看一張「錨」圖片

24
00:01:17,415 --> 00:01:22,185
一張「正面」照片、還有一張「反例」照片

25
00:01:22,185 --> 00:01:25,993
我把「錨」「正例」「反例」縮寫成 "A",

26
00:01:25,993 --> 00:01:29,561
"P" 和 "N"。用公式來描述的話

27
00:01:29,561 --> 00:01:32,700
你所要的是，讓你的

28
00:01:32,700 --> 00:01:36,060
神經網路的參數造成的編碼具有下列性質：

29
00:01:36,060 --> 00:01:39,735
你想讓「錨」圖片的編碼

30
00:01:39,735 --> 00:01:44,445
減去「正例」圖片的編碼

31
00:01:44,445 --> 00:01:47,865
你想讓這差距小，特別是

32
00:01:47,865 --> 00:01:52,950
你希望讓這個小於等於某個距離

33
00:01:52,950 --> 00:01:58,900
也就是「錨」的編碼和「反例」編碼差距的範數的平方

34
00:01:58,900 --> 00:02:02,485
也就是這個是 d(A, P)

35
00:02:02,485 --> 00:02:06,610
而這個是 d(A, N)

36
00:02:06,610 --> 00:02:11,280
你可以把 d 看作是一種距離的函數

37
00:02:11,280 --> 00:02:14,700
所以我們叫他 d。

38
00:02:14,700 --> 00:02:18,825
那如果把右邊這一項移到左邊

39
00:02:18,825 --> 00:02:25,140
你就會得到 f(A) 減 f(P) 然後平方，減掉...

40
00:02:25,140 --> 00:02:27,675
讓我們拿右邊這一項

41
00:02:27,675 --> 00:02:31,404
... 減去 f(N) 然後平方

42
00:02:31,404 --> 00:02:34,800
你希望讓這個小於等於零

43
00:02:34,800 --> 00:02:38,280
不過呢，在這裡我們要改一下這個公式

44
00:02:38,280 --> 00:02:41,420
因為，有個很顯而易見的方法可以讓這式子成立

45
00:02:41,420 --> 00:02:44,245
就是把每個東西都學成 0

46
00:02:44,245 --> 00:02:46,275
如果 f 總是等於 0

47
00:02:46,275 --> 00:02:47,955
那這就是 0 減 0

48
00:02:47,955 --> 00:02:50,545
也就是 0；這邊是 0 減 0 也等於 0

49
00:02:50,545 --> 00:02:57,140
所以呢，只要宣稱任何圖片經過 f 都變成零向量

50
00:02:57,140 --> 00:03:01,410
你很容易就能滿足這個式子

51
00:03:01,410 --> 00:03:07,465
所以，為了不要讓神經網路對每個編碼都輸出 0

52
00:03:07,465 --> 00:03:12,480
為了確保不要讓網路輸出的編碼長得都一樣

53
00:03:12,480 --> 00:03:16,285
— 另一種讓網路不經大腦輸出的方法

54
00:03:16,285 --> 00:03:20,246
就是讓每張照片的編碼都一模一樣

55
00:03:20,246 --> 00:03:25,400
這樣子的話，你也會得到 0 減 0

56
00:03:25,400 --> 00:03:28,075
因此為了不要讓神經網路這樣做

57
00:03:28,075 --> 00:03:32,370
我們要改變這個目標：

58
00:03:32,370 --> 00:03:36,985
這個不只要小於等於 0

59
00:03:36,985 --> 00:03:40,575
這個必須要比 0 還小一些

60
00:03:40,575 --> 00:03:45,755
更進一步說，如果我們說這必須要小於負 alpha

61
00:03:45,755 --> 00:03:49,235
這裡 alpha 是一個超參數

62
00:03:49,235 --> 00:03:53,475
就能防止神經網路不經大腦、輸出顯然的解答

63
00:03:53,475 --> 00:03:55,230
而依慣例，通常

64
00:03:55,230 --> 00:03:59,550
我們會在這裡寫加 alpha 而不會在另邊寫負 alpha

65
00:03:59,550 --> 00:04:02,763
這一項也稱作 margin (邊距)

66
00:04:02,763 --> 00:04:05,190
如果看過 support vector machine (支撐向量機)

67
00:04:05,190 --> 00:04:10,320
的文獻，你會對這個術語很熟悉

68
00:04:10,320 --> 00:04:12,675
不過沒聽過也不用擔心

69
00:04:12,675 --> 00:04:17,995
我們也可以改變上面這個公式，多加一個「邊距」項

70
00:04:17,995 --> 00:04:19,395
舉個例子

71
00:04:19,395 --> 00:04:23,260
假設邊距是 0.2

72
00:04:23,260 --> 00:04:24,855
如果在這例子

73
00:04:24,855 --> 00:04:29,550
錨圖和正例圖的 d 等於 0.5

74
00:04:29,550 --> 00:04:32,580
那麼當錨圖和反例圖之間的 d

75
00:04:32,580 --> 00:04:37,087
只大一點點時，例如 0.51，這樣你並不會滿意

76
00:04:37,087 --> 00:04:41,610
就算 0.51 比 0.5 還大

77
00:04:41,610 --> 00:04:43,917
你會說「這樣還不夠好」，我們要

78
00:04:43,917 --> 00:04:47,610
d(A, N) 遠大於 d(A, P)

79
00:04:47,610 --> 00:04:49,245
特別是

80
00:04:49,245 --> 00:04:53,520
你要這一項大於等於 0.7

81
00:04:53,520 --> 00:04:58,740
換句話說，讓兩者的差距、邊距至少有 0.2

82
00:04:58,740 --> 00:05:02,330
你可以把這項拉高，或把這項拉低

83
00:05:02,330 --> 00:05:06,305
讓他們至少有 alpha 的差距

84
00:05:06,305 --> 00:05:09,350
這個超參數 alpha 0.2

85
00:05:09,350 --> 00:05:14,530
也就是「正例到錨的距離」跟「反例到錨的距離」的差距

86
00:05:14,530 --> 00:05:17,491
所以這就是邊距參數的功用

87
00:05:17,491 --> 00:05:19,055
也就是

88
00:05:19,055 --> 00:05:25,720
把「錨-正例」這一對跟「錨-反例」這一對推開，遠離彼此

89
00:05:25,720 --> 00:05:29,435
因此，讓我們拿最下面這個式子

90
00:05:29,435 --> 00:05:31,160
在下一張投影片

91
00:05:31,160 --> 00:05:35,225
更正式地用它來定義「三元損失函數」(triplet loss)

92
00:05:35,225 --> 00:05:40,810
那麼，三元損失函數是定義在三張一組的圖片上

93
00:05:40,810 --> 00:05:43,465
給定三張圖片

94
00:05:43,465 --> 00:05:46,350
A, P 和 N

95
00:05:46,350 --> 00:05:48,990
代表「錨」、「正例」和「反例」

96
00:05:48,990 --> 00:05:53,245
「正例」和「錨」會是同一個人

97
00:05:53,245 --> 00:05:58,040
而「反例」的人和「錨」的不一樣

98
00:05:58,040 --> 00:06:01,515
我們將損失函數定義如下

99
00:06:01,515 --> 00:06:03,055
這些東西的損失

100
00:06:03,055 --> 00:06:06,465
也就是定義在這組三張圖片上的

101
00:06:06,465 --> 00:06:10,169
— 讓我先把前一張投影片的拷貝過來

102
00:06:10,169 --> 00:06:16,045
也就是 f(A) 減 f(P) 的平方

103
00:06:16,045 --> 00:06:23,790
再減掉 f(A) 減 f(N) 的平方

104
00:06:23,790 --> 00:06:26,755
然後加上 alpha，也就是「邊距」參數

105
00:06:26,755 --> 00:06:31,600
你希望讓這一整個小於等於 0

106
00:06:31,600 --> 00:06:34,365
所以要定義這個損失函數的話

107
00:06:34,365 --> 00:06:39,040
讓我們取這個東西和 0 之間的最大值

108
00:06:39,040 --> 00:06:42,030
這邊取了最大值以後

109
00:06:42,030 --> 00:06:45,225
只要這一個比零還小

110
00:06:45,225 --> 00:06:47,070
那損失就是零

111
00:06:47,070 --> 00:06:49,847
因為把一個小於等於零的東西

112
00:06:49,847 --> 00:06:52,705
和零去取最大值，會得到零

113
00:06:52,705 --> 00:06:56,370
所以只要你能把這個綠色底線的東西

114
00:06:56,370 --> 00:07:00,950
只要你能達到目標，讓這個小於或等於零

115
00:07:00,950 --> 00:07:04,150
這樣這個例子的損失就會是零

116
00:07:04,150 --> 00:07:05,355
反之

117
00:07:05,355 --> 00:07:07,650
如果這一個比零還大

118
00:07:07,650 --> 00:07:09,120
那你取最大值的時候

119
00:07:09,120 --> 00:07:10,665
他會去選擇

120
00:07:10,665 --> 00:07:12,343
綠色底線的這一項

121
00:07:12,343 --> 00:07:15,455
所以你會得到一個大於零的損失

122
00:07:15,455 --> 00:07:17,475
因此，為了讓損失越小越好

123
00:07:17,475 --> 00:07:22,130
就會導致把這項推往 0

124
00:07:22,130 --> 00:07:23,450
小於或等於零

125
00:07:23,450 --> 00:07:26,550
只要這項小於或等於零

126
00:07:26,550 --> 00:07:31,980
神經網路並不會在乎他要負多大

127
00:07:31,980 --> 00:07:33,990
那麼，這就是要怎麼去定義

128
00:07:33,990 --> 00:07:38,970
單一個「三元組」的損失。而你的網路整體的成本

129
00:07:38,970 --> 00:07:47,575
可以是你的訓練資料裡各個三元組的損失的總和

130
00:07:47,575 --> 00:07:55,080
假設你的訓練資料有 1000 個不同的人，共有 10000 張照片

131
00:07:55,080 --> 00:08:00,360
你要做的是拿這一萬張圖片去產生、

132
00:08:00,360 --> 00:08:03,720
去選出像這樣的三元組，然後訓練

133
00:08:03,720 --> 00:08:08,005
你的演算法，利用梯度下降法去減少這種成本函數

134
00:08:08,005 --> 00:08:14,145
也就是定義在一組三張的圖片，從你的訓練集挑出來的

135
00:08:14,145 --> 00:08:19,635
注意到，為了要定義這種「三元組」的資料集

136
00:08:19,635 --> 00:08:25,405
你的確會需要一些成對的 A 和 P、同一個人的一對圖片

137
00:08:25,405 --> 00:08:27,510
所以為了訓練你的系統

138
00:08:27,510 --> 00:08:32,600
你的資料集的確會需要來自同個人的多張圖片

139
00:08:32,600 --> 00:08:33,960
這就是為什麼在這例子裡

140
00:08:33,960 --> 00:08:38,040
我會說「如果你有 10000 張圖片，來自 1000 位不同的人」

141
00:08:38,040 --> 00:08:40,965
所以或許平均來說這 1000 個人

142
00:08:40,965 --> 00:08:44,310
每個人平均有 10 張圖片，這樣子來構成你的資料集

143
00:08:44,310 --> 00:08:47,085
如果每個人你都只有一張圖片

144
00:08:47,085 --> 00:08:49,725
那實際上你無法訓練這個系統。

145
00:08:49,725 --> 00:08:52,080
不過當然，訓練完以後

146
00:08:52,080 --> 00:08:54,205
如果你要用它..

147
00:08:54,205 --> 00:08:56,565
不過當然，訓練完這套系統後

148
00:08:56,565 --> 00:08:58,200
你可以把這系統用在

149
00:08:58,200 --> 00:09:02,685
你的單樣本問題，也就是在你的人臉辨認軟體

150
00:09:02,685 --> 00:09:06,945
對於你想要辨認的人，你可能只有他的一張照片。

151
00:09:06,945 --> 00:09:08,335
不過對於訓練資料

152
00:09:08,335 --> 00:09:12,780
你的確需要同一個人的不同照片

153
00:09:12,780 --> 00:09:14,940
至少你的訓練集的某一些人要這樣，如此一來

154
00:09:14,940 --> 00:09:19,000
你才擁有成對的「錨」和「正例」圖片。

155
00:09:19,000 --> 00:09:25,240
那麼實務上，你要怎麼從訓練集當中挑出這些三元組呢？

156
00:09:25,240 --> 00:09:28,635
如果你這樣做的話，會遭遇到難題：

157
00:09:28,635 --> 00:09:34,260
從訓練資料中隨機選出 A, P 和 N，只管 A 和 P 是同個人

158
00:09:34,260 --> 00:09:36,270
而 A 和 N 是不同人

159
00:09:36,270 --> 00:09:40,140
如果你任意隨機挑出他們，一個問題是

160
00:09:40,140 --> 00:09:44,160
這個不等式很容易就可以滿足

161
00:09:44,160 --> 00:09:48,405
因為隨便挑兩個人的照片

162
00:09:48,405 --> 00:09:51,945
有很高的機會 A 和 N 會非常不一樣

163
00:09:51,945 --> 00:09:55,740
比 A和P 還不一樣。我希望你還記得

164
00:09:55,740 --> 00:10:02,710
這個 d(A,P) 是前面幾張投影片談過的這種編碼

165
00:10:02,710 --> 00:10:06,190
所以這個會等於

166
00:10:06,190 --> 00:10:11,040
前面投影片看到的編碼差距的範數的平方

167
00:10:11,040 --> 00:10:14,640
如果 A 和 N 是隨機挑出的兩個人

168
00:10:14,640 --> 00:10:17,610
那麼這一項有很高的機率會很大

169
00:10:17,610 --> 00:10:21,630
比左邊那一項加邊距還要大

170
00:10:21,630 --> 00:10:24,405
所以神經網路無法從中學到東西

171
00:10:24,405 --> 00:10:25,940
因此，要建構訓練資料的話

172
00:10:25,940 --> 00:10:28,340
你要挑那種很難訓練的

173
00:10:28,340 --> 00:10:31,280
三元組 A, P 和 N

174
00:10:31,280 --> 00:10:38,685
更仔細地說，你的目標是讓所有的三元組都滿足這個條件

175
00:10:38,685 --> 00:10:44,995
因此，當我們說某個三元組很難，表示

176
00:10:44,995 --> 00:10:47,454
你挑的 A, P, N 會讓

177
00:10:47,454 --> 00:10:52,550
d(A,P) 會很靠近 d(A,N)

178
00:10:52,550 --> 00:10:54,020
這樣子的話

179
00:10:54,020 --> 00:10:57,230
演算法在學習的時候要花更多的力氣

180
00:10:57,230 --> 00:11:00,740
嘗試讓右邊這一項往上推

181
00:11:00,740 --> 00:11:04,030
或者讓左邊這項往下掉

182
00:11:04,030 --> 00:11:08,430
讓左邊右邊至少相隔 alpha 的邊距。

183
00:11:08,430 --> 00:11:11,900
這樣挑選三元組會有一種效果

184
00:11:11,900 --> 00:11:16,460
就是能讓你的演算法學得更有效率

185
00:11:16,460 --> 00:11:18,500
如果你隨便亂選

186
00:11:18,500 --> 00:11:21,725
有很多組三元組解起來都很簡單

187
00:11:21,725 --> 00:11:25,970
這樣梯度下降法就不會做任何事，
因為你的神經網路早已把那些弄對了

188
00:11:25,970 --> 00:11:27,090
幾乎所有時候都對

189
00:11:27,090 --> 00:11:32,270
所以必須要拿難以解決的三元組，讓梯度下降法

190
00:11:32,270 --> 00:11:38,700
必須要花些功夫，把這兩個值互相推開

191
00:11:38,700 --> 00:11:40,155
如果你有興趣

192
00:11:40,155 --> 00:11:46,295
這篇論文有詳細的說明，由 Florian Schroff,
Dmitry Kalenichenko

193
00:11:46,295 --> 00:11:51,305
和 James Philbin 所著，他們做了個系統叫 "FaceNet"

194
00:11:51,305 --> 00:11:55,860
這部影片有很多概念都是從那篇論文來的

195
00:11:55,860 --> 00:11:58,220
題外話，有件很好玩的事

196
00:11:58,220 --> 00:12:02,030
在深度學習的世界裡，大家是怎麼命名演算法的呢

197
00:12:02,030 --> 00:12:05,810
如果你在研究某個領域，假設叫「某某」

198
00:12:05,810 --> 00:12:10,710
你常常會叫你的系統「某某 Net」或是「Deep 某某」

199
00:12:10,710 --> 00:12:13,095
那我們在談的是人臉辨識

200
00:12:13,095 --> 00:12:16,123
所以這篇論文叫 "FaceNet"

201
00:12:16,123 --> 00:12:17,465
而在前一部影片

202
00:12:17,465 --> 00:12:19,910
你也看過了 "DeepFace"

203
00:12:19,910 --> 00:12:23,600
這種"某某Net"或是"Deep某某"的命名法

204
00:12:23,600 --> 00:12:28,370
在深度學習這個領域是非常流行的。

205
00:12:28,370 --> 00:12:32,780
那麼，你可以看看這篇論文，你能學到

206
00:12:32,780 --> 00:12:34,940
其他加速演算法的細節

207
00:12:34,940 --> 00:12:38,745
藉由挑出最有用的三元組並訓練之

208
00:12:38,745 --> 00:12:40,025
這論文很棒

209
00:12:40,025 --> 00:12:41,240
那麼，總結一下

210
00:12:41,240 --> 00:12:42,670
要訓練三元損失的時候

211
00:12:42,670 --> 00:12:47,060
你需要把你的訓練集轉換成很多組三元組

212
00:12:47,060 --> 00:12:50,550
例如這個是我們的三元組，有「錨」和「正例」

213
00:12:50,550 --> 00:12:54,375
— 這兩個都是同一個人 — 還有來自不同人的「反例」

214
00:12:54,375 --> 00:12:58,445
這邊是另一組，「錨」和「正例」是同個人

215
00:12:58,445 --> 00:13:04,315
而「錨」和「反例」是不同人，依此類推

216
00:13:04,315 --> 00:13:07,000
定義好了這些訓練資料，有了這些

217
00:13:07,000 --> 00:13:09,920
(錨, 正例, 反例)三元組之後，你就使用

218
00:13:09,920 --> 00:13:16,740
梯度下降法去最小化前面投影片定義的成本函數 J

219
00:13:16,740 --> 00:13:20,090
如此一來，藉由反向傳播

220
00:13:20,090 --> 00:13:23,640
這神經網路的所有參數

221
00:13:23,640 --> 00:13:27,435
就會學到一個編碼

222
00:13:27,435 --> 00:13:33,395
讓兩張圖片的 d 很小 — 如果兩張是同一個人

223
00:13:33,395 --> 00:13:40,286
而如果兩張圖片是不同人，他們的 d 就會很大。

224
00:13:40,286 --> 00:13:43,805
那麼，這就是「三元損失」(triplet loss)，以及如何

225
00:13:43,805 --> 00:13:48,200
訓練你的神經網路，讓它學到某種編碼，來達到人臉辨認

226
00:13:48,200 --> 00:13:49,715
其實呢

227
00:13:49,715 --> 00:13:54,556
目前商業用的人臉辨識系統拿了非常龐大的資料來訓練

228
00:13:54,556 --> 00:13:56,630
常常是超過百萬張的圖片

229
00:13:56,630 --> 00:14:00,275
甚至超過千萬張也不罕見

230
00:14:00,275 --> 00:14:05,210
有些公司宣稱他們用了超過一億張的圖片

231
00:14:05,210 --> 00:14:09,300
就算以現今的角度來看，這些資料也非常龐大 [影音中斷]

232
00:14:09,300 --> 00:14:12,800
那麼，這就是「三元損失」(triplet loss)，以及如何

233
00:14:12,800 --> 00:14:18,230
訓練神經網路去輸出一個好的編碼，來達到人臉辨認

234
00:14:18,230 --> 00:14:21,500
其實呢，現今的人臉辨認系統

235
00:14:21,500 --> 00:14:24,830
特別是大規模商業用的人臉系統

236
00:14:24,830 --> 00:14:27,360
用了非常龐大的資料訓練

237
00:14:27,360 --> 00:14:30,350
百萬級的資料集很常見

238
00:14:30,350 --> 00:14:34,040
有些公司用千萬張圖片，有些公司

239
00:14:34,040 --> 00:14:38,135
用超過一億張的圖片來訓練系統

240
00:14:38,135 --> 00:14:41,730
就算以現代的角度來看，這些資料也非常龐大

241
00:14:41,730 --> 00:14:45,230
這樣子的資料取得並不容易

242
00:14:45,230 --> 00:14:48,140
幸運的是，有些公司訓練好了

243
00:14:48,140 --> 00:14:51,875
這些大型網路後把參數公佈出來

244
00:14:51,875 --> 00:14:54,790
所以並不用嘗試從頭到尾訓練自己的網路

245
00:14:54,790 --> 00:14:59,280
在這個領域，因為資料大小的關係

246
00:14:59,280 --> 00:15:02,390
所以在這個領域比較實際的做法是

247
00:15:02,390 --> 00:15:05,313
你去下載別人已經訓練好的模型 (pre-trained model)

248
00:15:05,313 --> 00:15:07,685
不用自己從無到有、做全部的事情

249
00:15:07,685 --> 00:15:10,130
儘管如此，就算你是下載別人的模型

250
00:15:10,130 --> 00:15:14,195
我認為去理解這些演算法怎麼訓練也很實用

251
00:15:14,195 --> 00:15:19,225
可能在其他的應用，你可以利用這些概念自己打造別的東西

252
00:15:19,225 --> 00:15:21,405
那麼，這就是三元損失

253
00:15:21,405 --> 00:15:22,640
在下一個影片中

254
00:15:22,640 --> 00:15:25,280
我想讓你看看其他種類的

255
00:15:25,280 --> 00:15:28,510
Siamese 網路，以及如何訓練之

256
00:15:28,510 --> 00:15:30,000
讓我們進入下一段影片