1
00:00:00,300 --> 00:00:04,300
我们在上一节视频中学到，函数d的任务

2
00:00:04,300 --> 00:00:08,860
是接受两张脸的输入，并告诉你，它们有多相似，或有多不同。

3
00:00:08,860 --> 00:00:12,605
实现这个的一个好办法是Siamese网络。

4
00:00:12,605 --> 00:00:13,105
让我们一起来看看让我们一起来看看

5
00:00:15,117 --> 00:00:19,098
大家应该熟悉例如这样的ConvNet的例子

6
00:00:19,098 --> 00:00:20,635
这里输入是一张图片，我们称之为x1

7
00:00:20,635 --> 00:00:24,165
经过一系列的卷积和池化以及

8
00:00:24,165 --> 00:00:28,465
全连接层，最后得到了一个特征向量，像这样。

9
00:00:30,260 --> 00:00:35,940
我们有时候把它输入到一个softmax层中，去做分类。

10
00:00:35,940 --> 00:00:39,000
在这节视频中我们不会这样去做。

11
00:00:39,000 --> 00:00:44,090
而是专注在这个向量本身，比如说128个数

12
00:00:44,090 --> 00:00:49,900
它由神经网络深处的某个全连接层计算而来。

13
00:00:50,930 --> 00:00:54,850
我给这128个数(组成的向量）起个名字。

14
00:00:54,850 --> 00:01:00,220
把它叫做 f(x1)

15
00:01:00,220 --> 00:01:07,476
大家可以把f(x1)看成是输入图片x1的编码。

16
00:01:07,476 --> 00:01:12,653
那么它接受一张输入图片，这里是Kian的照片，

17
00:01:12,653 --> 00:01:17,750
将它重新表达为一个128个数字组成的向量。

18
00:01:17,750 --> 00:01:22,840
那么构建一个人脸识别系统的方法就是，如果你想比较

19
00:01:22,840 --> 00:01:27,890
两张图片，比如这里的第一张和第二张。

20
00:01:27,890 --> 00:01:31,860
你可以将第二张图片输入到同一个网络

21
00:01:31,860 --> 00:01:37,625
使用相同的参数，得到一个不同的，128个数字组成的向量

22
00:01:37,625 --> 00:01:41,740
这就是第二张图片的编码。

23
00:01:41,740 --> 00:01:43,560
我称之为

24
00:01:44,570 --> 00:01:50,480
第二张图片的编码，即f(x2)

25
00:01:50,480 --> 00:01:55,680
在这里我用x1和x2来代表两张输入图片。

26
00:01:55,680 --> 00:01:58,030
它们不一定是你训练集中的

27
00:01:58,030 --> 00:02:00,010
第一个和第二个样本。

28
00:02:00,010 --> 00:02:02,230
可以是任意两张图片。

29
00:02:02,230 --> 00:02:07,320
最后，如果你确信这些编码是对这两张图片

30
00:02:07,320 --> 00:02:11,430
良好的表达，接下来你可以定义

31
00:02:12,670 --> 00:02:16,463
距离d是x1和

32
00:02:16,463 --> 00:02:21,820
x2这两张图片的编码

33
00:02:21,820 --> 00:02:25,750
之间差的范数。

34
00:02:26,990 --> 00:02:29,434
这种方法，用两个完全相同的

35
00:02:29,434 --> 00:02:34,544
卷积神经网络对两张不同的图片进行计算，比较二者的结果

36
00:02:34,544 --> 00:02:39,380
有时我们称之为孪生网络（Siamese Network）架构。

37
00:02:39,380 --> 00:02:43,530
我呈现在这里的很多想法和理念来自于

38
00:02:43,530 --> 00:02:48,490
Yaniv Taigman, Ming Yang, Marc'Aurelio, Ranzato 和

39
00:02:48,490 --> 00:02:53,690
Lior Wolf 开发的DeepFace研究系统的论文

40
00:02:54,890 --> 00:03:00,741
我呈现在这里的很多想法和理念来自于 Yaniv Taigman，

41
00:03:00,741 --> 00:03:02,920
Ming Yang, Marc'Aurelio Ranzato, 和

42
00:03:02,920 --> 00:03:07,155
Lior Wolf 的一篇来自于他们开发的叫做DeepFace的系统的论文

43
00:03:08,520 --> 00:03:11,830
那么你该如何训练Siamese Network?

44
00:03:11,830 --> 00:03:15,380
考虑到这两个神经网络具有相同的参数

45
00:03:16,730 --> 00:03:19,600
所以你想做的是训练神经网络

46
00:03:19,600 --> 00:03:24,250
使得它计算的编码可以生成一个函数d来

47
00:03:24,250 --> 00:03:27,420
告诉你这两张照片是同一个人的

48
00:03:27,420 --> 00:03:33,350
更正式的来说，神经网络的参数定义了编码f（xi）

49
00:03:33,350 --> 00:03:35,548
当给定输入图片xi，

50
00:03:35,548 --> 00:03:40,968
这个神经网络输出这个128维的编码 f(xi)

51
00:03:40,968 --> 00:03:45,655
更正式的来说，你想做的是学习参数以使得

52
00:03:45,655 --> 00:03:50,152
如果两张图片xi和xj上是同一个人，

53
00:03:50,152 --> 00:03:55,347
那么他们的编码的差距就会小

54
00:03:55,347 --> 00:03:59,583
在之前的幻灯片中，我用了x1和x2，但是

55
00:03:59,583 --> 00:04:03,841
它可以是训练集里的任何一对xi和xj，

56
00:04:03,841 --> 00:04:07,959
相反的，如果xi和xj上是不同的人，

57
00:04:07,959 --> 00:04:13,340
那么你就想要他们的编码的差距大。

58
00:04:13,340 --> 00:04:18,160
因此, 当你改变所有这些层的神经网络的参数,

59
00:04:18,160 --> 00:04:20,665
你最终会有不同的编码。

60
00:04:20,665 --> 00:04:23,639
你可以做的是使用反向传播来

61
00:04:23,639 --> 00:04:29,590
更改所有这些参数以确保满足这些条件。

62
00:04:29,590 --> 00:04:33,460
现在你已经了解了Siamese Network的体系结构并且

63
00:04:33,460 --> 00:04:36,890
对你想要神经网络给你什么样的一个

64
00:04:36,890 --> 00:04:39,830
输出（需要输出一个好的编码而言）有了一个大概的了解

65
00:04:39,830 --> 00:04:42,790
但你如何定义一个目标函数

66
00:04:42,790 --> 00:04:46,700
让神经网络学会做我们刚才讨论的事情？

67
00:04:46,700 --> 00:04:50,940
在下一个视频中让我们看看如何使用三重损耗函数（triplet loss function）来做到这一点。