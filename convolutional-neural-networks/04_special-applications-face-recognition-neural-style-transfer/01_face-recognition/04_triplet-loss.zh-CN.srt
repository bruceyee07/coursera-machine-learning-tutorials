1
00:00:00,000 --> 00:00:04,650
为了学习神经网络的参数并以此

2
00:00:04,650 --> 00:00:07,875
获得一个优良的人脸图片的编码，

3
00:00:07,875 --> 00:00:11,930
有一种方法是定义一个应用了梯度下降的三元组损失函数（triplet loss function）

4
00:00:11,930 --> 00:00:13,425
我们看看这是什么意思

5
00:00:13,425 --> 00:00:15,341
要想使用三元组损失，

6
00:00:15,341 --> 00:00:18,630
你需要对比照片组。

7
00:00:18,630 --> 00:00:21,365
比如，我们现在有这张照片，

8
00:00:21,365 --> 00:00:24,075
为了学习到神经网络的参数，

9
00:00:24,075 --> 00:00:27,605
你需要同时看数张照片。

10
00:00:27,605 --> 00:00:29,685
例如，对于这组照片来说，

11
00:00:29,685 --> 00:00:33,895
你希望它们的编码相对类似，因为这是同一个人。

12
00:00:33,895 --> 00:00:35,925
而对于这组照片来说，

13
00:00:35,925 --> 00:00:41,500
你希望它们的编码十分不同，因为这是不同的人。

14
00:00:41,500 --> 00:00:44,770
在三元组损失的术语当中，

15
00:00:44,770 --> 00:00:49,290
你需要做的是查看锚照片，

16
00:00:49,290 --> 00:00:53,820
然后得到锚照片和正例照片之间的差距。

17
00:00:53,820 --> 00:00:55,200
正例照片的意思是

18
00:00:55,200 --> 00:00:58,025
相同的人会有相似的照片

19
00:00:58,025 --> 00:01:01,470
相对而言，当你把锚照片和负例照片对比时，

20
00:01:01,470 --> 00:01:07,455
你希望它们的差距会显得比较大。

21
00:01:07,455 --> 00:01:10,755
这就是为什么这个函数叫三元组损失，

22
00:01:10,755 --> 00:01:15,145
因为你将一直同时查看三张照片。

23
00:01:15,145 --> 00:01:17,415
这三张分别为锚照片，

24
00:01:17,415 --> 00:01:22,185
正例照片和负例照片

25
00:01:22,185 --> 00:01:25,993
我将把锚照片，正例照片和负例照片简写为，

26
00:01:25,993 --> 00:01:29,561
A (anchor)，P (positive) 和 N (negative)。所以为了将其形式化，

27
00:01:29,561 --> 00:01:32,700
你需要做的是使你的编码的神经网络中

28
00:01:32,700 --> 00:01:36,060
的参数获得以下性质，

29
00:01:36,060 --> 00:01:39,735
你需要将锚照片的编码

30
00:01:39,735 --> 00:01:44,445
减去正例照片的编码，

31
00:01:44,445 --> 00:01:47,865
你希望这个差很小，而且

32
00:01:47,865 --> 00:01:52,950
你希望这个差小于等于

33
00:01:52,950 --> 00:01:58,900
锚照片的编码和负例照片的编码之间差距的平方。

34
00:01:58,900 --> 00:02:02,485
这边是d(A,P)（A和P的距离）

35
00:02:02,485 --> 00:02:06,610
而这边是d(A,N)（A和N的距离）。

36
00:02:06,610 --> 00:02:11,280
你可以把d想象成距离方程，

37
00:02:11,280 --> 00:02:14,700
所以我们用字母d命名。

38
00:02:14,700 --> 00:02:18,825
现在，如果我们把右边的式子移到左边来，

39
00:02:18,825 --> 00:02:25,140
你将会得到 f(A)减去f(P)的平方，减去，

40
00:02:25,140 --> 00:02:27,675
右手边的式子，

41
00:02:27,675 --> 00:02:31,404
f(A)减去f(N)的平方，

42
00:02:31,404 --> 00:02:34,800
小于等于0。

43
00:02:34,800 --> 00:02:38,280
但现在，我们要对这个表达式做些小改变，

44
00:02:38,280 --> 00:02:41,420
有一个情况会使式子的条件轻易得到满足，

45
00:02:41,420 --> 00:02:44,245
是把每一项学习成0。

46
00:02:44,245 --> 00:02:46,275
如果f()永远等于0，

47
00:02:46,275 --> 00:02:47,955
那这就是0减去0，

48
00:02:47,955 --> 00:02:50,545
也就是0，这也是0减去0得到0。

49
00:02:50,545 --> 00:02:57,140
如果说f(任何照片)得到的是一个全是0的矢量，

50
00:02:57,140 --> 00:03:01,410
你可以永远满足这个式子的条件（小于等于0）。

51
00:03:01,410 --> 00:03:07,465
所以，为了确保神经网络不会为所有编码都一直输出0，

52
00:03:07,465 --> 00:03:12,480
为了确保它不会把这些编码训练得和其他的一样。

53
00:03:12,480 --> 00:03:16,285
另一个使神经网络给出一个退化的输出的情况是，

54
00:03:16,285 --> 00:03:20,246
如果每一张照片的编码都和其他任何一张照片的编码完全相同，

55
00:03:20,246 --> 00:03:25,400
你将再次得到0减去0等于0。

56
00:03:25,400 --> 00:03:28,075
所以为了防止神经网络做这些事，

57
00:03:28,075 --> 00:03:32,370
我们需要做的是调整这个式子，

58
00:03:32,370 --> 00:03:36,985
使它不仅仅小于等于0，

59
00:03:36,985 --> 00:03:40,575
而是比0小很多。

60
00:03:40,575 --> 00:03:45,755
所以，比如说我们想要这个式子小于 负alpha,

61
00:03:45,755 --> 00:03:49,235
这里的alpha是另外一个超参数，

62
00:03:49,235 --> 00:03:53,475
这样的话就可以防止神经网络输出退化解。

63
00:03:53,475 --> 00:03:55,230
按照惯例，我们通常

64
00:03:55,230 --> 00:03:59,550
在在左边写成正alpha而不是在右边的负alpha。

65
00:03:59,550 --> 00:04:02,763
这也被称为margin，

66
00:04:02,763 --> 00:04:05,190
如果你之前看过支持向量机的文献的话，

67
00:04:05,190 --> 00:04:10,320
你会熟悉这些术语，

68
00:04:10,320 --> 00:04:12,675
如果没有了解也不用担心。

69
00:04:12,675 --> 00:04:17,995
我们也可以通过加入margin参数来调整上面的式子，

70
00:04:17,995 --> 00:04:19,395
现在来举个例子，

71
00:04:19,395 --> 00:04:23,260
我们把margin设定成0.2，

72
00:04:23,260 --> 00:04:24,855
如果在这个例子里，

73
00:04:24,855 --> 00:04:29,550
锚照片和正例照片的差 d(A,P) 是0.5，

74
00:04:29,550 --> 00:04:32,580
那当锚照片和负例照片的差 d(A,N) 

75
00:04:32,580 --> 00:04:37,087
只是稍大一点的时候，比如0.51，式子的条件是满足不了的。

76
00:04:37,087 --> 00:04:41,610
即使0.51确实大于0.5，

77
00:04:41,610 --> 00:04:43,917
这个意思是说，这还不够好，我们想要

78
00:04:43,917 --> 00:04:47,610
d(A,N)远大于d(A,P)，

79
00:04:47,610 --> 00:04:49,245
具体来说，

80
00:04:49,245 --> 00:04:53,520
你想要0.7或者更大的数字。

81
00:04:53,520 --> 00:04:58,740
换种说法，如果要使这个margin达到至少0.2，

82
00:04:58,740 --> 00:05:02,330
你可以把这一项变高，也可以把这一项变低，

83
00:05:02,330 --> 00:05:06,305
从而使两项之间的差距

84
00:05:06,305 --> 00:05:09,350
可以达到超参数alpha＝0.2这个值，

85
00:05:09,350 --> 00:05:14,530
别忘了alpha代表d(A,P)和d(A,N)之间的差距。

86
00:05:14,530 --> 00:05:17,491
这就是这个margin参数的用途，

87
00:05:17,491 --> 00:05:19,055
它可以拉大

88
00:05:19,055 --> 00:05:25,720
d(A,P)和d(A,N)之间的差距。

89
00:05:25,720 --> 00:05:29,435
那么让我们来看一看底部的这个式子，

90
00:05:29,435 --> 00:05:31,160
在下个页面里，

91
00:05:31,160 --> 00:05:35,225
我们将会正式定义三元组损失函数（triplet loss function）。

92
00:05:35,225 --> 00:05:40,810
三元组损失函数由一组中的三张照片而得名，

93
00:05:40,810 --> 00:05:43,465
现在有3张照片，

94
00:05:43,465 --> 00:05:46,350
A，P和N，

95
00:05:46,350 --> 00:05:48,990
分别代表锚照片，正例照片和负例照片。

96
00:05:48,990 --> 00:05:53,245
正例照片与锚照片中的人相同，

97
00:05:53,245 --> 00:05:58,040
而负例照片和锚照片中的人不同。

98
00:05:58,040 --> 00:06:01,515
我们将如此定义“损失“ L()

99
00:06:01,515 --> 00:06:03,055
在这里由三张图片

100
00:06:03,055 --> 00:06:06,465
形成的“损失“ L(A,P,N)

101
00:06:06,465 --> 00:06:10,169
让我先将前一页的式子抄下来，

102
00:06:10,169 --> 00:06:16,045
也就是f(A)减去f(P) 的平方

103
00:06:16,045 --> 00:06:23,790
减去 f(A)减去f(N) 的平方

104
00:06:23,790 --> 00:06:26,755
再加上alpha，margin参数，

105
00:06:26,755 --> 00:06:31,600
你想要这整个式子小于等于0。

106
00:06:31,600 --> 00:06:34,365
损失函数的定义即为

107
00:06:34,365 --> 00:06:39,040
这整个式子的结果和0之间的最大值，

108
00:06:39,040 --> 00:06:42,030
这里取最大值的效果是

109
00:06:42,030 --> 00:06:45,225
只要这一项小于0，

110
00:06:45,225 --> 00:06:47,070
那么“损失“便为0，

111
00:06:47,070 --> 00:06:49,847
因为一个小于0的值和0之间的最大值

112
00:06:49,847 --> 00:06:52,705
一定是0。

113
00:06:52,705 --> 00:06:56,370
所以只要你能实现我用绿色线下划的目标，

114
00:06:56,370 --> 00:07:00,950
使它小于等于0，

115
00:07:00,950 --> 00:07:04,150
那么这个例子里的“损失“就是0。

116
00:07:04,150 --> 00:07:05,355
另一方面，

117
00:07:05,355 --> 00:07:07,650
如果这一项是大于0的，

118
00:07:07,650 --> 00:07:09,120
那如果你取最大值，

119
00:07:09,120 --> 00:07:10,665
最终选出的结果

120
00:07:10,665 --> 00:07:12,343
将会是绿色下划线的这一项，

121
00:07:12,343 --> 00:07:15,455
然后你会获得一个大于0的“损失“。

122
00:07:15,455 --> 00:07:17,475
所以通过尝试使这个最小化，

123
00:07:17,475 --> 00:07:22,130
对应的结果是这一项会等于0

124
00:07:22,130 --> 00:07:23,450
或者小于0。

125
00:07:23,450 --> 00:07:26,550
所以只要它是0或者小于0，

126
00:07:26,550 --> 00:07:31,980
神经网络并不需要考虑具体是负多少。

127
00:07:31,980 --> 00:07:33,990
所以这就是你定义一个三元组“损失“的方法，

128
00:07:33,990 --> 00:07:38,970
而神经网络中整体损失函数可以是

129
00:07:38,970 --> 00:07:47,575
一套训练集中不同三元组对应的“损失“的总和。

130
00:07:47,575 --> 00:07:55,080
假如你有一个训练集，其中包含1000个不同的人组成的10000张照片，

131
00:07:55,080 --> 00:08:00,360
你需要做的是用这10000张照片去生成

132
00:08:00,360 --> 00:08:03,720
像这样的三元组，

133
00:08:03,720 --> 00:08:08,005
然后用这种损失函数 训练你那使用梯度下降的学习算法，

134
00:08:08,005 --> 00:08:14,145
而该损失函数是定义在从训练集中抽取的图片上的三元组。

135
00:08:14,145 --> 00:08:19,635
请注意，如果要定义三元组的数据集，

136
00:08:19,635 --> 00:08:25,405
你需要一些成对的A和P，也就是一对包含同一人的照片。

137
00:08:25,405 --> 00:08:27,510
所以为了达到训练的目的，

138
00:08:27,510 --> 00:08:32,600
必须要一个的同一个人会有数张不同照片数据集。

139
00:08:32,600 --> 00:08:33,960
这就是为什么在这个例子中，

140
00:08:33,960 --> 00:08:38,040
我说你有10000张包含1000个不同人的照片，

141
00:08:38,040 --> 00:08:40,965
这样1000人中每个人平均会有10张照片，

142
00:08:40,965 --> 00:08:44,310
来组成你的整个数据集。

143
00:08:44,310 --> 00:08:47,085
如果你每个人只有一张照片，

144
00:08:47,085 --> 00:08:49,725
那你无法训练你的系统。

145
00:08:49,725 --> 00:08:52,080
但训练完成之后，

146
00:08:52,080 --> 00:08:54,205
（口误）

147
00:08:54,205 --> 00:08:56,565
当然，在训练好了这个系统后，

148
00:08:56,565 --> 00:08:58,200
你可以将其应用在

149
00:08:58,200 --> 00:09:02,685
你人脸识别系统的一次性的学习任务，

150
00:09:02,685 --> 00:09:06,945
其中你可能只有某个你想要识别的人的一张照片。

151
00:09:06,945 --> 00:09:08,335
但对于你的训练集来说，

152
00:09:08,335 --> 00:09:12,780
你需要确保训练集中的至少其中一部分人

153
00:09:12,780 --> 00:09:14,940
会有数张照片，使得

154
00:09:14,940 --> 00:09:19,000
你可以有成对的锚照片和正向照片。

155
00:09:19,000 --> 00:09:25,240
现在，应该如何正确的选择三元组来组成你的训练集呢？

156
00:09:25,240 --> 00:09:28,635
这里的问题之一是，如果你从训练集中

157
00:09:28,635 --> 00:09:34,260
随机选择A，P和N，并使A，P为相同的人，

158
00:09:34,260 --> 00:09:36,270
而A，N为不同的人。

159
00:09:36,270 --> 00:09:40,140
有个问题是如果你随机选择它们，

160
00:09:40,140 --> 00:09:44,160
那么这个约束将会非常容易得到满足，

161
00:09:44,160 --> 00:09:48,405
因为如果有两张随机选出的照片，

162
00:09:48,405 --> 00:09:51,945
A，N之间的差异会远远大于

163
00:09:51,945 --> 00:09:55,740
A，P之间的差异。希望你仍然记得这些符号

164
00:09:55,740 --> 00:10:02,710
这个d(A,P)就是我们之前讲过的A和P之间的距离

165
00:10:02,710 --> 00:10:06,190
所以这一边是

166
00:10:06,190 --> 00:10:11,040
我们前一页上写的距离的平方。

167
00:10:11,040 --> 00:10:14,640
但如果A和N是两个随机选择的不同的人，

168
00:10:14,640 --> 00:10:17,610
那么有很大几率

169
00:10:17,610 --> 00:10:21,630
右边的式子远远大于左边的式子加alpha。

170
00:10:21,630 --> 00:10:24,405
那么神经网络无法从中学习很多。

171
00:10:24,405 --> 00:10:25,940
所以要建立一个训练集，

172
00:10:25,940 --> 00:10:28,340
你要做的是选择

173
00:10:28,340 --> 00:10:31,280
训练起来比较难的三元组A，P和N。

174
00:10:31,280 --> 00:10:38,685
具体来说，你想要的是所有满足这个约束的三元组，

175
00:10:38,685 --> 00:10:44,995
还需要是一个相对难以训练的三元组

176
00:10:44,995 --> 00:10:47,454
难训练是说A，P，N会使得d(A,P)和d(A,N)

177
00:10:47,454 --> 00:10:52,550
相当接近。

178
00:10:52,550 --> 00:10:54,020
这么一来，

179
00:10:54,020 --> 00:10:57,230
学习算法需要更加努力来

180
00:10:57,230 --> 00:11:00,740
使得右边的值增加或是

181
00:11:00,740 --> 00:11:04,030
左边的值减少，

182
00:11:04,030 --> 00:11:08,430
这样才能使代表左右差距的alpha有意义。

183
00:11:08,430 --> 00:11:11,900
选择这些三元组的效果是

184
00:11:11,900 --> 00:11:16,460
增强你的学习算法的计算效率。

185
00:11:16,460 --> 00:11:18,500
如果你随机选择三元组，

186
00:11:18,500 --> 00:11:21,725
那么很多三元组会是非常简单的，

187
00:11:21,725 --> 00:11:25,970
那么梯度下降无法做任何事，因为你的神经网络

188
00:11:25,970 --> 00:11:27,090
本来就能做对它们。

189
00:11:27,090 --> 00:11:32,270
因此只能通过有难度的三元组来使梯度下降

190
00:11:32,270 --> 00:11:38,700
能做到把这两项之间的距离分得更开。

191
00:11:38,700 --> 00:11:40,155
如果你有兴趣的话，

192
00:11:40,155 --> 00:11:46,295
你可以在底部这篇文献中找到更多的细节，由Florian Schroff，Dmitry Kalinichenko，

193
00:11:46,295 --> 00:11:51,305
和 James Philbin所写，他们有一个叫FaceNet的系统，

194
00:11:51,305 --> 00:11:55,860
我在这个视频里展示的许多概念都是从那里而来。

195
00:11:55,860 --> 00:11:58,220
顺便一提，对于深度学习领域内

196
00:11:58,220 --> 00:12:02,030
如何命名算法有个有趣的事实，

197
00:12:02,030 --> 00:12:05,810
如果你研究某一领域，那么我们称它"__"，

198
00:12:05,810 --> 00:12:10,710
你常会有一个系统叫 "__"网络(__net) 或者 深度"__"(deep __)。

199
00:12:10,710 --> 00:12:13,095
我们现在在讲人脸识别，

200
00:12:13,095 --> 00:12:16,123
所以这篇文献起名为 Facenet (人脸网络)，

201
00:12:16,123 --> 00:12:17,465
在上一个视频中，

202
00:12:17,465 --> 00:12:19,910
你看到了 深度人脸 (deep face)。

203
00:12:19,910 --> 00:12:23,600
这个"__net"或者"deep __"的主意

204
00:12:23,600 --> 00:12:28,370
在深度学习领域中是很普遍的命名算法的方式。

205
00:12:28,370 --> 00:12:32,780
如果你想要了解更多关于如何选择最有用的三元组

206
00:12:32,780 --> 00:12:34,940
训练系统来使你的算法提速的细节，

207
00:12:34,940 --> 00:12:38,745
那你可以去看一下这篇文献。

208
00:12:38,745 --> 00:12:40,025
这篇文献非常不错。

209
00:12:40,025 --> 00:12:41,240
总结一下，

210
00:12:41,240 --> 00:12:42,670
要训练三元组损失，

211
00:12:42,670 --> 00:12:47,060
你需要把你的训练集组成许多三元组。

212
00:12:47,060 --> 00:12:50,550
这是我们的三元组，其中显示同一个人的

213
00:12:50,550 --> 00:12:54,375
锚照片和正例照片，以及显示另一个不同的人的负例照片。

214
00:12:54,375 --> 00:12:58,445
这是另一个锚照片和正例照片是同一个人，

215
00:12:58,445 --> 00:13:04,315
而锚照片和负例照片是不同的人的例子。

216
00:13:04,315 --> 00:13:07,000
你定义完这个包含锚照片，正例照片和负例照片

217
00:13:07,000 --> 00:13:09,920
训练集之后的要做的是

218
00:13:09,920 --> 00:13:16,740
用梯度下降来最小化我们前几页定义的损失函数J

219
00:13:16,740 --> 00:13:20,090
这会随后扩散并影响到

220
00:13:20,090 --> 00:13:23,640
神经网络里所有参数，

221
00:13:23,640 --> 00:13:27,435
从而学习这样一个编码，

222
00:13:27,435 --> 00:13:33,395
使得当两张照片中是同一个人时，这两张照片间的d会很小，

223
00:13:33,395 --> 00:13:40,286
而当两张照片中的人不同时，d的值会很大。

224
00:13:40,286 --> 00:13:43,805
这就是所谓的三元组损失，以及

225
00:13:43,805 --> 00:13:48,200
训练神经网络来学习一个人脸识别的编码的方法。

226
00:13:48,200 --> 00:13:49,715
目前来看，

227
00:13:49,715 --> 00:13:54,556
商业化的人脸识别系统目前是通过相当大的数据库来训练的。

228
00:13:54,556 --> 00:13:56,630
通常会有几百万张照片，

229
00:13:56,630 --> 00:14:00,275
有时候超过一千万照片。

230
00:14:00,275 --> 00:14:05,210
有些商业公司甚至在讨论用超过一亿的照片来训练。

231
00:14:05,210 --> 00:14:09,300
这些即使就当代的标准来说都是非常大的数据集。

232
00:14:09,300 --> 00:14:12,800
这就是所谓的三元组损失，以及

233
00:14:12,800 --> 00:14:18,230
训练神经网络来学习一个人脸识别的好的编码的方法。

234
00:14:18,230 --> 00:14:21,500
目前来看，当今的人脸识别系统，

235
00:14:21,500 --> 00:14:24,830
尤其是大型(large scale)商业化人脸识别系统

236
00:14:24,830 --> 00:14:27,360
是通过相当大的数据库来训练的。

237
00:14:27,360 --> 00:14:30,350
一百万张照片的数据库极其普遍，

238
00:14:30,350 --> 00:14:34,040
有些公司会用一千万张照片，甚至

239
00:14:34,040 --> 00:14:38,135
有些公司会用一亿张照片来训练这些系统。

240
00:14:38,135 --> 00:14:41,730
这些即使就当代的标准来说都是非常大的数据集，

241
00:14:41,730 --> 00:14:45,230
这些数据库资产很难获得。

242
00:14:45,230 --> 00:14:48,140
幸运的是，有些公司已经训练了

243
00:14:48,140 --> 00:14:51,875
大型的神经网络并发布到了网上。

244
00:14:51,875 --> 00:14:54,790
所以，你可以不用从零开始训练这些神经网络，

245
00:14:54,790 --> 00:14:59,280
这个领域里共享数据体积过于庞大，

246
00:14:59,280 --> 00:15:02,390
这个领域里对你更有帮助的做法是

247
00:15:02,390 --> 00:15:05,313
下载别人已训练的模型，

248
00:15:05,313 --> 00:15:07,685
而不是通过自己来做所有事情。

249
00:15:07,685 --> 00:15:10,130
不过即使你下载别人已训练的模型，

250
00:15:10,130 --> 00:15:14,195
了解如何训练这些算法依然对你有帮助，

251
00:15:14,195 --> 00:15:19,225
或者你可以自己应用这些概念来做一些实例。

252
00:15:19,225 --> 00:15:21,405
那么这就是三元组损失了。

253
00:15:21,405 --> 00:15:22,640
这里这个

254
00:15:22,640 --> 00:15:25,280
我会展示同一个神经网络中

255
00:15:25,280 --> 00:15:28,510
不同的变化以及如何训练这些系统。

256
00:15:28,510 --> 00:15:30,000
我们下一节再见