關於前面提到的神經網路，有個方法可以學出參數 能給你一個良好的人臉照片的編碼 就是定義「三元損失」函數 (triplet loss)，
用他來執行梯度下降法 讓我們來看看這是什麼意思 要利用三元損失 (tripet loss) 你需要比較兩對照片 舉個例子，給定這一張圖 如果要學出這神經網路的參數 你必須同時看過若干張照片 例如，給你這一對照片 你想要讓他們的編碼很接近，因為這兩張是同一個人 而對於這一對照片 你想讓他們的編碼很不一樣，因為這兩張是不同人 在三元損失的術語中 你都會看著一張「錨」照片 (anchor image) 然後你要讓錨照片和「正例」照片之間的距離 — 也就是正面的例子 意思是同一個人 — 變得比較相近 而當錨照片是和反面的例子 做比較的時候，你想要兩者之間的距離比較遠。 所以這就是「三元損失」名字的由來 你每次都要同時觀察三張圖片 你會看一張「錨」圖片 一張「正面」照片、還有一張「反例」照片 我把「錨」「正例」「反例」縮寫成 "A", "P" 和 "N"。用公式來描述的話 你所要的是，讓你的 神經網路的參數造成的編碼具有下列性質： 你想讓「錨」圖片的編碼 減去「正例」圖片的編碼 你想讓這差距小，特別是 你希望讓這個小於等於某個距離 也就是「錨」的編碼和「反例」編碼差距的範數的平方 也就是這個是 d(A, P) 而這個是 d(A, N) 你可以把 d 看作是一種距離的函數 所以我們叫他 d。 那如果把右邊這一項移到左邊 你就會得到 f(A) 減 f(P) 然後平方，減掉... 讓我們拿右邊這一項 ... 減去 f(N) 然後平方 你希望讓這個小於等於零 不過呢，在這裡我們要改一下這個公式 因為，有個很顯而易見的方法可以讓這式子成立 就是把每個東西都學成 0 如果 f 總是等於 0 那這就是 0 減 0 也就是 0；這邊是 0 減 0 也等於 0 所以呢，只要宣稱任何圖片經過 f 都變成零向量 你很容易就能滿足這個式子 所以，為了不要讓神經網路對每個編碼都輸出 0 為了確保不要讓網路輸出的編碼長得都一樣 — 另一種讓網路不經大腦輸出的方法 就是讓每張照片的編碼都一模一樣 這樣子的話，你也會得到 0 減 0 因此為了不要讓神經網路這樣做 我們要改變這個目標： 這個不只要小於等於 0 這個必須要比 0 還小一些 更進一步說，如果我們說這必須要小於負 alpha 這裡 alpha 是一個超參數 就能防止神經網路不經大腦、輸出顯然的解答 而依慣例，通常 我們會在這裡寫加 alpha 而不會在另邊寫負 alpha 這一項也稱作 margin (邊距) 如果看過 support vector machine (支撐向量機) 的文獻，你會對這個術語很熟悉 不過沒聽過也不用擔心 我們也可以改變上面這個公式，多加一個「邊距」項 舉個例子 假設邊距是 0.2 如果在這例子 錨圖和正例圖的 d 等於 0.5 那麼當錨圖和反例圖之間的 d 只大一點點時，例如 0.51，這樣你並不會滿意 就算 0.51 比 0.5 還大 你會說「這樣還不夠好」，我們要 d(A, N) 遠大於 d(A, P) 特別是 你要這一項大於等於 0.7 換句話說，讓兩者的差距、邊距至少有 0.2 你可以把這項拉高，或把這項拉低 讓他們至少有 alpha 的差距 這個超參數 alpha 0.2 也就是「正例到錨的距離」跟「反例到錨的距離」的差距 所以這就是邊距參數的功用 也就是 把「錨-正例」這一對跟「錨-反例」這一對推開，遠離彼此 因此，讓我們拿最下面這個式子 在下一張投影片 更正式地用它來定義「三元損失函數」(triplet loss) 那麼，三元損失函數是定義在三張一組的圖片上 給定三張圖片 A, P 和 N 代表「錨」、「正例」和「反例」 「正例」和「錨」會是同一個人 而「反例」的人和「錨」的不一樣 我們將損失函數定義如下 這些東西的損失 也就是定義在這組三張圖片上的 — 讓我先把前一張投影片的拷貝過來 也就是 f(A) 減 f(P) 的平方 再減掉 f(A) 減 f(N) 的平方 然後加上 alpha，也就是「邊距」參數 你希望讓這一整個小於等於 0 所以要定義這個損失函數的話 讓我們取這個東西和 0 之間的最大值 這邊取了最大值以後 只要這一個比零還小 那損失就是零 因為把一個小於等於零的東西 和零去取最大值，會得到零 所以只要你能把這個綠色底線的東西 只要你能達到目標，讓這個小於或等於零 這樣這個例子的損失就會是零 反之 如果這一個比零還大 那你取最大值的時候 他會去選擇 綠色底線的這一項 所以你會得到一個大於零的損失 因此，為了讓損失越小越好 就會導致把這項推往 0 小於或等於零 只要這項小於或等於零 神經網路並不會在乎他要負多大 那麼，這就是要怎麼去定義 單一個「三元組」的損失。而你的網路整體的成本 可以是你的訓練資料裡各個三元組的損失的總和 假設你的訓練資料有 1000 個不同的人，共有 10000 張照片 你要做的是拿這一萬張圖片去產生、 去選出像這樣的三元組，然後訓練 你的演算法，利用梯度下降法去減少這種成本函數 也就是定義在一組三張的圖片，從你的訓練集挑出來的 注意到，為了要定義這種「三元組」的資料集 你的確會需要一些成對的 A 和 P、同一個人的一對圖片 所以為了訓練你的系統 你的資料集的確會需要來自同個人的多張圖片 這就是為什麼在這例子裡 我會說「如果你有 10000 張圖片，來自 1000 位不同的人」 所以或許平均來說這 1000 個人 每個人平均有 10 張圖片，這樣子來構成你的資料集 如果每個人你都只有一張圖片 那實際上你無法訓練這個系統。 不過當然，訓練完以後 如果你要用它.. 不過當然，訓練完這套系統後 你可以把這系統用在 你的單樣本問題，也就是在你的人臉辨認軟體 對於你想要辨認的人，你可能只有他的一張照片。 不過對於訓練資料 你的確需要同一個人的不同照片 至少你的訓練集的某一些人要這樣，如此一來 你才擁有成對的「錨」和「正例」圖片。 那麼實務上，你要怎麼從訓練集當中挑出這些三元組呢？ 如果你這樣做的話，會遭遇到難題： 從訓練資料中隨機選出 A, P 和 N，只管 A 和 P 是同個人 而 A 和 N 是不同人 如果你任意隨機挑出他們，一個問題是 這個不等式很容易就可以滿足 因為隨便挑兩個人的照片 有很高的機會 A 和 N 會非常不一樣 比 A和P 還不一樣。我希望你還記得 這個 d(A,P) 是前面幾張投影片談過的這種編碼 所以這個會等於 前面投影片看到的編碼差距的範數的平方 如果 A 和 N 是隨機挑出的兩個人 那麼這一項有很高的機率會很大 比左邊那一項加邊距還要大 所以神經網路無法從中學到東西 因此，要建構訓練資料的話 你要挑那種很難訓練的 三元組 A, P 和 N 更仔細地說，你的目標是讓所有的三元組都滿足這個條件 因此，當我們說某個三元組很難，表示 你挑的 A, P, N 會讓 d(A,P) 會很靠近 d(A,N) 這樣子的話 演算法在學習的時候要花更多的力氣 嘗試讓右邊這一項往上推 或者讓左邊這項往下掉 讓左邊右邊至少相隔 alpha 的邊距。 這樣挑選三元組會有一種效果 就是能讓你的演算法學得更有效率 如果你隨便亂選 有很多組三元組解起來都很簡單 這樣梯度下降法就不會做任何事，
因為你的神經網路早已把那些弄對了 幾乎所有時候都對 所以必須要拿難以解決的三元組，讓梯度下降法 必須要花些功夫，把這兩個值互相推開 如果你有興趣 這篇論文有詳細的說明，由 Florian Schroff,
Dmitry Kalenichenko 和 James Philbin 所著，他們做了個系統叫 "FaceNet" 這部影片有很多概念都是從那篇論文來的 題外話，有件很好玩的事 在深度學習的世界裡，大家是怎麼命名演算法的呢 如果你在研究某個領域，假設叫「某某」 你常常會叫你的系統「某某 Net」或是「Deep 某某」 那我們在談的是人臉辨識 所以這篇論文叫 "FaceNet" 而在前一部影片 你也看過了 "DeepFace" 這種"某某Net"或是"Deep某某"的命名法 在深度學習這個領域是非常流行的。 那麼，你可以看看這篇論文，你能學到 其他加速演算法的細節 藉由挑出最有用的三元組並訓練之 這論文很棒 那麼，總結一下 要訓練三元損失的時候 你需要把你的訓練集轉換成很多組三元組 例如這個是我們的三元組，有「錨」和「正例」 — 這兩個都是同一個人 — 還有來自不同人的「反例」 這邊是另一組，「錨」和「正例」是同個人 而「錨」和「反例」是不同人，依此類推 定義好了這些訓練資料，有了這些 (錨, 正例, 反例)三元組之後，你就使用 梯度下降法去最小化前面投影片定義的成本函數 J 如此一來，藉由反向傳播 這神經網路的所有參數 就會學到一個編碼 讓兩張圖片的 d 很小 — 如果兩張是同一個人 而如果兩張圖片是不同人，他們的 d 就會很大。 那麼，這就是「三元損失」(triplet loss)，以及如何 訓練你的神經網路，讓它學到某種編碼，來達到人臉辨認 其實呢 目前商業用的人臉辨識系統拿了非常龐大的資料來訓練 常常是超過百萬張的圖片 甚至超過千萬張也不罕見 有些公司宣稱他們用了超過一億張的圖片 就算以現今的角度來看，這些資料也非常龐大 [影音中斷] 那麼，這就是「三元損失」(triplet loss)，以及如何 訓練神經網路去輸出一個好的編碼，來達到人臉辨認 其實呢，現今的人臉辨認系統 特別是大規模商業用的人臉系統 用了非常龐大的資料訓練 百萬級的資料集很常見 有些公司用千萬張圖片，有些公司 用超過一億張的圖片來訓練系統 就算以現代的角度來看，這些資料也非常龐大 這樣子的資料取得並不容易 幸運的是，有些公司訓練好了 這些大型網路後把參數公佈出來 所以並不用嘗試從頭到尾訓練自己的網路 在這個領域，因為資料大小的關係 所以在這個領域比較實際的做法是 你去下載別人已經訓練好的模型 (pre-trained model) 不用自己從無到有、做全部的事情 儘管如此，就算你是下載別人的模型 我認為去理解這些演算法怎麼訓練也很實用 可能在其他的應用，你可以利用這些概念自己打造別的東西 那麼，這就是三元損失 在下一個影片中 我想讓你看看其他種類的 Siamese 網路，以及如何訓練之 讓我們進入下一段影片