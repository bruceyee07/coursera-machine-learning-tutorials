1
00:00:00,000 --> 00:00:02,580
삼중항 손실는 얼굴 인식을 위한

2
00:00:02,580 --> 00:00:05,950
컨볼네트의 파라미터를 배우는 좋은 방법 중 하나입니다.

3
00:00:05,950 --> 00:00:08,490
이러한 파라미터를 학습하는 또 다른 방법이 있습니다.

4
00:00:08,490 --> 00:00:11,475
얼굴 인식이 어떻게 직선 이진 분류 문제로

5
00:00:11,475 --> 00:00:15,175
제기 될 수 있는지 보여 드리겠습니다.

6
00:00:15,175 --> 00:00:17,085
신경망을 훈련시키는 또 다른 방법은

7
00:00:17,085 --> 00:00:19,740
이 Siamese Network를 가져 와서

8
00:00:19,740 --> 00:00:25,260
이 두 가지 임베딩을 계산하도록 합니다.

9
00:00:25,260 --> 00:00:27,255
아마도 128 차원의 임베딩일텐데요,

10
00:00:27,255 --> 00:00:28,770
어쩌면 더 높은 차원일수도 있습니다.

11
00:00:28,770 --> 00:00:31,530
그리고 나서

12
00:00:31,530 --> 00:00:36,375
이들을 로지스틱 회귀 유닛에 인풋해서 예측을 하게 합니다.

13
00:00:36,375 --> 00:00:42,705
여기서 두 사람이 같은 사람이라면 목표 아웃풋은 1 이 되고,

14
00:00:42,705 --> 00:00:46,530
이 둘이 다른 사람의 경우는 0이됩니다.

15
00:00:46,530 --> 00:00:52,960
따라서 이것이 얼굴 인식을 이진 분류 문제로 취급하는 이유입니다.

16
00:00:52,960 --> 00:00:58,890
이것은 이와 같은 시스템을 훈련시키기 위한 삼중 항 손실의 대안입니다.

17
00:00:58,890 --> 00:01:03,405
자, 이 최종 로지스틱 회귀 분석 유닛은 실제로 무슨 일을 할까요?

18
00:01:03,405 --> 00:01:08,400
아웃풋 Y 모자는 시그모이드 함수이고,

19
00:01:08,400 --> 00:01:12,750
몇 가지 피처 세트에 적용될 것입니다. 단지 인코딩 만 하는 것은 아니고

20
00:01:12,750 --> 00:01:18,690
인코딩 사이의 차이점을 알아내는 것이죠.

21
00:01:18,690 --> 00:01:20,795
이게 무슨 뜻인지 보시죠.

22
00:01:20,795 --> 00:01:30,020
K는 1 에서 128까지의 합이고,

23
00:01:30,020 --> 00:01:35,525
이 두 다른 인코딩 사이에 있는 요소들의 차이의 절대값 이라고 썼습니다.

24
00:01:35,525 --> 00:01:39,930
이거 먼저 다 쓰고, 무슨 뜻인지 말씀 드리죠.

25
00:01:39,930 --> 00:01:45,335
이 수식에서, 함수 f(xi)는 이미지 xi의 인코딩이고

26
00:01:45,335 --> 00:01:52,210
치환기 K는 이 벡터의 cave components를 선택하는 것을 의미합니다.

27
00:01:52,210 --> 00:01:59,625
이렇게 해서 이 두 인코딩 간의 요소 Y 차이를 절대값으로 얻는 것입니다..

28
00:01:59,625 --> 00:02:03,240
그리고 여러분이 할 수있는 일은 이 128 개의 숫자를

29
00:02:03,240 --> 00:02:07,140
로지스틱 회귀 분석에 넣는 것입니다.

30
00:02:07,140 --> 00:02:11,350
그러면, 작은 회귀가 일반적인 로지스틱 회귀 단위와 유사한

31
00:02:11,350 --> 00:02:16,030
추가 파라미터 w, i 및 b를 가질 수 있음을 알게 될 것입니다.

32
00:02:16,030 --> 00:02:21,990
이 두 가지 이미지가 같은 사람인지

33
00:02:21,990 --> 00:02:24,105
아니면 다른 사람인지를 예측하기 위해

34
00:02:24,105 --> 00:02:28,225
이 128 개의 피처에 대해 적절히 기다리는 것을 훈련할 것입니다.

35
00:02:28,225 --> 00:02:31,035
따라서 이것은 동일한 사람인지 다른 사람인지에 따라

36
00:02:31,035 --> 00:02:37,300
0 또는 1을 예측하는 법을 배우는 아주 유용한 방법이 될 것입니다.

37
00:02:37,300 --> 00:02:40,230
그리고 녹색으로 밑줄 친 수식을 계산하는 방법에 대한

38
00:02:40,230 --> 00:02:44,220
몇 가지 다른 변형이 있습니다.

39
00:02:44,220 --> 00:02:51,405
예를 들어, 다른 수식은 f(xi)k - f(xj)k 를 제곱한 후

40
00:02:51,405 --> 00:02:56,220
f(xi)k + f(xj)k 로 나누는 것입니다.

41
00:02:56,220 --> 00:03:02,980
이것은 카이 제곱 공식이라고 불리는데요,

42
00:03:02,980 --> 00:03:05,700
그리스의 알파벳 카이에서 비롯되었습니다.

43
00:03:05,700 --> 00:03:08,874
이것은 때때로 카이 제곱 유사도라고도 합니다.

44
00:03:08,874 --> 00:03:15,810
그리고 이것과 다른 변형은 이 DeepFace 논문에서 연구됩니다.

45
00:03:15,810 --> 00:03:18,015
예전에 언급했어요.

46
00:03:18,015 --> 00:03:20,760
따라서 이 학습 공식에서

47
00:03:20,760 --> 00:03:23,801
인풋은 한 쌍의 이미지이므로

48
00:03:23,801 --> 00:03:28,920
이것이 여러분이 트레이닝 인풋 x이고

49
00:03:28,920 --> 00:03:32,085
이 아웃풋 y는 여러분이 비슷하거나 다른 이미지를 인풋하는지에 따라

50
00:03:32,085 --> 00:03:35,680
이것은 0 이거나 1 이 됩니다.

51
00:03:35,680 --> 00:03:37,070
그리고 이전과 마찬가지로,

52
00:03:37,070 --> 00:03:40,065
여러분의 훈련은 Siamese Network 입니다.

53
00:03:40,065 --> 00:03:44,035
이는 이 위쪽에 있는 신경망은

54
00:03:44,035 --> 00:03:48,455
이 아래 쪽 파라미터와 연결되어 있습니다.

55
00:03:48,455 --> 00:03:52,235
그리고 이 시스템은 꽤 잘 작동 할 수 있습니다.

56
00:03:52,235 --> 00:03:53,420
마지막으로 언급할만한 것은

57
00:03:53,420 --> 00:03:58,905
신경 배치를 상당히 도와 줄 수 있는 계산법 입니다.

58
00:03:58,905 --> 00:04:00,375
즉, 이것이 새로운 이미지라면,

59
00:04:00,375 --> 00:04:03,910
이것은 개찰구가 출입구를 열어 줄 것을 기대하면서 걸어 다니는 직원이라고 해봅시다.

60
00:04:03,910 --> 00:04:08,815
그리고 이것은 여러분의 데이터베이스 이미지 온 것이라고 합시다.

61
00:04:08,815 --> 00:04:11,190
그러면, 매번 이 임베딩을

62
00:04:11,190 --> 00:04:17,520
계산하게 할 필요 없이,

63
00:04:17,520 --> 00:04:20,970
미리 계산 계산해두는 것입니다.

64
00:04:20,970 --> 00:04:22,970
따라서 신입 사원이 들어올 때

65
00:04:22,970 --> 00:04:29,500
이 위쪽 구성 요소를 사용하여 인코딩을 계산하고 사용하면 됩니다

66
00:04:29,500 --> 00:04:31,020
그리고 나서 이걸 미리 계산 된 인코딩과 비교 한 다음

67
00:04:31,020 --> 00:04:36,730
그걸 사용해서 y 모자를 예측하는 것입니다.

68
00:04:36,730 --> 00:04:40,770
원시 이미지를 저장할 필요가 없고,

69
00:04:40,770 --> 00:04:44,880
또한 직원 데이터베이스가 매우 큰 경우

70
00:04:44,880 --> 00:04:50,935
매번 모든 사원 데이터베이스에 대해 이러한 인코딩을 매번 계산할 필요가 없기 때문에.

71
00:04:50,935 --> 00:04:52,980
이러한 자유 컴퓨팅 개념에서는

72
00:04:52,980 --> 00:04:56,880
이러한 인코딩이 중요한 계산을 저장할 수 있습니다.

73
00:04:56,880 --> 00:05:00,775
그리고 이러한 유형의 사전 계산은

74
00:05:00,775 --> 00:05:02,950
얼굴 인식을 이진 분류 문제로 취급하는

75
00:05:02,950 --> 00:05:07,485
Siamese Central architecture뿐 아니라

76
00:05:07,485 --> 00:05:11,160
마지막 강의들에서 설명한 것처럼, 삼중 항 손실 함수를 사용하여

77
00:05:11,160 --> 00:05:15,070
인코딩을 학습했을 때도 모두 작동합니다.

78
00:05:15,070 --> 00:05:16,760
마지막으로 정리하자면,

79
00:05:16,760 --> 00:05:19,530
face verification supervised learning을 다루기 위해,

80
00:05:19,530 --> 00:05:23,460
여러분은 이미지 쌍의 트레이닝 세트를 작성합니다.

81
00:05:23,460 --> 00:05:28,045
여기서는 세 개로 된 이미지 쌍이 되겠네요, 자, 이 타겟 레이블은 1이 됩니다.

82
00:05:28,045 --> 00:05:34,366
같은 사람의 사진 쌍으로 되어있어서요. 그리고 이 타겟레이블은 0입니다.

83
00:05:34,366 --> 00:05:38,880
이것들은 다른 사람의 사진이니까요. 그리고

84
00:05:38,880 --> 00:05:40,845
또 다른 쌍을 가지게 되는데요, 후 방향 전파를 사용하는 과학자들을 교육하는

85
00:05:40,845 --> 00:05:45,660
신경망을 훈련하기 위해 사용하시면 됩니다.

86
00:05:45,660 --> 00:05:49,755
그래서, 여러분이 보셨던 얼굴 검증을 처리 버전, 즉

87
00:05:49,755 --> 00:05:53,918
더 나아가 이진 분류 문제로서의 얼굴 인식인데요,

88
00:05:53,918 --> 00:05:55,645
이것 또한 잘 작동합니다.

89
00:05:55,645 --> 00:05:57,645
이런 식으로, 여러분이

90
00:05:57,645 --> 00:05:59,490
원샷러닝을 할 수 있는 자신의 얼굴 검증이나 얼굴 인식 시스템을 훈련 시키기 위해

91
00:05:59,490 --> 00:06:05,000
필요한 것들을 알게 되기를 바랍니다.