마지막 비디오에서 배웠던 함수 d의 작업은 두 얼굴을 입력하고, 그것이 얼마나 유사한 지 또는 얼마나 다른지를 알려주는 것이었습니다. 이를 수행하는 좋은 방법은 Siamese network를 사용하는 것입니다. 한 번 보시죠. 한번 자세히 살펴볼까요. 여러분께서는 이러한 컨볼네트 사진을 보는 것에 익숙하시죠. x1이라는 이미지를 입력해보겠습니다. 그리고 일련의 컨볼루션, 풀링, 그리고 완전 연결 레이어를 통해 이와 같은 feature vector(피처 벡터)로 마무리됩니다. 그리고 때로는 이것을 softmax 단위로 보내 분류를 합니다. 이번 강의에서는 그렇게 하진 않을 겁니다. 대신, 우리는 이 벡터, 128 에 초점을 맞출 것입니다. 이는 더 깊은 네트워크인 완전 연결 레이어에 의해 계산된 것입니다. 그리고 이 128 개의 숫자 목록에 이름을 붙여보죠. 이 f(x1)이라고 부르겠습니다. f(x1)은 바로 x1의 인풋이미지를 인코딩하는 것으로 생각해야 합니다 Kian의 이 그림을 인풋이미지로 취해서 128 개 숫자의 벡터로 다시 표현합니다. 얼굴 인식 시스템을 구축 할 수 있는 방법은, 두 장의 사진을 비교하고 싶다면 이 두 번째 사진을 이 첫 번째 사진과 비교하고 싶다면, 여러분이 할 일은, 이 두 번째 그림을 동일한 파라미터를 가진 동일한 신경망으로 보내서 이 두 번째 그림을 부호화하는 128 개의 다른 벡터를 얻는 것입니다. 그래서 저는 이 두 번째 그림을 그래서 저는 이 두 번째 그림 인코딩을 f(x2)라고 부르고 여기서 저는 이 두 인풋이미지를 표시하기 위해 x1과 x2를 사용하고 있습니다. 이것이 반드시 트레이닝 세트에 있는 첫 번째 및 두 번째 예시일 필요는 없습니다. 이것은 어떤 그림 두 장이 될 수도 있는 거죠. 마지막으로 이러한 인코딩이이 두 이미지를 잘 나타내 준다고 생각한다면, 여러분이 할 수 있는 것은 d, 즉 x1과 x2 사이의 거리 d는 이 두 이미지의 인코딩의 차이의 표준으로서 이 이미지를 정의하는 것입니다. 두 개의 서로 다른 인풋에 두 개의 동일한 컨볼루션 신경망을 실행 한 다음 비교하는 이 개념을 Siamese 신경망 아키텍처라고 부르기도 합니다. 제가 여기 제시 한 많은 아이디어는 Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato와 Lior Wolf 가 작성한 이 논문에서 비롯되었는데요, 그들이 계발한 연구 시스템에서는 DeepFace라고 불리는 논문입니다. 제가 여기 제시 한 많은 아이디어는 Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato 와Lior Wolf 가 작성한 이 논문에서 비롯되었는데요, 그들이 계발한 시스템에서는 DeepFace라고 불리는 것입니다. 그럼이 Siamese 신경망을 어떻게 훈련 시키나요? 이 두 신경망에는 동일한 파라미터가 있음을 기억하십시오. 여러분이 하고자 하는 것은 신경망을 훈련 시켜서 그것이 계산하는 인코딩이 두 그림이 같은 사람인지를 알려주는 함수 d를 만들어내는 것입니다. 더 형식적으로, 신경망의 파라미터는 f(xi)의 인코딩을 정의합니다. 그래서 임의의 인풋이미지 xi가 주어지면, 신경망은 이 f(xi)를 인코딩하여 이 128차원을 출력합니다. 더 형식적으로, 여러분이 하고 싶은 것은 파라미터를 학습해서 만약 같은 사람의 두 그림 xi, xj가 있다면 인코딩 사이의 거리를 작게 하는 것이죠. 이전 슬라이드에서는 x1과 x2를 사용했지만 이것은 사실 트레이닝 세트에서 xi와 xj의 쌍입니다. 반대로, xi와 xj가 서로 다른 사람이라면, 인코딩 간의 거리가 길어져야 합니다 따라서 신경망의 모든 레이어에서 파라미터를 변경하면 결국 다른 인코딩으로 끝나게 됩니다. 그리고 여러분이 할 수 있는 것은, 후 방향전파를 사용하고 이러한 조건들을 만족시키기 위해 모든 파라미터를 변화시키는 것입니다. 이렇게 Siamese 네트워크 아키텍처에 대해 배워보았습니다. 좋은 인코딩을 만드는 관점에서 신경망이 무엇을 출력하게 해야 하는지에 대한 감각을 얻었습니다. 그러나 실제로 신경망이 방금 우리가 논의한 것을 학습하게 하려면 목적 함수를 어떻게 정의해야 할까요? triplet loss function(삼중 항 손실 기능)을 사용하여 어떻게 그것을 할 수 있는지 다음 강의에서 함께 보도록 하겠습니다.