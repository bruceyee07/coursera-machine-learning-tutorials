为了学习神经网络的参数并以此 获得一个优良的人脸图片的编码， 有一种方法是定义一个应用了梯度下降的三元组损失函数（triplet loss function） 我们看看这是什么意思 要想使用三元组损失， 你需要对比照片组。 比如，我们现在有这张照片， 为了学习到神经网络的参数， 你需要同时看数张照片。 例如，对于这组照片来说， 你希望它们的编码相对类似，因为这是同一个人。 而对于这组照片来说， 你希望它们的编码十分不同，因为这是不同的人。 在三元组损失的术语当中， 你需要做的是查看锚照片， 然后得到锚照片和正例照片之间的差距。 正例照片的意思是 相同的人会有相似的照片 相对而言，当你把锚照片和负例照片对比时， 你希望它们的差距会显得比较大。 这就是为什么这个函数叫三元组损失， 因为你将一直同时查看三张照片。 这三张分别为锚照片， 正例照片和负例照片 我将把锚照片，正例照片和负例照片简写为， A (anchor)，P (positive) 和 N (negative)。所以为了将其形式化， 你需要做的是使你的编码的神经网络中 的参数获得以下性质， 你需要将锚照片的编码 减去正例照片的编码， 你希望这个差很小，而且 你希望这个差小于等于 锚照片的编码和负例照片的编码之间差距的平方。 这边是d(A,P)（A和P的距离） 而这边是d(A,N)（A和N的距离）。 你可以把d想象成距离方程， 所以我们用字母d命名。 现在，如果我们把右边的式子移到左边来， 你将会得到 f(A)减去f(P)的平方，减去， 右手边的式子， f(A)减去f(N)的平方， 小于等于0。 但现在，我们要对这个表达式做些小改变， 有一个情况会使式子的条件轻易得到满足， 是把每一项学习成0。 如果f()永远等于0， 那这就是0减去0， 也就是0，这也是0减去0得到0。 如果说f(任何照片)得到的是一个全是0的矢量， 你可以永远满足这个式子的条件（小于等于0）。 所以，为了确保神经网络不会为所有编码都一直输出0， 为了确保它不会把这些编码训练得和其他的一样。 另一个使神经网络给出一个退化的输出的情况是， 如果每一张照片的编码都和其他任何一张照片的编码完全相同， 你将再次得到0减去0等于0。 所以为了防止神经网络做这些事， 我们需要做的是调整这个式子， 使它不仅仅小于等于0， 而是比0小很多。 所以，比如说我们想要这个式子小于 负alpha, 这里的alpha是另外一个超参数， 这样的话就可以防止神经网络输出退化解。 按照惯例，我们通常 在在左边写成正alpha而不是在右边的负alpha。 这也被称为margin， 如果你之前看过支持向量机的文献的话， 你会熟悉这些术语， 如果没有了解也不用担心。 我们也可以通过加入margin参数来调整上面的式子， 现在来举个例子， 我们把margin设定成0.2， 如果在这个例子里， 锚照片和正例照片的差 d(A,P) 是0.5， 那当锚照片和负例照片的差 d(A,N) 只是稍大一点的时候，比如0.51，式子的条件是满足不了的。 即使0.51确实大于0.5， 这个意思是说，这还不够好，我们想要 d(A,N)远大于d(A,P)， 具体来说， 你想要0.7或者更大的数字。 换种说法，如果要使这个margin达到至少0.2， 你可以把这一项变高，也可以把这一项变低， 从而使两项之间的差距 可以达到超参数alpha＝0.2这个值， 别忘了alpha代表d(A,P)和d(A,N)之间的差距。 这就是这个margin参数的用途， 它可以拉大 d(A,P)和d(A,N)之间的差距。 那么让我们来看一看底部的这个式子， 在下个页面里， 我们将会正式定义三元组损失函数（triplet loss function）。 三元组损失函数由一组中的三张照片而得名， 现在有3张照片， A，P和N， 分别代表锚照片，正例照片和负例照片。 正例照片与锚照片中的人相同， 而负例照片和锚照片中的人不同。 我们将如此定义“损失“ L() 在这里由三张图片 形成的“损失“ L(A,P,N) 让我先将前一页的式子抄下来， 也就是f(A)减去f(P) 的平方 减去 f(A)减去f(N) 的平方 再加上alpha，margin参数， 你想要这整个式子小于等于0。 损失函数的定义即为 这整个式子的结果和0之间的最大值， 这里取最大值的效果是 只要这一项小于0， 那么“损失“便为0， 因为一个小于0的值和0之间的最大值 一定是0。 所以只要你能实现我用绿色线下划的目标， 使它小于等于0， 那么这个例子里的“损失“就是0。 另一方面， 如果这一项是大于0的， 那如果你取最大值， 最终选出的结果 将会是绿色下划线的这一项， 然后你会获得一个大于0的“损失“。 所以通过尝试使这个最小化， 对应的结果是这一项会等于0 或者小于0。 所以只要它是0或者小于0， 神经网络并不需要考虑具体是负多少。 所以这就是你定义一个三元组“损失“的方法， 而神经网络中整体损失函数可以是 一套训练集中不同三元组对应的“损失“的总和。 假如你有一个训练集，其中包含1000个不同的人组成的10000张照片， 你需要做的是用这10000张照片去生成 像这样的三元组， 然后用这种损失函数 训练你那使用梯度下降的学习算法， 而该损失函数是定义在从训练集中抽取的图片上的三元组。 请注意，如果要定义三元组的数据集， 你需要一些成对的A和P，也就是一对包含同一人的照片。 所以为了达到训练的目的， 必须要一个的同一个人会有数张不同照片数据集。 这就是为什么在这个例子中， 我说你有10000张包含1000个不同人的照片， 这样1000人中每个人平均会有10张照片， 来组成你的整个数据集。 如果你每个人只有一张照片， 那你无法训练你的系统。 但训练完成之后， （口误） 当然，在训练好了这个系统后， 你可以将其应用在 你人脸识别系统的一次性的学习任务， 其中你可能只有某个你想要识别的人的一张照片。 但对于你的训练集来说， 你需要确保训练集中的至少其中一部分人 会有数张照片，使得 你可以有成对的锚照片和正向照片。 现在，应该如何正确的选择三元组来组成你的训练集呢？ 这里的问题之一是，如果你从训练集中 随机选择A，P和N，并使A，P为相同的人， 而A，N为不同的人。 有个问题是如果你随机选择它们， 那么这个约束将会非常容易得到满足， 因为如果有两张随机选出的照片， A，N之间的差异会远远大于 A，P之间的差异。希望你仍然记得这些符号 这个d(A,P)就是我们之前讲过的A和P之间的距离 所以这一边是 我们前一页上写的距离的平方。 但如果A和N是两个随机选择的不同的人， 那么有很大几率 右边的式子远远大于左边的式子加alpha。 那么神经网络无法从中学习很多。 所以要建立一个训练集， 你要做的是选择 训练起来比较难的三元组A，P和N。 具体来说，你想要的是所有满足这个约束的三元组， 还需要是一个相对难以训练的三元组 难训练是说A，P，N会使得d(A,P)和d(A,N) 相当接近。 这么一来， 学习算法需要更加努力来 使得右边的值增加或是 左边的值减少， 这样才能使代表左右差距的alpha有意义。 选择这些三元组的效果是 增强你的学习算法的计算效率。 如果你随机选择三元组， 那么很多三元组会是非常简单的， 那么梯度下降无法做任何事，因为你的神经网络 本来就能做对它们。 因此只能通过有难度的三元组来使梯度下降 能做到把这两项之间的距离分得更开。 如果你有兴趣的话， 你可以在底部这篇文献中找到更多的细节，由Florian Schroff，Dmitry Kalinichenko， 和 James Philbin所写，他们有一个叫FaceNet的系统， 我在这个视频里展示的许多概念都是从那里而来。 顺便一提，对于深度学习领域内 如何命名算法有个有趣的事实， 如果你研究某一领域，那么我们称它"__"， 你常会有一个系统叫 "__"网络(__net) 或者 深度"__"(deep __)。 我们现在在讲人脸识别， 所以这篇文献起名为 Facenet (人脸网络)， 在上一个视频中， 你看到了 深度人脸 (deep face)。 这个"__net"或者"deep __"的主意 在深度学习领域中是很普遍的命名算法的方式。 如果你想要了解更多关于如何选择最有用的三元组 训练系统来使你的算法提速的细节， 那你可以去看一下这篇文献。 这篇文献非常不错。 总结一下， 要训练三元组损失， 你需要把你的训练集组成许多三元组。 这是我们的三元组，其中显示同一个人的 锚照片和正例照片，以及显示另一个不同的人的负例照片。 这是另一个锚照片和正例照片是同一个人， 而锚照片和负例照片是不同的人的例子。 你定义完这个包含锚照片，正例照片和负例照片 训练集之后的要做的是 用梯度下降来最小化我们前几页定义的损失函数J 这会随后扩散并影响到 神经网络里所有参数， 从而学习这样一个编码， 使得当两张照片中是同一个人时，这两张照片间的d会很小， 而当两张照片中的人不同时，d的值会很大。 这就是所谓的三元组损失，以及 训练神经网络来学习一个人脸识别的编码的方法。 目前来看， 商业化的人脸识别系统目前是通过相当大的数据库来训练的。 通常会有几百万张照片， 有时候超过一千万照片。 有些商业公司甚至在讨论用超过一亿的照片来训练。 这些即使就当代的标准来说都是非常大的数据集。 这就是所谓的三元组损失，以及 训练神经网络来学习一个人脸识别的好的编码的方法。 目前来看，当今的人脸识别系统， 尤其是大型(large scale)商业化人脸识别系统 是通过相当大的数据库来训练的。 一百万张照片的数据库极其普遍， 有些公司会用一千万张照片，甚至 有些公司会用一亿张照片来训练这些系统。 这些即使就当代的标准来说都是非常大的数据集， 这些数据库资产很难获得。 幸运的是，有些公司已经训练了 大型的神经网络并发布到了网上。 所以，你可以不用从零开始训练这些神经网络， 这个领域里共享数据体积过于庞大， 这个领域里对你更有帮助的做法是 下载别人已训练的模型， 而不是通过自己来做所有事情。 不过即使你下载别人已训练的模型， 了解如何训练这些算法依然对你有帮助， 或者你可以自己应用这些概念来做一些实例。 那么这就是三元组损失了。 这里这个 我会展示同一个神经网络中 不同的变化以及如何训练这些系统。 我们下一节再见