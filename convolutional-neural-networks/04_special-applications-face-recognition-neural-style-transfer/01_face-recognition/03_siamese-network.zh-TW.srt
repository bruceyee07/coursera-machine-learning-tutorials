1
00:00:00,300 --> 00:00:04,300
你從上部影片學到了，d 函數的任務是

2
00:00:04,300 --> 00:00:08,860
輸入兩張臉孔，告訴你他們多像或多不像

3
00:00:08,860 --> 00:00:12,605
要做到這個的好方法是利用 Siamese 網路 (孿生網路)

4
00:00:12,605 --> 00:00:13,105
讓我們來看看

5
00:00:15,117 --> 00:00:19,098
你已經很習慣看到像這種 ConvNet 的圖例，你輸入

6
00:00:19,098 --> 00:00:20,635
一張圖，叫他 x1

7
00:00:20,635 --> 00:00:24,165
然後經過一連串的卷積、池化、

8
00:00:24,165 --> 00:00:28,465
全連結層，最後得到了像這樣子的特徵向量

9
00:00:30,260 --> 00:00:35,940
有時候這個向量會餵給 softmax 進行分類

10
00:00:35,940 --> 00:00:39,000
不過在這部影片，我們不這樣用

11
00:00:39,000 --> 00:00:44,090
取而代之，我們會專注在這一個向量

12
00:00:44,090 --> 00:00:49,900
假設有 128 個數字，是由網路某個深層的全連結層計算出來的

13
00:00:50,930 --> 00:00:54,850
我要將這 128 個數字取個名字

14
00:00:54,850 --> 00:01:00,220
我要叫這 f(x1)

15
00:01:00,220 --> 00:01:07,476
你應該把 f(x1) 想成輸入圖片 x1 的一個編碼

16
00:01:07,476 --> 00:01:12,653
所以它輸入了一張圖，這裡是 Kian 的照片

17
00:01:12,653 --> 00:01:17,750
它會把照片重新表示成一個 128 維的向量

18
00:01:17,750 --> 00:01:22,840
如此一來，要建造一個人臉辨識的系統的話，你可以比較

19
00:01:22,840 --> 00:01:27,890
兩張照片，假設比較這邊第一張和第二張

20
00:01:27,890 --> 00:01:31,860
你可以把第二張照片餵給同樣這個神經網路、

21
00:01:31,860 --> 00:01:37,625
用同樣的參數，然後得到不同的128維的向量

22
00:01:37,625 --> 00:01:41,740
也就是把第二張照片編碼

23
00:01:41,740 --> 00:01:43,560
所以我要把這叫做第二張照片

24
00:01:44,570 --> 00:01:50,480
所以我要把這叫做第二張照片的編碼 f(x2)

25
00:01:50,480 --> 00:01:55,680
這邊我用 x1 和 x2 只是為了表示兩張照片

26
00:01:55,680 --> 00:01:58,030
他們不一定是訓練資料裡面的

27
00:01:58,030 --> 00:02:00,010
第一張和第二張照片

28
00:02:00,010 --> 00:02:02,230
他們可以是任何兩張

29
00:02:02,230 --> 00:02:07,320
最後，如果你相信這些編碼可以很好地代表

30
00:02:07,320 --> 00:02:11,430
這兩張照片的話，那你可以定義

31
00:02:12,670 --> 00:02:16,463
照片 x1 和 x2 之間的距離

32
00:02:16,463 --> 00:02:21,820
為兩張照片的編碼的相差

33
00:02:21,820 --> 00:02:25,750
的範數 (norm)。

34
00:02:26,990 --> 00:02:29,434
將兩個不同的輸入

35
00:02:29,434 --> 00:02:34,544
跑過相同的卷積神經網路，然後比較他們

36
00:02:34,544 --> 00:02:39,380
這種概念有時被稱作 Siamese 神經網路架構

37
00:02:39,380 --> 00:02:43,530
很多我在這邊展示的想法來自於

38
00:02:43,530 --> 00:02:48,490
這篇論文，由 Yaniv Taigman, Ming Yang,
Marc’Aurelio Ranzato

39
00:02:48,490 --> 00:02:53,690
和 Lior Wolf 開發的一個研究系統叫 DeepFace

40
00:02:54,890 --> 00:03:00,741
很多我在這邊展示的想法來自於 Yaniv Taigman,

41
00:03:00,741 --> 00:03:02,920
Ming Yang, Marc’Aurelio Ranzato

42
00:03:02,920 --> 00:03:07,155
和 Lior Wolf 的論文，他們開發了一個 DeepFace 的系統

43
00:03:08,520 --> 00:03:11,830
那麼，你要怎麼訓練這個 Siamese 神經網路呢

44
00:03:11,830 --> 00:03:15,380
還記得這兩個神經網路共享同樣的參數

45
00:03:16,730 --> 00:03:19,600
所以你要做的是訓練這個網路，

46
00:03:19,600 --> 00:03:24,250
讓它計算出的編碼能夠變成 d 函數

47
00:03:24,250 --> 00:03:27,420
而這 d 函數能告訴你兩張照片是否為同一人

48
00:03:27,420 --> 00:03:33,350
更正式地說，這個神經網路的參數定義了一個編碼 f(xi)

49
00:03:33,350 --> 00:03:35,548
所以給定一張輸入的圖片 xi

50
00:03:35,548 --> 00:03:40,968
這神經網路會輸出 128 維的編碼 f(xi)

51
00:03:40,968 --> 00:03:45,655
更正式地說，你要做的是學出參數，達成這個目的：

52
00:03:45,655 --> 00:03:50,152
如果兩張照片 xi 和 xj 是同一人

53
00:03:50,152 --> 00:03:55,347
那你想要兩者的編碼之間的距離很小

54
00:03:55,347 --> 00:03:59,583
— 在上一張投影片我用的是 x1 和 x2

55
00:03:59,583 --> 00:04:03,841
不過其實是訓練資料的任何一對圖片 xi 和 xj

56
00:04:03,841 --> 00:04:07,959
相對地，如果 xi 和 xj 是不同人

57
00:04:07,959 --> 00:04:13,340
那麼你想要兩者的編碼之間的距離很大

58
00:04:13,340 --> 00:04:18,160
所以當你改變神經網路每一層的參數時

59
00:04:18,160 --> 00:04:20,665
你會得到不同種類的編碼

60
00:04:20,665 --> 00:04:23,639
所以你可以利用反向傳播

61
00:04:23,639 --> 00:04:29,590
改變這堆參數，來滿足這些條件

62
00:04:29,590 --> 00:04:33,460
那麼，你學到了 Siamese 網路架構

63
00:04:33,460 --> 00:04:36,890
你也有了些許概念，關於要神經網路輸出什麼

64
00:04:36,890 --> 00:04:39,830
才能達成一個好的編碼

65
00:04:39,830 --> 00:04:42,790
可是，實際上你要如何定義目標函數

66
00:04:42,790 --> 00:04:46,700
讓神經網路能學習到我們剛剛所討論的呢？

67
00:04:46,700 --> 00:04:50,940
在下一部影片，讓我們看看如何利用 "triplet loss" 函數來達成