你從上部影片學到了，d 函數的任務是 輸入兩張臉孔，告訴你他們多像或多不像 要做到這個的好方法是利用 Siamese 網路 (孿生網路) 讓我們來看看 你已經很習慣看到像這種 ConvNet 的圖例，你輸入 一張圖，叫他 x1 然後經過一連串的卷積、池化、 全連結層，最後得到了像這樣子的特徵向量 有時候這個向量會餵給 softmax 進行分類 不過在這部影片，我們不這樣用 取而代之，我們會專注在這一個向量 假設有 128 個數字，是由網路某個深層的全連結層計算出來的 我要將這 128 個數字取個名字 我要叫這 f(x1) 你應該把 f(x1) 想成輸入圖片 x1 的一個編碼 所以它輸入了一張圖，這裡是 Kian 的照片 它會把照片重新表示成一個 128 維的向量 如此一來，要建造一個人臉辨識的系統的話，你可以比較 兩張照片，假設比較這邊第一張和第二張 你可以把第二張照片餵給同樣這個神經網路、 用同樣的參數，然後得到不同的128維的向量 也就是把第二張照片編碼 所以我要把這叫做第二張照片 所以我要把這叫做第二張照片的編碼 f(x2) 這邊我用 x1 和 x2 只是為了表示兩張照片 他們不一定是訓練資料裡面的 第一張和第二張照片 他們可以是任何兩張 最後，如果你相信這些編碼可以很好地代表 這兩張照片的話，那你可以定義 照片 x1 和 x2 之間的距離 為兩張照片的編碼的相差 的範數 (norm)。 將兩個不同的輸入 跑過相同的卷積神經網路，然後比較他們 這種概念有時被稱作 Siamese 神經網路架構 很多我在這邊展示的想法來自於 這篇論文，由 Yaniv Taigman, Ming Yang,
Marc’Aurelio Ranzato 和 Lior Wolf 開發的一個研究系統叫 DeepFace 很多我在這邊展示的想法來自於 Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato 和 Lior Wolf 的論文，他們開發了一個 DeepFace 的系統 那麼，你要怎麼訓練這個 Siamese 神經網路呢 還記得這兩個神經網路共享同樣的參數 所以你要做的是訓練這個網路， 讓它計算出的編碼能夠變成 d 函數 而這 d 函數能告訴你兩張照片是否為同一人 更正式地說，這個神經網路的參數定義了一個編碼 f(xi) 所以給定一張輸入的圖片 xi 這神經網路會輸出 128 維的編碼 f(xi) 更正式地說，你要做的是學出參數，達成這個目的： 如果兩張照片 xi 和 xj 是同一人 那你想要兩者的編碼之間的距離很小 — 在上一張投影片我用的是 x1 和 x2 不過其實是訓練資料的任何一對圖片 xi 和 xj 相對地，如果 xi 和 xj 是不同人 那麼你想要兩者的編碼之間的距離很大 所以當你改變神經網路每一層的參數時 你會得到不同種類的編碼 所以你可以利用反向傳播 改變這堆參數，來滿足這些條件 那麼，你學到了 Siamese 網路架構 你也有了些許概念，關於要神經網路輸出什麼 才能達成一個好的編碼 可是，實際上你要如何定義目標函數 讓神經網路能學習到我們剛剛所討論的呢？ 在下一部影片，讓我們看看如何利用 "triplet loss" 函數來達成