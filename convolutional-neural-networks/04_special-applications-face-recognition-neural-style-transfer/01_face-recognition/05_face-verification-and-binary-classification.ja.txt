Triplet Loss は 顔認識のための ConvNet パラメータを学ぶ いいやり方だ このパラメータを学ぶ 別の方法がある 顔認識がどのようにして 純粋な２項分類の問題なるのかを見てみよう ニューラルネットワークを訓練する別の方法は このニューラルネットワークのペアで シャムネットワークを作り ここを埋める値を どちらも計算する 128次元の値とかだ もしかしたら もっと高次元かもしれないけど それから これらを ロジスティック回帰部に入力して 予測をすればいい これらが 同じ人なら 目的出力は１となり 異なる人なら ０となる これが 顔認識を ただの２項分類問題として扱う方法だ そして これは このようなシステムを訓練する Triplet Loss の代わりになる では この最後の ロジスティック回帰部は 実際には 何をしているのか？ 出力 yハット は シグモイド関数で ある特徴量のセットが投入される ただし 単に これらの符号を 喰わせるのではなく 符号間の差異を取る どういうことか 説明しよう k=１~128で 絶対値の合計を書く この異なる２つの符号間の要素毎のだ 書き終えたら どいうことか説明するよ この表記では f(x(i)) は 画像 x(i) を符号化したものだ 添え字の k は このベクトルの k 番目の要素を意味する これが これら２つの符号の 絶対値での 要素毎の差だ そして これらの128個の数を 特徴量と見なして ロジスティック回帰に喰わせる そして 最後のロジスティック回帰では 追加のパラメータ wi b を 普通のロジスティック回帰と同じように持つ そして これらの128個の特徴量についての重みを訓練する そうして この２つの画像が 同じ人か 違う人か 予測できるようになる これは とても合理的なやり方だ ０か１か 同じ人か違う人か 予測するための学習だ この緑の下線の式の計算には 他にも いくつか方法がある 例えば 別の式は これ k - f(x(j)) k の２乗 割るf(x(i)) + f(x(j))k これは 時々 カイ２乗式と呼ばれる これは ギリシャ文字の χ(カイ) だ これは カイ２乗類似度 とも呼ばれる これと 他のやり方は この DeepFace 論文で探求されている この論文は 前にも引用したよね この学習式では 入力は ペア画像で これが 学習入力 x と y だ y は ０か１で 入力したペアが 似ているか 似ていないかで決まる 前回のと同様に シャム ネットワークを訓練して この上のニューラルネットワークのパラメータが この下のニューラルネットワークのパラメータと結びつく このシステムも 同様に とてもうまく機能する 最後に言っておくことがある 実用上 非常に有意義な計算上の工夫がある もし これが新しい画像の場合 これが 入場ゲートに向かって歩いてる従業員で ゲートが開くのを期待している そして これが データベースの画像だとすると 計算する代わりに 毎回 ここを埋めるのではなく これを事前に計算しておくことができる そして 新しい従業員が歩いてきたら この上の ConvNet を使って 符号化を計算し それを 事前計算しておいた符号と 比較できる そして 予測 yハットを生成できる 生の画像を保存しておく必要は無いから そして とても巨大な従業員データベースがあるなら 毎回 全ての従業員にについて 符号化を計算する必要は無い 計算しないというアイデア これらの事前符号化で 計算を著しく節約できる この種の事前計算は シャム構造を持つようなものに対し 有効だ ２項分類として顔認識を行う場合にも 前のビデオで説明した Triplet Loss を使った符号化を学習する場合にもね じゃ まとめると 顔認識を教師有り学習として扱うには 今回は 学習セットを 単なる画像のペアとして作ればよくて 同じ人の写真のペアなら 目的ラベルが１で 違う人なら０ 色んなペアを使って 誤差逆伝播を使って ニューラルネットワークを訓練して シャム ネットワークを訓練する 今見た２項分類バージョンは 顔認証をする場合も 拡張した顔認識をする場合も どちらも とても良く機能する そんな風に 理解してもらえたらいいな 顔認証を訓練するにせよ One Shot Learning の顔認識システムを訓練するにせよね