1
00:00:00,300 --> 00:00:04,300
마지막 비디오에서 배웠던 함수 d의 작업은

2
00:00:04,300 --> 00:00:08,860
두 얼굴을 입력하고, 그것이 얼마나 유사한 지 또는 얼마나 다른지를 알려주는 것이었습니다.

3
00:00:08,860 --> 00:00:12,605
이를 수행하는 좋은 방법은 Siamese network를 사용하는 것입니다. 한 번 보시죠.

4
00:00:12,605 --> 00:00:13,105
한번 자세히 살펴볼까요.

5
00:00:15,117 --> 00:00:19,098
여러분께서는 이러한 컨볼네트 사진을 보는 것에 익숙하시죠.

6
00:00:19,098 --> 00:00:20,635
x1이라는 이미지를 입력해보겠습니다.

7
00:00:20,635 --> 00:00:24,165
그리고 일련의 컨볼루션, 풀링, 그리고 완전 연결 레이어를 통해

8
00:00:24,165 --> 00:00:28,465
이와 같은 feature vector(피처 벡터)로 마무리됩니다.

9
00:00:30,260 --> 00:00:35,940
그리고 때로는 이것을 softmax 단위로 보내 분류를 합니다.

10
00:00:35,940 --> 00:00:39,000
이번 강의에서는 그렇게 하진 않을 겁니다.

11
00:00:39,000 --> 00:00:44,090
대신, 우리는 이 벡터, 128 에 초점을 맞출 것입니다.

12
00:00:44,090 --> 00:00:49,900
이는 더 깊은 네트워크인 완전 연결 레이어에 의해 계산된 것입니다.

13
00:00:50,930 --> 00:00:54,850
그리고 이 128 개의 숫자 목록에 이름을 붙여보죠.

14
00:00:54,850 --> 00:01:00,220
이 f(x1)이라고 부르겠습니다.

15
00:01:00,220 --> 00:01:07,476
f(x1)은 바로 x1의 인풋이미지를 인코딩하는 것으로 생각해야 합니다

16
00:01:07,476 --> 00:01:12,653
Kian의 이 그림을 인풋이미지로 취해서

17
00:01:12,653 --> 00:01:17,750
128 개 숫자의 벡터로 다시 표현합니다.

18
00:01:17,750 --> 00:01:22,840
얼굴 인식 시스템을 구축 할 수 있는 방법은, 두 장의 사진을 비교하고 싶다면

19
00:01:22,840 --> 00:01:27,890
이 두 번째 사진을 이 첫 번째 사진과 비교하고 싶다면,

20
00:01:27,890 --> 00:01:31,860
여러분이 할 일은, 이 두 번째 그림을 동일한 파라미터를 가진 동일한 신경망으로 보내서

21
00:01:31,860 --> 00:01:37,625
이 두 번째 그림을 부호화하는

22
00:01:37,625 --> 00:01:41,740
128 개의 다른 벡터를 얻는 것입니다.

23
00:01:41,740 --> 00:01:43,560
그래서 저는 이 두 번째 그림을

24
00:01:44,570 --> 00:01:50,480
그래서 저는 이 두 번째 그림 인코딩을 f(x2)라고 부르고

25
00:01:50,480 --> 00:01:55,680
여기서 저는 이 두 인풋이미지를 표시하기 위해 x1과 x2를 사용하고 있습니다.

26
00:01:55,680 --> 00:01:58,030
이것이 반드시 트레이닝 세트에 있는

27
00:01:58,030 --> 00:02:00,010
첫 번째 및 두 번째 예시일 필요는 없습니다.

28
00:02:00,010 --> 00:02:02,230
이것은 어떤 그림 두 장이 될 수도 있는 거죠.

29
00:02:02,230 --> 00:02:07,320
마지막으로 이러한 인코딩이이 두 이미지를 잘 나타내 준다고 생각한다면,

30
00:02:07,320 --> 00:02:11,430
여러분이 할 수 있는 것은

31
00:02:12,670 --> 00:02:16,463
d, 즉 x1과 x2 사이의 거리 d는

32
00:02:16,463 --> 00:02:21,820
이 두 이미지의 인코딩의 차이의 표준으로서

33
00:02:21,820 --> 00:02:25,750
이 이미지를 정의하는 것입니다.

34
00:02:26,990 --> 00:02:29,434
두 개의 서로 다른 인풋에

35
00:02:29,434 --> 00:02:34,544
두 개의 동일한 컨볼루션 신경망을 실행 한 다음 비교하는 이 개념을

36
00:02:34,544 --> 00:02:39,380
Siamese 신경망 아키텍처라고 부르기도 합니다.

37
00:02:39,380 --> 00:02:43,530
제가 여기 제시 한 많은 아이디어는

38
00:02:43,530 --> 00:02:48,490
Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato와 Lior Wolf 가 작성한 이 논문에서 비롯되었는데요,

39
00:02:48,490 --> 00:02:53,690
그들이 계발한 연구 시스템에서는 DeepFace라고 불리는 논문입니다.

40
00:02:54,890 --> 00:03:00,741
제가 여기 제시 한 많은 아이디어는

41
00:03:00,741 --> 00:03:02,920
Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato

42
00:03:02,920 --> 00:03:07,155
와Lior Wolf 가 작성한 이 논문에서 비롯되었는데요, 그들이 계발한 시스템에서는 DeepFace라고 불리는 것입니다.

43
00:03:08,520 --> 00:03:11,830
그럼이 Siamese 신경망을 어떻게 훈련 시키나요?

44
00:03:11,830 --> 00:03:15,380
이 두 신경망에는 동일한 파라미터가 있음을 기억하십시오.

45
00:03:16,730 --> 00:03:19,600
여러분이 하고자 하는 것은 신경망을 훈련 시켜서

46
00:03:19,600 --> 00:03:24,250
그것이 계산하는 인코딩이 두 그림이 같은 사람인지를 알려주는

47
00:03:24,250 --> 00:03:27,420
함수 d를 만들어내는 것입니다.

48
00:03:27,420 --> 00:03:33,350
더 형식적으로, 신경망의 파라미터는 f(xi)의 인코딩을 정의합니다.

49
00:03:33,350 --> 00:03:35,548
그래서 임의의 인풋이미지 xi가 주어지면,

50
00:03:35,548 --> 00:03:40,968
신경망은 이 f(xi)를 인코딩하여 이 128차원을 출력합니다.

51
00:03:40,968 --> 00:03:45,655
더 형식적으로, 여러분이 하고 싶은 것은 파라미터를 학습해서

52
00:03:45,655 --> 00:03:50,152
만약 같은 사람의 두 그림 xi, xj가 있다면

53
00:03:50,152 --> 00:03:55,347
인코딩 사이의 거리를 작게 하는 것이죠.

54
00:03:55,347 --> 00:03:59,583
이전 슬라이드에서는 x1과 x2를 사용했지만

55
00:03:59,583 --> 00:04:03,841
이것은 사실 트레이닝 세트에서 xi와 xj의 쌍입니다.

56
00:04:03,841 --> 00:04:07,959
반대로, xi와 xj가 서로 다른 사람이라면,

57
00:04:07,959 --> 00:04:13,340
인코딩 간의 거리가 길어져야 합니다

58
00:04:13,340 --> 00:04:18,160
따라서 신경망의 모든 레이어에서 파라미터를 변경하면

59
00:04:18,160 --> 00:04:20,665
결국 다른 인코딩으로 끝나게 됩니다.

60
00:04:20,665 --> 00:04:23,639
그리고 여러분이 할 수 있는 것은, 후 방향전파를 사용하고

61
00:04:23,639 --> 00:04:29,590
이러한 조건들을 만족시키기 위해 모든 파라미터를 변화시키는 것입니다.

62
00:04:29,590 --> 00:04:33,460
이렇게 Siamese 네트워크 아키텍처에 대해 배워보았습니다.

63
00:04:33,460 --> 00:04:36,890
좋은 인코딩을 만드는 관점에서

64
00:04:36,890 --> 00:04:39,830
신경망이 무엇을 출력하게 해야 하는지에 대한 감각을 얻었습니다.

65
00:04:39,830 --> 00:04:42,790
그러나 실제로 신경망이 방금 우리가 논의한 것을 학습하게 하려면

66
00:04:42,790 --> 00:04:46,700
목적 함수를 어떻게 정의해야 할까요?

67
00:04:46,700 --> 00:04:50,940
triplet loss function(삼중 항 손실 기능)을 사용하여 어떻게 그것을 할 수 있는지 다음 강의에서 함께 보도록 하겠습니다.