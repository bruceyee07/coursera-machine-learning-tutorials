신경 스타일 변형 알고리즘의 비용 함수는 내용 원가 요소와 스타일 원가 요소를 가지고 있습니다. 콘텐츠 비용 구성 요소를 정의하여 시작하겠습니다. 이것은 신경 스타일 변형 알고리즘의 전체적인 비용 함수라는 것을 기억하십시오. 콘텐츠 비용 기능이 무엇인지 알아 봅시다. 히든 레이어 l (알파벳 L의 소문자)을 사용하여 콘텐츠 비용을 계산한다고 가정 해 보겠습니다. l이 매우 작은 숫자인 경우, 히든 레이어 1을 사용하면 생성된 이미지가 콘텐츠 이미지와 . 매우 비슷한 픽셀 값을 가지도록 만듭니다. 반면에 심층 레이어를 사용하면 그것은 이렇게 요청합니다. ‘콘텐츠 이미지에 개가 있는 경우엔, 생성 된 이미지의 어딘가에 개가 있는지 확인해야 해’ 라고 말이죠. 실제로는, 레이어 l 은 너무 얕지도 않고, 너무 깊지도 않는 신경망 사이에서 선택된 것이죠. 자, 여러분은 이번 주 마지막에 하는 문제연습에서, 이걸 계획하고 계실 테니, 문제 연습에서 구체적인 예시들을 가지고 좀 더 직관을 키우실 수 있도록 여러분에게 맡기도록 하죠. 하지만 보통 l 은 신경망 레이어의 중간 어딘가에 있도록 선택되어서, 너무 얕지도, 너무 깊지도 않게 되었습니다. 여러분이 할 수 있는 것은 사전 훈련 된 컨볼네트 어쩌면 VGG 네트워크를 사용하거나 다른 신경망을 사용하는 것입니다. 이제, 콘텐츠 이미지와 생성 된 이미지가 주어지면 그 둘이 얼마나 유사한지 측정하면 됩니다. 그리고 나서 이 a의 위 첨자 [l] (c) 와 이것이 이 두 이미지 C와 G 에 대해 레이어 l 의 활성화(activation)가 되게 하십시오. 이 두 가지 활성화가 유사하다면 두 이미지가 비슷한 내용을 가지고 있다는 것을 함축하고 있는 것이죠. 그래서 우리가 할 일은 J content(C, G) 는 이 활성화가 얼마나 빠르고 혹은 얼마나 다른지를 알려줍니다. 그래서, 우리는 레이어 l 에 있는 히든 유닛 활성화 사이에 생긴 이 요소 간 차이를 취할 것 입니다. 컨텐츠 이미지에서 지나간 것과 생성된 이미지에서 지나간 것을 비교하고 그것에다가 제곱을 하여 값을 구할 것입니다. 그리고 normalization constant가 앞에 올 수도 있고 아닐 수도 있는데, 이건 1/2 혹은 다른 게 될 수도 있습니다. 이것은 이 하이퍼 파라미터 알파에 의해서도 조정될 수 있기 때문에 정말로 중요하지 않습니다. 그래서 분명히 할 것은, 저는 이 두 수식이 벡터로 전개된 것처럼 이를 사용하고 있다는 것입니다. 따라서, 이것과 이것을 벡터로 펼치고 나면 이것은 이 두 l norm들의 제곱이 됩니다. 이것은 실제로 이 두 활성화 사이의 차이를 제곱한 요소 간 합이 되는 것이죠. 이것은 실제로 레이어 l 에서 활성화, 즉 이미지 C와 G 사이의 차이를 제곱한. 요소 간 합 입니다 나중에 여러분이 G 값을 찾기 위해 J(G)로 기울기 강하를 수행할 때 전체적인 비용은 낮게 되는데요, 이것은 이미지 G를 찾는 알고리즘을 권장할 것입니다. 그러면 이 히든 레이어 활성화는 컨텐츠 이미지에서 얻은 것과 비슷해지겠죠. 자, 이것이 신경 스타일 변형을 위한 콘텐츠 비용 함수를 정의하는 방법입니다. 다음으로는, 스타일 비용 함수 강의로 가시죠.