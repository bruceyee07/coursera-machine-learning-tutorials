1
00:00:00,570 --> 00:00:03,330
深度ConvNets真正在学习什么

2
00:00:03,330 --> 00:00:07,420
在本节中 我想向你展示<br />一些可视化的结果 帮你

3
00:00:07,420 --> 00:00:11,900
训练直觉 了解ConvNet中那些很深的层真正在做什么

4
00:00:11,900 --> 00:00:14,845
这能帮助我们通盘考虑<br />如何实现

5
00:00:14,845 --> 00:00:17,015
神经风格迁移

6
00:00:17,015 --> 00:00:18,735
让我们从一个例子开始

7
00:00:18,735 --> 00:00:23,895
假设你已经训练好了一个ConvNet<br />就像AlexNet这样的网络

8
00:00:23,895 --> 00:00:28,885
你想用可视化的方法把不同层中<br />隐藏单元的当前计算内容展现出来

9
00:00:28,885 --> 00:00:30,255
你可以这么做

10
00:00:30,255 --> 00:00:33,920
让我们  从第一层的隐藏单元开始

11
00:00:33,920 --> 00:00:38,790
假设你浏览你的训练集<br />找出哪些图像或

12
00:00:38,790 --> 00:00:43,960
图块对该单元的激励程度最大

13
00:00:43,960 --> 00:00:49,260
换句话说 在你的神经网络中把<br />训练集暂停下来

14
00:00:49,260 --> 00:00:55,250
弄清楚哪个图片最大程度地<br />激活了该特定单元

15
00:00:55,250 --> 00:00:58,130
现在我们来看 第1层中的隐藏单元

16
00:00:58,130 --> 00:01:02,750
只能看到这个神经网络中<br />较小的一部分

17
00:01:02,750 --> 00:01:08,170
所以如果你要可视化画出<br />是什么激活了该单元 

18
00:01:08,170 --> 00:01:11,360
只画出一小块图像<br />也是合理的

19
00:01:11,360 --> 00:01:15,190
因为那个特定的单元只<br />看到了这些图像部分

20
00:01:15,190 --> 00:01:20,220
所以如果你选择了一个隐藏层<br />要找出有哪九个输入图像最大程度地

21
00:01:20,220 --> 00:01:25,380
激励了该单元 你可能<br />会发现像这样的九个图块

22
00:01:25,380 --> 00:01:30,293
看起来就像在那个特定的隐藏单元<br />看到的图片中

23
00:01:30,293 --> 00:01:34,691
它正在偏下的区域找像一条边或<br />一根线那样的东西

24
00:01:34,691 --> 00:01:39,091
所以这些就是那九个图块<br />他们最大程度地激活了

25
00:01:39,091 --> 00:01:41,559
一个隐藏单元

26
00:01:41,559 --> 00:01:47,055
接下来你可以在第1层中挑出<br />不同的隐藏单元再做一遍类似的事

27
00:01:47,055 --> 00:01:51,149
这是不同的隐藏单元<br />看起来第二个隐藏单元

28
00:01:51,149 --> 00:01:54,170
由这9个图块表示

29
00:01:54,170 --> 00:01:58,679
看起来这个隐藏单元正在<br />输入区域的那部分里面找

30
00:01:58,679 --> 00:02:02,540
类似一条线的东西<br />输入区域的那个部分我们也把它叫做感受野

31
00:02:02,540 --> 00:02:07,075
对于其他的隐藏单元 如果你这么做<br /> 你会发现其他的隐藏单元

32
00:02:07,075 --> 00:02:11,140
倾向于受到类似这样的图块激活

33
00:02:11,140 --> 00:02:15,180
这一个看起来喜欢垂直的浅色边<br />但是

34
00:02:15,180 --> 00:02:18,710
最好它的左侧是绿色的

35
00:02:18,710 --> 00:02:23,882
这一个真的喜欢橘色<br />这是一个有趣的图块

36
00:02:23,882 --> 00:02:29,730
红色和绿色合在一起会<br />组成棕色或棕橘色

37
00:02:29,730 --> 00:02:34,294
不过神经元仍然很高兴<br />会被它激活，等等

38
00:02:34,294 --> 00:02:38,399
这是九种不同的<br />代表性神经元

39
00:02:38,399 --> 00:02:43,369
每种都对应能最大程度激活它的九个图块

40
00:02:43,369 --> 00:02:48,066
这会给你一种感觉<br />第1层中的训练用隐藏单元

41
00:02:48,066 --> 00:02:49,868
它们通常在寻找

42
00:02:49,868 --> 00:02:55,010
相对简单的特征<br />比如边或特别的颜色

43
00:02:55,010 --> 00:02:57,920
我在这个视频中用到的所有例子

44
00:02:57,920 --> 00:03:01,160
来源于Mathew Zeiler和Rob Fergus的这篇论文

45
00:03:01,160 --> 00:03:06,440
论文的标题为可视化及理解卷积网络

46
00:03:06,440 --> 00:03:10,689
下面我会用一种更简单的方式来

47
00:03:10,689 --> 00:03:14,680
可视化展现神经网络中<br />隐藏单元所计算的东西

48
00:03:14,680 --> 00:03:18,706
如果你读过他们的论文<br />会发现在ConvNet运行时

49
00:03:18,706 --> 00:03:21,480
还可以用一些更复杂的方法进行可视化

50
00:03:22,520 --> 00:03:26,064
现在你把这个过程已经重复了好几遍

51
00:03:26,064 --> 00:03:28,380
得到了第1层中九个隐藏单元的情况

52
00:03:28,380 --> 00:03:29,900
在神经网络更深的层中

53
00:03:29,900 --> 00:03:33,790
如果你对其中的某些<br />隐藏单元做这样的操作会发生什么呢

54
00:03:33,790 --> 00:03:37,950
在更深的层中神经网络学习了什么

55
00:03:37,950 --> 00:03:43,120
在更深的层中隐藏单元<br />将看到更大一部分图像

56
00:03:43,120 --> 00:03:46,540
在极端的情况下每个像素

57
00:03:46,540 --> 00:03:51,560
说不定都会影响神经网络<br />后面这些层的输出

58
00:03:51,560 --> 00:03:55,040
所以后续的单元实际上看到了更大的图块

59
00:03:55,040 --> 00:03:59,580
在这些幻灯片上面<br />我会画一些相同大小的图块

60
00:03:59,580 --> 00:04:04,370
但是如果我们重复这一过程<br />也就是之前在第1层做的那样

61
00:04:04,370 --> 00:04:09,610
这是最大程度激活第2层中九个不同隐藏单元

62
00:04:09,610 --> 00:04:12,320
的因素的可视化

63
00:04:12,320 --> 00:04:15,416
现在我想讲清楚这个可视化是什么

64
00:04:15,416 --> 00:04:20,864
这些是让一个隐藏单元<br />高度激活的九个图块

65
00:04:20,864 --> 00:04:25,471
然后 对于每个分组 这是由<br />九个图块组成的不同的集合

66
00:04:25,471 --> 00:04:27,940
使得一个隐藏单元被激活

67
00:04:27,940 --> 00:04:32,630
这个可视化展示了第2层的<br />九个隐藏单元

68
00:04:32,630 --> 00:04:36,700
对于其中的每一个展示了<br />九个图块 它们让隐藏单元

69
00:04:36,700 --> 00:04:39,890
拥有了非常大的输出<br />非常大的激活

70
00:04:39,890 --> 00:04:44,120
对于更深的层<br />你也可以重复这些过程

71
00:04:44,120 --> 00:04:46,980
现在在这张幻灯片上<br />我知道看清这些小的图块

72
00:04:46,980 --> 00:04:49,188
有点难 所以让我们放大<br />其中的一部分

73
00:04:49,188 --> 00:04:52,170
对于第1层 你已经看到了这个

74
00:04:52,170 --> 00:04:58,270
例如 这是我们看到的<br />第一个高度激活的单元

75
00:04:58,270 --> 00:05:03,840
如果在输入图片的区域内<br />你可以看到可能那个角上面有一条边

76
00:05:03,840 --> 00:05:08,350
现在我们再放大第2层 看看这边的可视化

77
00:05:08,350 --> 00:05:09,750
很有意思

78
00:05:09,750 --> 00:05:14,030
看起来第2层在检测<br />更复杂的形状和模式

79
00:05:14,030 --> 00:05:17,300
例如 这个隐藏单元<br />看起来像在寻找

80
00:05:17,300 --> 00:05:21,110
拥有很多垂直线条<br />的垂直纹理

81
00:05:21,110 --> 00:05:24,150
这个隐藏单元看起来就像<br />当图像的左边部分

82
00:05:24,150 --> 00:05:27,730
有一个较圆的形状时<br />它就会被高度激活

83
00:05:27,730 --> 00:05:33,690
这个在寻找非常细的垂直线条等等

84
00:05:33,690 --> 00:05:38,810
所以第二层探测的特征<br />变得更复杂

85
00:05:38,810 --> 00:05:39,980
第3层怎么样呢

86
00:05:39,980 --> 00:05:43,476
我们放大一下<br />事实上 让我再放大一点

87
00:05:43,476 --> 00:05:48,156
你可以看得更清楚<br />这些是最大程度激活第3层的东西

88
00:05:48,156 --> 00:05:52,806
让我们再放大一点<br />这也非常有意思

89
00:05:52,806 --> 00:05:57,139
看起来有一个隐藏单元<br />似乎对

90
00:05:57,139 --> 00:06:01,981
图像左下部分处较圆的形状反应很大

91
00:06:01,981 --> 00:06:06,523
所以最后检测出了很多<br />汽车 狗

92
00:06:06,523 --> 00:06:10,735
令人惊喜的是甚至开始检测人

93
00:06:10,735 --> 00:06:15,593
这个看起来正在检测<br />像蜂巢的某种纹理

94
00:06:15,593 --> 00:06:18,358
或是方形 或是不规则的纹理

95
00:06:18,358 --> 00:06:22,356
其中的一些看起来相当难<br />需要人工判断它

96
00:06:22,356 --> 00:06:26,900
正在检测的是什么<br />但它明显开始在检测更复杂的模式

97
00:06:26,900 --> 00:06:27,880
那么下一层是什么情况呢

98
00:06:27,880 --> 00:06:30,903
这是第4层<br />你会看到正在检测

99
00:06:30,903 --> 00:06:33,508
的特征或模式更为复杂

100
00:06:33,508 --> 00:06:37,410
看起来几乎已经<br />学出了一个狗检测器 但是

101
00:06:37,410 --> 00:06:39,250
所有这些狗都比较类似 对吧

102
00:06:39,250 --> 00:06:42,770
这是 我不知道是哪种狗<br />或者说不知道狗的血统

103
00:06:42,770 --> 00:06:47,700
不过现在所有这些都是狗<br />它们看起来比较彼此相似

104
00:06:47,700 --> 00:06:51,680
看看这个隐藏单元<br />它在识别水

105
00:06:53,130 --> 00:06:58,440
这个看起来像实际上<br />在识别鸟腿等等

106
00:06:58,440 --> 00:07:02,740
然后第5层在识别<br />更复杂的东西

107
00:07:02,740 --> 00:07:07,396
那么 你会发现这还有一个神经元<br />似乎是一个狗检测器

108
00:07:07,396 --> 00:07:12,450
但这里检测出的狗的集合中<br />狗的种类看起来更多

109
00:07:12,450 --> 00:07:17,610
然后这看起来这是在识别键盘<br />以及带类似键盘纹理的东西

110
00:07:17,610 --> 00:07:22,360
虽然可能是背景上的很多点

111
00:07:22,360 --> 00:07:27,950
我觉得这个神经元可能在检测文字<br />总是很难得到确定的答案

112
00:07:27,950 --> 00:07:31,520
这个在检测花

113
00:07:31,520 --> 00:07:35,430
我们经历了很长的过程<br />才检测出相对简单的东西

114
00:07:35,430 --> 00:07:38,135
比如从第1层的边<br />到第2层的纹理

115
00:07:38,135 --> 00:07:43,780
再到在更深的层中检测的<br />非常复杂的物体

116
00:07:43,780 --> 00:07:48,420
所以我希望这能让你有<br />更好的直觉 了解

117
00:07:48,420 --> 00:07:52,120
神经网络中较浅和较深的各层在计算什么

118
00:07:52,120 --> 00:07:56,763
在下一节中 我们会使用这种直觉<br />搭建神经风格迁移

119
00:07:56,763 --> 00:07:57,530
只有两行的算法。