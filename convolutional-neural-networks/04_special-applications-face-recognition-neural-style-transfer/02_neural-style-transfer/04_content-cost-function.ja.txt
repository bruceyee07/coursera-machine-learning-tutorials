ニューラル スタイル変換アルゴリズムのコスト関数は 内容コスト関数 と スタイルコスト関数 だ まず 内容コスト関数を定義しよう これが ニューラル スタイル変換アルゴリズムの全コスト関数だ 内容コスト関数をどうすべきか 明らかにしよう 内容コストを計算するのに 隠れ層 l(エル) を使うものとする もし l が とても小さい数なら もし 隠れ層１を使うなら 生成画像に 本当に 内容画像に とても良く似たピクセル値を持たせることになる 一方 とても深い層を使うなら そうしたら こう尋ねていることになる 「もし 内容画像に犬がいるなら 生成画像のどこかに 確実に犬を置いてくれ」 実際には 層 l は どこか中間が選ばれる ニューラルネットワークの中の 浅すぎも 深すぎもしない場所だ 今週終わりに行う プログラミング演習では あなた自身が行う あなた自身で 何らかの洞察を得てやってもらいたい プログラミング演習での具体例でね しかし 通常 l は どこか ニューラルネットワークの中間が選ばれる 浅すぎず 深すぎない それから 事前訓練された ConvNet を使う 例えば VGG ネットワークや 他のニューラルネットワークを使うことができる そして 内容画像と生成画像が 内容面で どのくらい似ているかを測りたい だから こうする a[l](c) と これを ２画像 画像 C と G の 層 l における活性とする この２つの活性が似ていれば 両画像は 似た内容を持っているということになる だから こう定義する J_contnet(C, G) は この２つの活性が どのくらい似ているか違っているかを表す よって 要素毎の違いを取ろう 層 l における この隠れユニット活性の 内容画像を渡した時のと 生成画像を渡した時のの違いを そして それを２乗する 前に 正規化常数を入れてもよい それは ２分の１とか 他の値になるだけだ それは 重要ではない このハイパーパラメータ α で 調整できるから ハッキリさせておきたいことがある ここでは この両方が ベクトルに展開されているかのような表記にしている つまり これは これと これの L2ノルムの 2乗になっているけど これらをベクトルに展開した後 そうするということだ これは この２つの活性間の 要素毎の違いの ２乗の合計だ これは 画像 C と G の 層 l における活性の 要素毎の違いの２乗だ そして G の値を探すため J(G) を 後で 勾配降下法にかけると 全コストが低くなるようにする これは 画像 G を見つけるようにアルゴリズムに作用する そうして ここの隠れ層の活性が 内容画像に対してのものと 似てくる 以上が ニューラル スタイル変換の 内容コスト関数の定義方法だ 次は スタイルコスト関数に移ろう