神經風格轉換演算法的成本函數 包含「內容成本」和「風格成本」的部份
("content cost" and "style cost") 讓我們先從定義「內容成本」這一半開始 回憶一下，這整個式子是神經風格轉換的成本函數 那麼，讓我們想一下「內容成本」應該要是什麼 假設你使用了第 l 隱藏層來計算內容成本 如果 l 很小、如果你用第 1 層隱藏層 那麼這會迫使你生成的圖片 在像素的層級上，值非常接近內容圖片的值 反之，如果你取用非常深的層 那這就像是要求 「如果你的內容圖片裡面有狗的話， 確保你生成的圖片裡某處有狗就好」 所以實務上，選 l 層的時候會選中間的層 不會選網路太淺會太深的層。 在這周結尾的程式作業 因為你會自己體驗玩玩看 所以我就讓你到時候獲得一些感覺 藉由作業中實際的例子。 不過通常來說，我們會選 l 選在網路中間的某層 不會太淺也不會太深。 接下來，你可以利用預先訓練好的 ConvNet 例如 VGG 網路 或者可能是其他的網路 那現在，你想要衡量 給定一張內容圖片以及一張生成的圖片 就內容來說，兩者會多像呢？ 所以讓我們將 a^[l](C) 和這一項表示為這兩張圖片在第 l 層的啟動值 圖片 C 和 G 的啟動值 所以如果這兩個啟動值很相似 那麼這似乎意味著兩張圖片的內容很像 所以，我們會去定義 J_content(C, G) 為 這兩個啟動值多像或多不一樣 所以我們會拿逐元素的差異 兩者在第 l 層的隱藏單元之間的差異 當你把內容圖片傳入網路，跟 傳入生成圖片時的差異 然後取平方 你可以在前面放個標準化的常數，也可不用 例如二分之一或是其他的 其實不大重要，因為這也會被超參數 alpha 調整掉 所以只是澄清一下 我這邊用這個符號，是當作這兩個被攤平成向量 所以這麼以來，這變成兩者之間的 L2 範數的平方 當你把這兩者攤平成向量以後 這其實是逐元素總和 取在兩者啟動值的相差的平方 不過這其實是圖片 C 和 G 在第 l 層的啟動值的 差異的平方的逐元素總和 因此，當之後對 J(G) 做梯度下降法，以嘗試得出 G 的值 讓整個成本很低的時候 這會鼓勵演算法去找出某張圖片 G 讓這隱藏層的這些啟動值和內容圖片的很相似。 那麼，這就是定義神經風格轉換中「內容成本」的方式 接下來，讓我們繼續研究「風格成本」函數