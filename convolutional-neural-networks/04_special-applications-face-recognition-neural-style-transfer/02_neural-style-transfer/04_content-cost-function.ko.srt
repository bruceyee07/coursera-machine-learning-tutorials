1
00:00:00,000 --> 00:00:03,500
신경 스타일 변형 알고리즘의 비용 함수는

2
00:00:03,500 --> 00:00:07,975
내용 원가 요소와 스타일 원가 요소를 가지고 있습니다.

3
00:00:07,975 --> 00:00:11,455
콘텐츠 비용 구성 요소를 정의하여 시작하겠습니다.

4
00:00:11,455 --> 00:00:17,595
이것은 신경 스타일 변형 알고리즘의 전체적인 비용 함수라는 것을 기억하십시오.

5
00:00:17,595 --> 00:00:21,660
콘텐츠 비용 기능이 무엇인지 알아 봅시다.

6
00:00:21,660 --> 00:00:26,380
히든 레이어 l (알파벳 L의 소문자)을 사용하여 콘텐츠 비용을 계산한다고 가정 해 보겠습니다.

7
00:00:26,380 --> 00:00:30,920
l이 매우 작은 숫자인 경우, 히든 레이어 1을 사용하면

8
00:00:30,920 --> 00:00:34,440
생성된 이미지가 콘텐츠 이미지와 .

9
00:00:34,440 --> 00:00:37,875
매우 비슷한 픽셀 값을 가지도록 만듭니다.

10
00:00:37,875 --> 00:00:39,735
반면에 심층 레이어를 사용하면

11
00:00:39,735 --> 00:00:41,260
그것은 이렇게 요청합니다.

12
00:00:41,260 --> 00:00:43,040
‘콘텐츠 이미지에 개가 있는 경우엔,

13
00:00:43,040 --> 00:00:46,150
생성 된 이미지의 어딘가에 개가 있는지 확인해야 해’ 라고 말이죠.

14
00:00:46,150 --> 00:00:50,310
실제로는, 레이어 l 은

15
00:00:50,310 --> 00:00:53,015
너무 얕지도 않고, 너무 깊지도 않는 신경망 사이에서 선택된 것이죠.

16
00:00:53,015 --> 00:00:55,780
자, 여러분은 이번 주 마지막에 하는 문제연습에서,

17
00:00:55,780 --> 00:00:58,765
이걸 계획하고 계실 테니,

18
00:00:58,765 --> 00:01:01,260
문제 연습에서 구체적인 예시들을 가지고

19
00:01:01,260 --> 00:01:04,475
좀 더 직관을 키우실 수 있도록 여러분에게 맡기도록 하죠.

20
00:01:04,475 --> 00:01:06,810
하지만 보통 l 은 신경망 레이어의

21
00:01:06,810 --> 00:01:09,080
중간 어딘가에 있도록 선택되어서,

22
00:01:09,080 --> 00:01:12,170
너무 얕지도, 너무 깊지도 않게 되었습니다.

23
00:01:12,170 --> 00:01:15,285
여러분이 할 수 있는 것은 사전 훈련 된 컨볼네트

24
00:01:15,285 --> 00:01:17,317
어쩌면 VGG 네트워크를 사용하거나

25
00:01:17,317 --> 00:01:20,020
다른 신경망을 사용하는 것입니다.

26
00:01:20,020 --> 00:01:22,050
이제, 콘텐츠 이미지와 생성 된 이미지가 주어지면

27
00:01:22,050 --> 00:01:26,160
그 둘이 얼마나 유사한지

28
00:01:26,160 --> 00:01:29,688
측정하면 됩니다.

29
00:01:29,688 --> 00:01:31,540
그리고 나서

30
00:01:31,540 --> 00:01:39,900
이 a의 위 첨자 [l] (c) 와 이것이 이 두 이미지 C와 G 에 대해

31
00:01:39,900 --> 00:01:42,814
레이어 l 의 활성화(activation)가 되게 하십시오.

32
00:01:42,814 --> 00:01:47,020
이 두 가지 활성화가 유사하다면

33
00:01:47,020 --> 00:01:52,602
두 이미지가 비슷한 내용을 가지고 있다는 것을 함축하고 있는 것이죠.

34
00:01:52,602 --> 00:01:54,855
그래서 우리가 할 일은

35
00:01:54,855 --> 00:02:01,510
J content(C, G) 는

36
00:02:01,510 --> 00:02:05,345
이 활성화가 얼마나 빠르고 혹은 얼마나 다른지를 알려줍니다.

37
00:02:05,345 --> 00:02:08,320
그래서, 우리는 레이어 l 에 있는

38
00:02:08,320 --> 00:02:12,200
히든 유닛 활성화 사이에 생긴 이 요소 간 차이를 취할 것 입니다.

39
00:02:12,200 --> 00:02:14,710
컨텐츠 이미지에서 지나간 것과

40
00:02:14,710 --> 00:02:17,736
생성된 이미지에서 지나간 것을 비교하고

41
00:02:17,736 --> 00:02:19,955
그것에다가 제곱을 하여 값을 구할 것입니다.

42
00:02:19,955 --> 00:02:23,760
그리고 normalization constant가 앞에 올 수도 있고 아닐 수도 있는데,

43
00:02:23,760 --> 00:02:25,535
이건 1/2 혹은 다른 게 될 수도 있습니다.

44
00:02:25,535 --> 00:02:31,935
이것은 이 하이퍼 파라미터 알파에 의해서도 조정될 수 있기 때문에 정말로 중요하지 않습니다.

45
00:02:31,935 --> 00:02:37,070
그래서 분명히 할 것은,

46
00:02:37,070 --> 00:02:42,635
저는 이 두 수식이 벡터로 전개된 것처럼 이를 사용하고 있다는 것입니다.

47
00:02:42,635 --> 00:02:47,975
따라서, 이것과 이것을 벡터로 펼치고 나면

48
00:02:47,975 --> 00:02:51,680
이것은 이 두 l norm들의 제곱이 됩니다.

49
00:02:51,680 --> 00:02:54,492
이것은 실제로 이 두 활성화 사이의 차이를 제곱한

50
00:02:54,492 --> 00:02:59,480
요소 간 합이 되는 것이죠.

51
00:02:59,480 --> 00:03:03,000
이것은 실제로 레이어 l 에서 활성화, 즉 이미지 C와 G

52
00:03:03,000 --> 00:03:06,150
사이의 차이를 제곱한.

53
00:03:06,150 --> 00:03:11,850
요소 간 합 입니다

54
00:03:11,850 --> 00:03:17,100
나중에 여러분이 G 값을 찾기 위해 J(G)로 기울기 강하를 수행할 때

55
00:03:17,100 --> 00:03:19,740
전체적인 비용은 낮게 되는데요,

56
00:03:19,740 --> 00:03:23,120
이것은 이미지 G를 찾는 알고리즘을 권장할 것입니다.

57
00:03:23,120 --> 00:03:29,203
그러면 이 히든 레이어 활성화는 컨텐츠 이미지에서 얻은 것과 비슷해지겠죠.

58
00:03:29,203 --> 00:03:33,985
자, 이것이 신경 스타일 변형을 위한 콘텐츠 비용 함수를 정의하는 방법입니다.

59
00:03:33,985 --> 00:03:37,000
다음으로는, 스타일 비용 함수 강의로 가시죠.