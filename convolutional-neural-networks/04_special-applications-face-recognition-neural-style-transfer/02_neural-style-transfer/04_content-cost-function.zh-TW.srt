1
00:00:00,000 --> 00:00:03,500
神經風格轉換演算法的成本函數

2
00:00:03,500 --> 00:00:07,975
包含「內容成本」和「風格成本」的部份
("content cost" and "style cost")

3
00:00:07,975 --> 00:00:11,455
讓我們先從定義「內容成本」這一半開始

4
00:00:11,455 --> 00:00:17,595
回憶一下，這整個式子是神經風格轉換的成本函數

5
00:00:17,595 --> 00:00:21,660
那麼，讓我們想一下「內容成本」應該要是什麼

6
00:00:21,660 --> 00:00:26,380
假設你使用了第 l 隱藏層來計算內容成本

7
00:00:26,380 --> 00:00:30,920
如果 l 很小、如果你用第 1 層隱藏層

8
00:00:30,920 --> 00:00:34,440
那麼這會迫使你生成的圖片

9
00:00:34,440 --> 00:00:37,875
在像素的層級上，值非常接近內容圖片的值

10
00:00:37,875 --> 00:00:39,735
反之，如果你取用非常深的層

11
00:00:39,735 --> 00:00:41,260
那這就像是要求

12
00:00:41,260 --> 00:00:43,040
「如果你的內容圖片裡面有狗的話，

13
00:00:43,040 --> 00:00:46,150
確保你生成的圖片裡某處有狗就好」

14
00:00:46,150 --> 00:00:50,310
所以實務上，選 l 層的時候會選中間的層

15
00:00:50,310 --> 00:00:53,015
不會選網路太淺會太深的層。

16
00:00:53,015 --> 00:00:55,780
在這周結尾的程式作業

17
00:00:55,780 --> 00:00:58,765
因為你會自己體驗玩玩看

18
00:00:58,765 --> 00:01:01,260
所以我就讓你到時候獲得一些感覺

19
00:01:01,260 --> 00:01:04,475
藉由作業中實際的例子。

20
00:01:04,475 --> 00:01:06,810
不過通常來說，我們會選 l

21
00:01:06,810 --> 00:01:09,080
選在網路中間的某層

22
00:01:09,080 --> 00:01:12,170
不會太淺也不會太深。

23
00:01:12,170 --> 00:01:15,285
接下來，你可以利用預先訓練好的 ConvNet

24
00:01:15,285 --> 00:01:17,317
例如 VGG 網路

25
00:01:17,317 --> 00:01:20,020
或者可能是其他的網路

26
00:01:20,020 --> 00:01:22,050
那現在，你想要衡量

27
00:01:22,050 --> 00:01:26,160
給定一張內容圖片以及一張生成的圖片

28
00:01:26,160 --> 00:01:29,688
就內容來說，兩者會多像呢？

29
00:01:29,688 --> 00:01:31,540
所以讓我們將

30
00:01:31,540 --> 00:01:39,900
a^[l](C) 和這一項表示為這兩張圖片在第 l 層的啟動值

31
00:01:39,900 --> 00:01:42,814
圖片 C 和 G 的啟動值

32
00:01:42,814 --> 00:01:47,020
所以如果這兩個啟動值很相似

33
00:01:47,020 --> 00:01:52,602
那麼這似乎意味著兩張圖片的內容很像

34
00:01:52,602 --> 00:01:54,855
所以，我們會去定義

35
00:01:54,855 --> 00:02:01,510
J_content(C, G) 為

36
00:02:01,510 --> 00:02:05,345
這兩個啟動值多像或多不一樣

37
00:02:05,345 --> 00:02:08,320
所以我們會拿逐元素的差異

38
00:02:08,320 --> 00:02:12,200
兩者在第 l 層的隱藏單元之間的差異

39
00:02:12,200 --> 00:02:14,710
當你把內容圖片傳入網路，跟

40
00:02:14,710 --> 00:02:17,736
傳入生成圖片時的差異

41
00:02:17,736 --> 00:02:19,955
然後取平方

42
00:02:19,955 --> 00:02:23,760
你可以在前面放個標準化的常數，也可不用

43
00:02:23,760 --> 00:02:25,535
例如二分之一或是其他的

44
00:02:25,535 --> 00:02:31,935
其實不大重要，因為這也會被超參數 alpha 調整掉

45
00:02:31,935 --> 00:02:37,070
所以只是澄清一下

46
00:02:37,070 --> 00:02:42,635
我這邊用這個符號，是當作這兩個被攤平成向量

47
00:02:42,635 --> 00:02:47,975
所以這麼以來，這變成兩者之間的 L2 範數的平方

48
00:02:47,975 --> 00:02:51,680
當你把這兩者攤平成向量以後

49
00:02:51,680 --> 00:02:54,492
這其實是逐元素總和

50
00:02:54,492 --> 00:02:59,480
取在兩者啟動值的相差的平方

51
00:02:59,480 --> 00:03:03,000
不過這其實是圖片 C 和 G

52
00:03:03,000 --> 00:03:06,150
在第 l 層的啟動值的

53
00:03:06,150 --> 00:03:11,850
差異的平方的逐元素總和

54
00:03:11,850 --> 00:03:17,100
因此，當之後對 J(G) 做梯度下降法，以嘗試得出 G 的值

55
00:03:17,100 --> 00:03:19,740
讓整個成本很低的時候

56
00:03:19,740 --> 00:03:23,120
這會鼓勵演算法去找出某張圖片 G

57
00:03:23,120 --> 00:03:29,203
讓這隱藏層的這些啟動值和內容圖片的很相似。

58
00:03:29,203 --> 00:03:33,985
那麼，這就是定義神經風格轉換中「內容成本」的方式

59
00:03:33,985 --> 00:03:37,000
接下來，讓我們繼續研究「風格成本」函數