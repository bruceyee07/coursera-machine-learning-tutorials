Sinirsel stil transfer algoritmasının maliyet fonksiyonun bir içerik maliyet bileşeni bir de stil maliyet bileşeni bulunur. İçerik maliyet bileşenini tanımlayarak başlayalım. Bunun sinirsel stil transfer algoritmasının maliyet fonksiyonunun tamamı olduğunu hatırlayalım. Öyleyse, içerik maliyeti fonksiyonunun ne olması gerektiğine bakalım. İçerik maliyetini hesaplamak için gizli katman l 'yi kullandığınızı düşünelim. Eğer l çok küçük bir sayı ise, eğer birinci gizli katmanı kullanıyorsanız, bu durum oluşturulan resminizi içerik resminize çok benzer piksel değerlerine zorlar. Buna karşılık, eğer çok derin bir katman kullanırsanız, bu durumda eğer içerik resminde bir köpek var ise, o zaman sadece oluşturulan resimde bir yerlerde köpek olduğundan emin olmanızı sorgulayacaktır. Pratikte l katmanı ikisi arasında bir yerlerde seçilir. Sinir ağında ne çok sığ ne de çok derinde değildir. Ve bunu kendiniz planladığınız için, Bu hafta sonunda yaptığınız problem alıştırmasında somut alıştırmalar ile bazı sezgiler kazanmanız için sizi serbest bırakacağım. Fakat genellikle l sinir ağının ortalarında bir yerlerde seçilir, ne çok sığ, ne de çok derin. Daha sonrasında önceden eğitilmiş bir ConvNet kullanabilirsiniz, belki bir VGG ağı ya da başka bir sinir ağı da olabilir. Ve şimdi ölçmek istediğiniz şey, verilen bir içerik resmi ve verilen bir oluşturulmuş resim ile, bunların içerik olarak ne kadar benzer olduklarını bulmak. Öyleyse a_üstü_[l](c) ve bunun bu iki resim üzerindeki l katmanının aktivasyonları olmasına izin verelim, resim C ve G üzerindeki. Böylelikle, eğer bu iki aktivasyon benzer ise bu her iki görüntünün benzer içeriğe sahip olduğuna işaret eder. Bu durumda yapacağımız şey J_content (C,G) 'yi bu iki aktivasyon fonksiyonunun ne kadar yakın ya da ne kadar farklı olduğu olarak tanımlamaktır. Yapacağımız şey l katmanı üzerindeki gizli aktivasyon birimlerini eleman bazında farkını almak, içerik resmine geçtiğinize kıyasla ile oluşturulmuş resme geçtiğiniz arasındaki ve bunun karesini alacağız. Önünde bir normalleştirme sabitiniz olabilir veya olmayabilir, belki 1/2 ya da başka bir şey. Bu hiper parametre alfa tarafından da ayarlanabileceğinden dolayı çok önemli değil. Buradaki formülün kullanımının bunların her ikisinin vektörlere doğru açılmasındaki kullanımında net olması için, Bu kısım bunun ile bunun arasındaki l_2 norm 'un karekökü haline gelir, her ikisini de vektörlere açtığınız zaman. Burada gerçekten sadece bu iki aktivasyon fonksiyonunu arasındaki farkların karesinin eleman bazlı toplamı var. Ama bu gerçekten sadece resim C ve G arasındaki l katmanındaki aktivasyonlar arasındaki farkların karalerinin eleman bazlı toplamıdır. Ve böylece, daha sonra G 'nin bir değerini bulmak için J(G) 'de dereceli alçalma yaptığınızda, maliyet düşük olacak, bu da algoritmayı bir G resmi bulmak için teşvik eder, böylece buradaki gizli katman aktivasyonları içerik resminden elde ettikleriniz ile benzer olur. Sinirsel stil transfer için içerik fonksiyonunu nasıl tanımlayabileceğinizi gördük. Bir sonraki adımda stil maliyet fonksiyonuna geçelim.