1
00:00:00,570 --> 00:00:03,330
ディープConvNet が 本当に学んでいるものは 何なのか？

2
00:00:03,330 --> 00:00:07,420
このビデオでは 視覚化の例を いくつか共有して

3
00:00:07,420 --> 00:00:11,900
ConvNet の深い層が行っていることについて 洞察を得て欲しい

4
00:00:11,900 --> 00:00:14,845
これは ニューラル スタイル変換の実装方法を考える上でも

5
00:00:14,845 --> 00:00:17,015
役に立つ

6
00:00:17,015 --> 00:00:18,735
例を見る事から始めよう。

7
00:00:18,735 --> 00:00:23,895
ConvNet を訓練したとしよう これは AlexNet のようなネットワークだ

8
00:00:23,895 --> 00:00:28,885
そして 隠れ層の異なるユニットで計算されているものを 視覚化したいとする

9
00:00:28,885 --> 00:00:30,255
こんなことができる

10
00:00:30,255 --> 00:00:33,920
層１の隠れユニットから始める

11
00:00:33,920 --> 00:00:38,790
学習セットを走査して どの画像 もしくは どの画像内小領域が

12
00:00:38,790 --> 00:00:43,960
ユニットの活性を最大化するか 探すものとする

13
00:00:43,960 --> 00:00:49,260
言い換えれば 学習セットを ニューラルネットワークに渡して 

14
00:00:49,260 --> 00:00:55,250
あるユニットの活性を最大化する画像が 何なのかを調べたい

15
00:00:55,250 --> 00:00:58,130
では 気付いているだろうけど 層１の隠れユニットは

16
00:00:58,130 --> 00:01:02,750
相対的に ニューラルネットワークの小さな部分しか見ない

17
00:01:02,750 --> 00:01:08,170
よって もし視覚化するなら
何が活性化されたか描くなら そのユニットの活性化を描くなら

18
00:01:08,170 --> 00:01:11,360
それが 画像のほんの小さな領域になるのは 当然だ

19
00:01:11,360 --> 00:01:15,190
なぜなら １つのユニットが見るのは 画像全体の中のほんの少しだからだ

20
00:01:15,190 --> 00:01:20,220
よって １つの隠れユニットを選び その活性を最大化する９つの画像を見つけたら

21
00:01:20,220 --> 00:01:25,380
こんな９つの小領域を見つけるんじゃないかな

22
00:01:25,380 --> 00:01:30,293
画像の多くの場所で この隠れユニットは

23
00:01:30,293 --> 00:01:34,691
こんな感じの エッジや線を探している

24
00:01:34,691 --> 00:01:39,091
１つの隠れユニットを 最高に活性化するのが

25
00:01:39,091 --> 00:01:41,559
これら９つの小領域だ

26
00:01:41,559 --> 00:01:47,055
今度は 層１の 別の隠れユニットを選んで 同じことを行うと

27
00:01:47,055 --> 00:01:51,149
異なる隠れユニットに対しては この２番目のようになる

28
00:01:51,149 --> 00:01:54,170
この９つの小領域で表される

29
00:01:54,170 --> 00:01:58,679
この隠れユニットは 入力域の こんな部分を探しているようだ

30
00:01:58,679 --> 00:02:02,540
ここで言う入力域は 受容野と呼ばれる

31
00:02:02,540 --> 00:02:07,075
そして 別の隠れユニットでは

32
00:02:07,075 --> 00:02:11,140
こんな感じの小領域で 活性化される傾向があると分かるだろう

33
00:02:11,140 --> 00:02:15,180
今度のは 垂直の明るいエッジを選ぶようだ

34
00:02:15,180 --> 00:02:18,710
ただし 左側が緑になっている

35
00:02:18,710 --> 00:02:23,882
これは オレンジを選ぶ そして 興味深い小領域だ

36
00:02:23,882 --> 00:02:29,730
この 赤と緑は 一緒になって 茶色や赤茶色を作る

37
00:02:29,730 --> 00:02:34,294
しかし ニューロンは それで活性化するだろう

38
00:02:34,294 --> 00:02:38,399
そして これが ９つの異なるニューロンの表現だ

39
00:02:38,399 --> 00:02:43,369
それぞれに対する９つの画像小領域が それらを最高に活性化する

40
00:02:43,369 --> 00:02:48,066
これで 層１の隠れユニットを訓練する感覚が掴めたでしょ

41
00:02:48,066 --> 00:02:49,868
そこのユニットは 探すわけだ

42
00:02:49,868 --> 00:02:55,010
比較的単純な特徴 エッジとか ある色をした影なんかをね

43
00:02:55,010 --> 00:02:57,920
なお このビデオで 使っている例は

44
00:02:57,920 --> 00:03:01,160
全て この論文から来ている Mathew Zeiler と

45
00:03:01,160 --> 00:03:06,440
Rob Fergus によるもので
タイトルは "Visualizing and understanding convolutional networks" だ

46
00:03:06,440 --> 00:03:10,689
私は もっと簡単な方法で 視覚化をしたい

47
00:03:10,689 --> 00:03:14,680
ニューラルネットワークが計算しているものの視覚化をね

48
00:03:14,680 --> 00:03:18,706
彼らの論文では もっと洗練されたやり方をしている

49
00:03:18,706 --> 00:03:21,480
ConvNet が学習しているものを視覚化するのにね

50
00:03:22,520 --> 00:03:26,064
兎に角 この手続きを 層１の隠れユニットに

51
00:03:26,064 --> 00:03:28,380
何度か繰り返す

52
00:03:28,380 --> 00:03:29,900
これを ニューラルネットワークの

53
00:03:29,900 --> 00:03:33,790
深い層の隠れユニットに行うと どうなるだろうか？

54
00:03:33,790 --> 00:03:37,950
ニューラルネットワークが深い層で学んでいるのは 何だろうか？

55
00:03:37,950 --> 00:03:43,120
深い層では 隠れ層は 画像のより大きな領域を見るだろう

56
00:03:43,120 --> 00:03:46,540
各ピクセルは 最終的に

57
00:03:46,540 --> 00:03:51,560
ニューラルネットワークの後の層の出力に 作用すると言えるだろう

58
00:03:51,560 --> 00:03:55,040
結局 後の層ほど 大きな領域を見る

59
00:03:55,040 --> 00:03:59,580
ただし このまま 同じサイズで 画像の小領域を描くよ

60
00:03:59,580 --> 00:04:04,370
この処理を繰り返すと これは 前に 層１で得たもので

61
00:04:04,370 --> 00:04:09,610
これは 層２の９つの隠れユニットを最高に活性化するものを

62
00:04:09,610 --> 00:04:12,320
視覚化したものだ

63
00:04:12,320 --> 00:04:15,416
この視覚化が何なのか ハッキリさせておきたい

64
00:04:15,416 --> 00:04:20,864
これら ９つの小領域は １つの隠れユニットを高く活性化させる

65
00:04:20,864 --> 00:04:25,471
各グループ 異なる９つの画像小領域は

66
00:04:25,471 --> 00:04:27,940
それぞれ１つの隠れユニットを活性化させる

67
00:04:27,940 --> 00:04:32,630
そして ここの視覚化は 層２の９つの隠れユニットを表し

68
00:04:32,630 --> 00:04:36,700
９つの画像小領域それぞれが 対応する１つの隠れユニットに

69
00:04:36,700 --> 00:04:39,890
とても大きな出力をさせる とても大きな活性化をさせる

70
00:04:39,890 --> 00:04:44,120
これを深い層にも繰り返していく

71
00:04:44,120 --> 00:04:46,980
このスライドでは これらの小さな画像域を

72
00:04:46,980 --> 00:04:49,188
見るのは難しいので いくつか拡大してみよう

73
00:04:49,188 --> 00:04:52,170
層１に対しては 既に見たこれ

74
00:04:52,170 --> 00:04:58,270
例えば これで 最初のユニットが高く活性化される

75
00:04:58,270 --> 00:05:03,840
入力画像の こんな角度のエッジがある場所でね

76
00:05:03,840 --> 00:05:08,350
では 層２の視覚化も拡大しよう

77
00:05:08,350 --> 00:05:09,750
これは 面白い

78
00:05:09,750 --> 00:05:14,030
層２は より複雑な形やパターンを検出している

79
00:05:14,030 --> 00:05:17,300
例えば この隠れユニットは 垂直の模様

80
00:05:17,300 --> 00:05:21,110
沢山の垂直線を探しているようだ

81
00:05:21,110 --> 00:05:24,150
この隠れユニットは 丸い形が

82
00:05:24,150 --> 00:05:27,730
画像の左にある時に 高く活性化されるようだ

83
00:05:27,730 --> 00:05:33,690
ここでは とても細い垂直線を探している 等々

84
00:05:33,690 --> 00:05:38,810
つまり ２番目の層が検出している特徴は より複雑になっている

85
00:05:38,810 --> 00:05:39,980
層３はどうなっている？

86
00:05:39,980 --> 00:05:43,476
拡大しよう もっと拡大した方が

87
00:05:43,476 --> 00:05:48,156
層３を最高に活性化するものが もっと良く見えるだろう

88
00:05:48,156 --> 00:05:52,806
もっと拡大してみよう これも また 非常に面白いね

89
00:05:52,806 --> 00:05:57,139
画像の左下にある丸い形に

90
00:05:57,139 --> 00:06:01,981
高く反応する隠れユニットが あるようだ

91
00:06:01,981 --> 00:06:06,523
そうして 多くの車を検出することになる

92
00:06:06,523 --> 00:06:10,735
驚くことに 人の検出も始まっている

93
00:06:10,735 --> 00:06:15,593
そして これは ハニカムのような質感を検出しているようだ

94
00:06:15,593 --> 00:06:18,358
もしくは 規則的な四角形を検出しているようだ

95
00:06:18,358 --> 00:06:22,356
この内のいくつかは 見るのが難しくて 何を検出しているのか ハッキリとしない

96
00:06:22,356 --> 00:06:26,900
しかし より複雑なパターンを検出し始めているのは 明らかだ

97
00:06:26,900 --> 00:06:27,880
次の層は？

98
00:06:27,880 --> 00:06:30,903
これが 層４だ 検出している

99
00:06:30,903 --> 00:06:33,508
特徴量 もしくはパターンは より複雑化している

100
00:06:33,508 --> 00:06:37,410
ここでは ほぼ犬検出器を学習したように見える しかし

101
00:06:37,410 --> 00:06:39,250
ここの犬は 似ているのばかりだ ね？

102
00:06:39,250 --> 00:06:42,770
ここは 犬という生物種になるのか 犬の種類になるのか分からないけど

103
00:06:42,770 --> 00:06:47,700
とにかく 犬に近いか 犬にとても良く似ているものだ

104
00:06:47,700 --> 00:06:51,680
この隠れユニットは 水を検出しているようだ

105
00:06:53,130 --> 00:06:58,440
これは 鳥の足か何かを検出しているようだ

106
00:06:58,440 --> 00:07:02,740
そして 層５では より洗練されたものを検出している

107
00:07:02,740 --> 00:07:07,396
犬検出器と思われるニューロンがあるのが分かるでしょ

108
00:07:07,396 --> 00:07:12,450
ただし 検出している犬の種類は もっと多くなっている

109
00:07:12,450 --> 00:07:17,610
それから ここでは キーボードを検出している それに キーボードのような模様があるもの

110
00:07:17,610 --> 00:07:22,360
背景に沢山の点があるものかもしれない

111
00:07:22,360 --> 00:07:27,950
このニューロンは 多分 文字を検出していると思う 確信を持つのは難しいけど

112
00:07:27,950 --> 00:07:31,520
そして これは 花を検出している

113
00:07:31,520 --> 00:07:35,430
比較的簡単なものの検出から ずっと来て

114
00:07:35,430 --> 00:07:38,135
層１ではエッジを 層２では質感を

115
00:07:38,135 --> 00:07:43,780
深い層では とても複雑なものを検出するようになった

116
00:07:43,780 --> 00:07:48,420
さて このことが 何らかの良い洞察を与えてくれたと期待する

117
00:07:48,420 --> 00:07:52,120
ニューラルネットワークの浅い層と深い層が計算しているものについてね

118
00:07:52,120 --> 00:07:56,763
次に この洞察を使って ニューラル スタイル変換アルゴリズムの構築を始めよう

119
00:07:56,763 --> 00:07:57,530
呼ぶ。