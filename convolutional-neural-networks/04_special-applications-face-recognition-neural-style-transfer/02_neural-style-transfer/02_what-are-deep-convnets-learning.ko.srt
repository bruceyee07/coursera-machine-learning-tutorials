1
00:00:00,570 --> 00:00:03,330
심층 컨볼네트가 정말로 배우고 있는 것은 무엇입니까?

2
00:00:03,330 --> 00:00:07,420
이 강의에서는 컨볼네트의 더 깊은 레이어가 실제로 하는 일에 대한

3
00:00:07,420 --> 00:00:11,900
직관을 연마하는 데 도움이 되는 몇 가지 시각화를 알려 드리고자 합니다.

4
00:00:11,900 --> 00:00:14,845
그리고 이것은 우리가 어떻게 신경 스타일 변형을

5
00:00:14,845 --> 00:00:17,015
구현할 수 있는지를 생각하는 데 도움이 될 것입니다. 예를 들어 설명해 보죠.

6
00:00:17,015 --> 00:00:18,735
우선 예제를 봅시다.

7
00:00:18,735 --> 00:00:23,895
여러분이 컨볼네트를 훈련시킨다고 가정 해 봅시다.

8
00:00:23,895 --> 00:00:28,885
그리고 다른 레이어들에 숨어있는 유닛이 연산하고 있는 것을 시각화하려고 합니다. 여러분이 할 수 있는 일은 이겁니다.

9
00:00:28,885 --> 00:00:30,255
여러분이 할 수 있는 일은 이것입니다.

10
00:00:30,255 --> 00:00:33,920
레이어 1에서 히든 유닛부터 시작해 봅시다.

11
00:00:33,920 --> 00:00:38,790
트레이닝 세트를 스캔 하여, 이미지가 무엇인지 또는 유닛의 활성화를 최대화하는 이미지 패치가 무엇인지

12
00:00:38,790 --> 00:00:43,960
알아 내려고 한다고 가정 해 보겠습니다.

13
00:00:43,960 --> 00:00:49,260
즉, 신경망을 통해 훈련을 일시 중지하고

14
00:00:49,260 --> 00:00:55,250
특정 유닛의 활성화를 최대화하는 이미지가 무엇인지 파악하십시오

15
00:00:55,250 --> 00:00:58,130
이제 레이어 1의 히든 유닛은

16
00:00:58,130 --> 00:01:02,750
신경망의 상대적으로 작은 부분 만 보게 될 것입니다.

17
00:01:02,750 --> 00:01:08,170
만약 여러분이 시각화한다면, 즉, 무엇이 이 unit activation (유닛 액티베이션)을 활성화 시켰는지 표시한다면,

18
00:01:08,170 --> 00:01:11,360
작은 이미지 패치를 그릴 수 있습니다.

19
00:01:11,360 --> 00:01:15,190
왜냐하면 그 특정한 유닛이 보는 것은 이 모든 이미지이기 때문입니다.

20
00:01:15,190 --> 00:01:20,220
따라서 한 개의 히든 유닛을 선택하고 해당 유닛의 활성화를 최대화하는 9 개의 입력 이미지를 찾으면

21
00:01:20,220 --> 00:01:25,380
이와 같은 9 개의 이미지 패치를 찾을 수 있습니다.

22
00:01:25,380 --> 00:01:30,293
따라서, 이 특정 히든 유닛이 보는 이 이미지의 낮은 영역들에서

23
00:01:30,293 --> 00:01:34,691
이렇게 생긴 모서리, 즉 선을 볼 수 있습니다.

24
00:01:34,691 --> 00:01:39,091
자, 이것들은 하나의 히든 유닛의 활성화를 최대로 활성화시키는

25
00:01:39,091 --> 00:01:41,559
9 개의 이미지 패치입니다.

26
00:01:41,559 --> 00:01:47,055
이제 레이어 1에서 다른 히든 유닛을 선택하여 같은 작업을 수행 할 수 있습니다.

27
00:01:47,055 --> 00:01:51,149
이것은 다른 히든 유닛이고, 이 두 번째 이미지는

28
00:01:51,149 --> 00:01:54,170
이 9 개의 이미지 패치로 나타납니다.

29
00:01:54,170 --> 00:01:58,679
이 히든 유닛은 마치 이것의 인풋 영역부분에 있는

30
00:01:58,679 --> 00:02:02,540
선을 찾고 있는 것 같아 보이네요. 우리는 이걸 receptive field (수용 영역)라고도 부릅니다.

31
00:02:02,540 --> 00:02:07,075
그리고 다른 히든 유닛에 대해 이렇게 하면, 다른 히든 유닛을 발견 할 수 있습니다.

32
00:02:07,075 --> 00:02:11,140
이들은 이런 모습의 이미지 패치로 활성화되는 경향이 있습니다

33
00:02:11,140 --> 00:02:15,180
이것은 수직 밝은 모서리를 선호하는 것처럼 보이지만,

34
00:02:15,180 --> 00:02:18,710
사실 이것의 왼쪽을 초록색으로 만드는 선호도가 있는 것입니다.

35
00:02:18,710 --> 00:02:23,882
이것은 주황색을 선호하는 것이고, 흥미로운 이미지 패치인데요,

36
00:02:23,882 --> 00:02:29,730
이쪽에 빨간색 초록색이 섞여서 갈색같은 혹은 갈색빛의 주황색을 만들고 있죠.

37
00:02:29,730 --> 00:02:34,294
하지만 신경은 여전히 이유닛이랑 활성화하는 걸 볼 수 있습니다. 계속해서 이렇게 진행됩니다.

38
00:02:34,294 --> 00:02:38,399
이것은 9 개의 서로 다른 대표 신경입니다. 그리고

39
00:02:38,399 --> 00:02:43,369
9 개의 이미지 패치 각각에 대해, 이들은 최대로 활성화시키는 것입니다.

40
00:02:43,369 --> 00:02:48,066
그래서 이것은 레이어 1의 히든 유닛을 훈련시키는 감각을 주는 것이죠.

41
00:02:48,066 --> 00:02:49,868
그들은 때로는 모서리나 특정 명암 색과 같은

42
00:02:49,868 --> 00:02:55,010
상대적으로 단순한 피쳐를 찾습니다.

43
00:02:55,010 --> 00:02:57,920
그리고 이 강의에서 사용하고 있는 모든 예제는

44
00:02:57,920 --> 00:03:01,160
Mathew Zeiler와 Rob Fergus의 논문 '컨볼루션망에 대한 이해와 시각화'에서

45
00:03:01,160 --> 00:03:06,440
가져온 것을 사용하고 있습니다.

46
00:03:06,440 --> 00:03:10,689
그리고 신경망에서 히든 유닛이 연산하는 것을 시각화하는

47
00:03:10,689 --> 00:03:14,680
간단한 방법 중 하나를 사용하려고 합니다.

48
00:03:14,680 --> 00:03:18,706
여러분이 논문을 읽어 보시면, 컨볼네트이 실행될 때

49
00:03:18,706 --> 00:03:21,480
시각화하는 좀 더 정교한 방법이 있습니다.

50
00:03:22,520 --> 00:03:26,064
이제는 레이어 1에 있는 9 개의 히든 유닛에 대해

51
00:03:26,064 --> 00:03:28,380
이 과정을 여러 번 반복했습니다.

52
00:03:28,380 --> 00:03:29,900
신경망의 심층 레이어에 있는 히든 유닛의 일부에 대해

53
00:03:29,900 --> 00:03:33,790
이것을 수행하면 어떻게 될까요?

54
00:03:33,790 --> 00:03:37,950
그러면 신경망이 심층 레이어에서 학습하면

55
00:03:37,950 --> 00:03:43,120
히든 유닛은 이미지의 더 큰 영역을 보게 될 것입니다.

56
00:03:43,120 --> 00:03:46,540
그러면 결국엔, 각 픽셀은

57
00:03:46,540 --> 00:03:51,560
가정컨대, 신경망의 이 후속 레이어의 아웃풋에 영향을 줄 수 있을 겁니다.

58
00:03:51,560 --> 00:03:55,040
나중에는 실제로 더 큰 이미지 패치로 보이겠죠.

59
00:03:55,040 --> 00:03:59,580
저는 여전히 이 슬라이드에서 같은 크기로 이미지 패치를 표현하려고 합니다.

60
00:03:59,580 --> 00:04:04,370
그러나 이 절차를 반복하면, 레이어 1에서 이전에 봤던 것과 동일하게 되죠.

61
00:04:04,370 --> 00:04:09,610
이는 레이어 2 에서 9 개의 다른 히든 유닛을

62
00:04:09,610 --> 00:04:12,320
최대한 활성화하는 것을 시각화 한 것 입니다.

63
00:04:12,320 --> 00:04:15,416
따라서 이 시각화가 무엇인지 명확히 알고 싶은데요,

64
00:04:15,416 --> 00:04:20,864
이것은 히든 유닛 하나가 고도로 활성화 되도록 만드는 9 개의 패치를 가리킵니다.

65
00:04:20,864 --> 00:04:25,471
그리고 각각의 그룹핑, 즉, 이것은 하나의 히든 유닛을 활성화시키는

66
00:04:25,471 --> 00:04:27,940
9 가지 이미지 패치의 또 다른 세트입니다.

67
00:04:27,940 --> 00:04:32,630
따라서 이 시각화가 보여주는 것은 레이어 2에 있는 9 개의 히든 유닛이죠.

68
00:04:32,630 --> 00:04:36,700
그리고 이 각각의 히든 유닛에 9개의 이미지 패치가 있습니다.

69
00:04:36,700 --> 00:04:39,890
이들은 히든 유닛이 매우 큰 출력, 매우 큰 활성화를 가질 수 있게 해 줍니다.

70
00:04:39,890 --> 00:04:44,120
그리고 더 심층 레이어에서도 이 작업을 반복 할 수 있습니다.

71
00:04:44,120 --> 00:04:46,980
이제, 이 슬라이드 상으로, 이러한 작은 이미지 패치를 보는 것이 어렵다는 것을 알고 있으므로

72
00:04:46,980 --> 00:04:49,188
일부 이미지를 확대 해 보겠습니다.

73
00:04:49,188 --> 00:04:52,170
레이어 1의 경우 이는 여러분이 봤던 것입니다.

74
00:04:52,170 --> 00:04:58,270
예를 들어, 이것은 우리가 보았던 첫 번째 유닛입니다. 매우 활성화되어 있죠.

75
00:04:58,270 --> 00:05:03,840
인풋 이미지 영역 안쪽을 보시면, 이런 각도로 생긴 이 선을 볼 수가 있죠,

76
00:05:03,840 --> 00:05:08,350
이제 레이어 2의 시각화를 위해 확대 해 보겠습니다.

77
00:05:08,350 --> 00:05:09,750
흥미롭네요

78
00:05:09,750 --> 00:05:14,030
레이어 2는 더 복잡한 모양과 패턴을 감지합니다.

79
00:05:14,030 --> 00:05:17,300
예를 들어, 이 히든 유닛은

80
00:05:17,300 --> 00:05:21,110
수직선이 많은 수직 텍스처를 찾고 있는 거처럼 보입니다.

81
00:05:21,110 --> 00:05:24,150
이 히든 유닛은 이미지의 왼쪽 부분에 둥근 모양이 있을 때

82
00:05:24,150 --> 00:05:27,730
매우 활성화 된 것처럼 보입니다.

83
00:05:27,730 --> 00:05:33,690
이게 바로 매우 얇은 세로선을 찾는 방법이고, 이렇게 계속 됩니다.

84
00:05:33,690 --> 00:05:38,810
따라서 두 번째 레이어가 감지하는 피처들이 점점 복잡해지고 있습니다.

85
00:05:38,810 --> 00:05:39,980
레이어 3은 어떨까요?

86
00:05:39,980 --> 00:05:43,476
더 크게 확대해보면

87
00:05:43,476 --> 00:05:48,156
더 잘 보이실 겁니다. 이것은 레이어 3을 최대로 활성화하는 것입니다.

88
00:05:48,156 --> 00:05:52,806
그러나 더 크게 확대 해 보겠습니다. 다시 흥미로운 것이 나왔네요

89
00:05:52,806 --> 00:05:57,139
이미지의 왼쪽 하단 부분에

90
00:05:57,139 --> 00:06:01,981
둥근 모양에 크게 반응하는 히든 유닛이있는 것 같습니다.

91
00:06:01,981 --> 00:06:06,523
그래서 많은 자동차와 강아지를 발견하고,

92
00:06:06,523 --> 00:06:10,735
놀랍게도 사람들을 감지하기 시작합니다.

93
00:06:10,735 --> 00:06:15,593
이 벌집 모양은 벌집 모양이나 정사각형 모양 같은

94
00:06:15,593 --> 00:06:18,358
불규칙한 질감을 감지하는 것과 같습니다.

95
00:06:18,358 --> 00:06:22,356
이 중 일부에 대해서는, 무엇을 감지한 것인지 보고 수동으로 파악하기가 어렵습니다.

96
00:06:22,356 --> 00:06:26,900
하지만 이것은 좀 더 복잡한 패턴을 분명하게 감지하기 시작합니다.

97
00:06:26,900 --> 00:06:27,880
다음 레이어는 어떻습니까?

98
00:06:27,880 --> 00:06:30,903
음, 여기에 레이어 4가 있습니다,

99
00:06:30,903 --> 00:06:33,508
피처들이나 패턴들이 훨씬 더 복잡한 것을 감지하는 걸 볼 수 있습니다.

100
00:06:33,508 --> 00:06:37,410
이것은 거의 개 탐지기를 배운 것처럼 보이지만

101
00:06:37,410 --> 00:06:39,250
이 모든 개들은 비슷하군요, 그렇죠?

102
00:06:39,250 --> 00:06:42,770
이게 개의 무슨 종인지, 혹은 개가 번식을 했는지 알 수는 없습니다.

103
00:06:42,770 --> 00:06:47,700
그러나 지금 이 모두 개 들이지만, 개가 비교적 비슷해 보입니다.

104
00:06:47,700 --> 00:06:51,680
이 히든 유닛처럼 보이므로, 이건 물을 감지하고 있습니다.

105
00:06:53,130 --> 00:06:58,440
실제로 새의 다리를 감지하는 것처럼 보입니다. 그리고 이렇게 계속 되죠.

106
00:06:58,440 --> 00:07:02,740
레이어 5는 더욱 정교한 것들을 감지합니다.

107
00:07:02,740 --> 00:07:07,396
따라서 개 탐지기 인 것으로 보이는 뉴런도 있음을 알게 될 것입니다.

108
00:07:07,396 --> 00:07:12,450
그러나 여기에서 탐지하는 개 세트는 더욱 다양해 보입니다.

109
00:07:12,450 --> 00:07:17,610
그리고 이것은 키보드 혹은 키보드 텍스쳐 같은 것들을 감지하고 있는 것 같아 보이는군요

110
00:07:17,610 --> 00:07:22,360
배경에 점들이 많이 있긴 하지만 말이죠.

111
00:07:22,360 --> 00:07:27,950
이 신경은 텍스트를 감지하고 있을지도 모른다고 생각이 드는 군요. 언제나 확신하긴 어렵습니다.

112
00:07:27,950 --> 00:07:31,520
그리고 여기 이것은 꽃을 감지하고 있습니다.

113
00:07:31,520 --> 00:07:35,430
우리는 레이어 1의 선, 레이어 2의 텍스처같은 비교적 간단한 것을 감지하는 것부터

114
00:07:35,430 --> 00:07:38,135
비교적 더 깊은 심층 레이어에 있는 매우 복잡한 객체를 감지하는 것까지

115
00:07:38,135 --> 00:07:43,780
긴 여정을 마쳤습니다.

116
00:07:43,780 --> 00:07:48,420
이것 신경망의 얕은 레이어와과 심층 레이어가 컴퓨팅하는 것에 대해

117
00:07:48,420 --> 00:07:52,120
여러분에게 더 나은 직감을 주기를 바랍니다.

118
00:07:52,120 --> 00:07:56,763
다음으로, 이 직관을 사용하여 신경망 스타일 변형 알고리즘을 작성해 봅시다.

119
00:07:56,763 --> 00:07:57,530
clustering 알고리즘입니다.