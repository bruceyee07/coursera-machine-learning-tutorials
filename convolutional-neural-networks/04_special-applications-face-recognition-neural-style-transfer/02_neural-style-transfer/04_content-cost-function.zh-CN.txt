神经风格转移的代价函数 由内容代价部分和风格代价部分组成 让我们从内容代价部分的定义开始说起 回忆一下，这个是神经风格转移算法的全局代价函数 那么，让我们先来弄清楚什么是内容代价函数。 假设你可以用隐藏层来 l 来计算内容代价 若 l 是非常小的数字，比如你用隐藏层1 那么它会让你得到 一个在像素值上与你的内容图像非常接近的图像 然而，若你使用一个非常深的层 那么，它会问你，比如 你的内容图像里面是否有一只狗 然后确保你生成的图像的某处有一只狗 所以，在实践中，隐藏层的数目，我会选择两者之间。 这样的话，这个神经网络就既不会太浅，也不会太深 并且，由于这些是你自己计划的 在本周结束的练习题中 我会给你留一些暗示 在具体的例子和练习中 但是，通常我会选择 在这个神经网络中间的某处 不会太浅，也不太深 你可以使用一个已经预训练过的卷积网络 例如 VGG 网络 或者用其他的神经网络也行 现在，你要去测量 在给定的内容图像(C)和生成的图像(G)之间 他们在内容上的相似程度 所以，我们令这个 a^[l](C) 和 a^[l](G) 分别为前面两图像的 l 层激活因子 对应图像 C 和 G 若这两个激活因子很接近 那么，可以认为，这两个图像在内容上有相似性 所以，我们将要做的是 定义 J_content(C,G) 为 两个激活因子的差异程度 所以，我们将用这个元素级别的差异 在隐藏层 l 之间的差异 比较当你传入内容图像 和传入生成图像的区别 将这个差的模平方 并且，你有没有没正则化（归一化）常数都可以 所以，这仅仅是其中的两个或者别的什么 这点影响不大，因为它可以被超参数 alpha 调整 所以，明确一下 在使用这个定义时，就像编入向量一样 然后，它会变成这两个量 l_2 模的平方根 在你把这两个量都编入向量之后 这些真的只是按元素 将这两个激活因子的差异平方进行求和 但是，它也仅仅是按元素 在隐藏层 l 中的图像C和图像G的激活因子 差的异平方求和。所以 在之后，你对 J(G) 使用梯度下降法来求 G 以使全局代价值比较低 这会激励这个算法去找到一个图像G 以使这些隐藏层激活因子和你的内容图像比较接近 所以，这就是如何在神经风格转移算法中定义内容代价函数 接下来，让我们来看看风格代价函数的定义。