1
00:00:00,000 --> 00:00:03,500
ニューラル スタイル変換アルゴリズムのコスト関数は

2
00:00:03,500 --> 00:00:07,975
内容コスト関数 と スタイルコスト関数 だ

3
00:00:07,975 --> 00:00:11,455
まず 内容コスト関数を定義しよう

4
00:00:11,455 --> 00:00:17,595
これが ニューラル スタイル変換アルゴリズムの全コスト関数だ

5
00:00:17,595 --> 00:00:21,660
内容コスト関数をどうすべきか 明らかにしよう

6
00:00:21,660 --> 00:00:26,380
内容コストを計算するのに 隠れ層 l(エル) を使うものとする

7
00:00:26,380 --> 00:00:30,920
もし l が とても小さい数なら もし 隠れ層１を使うなら

8
00:00:30,920 --> 00:00:34,440
生成画像に 本当に

9
00:00:34,440 --> 00:00:37,875
内容画像に とても良く似たピクセル値を持たせることになる

10
00:00:37,875 --> 00:00:39,735
一方 とても深い層を使うなら

11
00:00:39,735 --> 00:00:41,260
そうしたら こう尋ねていることになる

12
00:00:41,260 --> 00:00:43,040
「もし 内容画像に犬がいるなら

13
00:00:43,040 --> 00:00:46,150
生成画像のどこかに 確実に犬を置いてくれ」

14
00:00:46,150 --> 00:00:50,310
実際には 層 l は どこか中間が選ばれる

15
00:00:50,310 --> 00:00:53,015
ニューラルネットワークの中の 浅すぎも 深すぎもしない場所だ

16
00:00:53,015 --> 00:00:55,780
今週終わりに行う プログラミング演習では

17
00:00:55,780 --> 00:00:58,765
あなた自身が行う

18
00:00:58,765 --> 00:01:01,260
あなた自身で 何らかの洞察を得てやってもらいたい

19
00:01:01,260 --> 00:01:04,475
プログラミング演習での具体例でね

20
00:01:04,475 --> 00:01:06,810
しかし 通常 l は どこか

21
00:01:06,810 --> 00:01:09,080
ニューラルネットワークの中間が選ばれる

22
00:01:09,080 --> 00:01:12,170
浅すぎず 深すぎない

23
00:01:12,170 --> 00:01:15,285
それから 事前訓練された ConvNet を使う

24
00:01:15,285 --> 00:01:17,317
例えば VGG ネットワークや

25
00:01:17,317 --> 00:01:20,020
他のニューラルネットワークを使うことができる

26
00:01:20,020 --> 00:01:22,050
そして

27
00:01:22,050 --> 00:01:26,160
内容画像と生成画像が

28
00:01:26,160 --> 00:01:29,688
内容面で どのくらい似ているかを測りたい

29
00:01:29,688 --> 00:01:31,540
だから こうする

30
00:01:31,540 --> 00:01:39,900
a[l](c) と これを ２画像 画像 C と G の

31
00:01:39,900 --> 00:01:42,814
層 l における活性とする

32
00:01:42,814 --> 00:01:47,020
この２つの活性が似ていれば

33
00:01:47,020 --> 00:01:52,602
両画像は 似た内容を持っているということになる

34
00:01:52,602 --> 00:01:54,855
だから こう定義する

35
00:01:54,855 --> 00:02:01,510
J_contnet(C, G) は この２つの活性が

36
00:02:01,510 --> 00:02:05,345
どのくらい似ているか違っているかを表す

37
00:02:05,345 --> 00:02:08,320
よって 要素毎の違いを取ろう

38
00:02:08,320 --> 00:02:12,200
層 l における この隠れユニット活性の

39
00:02:12,200 --> 00:02:14,710
内容画像を渡した時のと

40
00:02:14,710 --> 00:02:17,736
生成画像を渡した時のの違いを

41
00:02:17,736 --> 00:02:19,955
そして それを２乗する

42
00:02:19,955 --> 00:02:23,760
前に 正規化常数を入れてもよい

43
00:02:23,760 --> 00:02:25,535
それは ２分の１とか 他の値になるだけだ

44
00:02:25,535 --> 00:02:31,935
それは 重要ではない このハイパーパラメータ α で 調整できるから

45
00:02:31,935 --> 00:02:37,070
ハッキリさせておきたいことがある

46
00:02:37,070 --> 00:02:42,635
ここでは この両方が ベクトルに展開されているかのような表記にしている

47
00:02:42,635 --> 00:02:47,975
つまり これは これと これの L2ノルムの 2乗になっているけど

48
00:02:47,975 --> 00:02:51,680
これらをベクトルに展開した後 そうするということだ

49
00:02:51,680 --> 00:02:54,492
これは この２つの活性間の 要素毎の違いの

50
00:02:54,492 --> 00:02:59,480
２乗の合計だ

51
00:02:59,480 --> 00:03:03,000
これは 画像 C と G の

52
00:03:03,000 --> 00:03:06,150
層 l における活性の

53
00:03:06,150 --> 00:03:11,850
要素毎の違いの２乗だ そして

54
00:03:11,850 --> 00:03:17,100
G の値を探すため J(G) を 後で 勾配降下法にかけると

55
00:03:17,100 --> 00:03:19,740
全コストが低くなるようにする

56
00:03:19,740 --> 00:03:23,120
これは 画像 G を見つけるようにアルゴリズムに作用する

57
00:03:23,120 --> 00:03:29,203
そうして ここの隠れ層の活性が 内容画像に対してのものと 似てくる

58
00:03:29,203 --> 00:03:33,985
以上が ニューラル スタイル変換の 内容コスト関数の定義方法だ

59
00:03:33,985 --> 00:03:37,000
次は スタイルコスト関数に移ろう