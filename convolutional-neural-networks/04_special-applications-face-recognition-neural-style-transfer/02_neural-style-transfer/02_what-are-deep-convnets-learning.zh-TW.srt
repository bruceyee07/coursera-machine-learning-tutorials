1
00:00:00,570 --> 00:00:03,330
深層 ConvNet 實際上真正在學什麼？

2
00:00:03,330 --> 00:00:07,420
在這部影片，我想和你分享一些視覺化的例子，幫助你

3
00:00:07,420 --> 00:00:11,900
增進你的直覺，了解 ConvNet 深的層究竟在做什麼

4
00:00:11,900 --> 00:00:14,845
這能幫助我們思考脈絡，了解怎麼實作

5
00:00:14,845 --> 00:00:17,015
神經風格轉換

6
00:00:17,015 --> 00:00:18,735
讓我們先從一個例子開始

7
00:00:18,735 --> 00:00:23,895
假設你訓練好了一個 ConvNet，這個架構和 AlexNet 很像

8
00:00:23,895 --> 00:00:28,885
而你想要視覺化呈現每一層的隱藏單元在計算什麼

9
00:00:28,885 --> 00:00:30,255
你可以這樣做

10
00:00:30,255 --> 00:00:33,920
先從第一層的某個隱藏單元開始

11
00:00:33,920 --> 00:00:38,790
假設你看過所有的訓練資料，找出是哪些圖片、

12
00:00:38,790 --> 00:00:43,960
或哪些圖片的部分區域 能讓這個單元的啟動值最大

13
00:00:43,960 --> 00:00:49,260
也就是說，把你的訓練資料傳給神經網路，去觀察

14
00:00:49,260 --> 00:00:55,250
哪一張圖片會讓該單元的啟動值最大

15
00:00:55,250 --> 00:00:58,130
要注意到，一個在第一層的單元

16
00:00:58,130 --> 00:01:02,750
只能看到網路中比較小的區域

17
00:01:02,750 --> 00:01:08,170
所以經過視覺化，如果你畫出什麼東西啟動了那一個單元

18
00:01:08,170 --> 00:01:11,360
你只會畫出圖片的一小塊，這很合理

19
00:01:11,360 --> 00:01:15,190
因為那就是一個隱藏單元能看到的全部

20
00:01:15,190 --> 00:01:20,220
所以如果你挑了一個隱藏單元，然後找出九張能夠

21
00:01:20,220 --> 00:01:25,380
讓該單元啟動值最大的圖，你可能會看到類似這九塊

22
00:01:25,380 --> 00:01:30,293
所以在這個隱藏單元所觀察到的照片的某個區域之中

23
00:01:30,293 --> 00:01:34,691
這單元會尋找像這樣子的邊界或是線條

24
00:01:34,691 --> 00:01:39,091
所以這九塊圖片最能激發出某一個

25
00:01:39,091 --> 00:01:41,559
隱藏單元的啟動值，讓值最大

26
00:01:41,559 --> 00:01:47,055
那麼，接下來你可以選另一個第一層的隱藏單元，做同樣的事

27
00:01:47,055 --> 00:01:51,149
所以這是另一個隱藏單元的。看起來這第二個、

28
00:01:51,149 --> 00:01:54,170
這邊九塊圖片所代表的

29
00:01:54,170 --> 00:01:58,679
看起來這個隱藏單元會尋找那塊區域的線條

30
00:01:58,679 --> 00:02:02,540
我們也可稱之為感受野 (receptive field)

31
00:02:02,540 --> 00:02:07,075
如果你對其他隱藏單元也這樣做，你會發現其他單元

32
00:02:07,075 --> 00:02:11,140
在類似這種的圖片區塊時，更會被激發

33
00:02:11,140 --> 00:02:15,180
這一個似乎喜歡垂直的邊界線

34
00:02:15,180 --> 00:02:18,710
也喜歡左邊是綠色的；

35
00:02:18,710 --> 00:02:23,882
這一個傾向於橘色的 — 這一塊圖片還滿有趣的

36
00:02:23,882 --> 00:02:29,730
這是紅色和綠色混在一起，像是褐色或棕黃色

37
00:02:29,730 --> 00:02:34,294
不過這個神經元看到那圖仍然很樂意被激發。依此類推。

38
00:02:34,294 --> 00:02:38,399
所以這邊是九個具代表性的神經元

39
00:02:38,399 --> 00:02:43,369
對於每個神經元，畫出九塊會造成最大啟動值的圖

40
00:02:43,369 --> 00:02:48,066
這讓你有點感覺：第一層訓練出的隱藏單元

41
00:02:48,066 --> 00:02:49,868
他們常常去尋找

42
00:02:49,868 --> 00:02:55,010
比較簡單的特徵，例如邊界、或是某特定顏色的陰影

43
00:02:55,010 --> 00:02:57,920
在這部影片舉的所有例子

44
00:02:57,920 --> 00:03:01,160
來自於這篇論文：由 Matthew Zeiler 和 Rob Fergus 所著

45
00:03:01,160 --> 00:03:06,440
叫 "Visualizing and Understanding Convolutional Networks"
(視覺化並理解卷積網路)

46
00:03:06,440 --> 00:03:10,689
我用的是比較簡單的方法去視覺化

47
00:03:10,689 --> 00:03:14,680
神經網路的隱藏單元在計算什麼

48
00:03:14,680 --> 00:03:18,706
如果你去讀這篇論文，他們有更細膩的方法

49
00:03:18,706 --> 00:03:21,480
把 ConvNet 在學什麼給視覺化

50
00:03:22,520 --> 00:03:26,064
總之，你重複這樣的流程若干次

51
00:03:26,064 --> 00:03:28,380
跑了第一層的九個隱藏單元

52
00:03:28,380 --> 00:03:29,900
如果同樣的事

53
00:03:29,900 --> 00:03:33,790
你做在網路比較深層的隱藏單元，會怎樣呢？

54
00:03:33,790 --> 00:03:37,950
神經網路在深一些的層會學到什麼呢？

55
00:03:37,950 --> 00:03:43,120
在比較深的層，一個隱藏單元會看到圖片比較大的區域

56
00:03:43,120 --> 00:03:46,540
也就是在圖片的那一端

57
00:03:46,540 --> 00:03:51,560
每個像素理論上都能影響到網路的後面幾層

58
00:03:51,560 --> 00:03:55,040
因此，後面幾層的單元，其實能看到比較大塊的圖片區域

59
00:03:55,040 --> 00:03:59,580
不過在投影片中，我還是會把這些區域畫成同樣大小

60
00:03:59,580 --> 00:04:04,370
如果我們重複這樣的程序，前面做過的第一層長這樣

61
00:04:04,370 --> 00:04:09,610
而這個是第二層中，哪些會讓九個隱藏單元的啟動值最大

62
00:04:09,610 --> 00:04:12,320
的視覺化結果

63
00:04:12,320 --> 00:04:15,416
我想說明這視覺化在做什麼

64
00:04:15,416 --> 00:04:20,864
這九塊圖，會讓某個隱藏單元的啟動值很高、很被激發

65
00:04:20,864 --> 00:04:25,471
然後每一組 — 這個是另外一組九塊區域

66
00:04:25,471 --> 00:04:27,940
會讓某個隱藏單元被激發

67
00:04:27,940 --> 00:04:32,630
所以這視覺化的結果顯示出 9 個第二層的隱藏單元

68
00:04:32,630 --> 00:04:36,700
其中每個隱藏單元，這邊顯示了九塊圖，會讓該隱藏單元

69
00:04:36,700 --> 00:04:39,890
的輸出非常大、有非常大的啟動值

70
00:04:39,890 --> 00:04:44,120
你也可以重複這步驟，做在更後面的層

71
00:04:44,120 --> 00:04:46,980
那麼在這張投影片中，要看這一堆小圖

72
00:04:46,980 --> 00:04:49,188
會有點困難，所以讓我放大其中的一些

73
00:04:49,188 --> 00:04:52,170
之前看到的第一層長這樣

74
00:04:52,170 --> 00:04:58,270
例如，這一組是之前看到的第一個單元：如果在輸入圖片的

75
00:04:58,270 --> 00:05:03,840
相對應區域，你能看到這種角度的邊線，那單元就會高度激發

76
00:05:03,840 --> 00:05:08,350
現在我們放大第二層的視覺化結果

77
00:05:08,350 --> 00:05:09,750
這很有趣

78
00:05:09,750 --> 00:05:14,030
看起來第二層會去偵測更複雜的形狀和花樣

79
00:05:14,030 --> 00:05:17,300
例如這個隱藏單元，它看起來在尋找

80
00:05:17,300 --> 00:05:21,110
某種垂直的紋理，有很多條垂直的線

81
00:05:21,110 --> 00:05:24,150
這一個隱藏單元似乎會在左邊有圓形

82
00:05:24,150 --> 00:05:27,730
的時候，被高度激發

83
00:05:27,730 --> 00:05:33,690
這邊這個會尋找非常細的垂直線。諸如此類的

84
00:05:33,690 --> 00:05:38,810
因此，第二層偵測的特徵逐漸變複雜

85
00:05:38,810 --> 00:05:39,980
那第三層呢？

86
00:05:39,980 --> 00:05:43,476
讓我們放大一下 — 實際上讓我們放更大

87
00:05:43,476 --> 00:05:48,156
這樣你能看更清楚。這些東西最會去激發第三層

88
00:05:48,156 --> 00:05:52,806
不過我們放更大來看。這同樣非常有趣

89
00:05:52,806 --> 00:05:57,139
看起來有某個隱藏單元，對於圖塊左下部份

90
00:05:57,139 --> 00:06:01,981
含有圓形的時候，會高度地回應

91
00:06:01,981 --> 00:06:06,523
所以最終會偵測到很多車

92
00:06:06,523 --> 00:06:10,735
看起來這一個甚至開始在偵測人

93
00:06:10,735 --> 00:06:15,593
而這個看起來在偵測某些材質，像蜂窩狀

94
00:06:15,593 --> 00:06:18,358
或是方格狀、不規則的材質

95
00:06:18,358 --> 00:06:22,356
而這邊有些很難用人眼看的出來在偵測什麼

96
00:06:22,356 --> 00:06:26,900
不過很明顯地在偵測更複雜的樣式了

97
00:06:26,900 --> 00:06:27,880
再下一層呢？

98
00:06:27,880 --> 00:06:30,903
這是第四層，你看它偵測出的

99
00:06:30,903 --> 00:06:33,508
特徵或是花樣甚至更複雜了

100
00:06:33,508 --> 00:06:37,410
看起來這幾乎就是個狗狗偵測器了

101
00:06:37,410 --> 00:06:39,250
不過這些狗狗看起來都很像對吧

102
00:06:39,250 --> 00:06:42,770
這個... 我不知道這是哪種品種的狗

103
00:06:42,770 --> 00:06:47,700
這些都是狗沒錯，但彼此看起來滿像的

104
00:06:47,700 --> 00:06:51,680
看起來這一個第四層的單元在偵測水

105
00:06:53,130 --> 00:06:58,440
這似乎其實是偵測鳥的腿。諸如此類的

106
00:06:58,440 --> 00:07:02,740
然後第五層，甚至偵測更細膩複雜的東西

107
00:07:02,740 --> 00:07:07,396
你會注意到這裡也有一個神經元像是個狗狗偵測器

108
00:07:07,396 --> 00:07:12,450
但是，這裡偵測出的狗看起來比較多樣

109
00:07:12,450 --> 00:07:17,610
然後這看起來在偵測鍵盤，或有鍵盤花樣的東西

110
00:07:17,610 --> 00:07:22,360
或許背景有很多點點

111
00:07:22,360 --> 00:07:27,950
我猜這個神經元可能在偵測文字，很難確定

112
00:07:27,950 --> 00:07:31,520
然後這一個在偵測花

113
00:07:31,520 --> 00:07:35,430
所以呢，我們走過漫長的路：從偵測比較簡單的東西

114
00:07:35,430 --> 00:07:38,135
例如第一層的邊線，到第二層的花樣

115
00:07:38,135 --> 00:07:43,780
一直到比較深的層偵測出非常複雜的物件

116
00:07:43,780 --> 00:07:48,420
那麼，我希望這能給你更清楚的直覺，體會到

117
00:07:48,420 --> 00:07:52,120
神經網路比較淺和比較深的層分別在計算什麼

118
00:07:52,120 --> 00:07:56,763
接下來，讓我們用這個概念來建構「神經風格轉換」

119
00:07:56,763 --> 00:07:57,530
的演算法