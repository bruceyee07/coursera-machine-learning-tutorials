上个视频中 你学到了滑动窗口(sliding windows)目标检测算法 它运用了卷积神经网络(ConvNet)<br />但是我们看到了它的速度太慢 在这个视频中<br />你将学习如何用卷积的形式(convolutionally)来实现这个算法 让我们一起来看看为什么这么说 为了搭建一个用卷积实现的滑动窗口，让我们先来看一下 如何将神经网络中的全连接(Fully-Connected)层转化成卷积层 我们先在这张幻灯片上介绍（概念），然后在下一张上 我们会用这张幻灯片上的概念，来展示如果进行卷积实现 假设你的目标检测算法的输入是14x14x3的图像 这是个很小的图像，只是用来说明 假设算法用5x5的滤波器 然后假设用16个滤波器<br />也就是把14x14x3映射到10x10x16上 然后做一个2x2的最大池化(max pooling)<br /> 把它缩小到5x5x16 随后有一个全连接层连接到400个(神经)单元上 然后另一个全连接层，最后用一个Softmax单元输出一个y 为了做我们马上要做出的改变 我要修改一下这张图 我将输出y改为4个数字 分别代表分类到softmax分类单元 所区分的4个类别中每一类的概率 这4个类别可以是 行人、汽车、摩托车和背景，或者其他东西 现在我想做的是展示 如何将这些层转化成卷积层 这是一个卷积神经网络，前几层和之前相同 现在，实现这一层全连接层的一个方式 是用5x5的滤波器 让我们用400个5x5的滤波器 如果你拿一个和5x5x16的图像<br />和一个5x5的滤波器做卷积操作 还记得，<br />一个5x5的滤波器实现时是用5x5x16的滤波器 因为按照惯例，这个滤波器要作用于全部16个通道 所以这个16和这个16要匹配，这样输出就必须是1x1 如果你有400个这样的5x5x16的滤波器 那么输出的维度就是1x1x400 所以与其只是把这400个看做一组节点 我们将把它看做一个1x1x400的体 数学操作上来讲，这和一个全连接层是一样的 因为这400个节点中的每一个<br />都对应一个维度为5x5x16的滤波器 也就是说这400个值中的每一个都是 这5x5x16个前一层的激活值，<br />输入某个任意的线性方程的结果 接下来，为了实现下一个卷积层 我们将实现一个1x`1的卷积 如果你有400个1x1的滤波器 那么下一层(的维度)也是1x1x400 这就得到了这个全连接层 最后我们还将用一个1x1的滤波器 然后是Softmax激活 以输出一个1x1x4的(数据)卷 以对应(上面的)这个网络输出的4个数字 这个过程，展示了如何将全连接网络层 用卷积层来实现 从而可以将这些单元 转化为1x1x400和1x1x4的(数据)卷 在这一转化之后 让我们来看一下你怎么样用卷积的形式来实现<br />滑动窗口目标识别 这个幻灯片上展示的内容根据是OverFeat论文 引用在底部，作者是Pierre Sermanet David Eigen, Xiang Zhang Michael Mathieu, Rob Fergus 和 Yann LeCun 假设你的滑动窗口卷积神经网络的输入是14x14x3的图像 同样我在幻灯片里用小的尺寸，比如14x14的图像 主要是为了简化示范 与之前相同，你有一个这样的神经网路 最终的输出是一个1x1x14的体 也就是Softmax单元的输出 同样，为了简化绘图 虽然14x14x3严格来讲是一卷，5x5x10 或者10x10x16也应该是体 不过为了简化幻灯片上的绘图 我就只画出这些体的前向的面 不画出1x1x400的体 只画1x1的部分 也就是丢掉这些绘图里的3维部分 假设你的卷积神经网络的输入14x14的图像 或者是说14x14x3的图像<br />而你的测试集里的图像(的维度)是16x16x3 也就是现在把这条黄色的边加到图像的边缘 在原来的滑动窗口算法中 你可以把蓝色的区域输入到卷积神经网络中 运行一次来得到分类结果0或1，然后向下滑动一点 这里我们用两个像素点的步长<br />然后你可以向右滑动 两个像素，将这个绿色的矩形区域 输入到卷积神经网络中 然后完整运算一次卷积神经网络来得到又一个标记0或1 之后你可以输入 这个橙色的区域，然后再运行一次来得到标记 第四次，也是最后一次，输入右下角这个紫色矩形的区域 也就是说<br />在这个相当小的16x16x3的图像上进行滑动窗口运算 你就需要运行这个卷积神经网络4次来得到4个标记 不过事实上，这里面的很多 运行卷积神经网络的计算是重复的 所以对滑动窗口的卷积方式的实现 是让这4次卷积神经网络的前向(forward pass)运算<br />共享计算过程 具体来说，你可以这么做 你可以运行这个卷积神经网络，用同样的参数 相同的5x5滤波器 运行同样的16个5x5的滤波器 现在你得到一个12x12x16的输出 然后像之前一样，做最大池化(max pool) 得到一个6x6x16(维度) 使用相同的400个5x5的滤波器<br />得到一个2x2x40的卷 也就不再是一个1x1x400的卷 而是得到一个2x2x400的卷 再经过一个1x1滤波器(卷积) 得到另一个2x2x400，而不是1x1x400(的体) 再做一次，你就得到一个 维度为2x2x4的输出体，而不是1x1x4 可以发现，这个蓝色的1x1x4的子域 包含的就是对(输入中)左上的这个14x14的部分图像<br />做(原来的)卷积运算的结果 这个右上角的1x1x4的体包含右上部分的结果 左下包含的是 对左下部分14x14的部分做卷积神经网络运算的结果 右下1x1x4的数据体包含的是 和对右下部分图像14x14的部分<br />做卷积神经网络运算一样的结果 如果你一步一步经过所有的运算过程 例如让我们来看一下绿色的部分 如果你只裁剪出这个部分 然后让它经过卷积神经网络的运算 那么第一层的激活值会刚好在这个区域里 下一层最大池化后得到的激活值就会 刚好在这个区域 下一层、下下一层，以此类推 那么这个过程所做的 也就是这个卷积形式的实现做的 就是不去强行在输入图像的4个子图像上分别 进行前向传播(forward propagation) 而是把4个合并成一个前向传播(forward prop)运算 从而利用这4个14x14的图像块的共同区域 共享了大量的运算 现在让我们来看一个更大的例子 假设你想在一个28x28x3的图像上使用滑动窗口 事实证明 如果你用同样的方式进行前向传播<br />你会得到一个8x8x4的输出 这对应的是对这个14x14的区域使用滑动窗口算法 这对应的是对这个区域使用滑动窗口算法 得到和左上角(区域)相对应的输出 然后用两个像素的步长将窗口移动一次 再移动一次、再移动一次，<br />如此下去一共有8个位置 这样得到第一行(的结果)，<br />然后当你在图像中继续进行下去 你可以得到所有8x8x4的输出 并且因为使用了2x2的最大池化 这个过程相当于在原来的图像上以2为步长<br />运行神经网络 复习一下 为了实现滑动窗口 之前的方法是，裁剪出一个区域 我们假设这是14x14 让它通过卷积神经网络 <br />然后对旁边下一个区域如法炮制 接着是下一个14x14的区域 然后下一个区域、下一个区域 下一个区域、下一个区域 直到有可能这个(区域)识别出一辆车 但是现在，我们不顺序进行运输 利用之前幻灯片上展示的卷积形式的实现 你可以实现对整张图像 比如整个28x28的区域，<br />以卷积操作的形式 进行一次这个大的卷积神经网络的前向传播 <br />同时得到得到所有的预测 然后就有可能识别出这辆车的位置 这就是如何用卷积的形式实现滑动窗口算法 这使得整个过程高效了很多 不过，这个算法仍然有一个弱点 那就是窗口边框的定位并不精确 在下一节视频中 让我们看看你可以怎样解决这个问题
GTC字幕组翻译