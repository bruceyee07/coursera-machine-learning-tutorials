1
00:00:01,100 --> 00:00:02,740
哈囉！歡迎回來

2
00:00:02,740 --> 00:00:05,368
這禮拜你會學到物件偵測 (object detection)

3
00:00:05,368 --> 00:00:08,980
這是電腦視覺這幾年來

4
00:00:08,980 --> 00:00:12,460
其中一個百花齊放、進步許多的領域

5
00:00:12,460 --> 00:00:18,430
為了要作到物件偵測，你得先學物件定位 (object localization)

6
00:00:18,430 --> 00:00:20,595
讓我們先從定義來談起

7
00:00:20,595 --> 00:00:25,760
你已經對圖片分類很熟了吧：有個演算法

8
00:00:25,760 --> 00:00:30,500
看了這圖片後，會說這是一輛車

9
00:00:30,500 --> 00:00:31,920
所以這是分類 (classification)

10
00:00:34,560 --> 00:00:38,964
而等等你會學到用神經網路來解決另個問題：

11
00:00:38,964 --> 00:00:41,550
分類且定位 (classification with localization)

12
00:00:41,550 --> 00:00:45,659
也就是，你不但要標示這是車，

13
00:00:45,659 --> 00:00:49,758
演算法還需要放一個「邊界框」(bounding box)

14
00:00:49,758 --> 00:00:55,090
也就是在車子的所在周圍畫一個紅色的長方形

15
00:00:55,090 --> 00:00:59,310
所以這問題叫「分類且定位」

16
00:00:59,310 --> 00:01:03,790
「定位」(localization) 意味著，去尋找你偵測到的車子

17
00:01:03,790 --> 00:01:05,760
是在圖片的哪裡

18
00:01:05,760 --> 00:01:09,530
這禮拜後面你會學到「偵測」(detection) 的問題

19
00:01:09,530 --> 00:01:13,590
也就是一張圖片可能有多個物件

20
00:01:13,590 --> 00:01:17,900
你必須全部偵測出來，而且全部定位之。

21
00:01:17,900 --> 00:01:21,820
如果你要做自動駕駛車的應用

22
00:01:21,820 --> 00:01:24,480
那你不但要偵測出車子

23
00:01:24,480 --> 00:01:29,310
也可能要偵測路人、機車、甚至其他物體

24
00:01:29,310 --> 00:01:31,090
之後你在這禮拜會看到。

25
00:01:31,090 --> 00:01:36,220
那麼，以我們這禮拜的術語

26
00:01:36,220 --> 00:01:42,130
「分類」和「分類且定位」通常有一個物件

27
00:01:42,130 --> 00:01:45,930
通常是一個大的物件，在圖片的中間

28
00:01:45,930 --> 00:01:47,600
你想辨認且定位之

29
00:01:47,600 --> 00:01:53,150
相比之下，在「偵測」的問題裡，會有多個物件

30
00:01:53,150 --> 00:01:57,450
實際上甚至是不同類別的多個物件

31
00:01:57,450 --> 00:01:59,110
就在同一張圖片內

32
00:01:59,110 --> 00:02:03,195
因此，你在圖片「分類」所學到的概念，會有助於

33
00:02:03,195 --> 00:02:04,815
「分類且定位」，

34
00:02:04,815 --> 00:02:06,885
而你在「分類且定位」學到的

35
00:02:06,885 --> 00:02:10,795
實際上也會對「偵測」有用。

36
00:02:10,795 --> 00:02:14,245
所以，就讓我們先談談分類且定位

37
00:02:15,255 --> 00:02:20,535
你已經對圖片分類的問題很熟了

38
00:02:20,535 --> 00:02:26,210
你可能把一張圖片餵進很多層的 ConvNet
— 這個是我們的 ConvNet

39
00:02:26,210 --> 00:02:31,348
然後結果會是一個特徵的向量，

40
00:02:31,348 --> 00:02:38,170
可能餵給一個 Softmax，來輸出預測的類別

41
00:02:38,170 --> 00:02:41,070
所以如果你在做自駕車

42
00:02:41,070 --> 00:02:44,370
你物件的分類可能會像這樣

43
00:02:44,370 --> 00:02:49,740
你可能有路人、汽車、機車，或是背景

44
00:02:49,740 --> 00:02:51,660
也就是以上皆非

45
00:02:51,660 --> 00:02:53,160
所以如果也沒人

46
00:02:53,160 --> 00:02:57,735
也沒車沒機車，那你會輸出「背景」

47
00:02:57,735 --> 00:03:03,755
所以分類有這四個，你的 Softmax 會有四個可能的輸出

48
00:03:03,755 --> 00:03:07,775
那麼，這是標準的分類流程

49
00:03:07,775 --> 00:03:12,585
如果你也想定位圖片中的車子，該怎麼做呢？

50
00:03:12,585 --> 00:03:17,156
要做的話，你可以改變你的神經網路

51
00:03:17,156 --> 00:03:21,940
讓他多幾個輸出單元，來輸出一個邊界框 (bounding box)

52
00:03:21,940 --> 00:03:27,179
特別是，你可以讓神經網路多輸出四個數字

53
00:03:27,179 --> 00:03:32,236
我要叫他們 b_x, b_y, b_h 和 b_w

54
00:03:32,236 --> 00:03:40,110
這四個數字描繪了要找的物件的邊界框

55
00:03:40,110 --> 00:03:44,820
那麼在課堂的影片中，我會用這樣的慣例：

56
00:03:44,820 --> 00:03:49,610
圖片左上角是座標 (0,0)

57
00:03:49,610 --> 00:03:52,660
而右下角是 (1,1)

58
00:03:52,660 --> 00:03:55,442
要指定邊界框

59
00:03:55,442 --> 00:04:00,060
這紅色長方形的話，你需要指定中間點

60
00:04:00,060 --> 00:04:03,057
這點是 (b_x, b_y)，

61
00:04:03,057 --> 00:04:08,193
而且你還需要邊界框的

62
00:04:08,193 --> 00:04:14,300
高度 b_h、和寬度 b_w。

63
00:04:14,300 --> 00:04:19,868
所以，如果你的訓練資料不但含有物件的類別

64
00:04:19,868 --> 00:04:23,950
— 就是神經網路的這個點想預測的 —

65
00:04:23,950 --> 00:04:26,740
也包含了額外四個數字來表示邊界框

66
00:04:26,740 --> 00:04:31,430
這樣的話你就能用監督式學習，來讓你的演算法

67
00:04:31,430 --> 00:04:35,910
輸出類別以及四個參數

68
00:04:35,910 --> 00:04:39,830
來告訴你偵測到的物件的邊界框在哪裡

69
00:04:39,830 --> 00:04:42,415
那麼，在這個例子，理想上 b_x 應該是 0.5

70
00:04:42,415 --> 00:04:47,254
因為這大概是圖片中的一半

71
00:04:47,254 --> 00:04:55,863
b_y 大概是 0.7，因為這大概是圖片往下約 70% 之處

72
00:04:55,863 --> 00:05:00,620
b_h 大概是 0.3，因為紅色長方形的高

73
00:05:00,620 --> 00:05:04,960
大約是整張圖片的 30%

74
00:05:04,960 --> 00:05:10,170
而 b_w 大概是 0.4，因為它的寬度

75
00:05:10,170 --> 00:05:14,510
紅色長方形的寬大約是整張圖片寬的 0.4 倍

76
00:05:15,940 --> 00:05:20,905
那麼，讓我們更正式一點，來定義目標的標籤 y

77
00:05:20,905 --> 00:05:24,581
在這個監督式學習的問題中。

78
00:05:24,581 --> 00:05:29,195
提醒一下，這是我們的四個類別

79
00:05:29,195 --> 00:05:34,775
而神經網路會輸出這4個數字、以及類別

80
00:05:36,035 --> 00:05:39,195
或者可能是這些類別的機率

81
00:05:40,530 --> 00:05:47,710
所以我們定義目標標籤 y 如下：

82
00:05:47,710 --> 00:05:53,480
這會是個向量，第一項 p_c 會是

83
00:05:53,480 --> 00:05:54,560
「有沒有物件呢？」

84
00:05:55,930 --> 00:06:02,140
所以如果物件屬於類別 1, 2 或 3，p_c 會等於 1

85
00:06:02,140 --> 00:06:04,477
如果是背景類別

86
00:06:04,477 --> 00:06:09,018
如果你想偵測的物件都不在，那 p_c 會是 0

87
00:06:09,018 --> 00:06:11,973
你可以想做 p_c 是表示

88
00:06:11,973 --> 00:06:15,020
會有物件的機率

89
00:06:15,020 --> 00:06:19,320
有你想要偵測的類別的機率

90
00:06:19,320 --> 00:06:22,640
也就是除了「背景」類別以外的。

91
00:06:22,640 --> 00:06:28,338
接下來，如果有物件，那你要輸出 b_x,

92
00:06:28,338 --> 00:06:35,010
b_y, b_h 和 b_w，也就是物件的邊界框

93
00:06:35,010 --> 00:06:40,436
最後，如果有物件，p_c 等於 1 時

94
00:06:40,436 --> 00:06:44,054
你也要輸出 c_1, c_2 和 c_3

95
00:06:44,054 --> 00:06:49,610
表示這是類別 1, 2 還是 3

96
00:06:49,610 --> 00:06:53,030
也就是路人、汽車或機車呢

97
00:06:53,030 --> 00:06:56,340
請記得在我們的問題中

98
00:06:56,340 --> 00:06:59,450
我們假設圖片裡面只有一個物件

99
00:06:59,450 --> 00:07:03,040
圖片中最多只會出現一個這裡的物件

100
00:07:03,040 --> 00:07:06,490
如果是分類且定位的問題

101
00:07:06,490 --> 00:07:09,240
那讓我們來看幾個例子：

102
00:07:09,240 --> 00:07:16,310
如果這是訓練資料的一張圖，如果這是 x，那麼 y 就會是

103
00:07:16,310 --> 00:07:22,650
第一維 p_c 會等於 1，因為有物件。然後 b_x, b_y

104
00:07:22,650 --> 00:07:27,870
b_h 和 b_h 表示著邊界框

105
00:07:27,870 --> 00:07:32,260
所以訓練資料的標籤必須含有邊界框

106
00:07:32,260 --> 00:07:35,570
最後，這是輛汽車，是類別 2

107
00:07:35,570 --> 00:07:38,680
所以 c_1 會是 0，因為不是行人；

108
00:07:38,680 --> 00:07:44,640
c_2 是 1，因為是汽車；c_3 會是 0，因為不是機車

109
00:07:44,640 --> 00:07:50,630
所以 c_1, c_2, c_3 當中，最多只有一個會是 1

110
00:07:50,630 --> 00:07:54,010
那麼，這是當圖片有一個物件的時候

111
00:07:54,010 --> 00:07:55,890
那如果沒有物件的時候呢？

112
00:07:55,890 --> 00:07:59,957
萬一你的訓練資料 x 等於這個呢？

113
00:07:59,957 --> 00:08:03,807
在這樣情況下，p_c 會等於 0

114
00:08:03,807 --> 00:08:08,979
而剩下其他的維度會是「無關」(don't cares)

115
00:08:08,979 --> 00:08:13,940
所以我把他們都填問號

116
00:08:13,940 --> 00:08:18,318
所以這是 don't care (無關)，因為如果沒物件

117
00:08:18,318 --> 00:08:23,074
那麼無論你的神經網路輸出什麼邊界框

118
00:08:23,074 --> 00:08:27,280
無論認為是 c_1, c_2, c_3 的哪一種，這都是沒有關係的

119
00:08:27,280 --> 00:08:33,870
所以給定一個有標籤的訓練集，你就根據這樣建出 x，

120
00:08:33,870 --> 00:08:38,680
輸入的圖片，以及 y，類別的標籤

121
00:08:38,680 --> 00:08:42,880
無論圖片裡有物件還是沒有物件

122
00:08:42,880 --> 00:08:45,660
這一堆的集合，就會是你的訓練集

123
00:08:47,100 --> 00:08:51,520
最後呢，讓我們描述你訓練這個

124
00:08:51,520 --> 00:08:53,930
神經網路時，所用的損失函數 (loss function)

125
00:08:53,930 --> 00:08:59,070
假設正確答案的標籤是 y，而神經網路輸出某個 y hat

126
00:08:59,070 --> 00:09:01,010
損失是多少呢？

127
00:09:01,010 --> 00:09:05,484
如果你用平方誤差

128
00:09:05,484 --> 00:09:10,105
那損失會是 (y hat_1 - y_1)平方

129
00:09:10,105 --> 00:09:15,026
加 (y hat_2 - y_2)平方...

130
00:09:15,026 --> 00:09:19,810
加 (y hat_8 - y_8)平方

131
00:09:19,810 --> 00:09:23,970
注意到我們有八個元素

132
00:09:23,970 --> 00:09:28,200
所以這是每個維度差異的平方和

133
00:09:28,200 --> 00:09:33,650
如果 y_1 = 1，這就是損失

134
00:09:33,650 --> 00:09:36,690
也就是有物件的情況下

135
00:09:36,690 --> 00:09:39,671
y_1 是 p_c

136
00:09:39,671 --> 00:09:43,685
所以 p_c = 1 表示圖片有個物件

137
00:09:43,685 --> 00:09:47,475
那麼損失會是各個維度差異的平方和

138
00:09:48,675 --> 00:09:53,418
另外一個情況是，如果 y_1 = 0

139
00:09:53,418 --> 00:09:57,790
也就是如果 p_c 是 0

140
00:09:57,790 --> 00:10:04,930
在這情況下，損失只有 (y hat_1 - y_1) 的平方

141
00:10:04,930 --> 00:10:11,170
因為在這第二個例子，其他的維度都「無關」

142
00:10:11,170 --> 00:10:16,068
所以在這例子唯一有關係的，是神經網路

143
00:10:16,068 --> 00:10:19,390
能多準確輸出 p_c

144
00:10:19,390 --> 00:10:23,304
回顧一下，如果 y_1 = 1，是這個例子

145
00:10:23,304 --> 00:10:28,343
那你可以用平方誤差來懲罰

146
00:10:28,343 --> 00:10:33,402
預測值和真正答案所有 8 個元素的差異

147
00:10:33,402 --> 00:10:39,749
而如果 y_1 = 0，那從第 2 到第 8 個元素是什麼都沒關係

148
00:10:39,749 --> 00:10:44,698
所以唯一有關的是你的神經網路

149
00:10:44,698 --> 00:10:48,880
估計 y_1 能夠多準，也就是 p_c

150
00:10:48,880 --> 00:10:53,554
如果你想知道細節的話，這只是題外話

151
00:10:53,554 --> 00:10:57,760
我用平方誤差的原因單純是為了簡單起見

152
00:10:57,760 --> 00:11:02,840
實務上你或許可拿對數似然 (log likelihood) 損失

153
00:11:02,840 --> 00:11:06,438
用在 softmax 輸出項 c_1, c_2, c_3 上；

154
00:11:06,438 --> 00:11:10,118
而邊界框座標的這幾項

155
00:11:10,118 --> 00:11:14,414
你通常可以用平方誤差；

156
00:11:14,414 --> 00:11:19,200
至於 p_c，你可以用像是羅吉斯回歸損失
(logistic regression loss)

157
00:11:19,200 --> 00:11:22,830
雖然就算你用平方誤差的話，應該也能有不錯的表現

158
00:11:22,830 --> 00:11:27,030
所以這就是如何用神經網路來分類物件

159
00:11:27,030 --> 00:11:29,140
而且還能定位之

160
00:11:29,140 --> 00:11:33,270
這個概念 — 關於神經網路輸出一堆數字

161
00:11:33,270 --> 00:11:38,040
來表示東西在圖片何處 — 這個概念其實非常厲害

162
00:11:38,040 --> 00:11:42,940
在下一部影片，我想分享其他可以使用這概念的情況

163
00:11:42,940 --> 00:11:48,180
也就是神經網路輸出一堆實數，像是個迴歸問題

164
00:11:48,180 --> 00:11:51,980
這種在電腦視覺其他問題上也非常有用

165
00:11:51,980 --> 00:11:53,360
讓我們進入下一段影片