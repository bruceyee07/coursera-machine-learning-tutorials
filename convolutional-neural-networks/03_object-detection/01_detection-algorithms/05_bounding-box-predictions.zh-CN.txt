上个视频中 您学习了如何使用卷积实现滑动窗口方法 虽然这在计算上更有效率 但它依然存在无法精确输出边界框的问题 在这个视频中 我们将学习 如何更精确地预测边界框 使用滑动窗口 你通过这些预先决定的窗口来扫过整个图像 在这种情况下 没有一个边框与车的位置恰好吻合 所以 也许这个边框是最吻合的 另一方面 看上去一个更为精确的边界框 实际上并不是一个正方形 它是一个较宽的长方形 长宽比稍扁平 所以 是否有一个算法可以给出更精确的边界框？ YOLO算法就是一个比较好的能精确输出边界框的算法 YOLO的全称是You Only Look Once 这个算法是由Joseph Redmon Santosh Divvala、 Ross Girshick和Ali Farhadi提出 下面是具体的做法 假设你有一张100乘100的图片作为输入 接着你要将其用网格划分 出于演示的目的 我将使用3乘3的网格 虽然在实际的操作中 你会使用更细分的网格 比如19乘19的网格 基本思路是你将把 几个视频以前学习的图像分类及定位的算法 应用到这九个网格中的每一个 基本思路是你将把 本周第一个视频中学习的图像分类及定位的算法 应用到这九个网格中的每一个 所以具体来说 下面是你要如何定义用于训练的标签 对于这九个网格中的每一个 你要给定一个标签Y 这里标签Y是一个8维的向量 和之前你学到的一样 第一个输出值Pc(0或1)取决于 那一个网格元中是否有目标物 如果在那个网格元中有目标物 bx by bh和bw将指定边界框的位置 最后需要包括C1 C2和C3 如果你想要识别三种类型的目标物 不包括背景 比如你想要识别行人 汽车 摩托车和背景 那么C1 C2和C3就可以代表行人 汽车和摩托车 所以在这个图像中 我们有9个网格元 所以每一个网格元你都会有一个这样的向量 让我们从左上角的网格元开始 这里这个 在这个网格中 没有目标物 所以左上角这个网格元的标签Y会是0 然后不考虑其他的元素 这个网格元和所有不包含目标物 不包含感兴趣的目标物的网格元 的输出标签Y都会是一样的，这样的 那么这个网格元是怎么样的呢？ 详细地说 这张图像有两个目标物 YOLO算法是将这两个目标物分别分配到 包含它们的中心点的网格元中 所以左边的汽车被分到了这个网格元中 而右边的汽车 这是它的中心点 被分到了这个网格元中 所以即使中间的网格元包含这两辆车的一部分 我们会假设中间的网格元不包含感兴趣的目标物 所以中间的网格元会有这样不包含目标物的标签Y 所以有第一个元素Pc 然后其他的元素都不重要 而这个网格元 在左边的这个我用绿色框圈出的网格元 它的目标标签Y会如下所示 它包含一个目标物 然后你写出bx by bh和bw 来给出这个边界框的位置 然后你需要指出 如果第一类是行人 那么它是0 第二类是汽车 它是1 第三类是摩托车 它是0 类似的 右边这个网格元 由于它包含一个目标物 它也会有一个像这样的向量 来作为与其对应的目标标签 所以 对于这9个网格元中的每一个 你都会有一个8维的输出向量 由于你有3乘3个网格元 一共是9个网格元 输出的总大小将会是3乘3乘8 因此输出目标将会是3乘3乘8 因为你有3乘3个网格元 然后这3乘3个网格元中的每一个 你都有一个8维的Y向量 所以输出目标的总量是3乘3乘8 举个例子 这个位于左上角的 1乘1乘8的输出块就对应着 这9个网格元中位于左上角的这个的输出向量 所以这3乘3个位置中的每一个 对于这9个网格中的每一个 这都对应着一个你要输出的8维目标向量Y 如果那个网格元中不包含目标物 其中的一些元素可以是不重要的 这就是为什么总的目标输出 即这个图像的输出标签现在是3乘3乘8的 所以现在 为了训练你的神经网络 输入的大小是100乘100乘3 也就是输入的图像 然后是一个普通的卷积神经网络 包括卷积层、最大池化层等等 最终 你需要选择这些卷积层和最大池化层等等 使得它逐渐映射到3乘3乘8的输出上 所以你要做的是 你有一个像这样的图像输入X 和这些3乘3乘8的目标标签Y 然后你用反向传播来训练神经网络 来将任一输入值X映射到输出值Y上 这个算法的优势在于 该神经网络可以精确地输出如下的边界框 所以在测试时 你需要做的是给进输入图像X 然后运行前向传播直到得到输出向量Y 然后对于这9个向量中的每一个 也就是这3乘3个位置中的每一个 你可以读到1或者0 说明了在这9个中的某一个是否包含目标物 以及如果包含目标物 那么那个目标物是什么 还有该网格元中的目标物的边界框 所以只要在每个网格中有不超过一个目标物 这个算法应该没有问题 而在某个网格中有多于一个目标物的问题 我们将在之后提及 但在实际操作中 相比这里使用的相对较少的3乘3的网格 你可能会使用更精细的网格 可能是19乘19的网格 所以最终你会得到19乘19乘8的结果 由于使用了更精细的网格 这会减少同一个网格元中有多个目标物的可能性 值得提醒的是 将目标物分配到网格元中的方式 即先找到目标物的中心点 再根据中心点的位置将它分配到包含该中心点的网格中 所以对于每一个目标物 即使它跨越了多个网格 它也只会被分配给这九个网格元中的一个 或者说这3乘3个网格元中的一个 或者19乘19个网格元中的一个 而使用19乘19的网格的算法 两个目标物的中心 出现在同一个网格元中的概率会稍小 所以值得注意的有两点 第一 这种算法和本周的第一个视频中讲到的 图像识别和定位算法十分相似 它会直接输出边界框的坐标位置 以及它允许你的神经网络输出 任意长宽比的边界框 同时输出的坐标位置也更为精确 而不会受限于滑动窗口的步长 第二 这个算法是 通过卷积实现的 你不需要在3乘3的网格上 执行这个算法9次 如果你使用19乘19的网格 19的平方是361 所以你不需要运行同样的算法361次 或者说19的平方次 与此不同的是 这个算法是一整个卷积实现的 你只需要用一个卷积网络 使得所有3乘3或19乘19个网格 所需的计算被大量地共享 所以 这是一个非常有效率的算法 事实上 YOLO算法的一个好处 也是它一直很流行的原因是它是通过卷积实现的 它实际上运行起来非常快 所以它甚至可以运用在实时的目标识别上 现在 在总结前 我还想和你们分享一个细节 那就是如何决定边界框的参数bx by bh和bw 我们会在下一张幻灯片中讨论 所以 给定图像中的这两辆车 还记得我们有3乘3的网格 让我们以右边的汽车为例 在这个网格元中有一个目标物 所以它的目标标签Y会是1 也就是Pc等于1 然后是bx by bh bw 最后是0 1 0 所以该如何指定边界框呢？ 在YOLO算法中 相对于这个正方形 我将按惯例把左上角的点 定为0 0 而把右下角的点定为1 1 所以 要指定中心点的位置 也就是那个橙色的点的位置 bx可能是 x看上去在0.4左右 因为它大概在距离左边0.4左右的位置<br />（译者：Andrew原话说到右边0.4左右，应该是口误） 然后y看上去在0.3左右 然后边界框的高度是通过它和 整个网格宽度的比例来指定的 所以这个红色方框的宽度大概是那条蓝色线段的90% 所以bh就是0.9 然后它的高度 大概是整个网格元的一半 那么bw大概是0.5 换句话说 这里的bx by bh bw 是相对网格来指定的 所以 bx by 一定会在0到1之间 对吧？ 因为根据定义 那个橙色的点一定是在包含它的网格元中的 如果它们不在0到1之间 那它就在那个正方形外部了 那么它将会被分配到另一个网格元中 但是这两个量可以大于1 特别是 如果有一辆车 它有像这样的边界框 那么它的边界框的高度和宽度 可以大于1 所以虽然有很多种指定边界框的方式 但依据这种惯例是一种较为合理的方式 虽然 当你阅读YOLO算法的研究论文时 那些关于YOLO的研究会用到 其他更好一些的参数化 但我希望可以提供这种较为合理 效果也不错的形式给大家 虽然 有一些更复杂的参数化 会用到S型(sigmoid)函数来保证这些参数介于0到1之间 还会用到指数参数来保证这些是非负的 因为0.9 0.5 这些必须是大于等于0的 还有一些更高级的参数化 效果会更好一些 但我们所讲的这一种效果也不错 所以 关于YOLO (You Only Lool Once)算法 我们就讲到这里 在接下来的几个视频中 我会向你展示 其他几种使得这个算法更优的想法 同时 如果你愿意的话 你可以读一下 在前几页幻灯片的下方 我列出的关于YOLO算法的参考文献 需要注意的是 当你读这些论文(你会发现) YOLO的论文是较难读懂的论文之一 我还记得我第一次读这些论文的时候 我真的很难搞懂这些论文在说些什么 于是我问了几个做研究很棒的朋友 来帮我弄清楚 甚至他们也很难理解这篇论文中的一些细节 所以 当你读这篇文章 并发现它很难理解 这都是正常的 我希望这不那么常见 但不幸的是 这并不少见 即使是审阅论文的 资深研究人员也很难完全理解其中的一些细节 他们不得不查看源代码 或者联系作者本人 或通过其他的方式来弄清楚这些结果的细节 但如果你想读的话 不要因问我刚才的话而退怯 但这的确是一篇较难的文章 所以 你现在已经理解了YOLO算法的基本概念 让我们继续学习使得这个算法更优化的一些其他的部分