你已經學會了「物件定位」和「特徵點偵測」 那現在，就讓我們邁向「物件偵測」演算法 在這部影片，你將會學到怎麼利用 Convnet 加上 Sliding Windows (滑動視窗) 偵測法
來做到物件偵測 假設你想做偵測汽車的演算法 你可以這樣做 首先，創一個標記好的訓練集 x, y 含有準確切好的車子圖片 所以這圖片 x 是個正面的例子，裡面有車 這有車、這有車 然後這張沒車、這沒有車 要創造這個訓練資料 你可以從緊密精準的切圖開始 也就是 x 裡面大概就只有車 你可以照張照片，把周圍切掉 把不屬於車的地方切掉 所以最後車子會佔滿整張圖片中間。 有了這個標好的訓練資料 接下來就能訓練一個 ConvNet，輸入一張圖片 例如這張切好的圖片 然後 ConvNet 要做的是輸出 y 0 或 1，代表有沒有車 一旦你訓練好了這個 ConvNet 你就能用它來做 Sliding Windows (滑動視窗) 偵測 方法如下： 如果你有個測試的圖片，像這張，那你要做的是 先挑某個視窗大小，如下圖示 然後你把一個小的方形區域輸入 ConvNet 就挑這小小的紅色區塊 輸入到 ConvNet 讓 ConvNet 預測他 在這例子，那一個紅色區域 ConvNet 會說那個紅色方框裡面沒有車。 Sliding Windows 偵測法的意思是 接下來你會輸入 第二張小圖片，也就是 平移一點點後的紅框框，再把他餵進去 ConvNet 你只需要把紅色框框圍起來的區域 餵給 ConvNet，再跑一次 ConvNet。 然後第三個小圖片也這樣做，依此類推 直到你把這紅框視窗滑過圖片的每個位置 在這裡我移的步伐很大，這只是為了讓動畫快一點 但概念是，你根據某個步伐，滑過每一個這樣大小的區域 把這堆大量的切好的小圖片 餵給 ConvNet，將每個位置分類成 0 或 1 那麼，這樣做過一遍 這個過程，叫做對這張圖片跑一次 sliding window 接下來你再重複一遍 但是用大一點的視窗 所以你用大一點的區域，用這個區域來跑 然後把這區域縮放到 ConvNet 能吃的大小、 餵給 ConvNet，讓他輸出 0 或 1 然後同樣地根據某個步伐大小，把這視窗滑過去 就一直這樣跑到底為止，看過整張圖片 接下來，你可能可以用更大的視窗做第三次，依此類推 我們的期望是，如果你這樣掃 只要圖片的某處有車，那就會有某個視窗 例如如果你把這一個視窗丟進 ConvNet 希望 ConvNet 能對這個區域輸出 1 所以你就偵測到那邊有輛車。 這之所以叫 Sliding Windows 偵測法，是因為你拿這些視窗、 這些框框，滑過整張圖片 跨幾步，分類每個方框，看看裡面有沒有車 那麼，sliding windows 偵測法有個很大的缺點 就是運算成本 因為你要從圖片切出非常多的區域 每一個都要獨立跑過 ConvNet 如果你滑得非常粗略 跨步 (stride) 非常大、非常遠 這樣可以減少要餵給 ConvNet 的視窗個數 但是粗略地跑可能會影響成效 而如果你很細膩地跑、跨很小步來掃 那就會有很大量的區域 要通過 ConvNet，意味著運算成本非常高 因此，在神經網路崛起之前，大家用非常簡單的分類器 例如用人類的智慧取特徵 再套用簡單的線性迴歸，來作到物件偵測 在那個時代，因為這種分類器運算比較快 就只是個線性函數 sliding window 偵測還可以 這方法並不壞 但用了 ConvNet 後，跑一次分類 要花更多的時間，這樣 sliding window 會慢到無法接受 但是除非你掃得很密集、用很小的跨步 否則你無法準確地定位到圖片中的物件 不過好險，這個運算成本的難題其實有很好的解法 特別是，sliding window 偵測 能夠用卷積的方式實作、更有效率 讓我們在下部影片看看要怎麼做