안녕하세요. 환영합니다. 이번 주에는 객체 탐색에 대해 배우도록 하겠습니다. ‘객체 탐색’이란 컴퓨터비전 분야 중 하나로서 불과 몇 년 전에 비해 급격히 증가하고 있으며, 훨씬 효과적으로 사용되고 있습니다. object detection 객체탐색기능을 구축하기 위해서는 먼저 object
localization (객체위치식별) 에 대해 학습하는 것이 필요합니다. 우선 그 의미를 한 번 정의하며 시작해 봅시다. 여러분은 이미 어떠한 알고리즘이 위와 같은 사진을 보며 자동차라고
알려주는 이미지분류작업 (Image
Classification Image) 에 익숙할 것 입니다. 이러한 기능을 바로 ‘분류법’ 이라고 할 수 있습니다. 이 강의영상의 뒷부분에서 언급하겠지만, 여러분이 네트워크 내에서의 구축작업 중 마주하게 되는 문제점들은 ‘위치측정기능을 동반한 분류법’ 입니다. 이것은 단순히 우리가 ‘이
물체가 자동차다’ 라고 이름 붙이는 것뿐만 아니라, 이 알고리즘이 사물을 대상으로 경계상자를 표시하거나, 사진 속에 있는 자동차의 위치 주변을 따라 빨간 직사각형을
그리는 일들 또한 담당하는 것을 의미합니다. 이러한 것을 위치측정문제가 있는 분류법 이라고 부릅니다. ‘로컬라이제이션’ 이라는 용어는 여러분이
탐지한 자동차가 사진 속 어디에 있는지 알아내는 것을 말합니다. 이번 주 후반에 가면, 탐지문제 (Detection Problem) 에 대해 알아볼 텐데요, 그때에는 사진 속에 여러 개의 객체가 등장할 수도 있으니 여러분은 그것들을 전부 탐지해내야 하고, 모든 객체의 위치들을 알아내야만 합니다. 만약 자율주행 애플리케이션에서 이 작업을 수행하는 경우, 다른 자동차들뿐만 아니라 그 외 보행자와 오토바이, 심지어는 다른 주변 물건들까지도 탐지해내야 할 수도 있습니다 그래서 이번 주 후반에 이것을 살펴보도록 하겠습니다 이번 주에 사용하게 될 용어들 중, 분류법과 위치측정문제 분류법은 대체적으로 하나의 객체를 다루고 있습니다. 대개는 여러분이 인식 혹은 인식과 위치측정 모두를 하고자
하는 이미지의 중앙에 큰 객체가 하나 있습니다. 이와는 반대로, 탐지문제에서는, 다수의 객체가 존재할 수 있습니다. 그리고 실제로는, 단일
이미지 내에 있는 다른 카테고리들의 여러 객체 일 수도 있습니다. 따라서 이미지 분류법에 대해 앞서 배웠던 아이디어들은 위치 측정 분류법에 매우 유용할 것 입니다. 또한 위치측정을 위해 배운 아이디어들은 탐지작업에 유용하게 사용된다는 것을 알 수 있을 것입니다. 그럼 먼저 위치측정 분류법에 대해 이야기하며 시작해보겠습니다. 여러분은 이미 이미지분류 문제에 익숙하실 겁니다, 여러 레이어를 가진 컨브네트에 사진을 입력할 수 있고, 보시는 것처럼 컨브네트가 생겼습니다. 그리고 이것은 예측된 조항을 출력하는 Softmax 유닛 공급의 벡터특징 생성이라는 결과를 가져옵니다. 그래서 여러분이 만약 자율주행 자동차를 만들고 있다면 아마도 여러분의 객체 카테고리들은 다음과 같을 수 있습니다. 보행자, 자동차, 오토바이 또는 배경 등이죠. 이 말은 위의 객체들 중 그 어느 것도 없는 경우라면, 예를 들어, 보행자도
없고, 차, 오토바이도
없다면, 여러분은 해당 출력 배경만 갖게 될 것입니다. 따라서 이것들이 종류입니다.
이들은 이렇게 4가지가 출력 가능한 softmax를
가지고 있습니다. 이것은 표준 분류 파이프라인입니다. 이미지에 있는 자동차를 위치측정하고 싶다면 어떻게 해야 될까요? 그걸 위해서는, 경계상자를
출력하는 출력단위를 갖는 신경망을 변경하시면 됩니다. 그래서, 특히
신경망 출력으로 4개의 종류를 더 가질 수 있고, 이제 그것들을 bx,
by, bh, 그리고 bw라고 부르겠습니다. 그리고 이 4개의
숫자는 탐지된 객체의 경계상자를 파라미터화 했습니다. 그래서 이 강의에서는, 이미지의
왼쪽 상단에 있는 표기법을 사용하려고 합니다. 좌표 (0,0)로
표시하겠습니다. 그리고 오른쪽 아래에는
(1,1)을 나타냅니다. 경계상자를 지정하면 빨간색 직사각형에 중간 점을 지정해야 합니다 그러면 경계상자의 폭,
bw뿐 아니라 높이 bh 에
의해 이 지점 bx를
정하는 것이죠. 이제 신경망이 예측하려고 하는 트레이닝 세트에 객체 교차 레이블뿐만 아니라 4개의 추가적인 숫자들을 포함하고 있다면, 경계상자를 제공하는 것이 여러분의 알고리즘 출력을 만들어내기
위한 지도학습을 사용할 수 있게 하는 것 입니다. 이는 분류라벨뿐만 아니라 탐지했던 객체의 경계상자가 어디에 있는지 알려줄 4개의
파라미터입니다. 따라서 이 예에서 이상적인
bx는 약 0.5 일 수 있습니다 왜냐하면 이것이 이미지의 오른쪽으로 절반 정도 이기 때문입니다. 0.7까지도 가능한데요, 이는 이미지의 아래쪽으로
대략 70% 이기 때문입니다. 이 붉은 사각형의 높이가 이미지의 전체 높이의 약 30%이기 때문에 bh는 대략 0.3정도 될 것입니다. 빨간색 상자의 너비가 전체 이미지의 전체 너비의 약 0.4이기 때문에 bw는 약 0.4
일 수 있습니다. 빨간색 상자의 너비가 전체 이미지의 전체 너비의 약 0.4이기 때문에 bw는 약 0.4
일 수 있습니다. 우리가 이것을 위해 지도학습과제로서 목표라벨 y를 어떻게 정의 내릴까 하는 측면에서, 한 번 이것을 공식화 해봅시다. 그래서 기억해야 할 것은,
이것들은 4 가지 분류이고, 신경망은 분류라벨, 즉
분류라벨의 가능성뿐만 아니라 이 4개의 숫자를
출력합니다. 다음과 같이 목표라벨 y를
정의 내려봅시다. 이것은 벡터입니다. 첫
번째 요소인 pc는 ‘객체가 있는가?’로 정했습니다. 따라서 객체가 클래스 1,
2 또는 3 이 되면, pc는 1이 될 것입니다. 이것이 배경 분류라면, 탐지하고자 하는 객체가 아무것도 없다면, pc는 0이 될 것입니다. 객체가 있을 가능성을 나타내는 것으로 pc를 간주할 수도 있습니다. 즉, 여러분이
탐지하려고 하는 분류 중 하나가 거기에 있다는 가능성을 말하는 것입니다. 따라서 이것은 배경분류 이외의 것을 가리키는 것이죠. 다음으로는, 만약
객체가 있다면, 여러분은 bx, by, bh와 bw, 즉 탐지했던 객체를 위해서 경계상자를
출력하고 싶어할 것입니다. 그리고 최종적으로 객체가 있다면, 만약 pc가 1이라면, c1, c2 그리고 c3를 출력값으로 입력해야 합니다, 이들은 class 1, class2, class3를 의미합니다. 따라서 이는 보행자, 자동차
또는 오토바이가 되겠네요. 그리고 우리가 다루고 있는 문제에서 여러분의 이미지는 단지 하나의 객체만을 가지고 있다고 가정합시다. 따라서 대부분의 개체 중 하나가 그림에 나타납니다. 이 위치 측정 문제를 가진 분류에서 나오는 것이죠. 몇 가지 예제를 좀 더 살펴봅시다. 이것이 트레이닝 세트 이미지이고, 이것이 x이고, y는 pc가 1이 되는 첫 번째 구성요소가 될 것입니다. 왜냐하면 객체 bx, by, bh와 bw가 경계상자를 지정할 테니까요. 따라서 라벨이 지정된 트레이닝 세트에는 라벨에 있는 경계상자가 필요할 것입니다. 그리고 마지막으로 이건 자동차인데요, class 2이죠. c1은 보행자가 아니기 때문입니다 0일 것입니다. c2는 자동차이므로 1이 되고, c3는 오토바이가 아니므로 0이 될 것입니다. c1, c2, 그리고 c3 중에서, 기껏해야 그 중 하나는 1이 될 것입니다. 이것은 이미지 안에 객체가 있다면 거죠. 이미지 안에 객체가 없다면 어떻게 될까요? x가 이것과 같은 트레이닝 예시가 있다면 어떻게 될까요? 이런 경우에는, pc는 0이 될 것이고, 이 나머지 원소들은 상관없는 것들이 됩니다. 이 안에 물음표를 다 써보겠습니다. 이것은 ‘don’t care’ (상관없는)것입니다. 왜냐하면 이 이미지 안에 객체가 없다면 세 개의 객체 c1, c2, c3뿐만 아니라 네트워크 출력 값에 있는 경계상자가 무엇인지 상관없기 때문입니다. 그래서 일련의 라벨 트레이닝 예제를 통해, 객체가 있는 이미지와 객체가 없는 이미지 둘 다를 위해서 어떻게 코스트 라벨 y뿐만 아니라 입력이미지 x를 구성할지를 생각해 보는 것입니다. 그러면 이 세트가 여러분의 트레이닝 세트를 결정할 것입니다. 마지막으로 신경망을 훈련시키기 위해 사용하는 loss function (손실함수)를 설명하겠습니다. 기본 참 레이블는 y 였고, 신경망은 ŷ을 입니다. 그럼 손실은 무엇이 될까요? 만약 제곱오차(squared error)를 사용하게 되면 손실은 (ŷ1 - y1)제곱, 더하기 (ŷ2 - y2)의 제곱, 더하기 이렇게 쭉 이어지다가 (ŷ - y8)의 제곱이 될 것입니다. 이처럼 y는 8개 구성요소를 가지고 있는걸 확인하십시오. 따라서 다른 원소들의 차이의 제곱의 총액이 되는 것입니다. 그리고 이것은 y1 = 1이면 손실입니다. 그리고 대상이 있는 경우입니다. 따라서, y1 = pc 이미지에 객체가 있으면 pc = 1 이죠. 따라서 손실은 모든 차이 나는 원소들의 제곱의 합이 되는 것입니다. 또 다른 경우는, 만약 y1 = 0이라면 다시 말해, pc = 0 이죠. 이 경우, 손실은 (ŷ1 -y1) 의 제곱 값입니다. 왜냐하면 이 두 번째 경우에, 나머지 요소들 전부 ‘don’t care’인 불필요한 것이기 때문이죠. 신경 써야 하는 것은 pc를 출력하는 데에 얼마나 정확하게 신경망이 작동하는지 입니다. 요약하자면, y1 = 1, 바로 이 경우를 말하는 건데요, 이 모든 여덟 개의 요소의 예측된 혹은 실제적인 출력값에서 생겨난 근 편차에 대해 벌칙을 주는 차원에서 오차제곱을 사용할 수 있습니다. 반면에, y1 = 0 이면, 두 번째 칸의 있는 ‘don’t care’ 상관없는 요소들 입니다.. 신경 써야 하는 것은 신경망이 y1, 즉 pc를 얼마나 정확하게 예측하는가 입니다. 모든 세부적인 것들을 알고 싶어하는 분들을 위해 추가 정보를 드리자면, 저는 설명을 단순하게 하려고 오차제곱을 사용했습니다만, 실제에서는 열어 기능들을 사용할 수 있습니다. 예를 들어, c1, c2, c3에 log-likelihood loss와 softmax 출력값들을 사용할 수 있을 것입니다. 다른 요소들에다가는 오차제곱을 사용할 수도 있습니다. 예를 들어, 경계상자 좌표에 오차제곱 같은 것을 사용할 수 있습니다. pc 에 대하여는, 로지스틱 회귀 손실과 같은 기능을 사용할 수 있을 것입니다. 오차제곱을 사용하더라도, 이것은 아마 잘 작동할 것입니다. 자, 이것이 객체를 분류하는 것뿐 아니라 위치 측정까지 하는 신경망을 어떻게 만들 수 있을지에 대한 내용입니다. 신경망으로 하여금 물체들이 사진 어디에 있는지를 알려주는 실제 숫자들을 출력하도록 시키는 이 아이디어는 매우 강력한 것으로 판명되었습니다. 다음 강의에서는, 이 아이디어가 몇몇 다른 위치에서도 사용되는지 공유하고 싶습니다. 신경망으로 하여금 실제 숫자 세트를 만들도록 하는 아이디어가 컴퓨터 비전 분야 어디에서 사용하기에도 강력할 것입니다. 다음 강의로 가시죠.