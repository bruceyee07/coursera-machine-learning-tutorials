前回の動画では スライディング ウィンドウの畳み込み実装を学んだ それは より効率的に計算することだった しかし 非常に正確な境界箱を出力するわけではない無いという問題が残っている このビデオでは どのように 境界箱を もっと正確にできるかを見ていく スライディング ウィンドウでは 予め特定された複数の場所で 一斉射撃を行う この例では 車の位置に 完全に適合する箱が無い おそらく この箱が一番合う そして また これは 正確に描かれたように見えるが 完璧な境界箱は 正確な正方形ではない それは 少し幅広の四角で 少し水平アスペクト比が高い では このアルゴリズムに 正確な境界箱を出力させる方法はあるのか？ このような より正確な境界箱を出力するいい方法は YOLO アルゴリズムだ YOLO は ”You Only Look Once" の略だ このアルゴリズムは Joseph Redmon, Santosh Divvala, Ross Girshick そして Ali Farhadi によるものだ それは こういう風にやる 入力画像が 100 x 100 だとする この画像を格子にする 描きやすくするため 3 x 3 格子を使うけど 実際の実装では もっと 細かいのを使う 19 x 19 格子とかをね 基本的なアイデアは 前に見た 画像分類と位置決めアルゴリズムを使い この９つの格子に適用する 今週の初めに見た 画像分類と 位置決めアルゴリズムを使い この画像の９つの格子 それぞれに適用する より具体的に 学習に使うラベルの定義方法を 見よう ９つの格子の各セルに ラベル y を付ける ラベル y は ８次元のベクトルだ 前に見た通りだ 最初の出力は Pc で 0 か 1 を取り それは 格子セルの中の ある画像の有無によって決まる それから bx by bh bw は ある画像がある場合の境界箱を示す その格子セルに 物体があればね それから C1 C2 C3 だ もし ３クラスを認識しようとしているのならね 背景クラスは入れてない つまり 歩行者クラス バイククラス そして 背景クラス(訳注: 背景は 車の言い間違いと思われる)で C1 C2 C3 は 歩行者 車 そして バイク クラスとかになる よって この画像には ９つの格子がある よって 各格子セル毎に このようなベクトルを持つ では 左上の格子セルから 始めよう この上にあるやつだ ここには 物体が無い 左上格子セルの ラベル ベクトル y は 0 となるだろう その他は 気にしない この格子セルの 出力ラベル y は 同じになる この格子セルも この格子セルにも 何も無い そこには 対象とする物体は存在しない では この格子セルはどうだ？ 少し詳細を言えば この画像には ２つの物体がある YOLO アルゴリズムは この２つの物体の 中心点を取り それを含む格子セルに 物体を紐付ける よって 左の車は この格子セルに紐付き 右の車は ここに中心点があって この格子セルに紐付く そして 中央の格子セルは 両方の車の一部を含むけど 中央の格子セルには 何の物体も無いとして クラス ラベル y は 物体無しの このベクトルのようになる 最初の要素 Pc は こうなって 後は 気にしない 一方 このセルでは 左の緑で囲ったセルでは 目的ラベル y は 次のようになる 物体がある それから bx by bh bw で 境界箱の位置を指定する それから ええっと もし クラス１が歩行者なら それは 0 だ クラス２が車なら 1 だ クラス３がバイクなら 0 それから 同じく 右のセルには 物体がある やはり あるベクトルになる それは 右の格子セルに対応した目的ラベルだ この９つの各格子セルには 結局 ８次元の 出力ベクトルがあることになる なぜなら 3 x 3 格子で ９つの格子セルがあるからだ 出力の総ボリュームは 3 x 3 x 8 だ つまり 目的とする出力は 3 x 3 x 8 になる なぜなら 3 x 3 格子だからだ この 3 x 3 格子セルの各々に対し ８次元の y ベクトルを持つ 結局 目的とする出力ボリュームは 3 x 3 x 8 だ 例えば この 左上の 1 x 1 x 8 ボリュームは ９つの格子セルの 左上への 出力ベクトルに 対応する それから 3 x 3 の各々に対し この９つのセル それぞれに対し 出力したい ８次元の目的ベクトル ｙ がある その中のいくつかは 気にしなくていい 物体が無いならね 結局 全ての目的とする出力 この画像の出力ラベルは 3 x 3 x 8 ボリュームになる では ニューラルネットワークを訓練するには 入力は 100 x 100 x 3 で これが 入力画像だ それから 普通の ConvNet が来る 畳み込み層 最大プーリング層 等々 最後は 畳み込み層と 最大プーリング層等 を選び 次第に 3 x 3 x 8 出力ボリュームに写像する つまり 行うのは このような入力画像 x から 3 x 3 x 8 の目的ラベルを得ることで 誤差逆伝播を使い このニューラルネットワークを訓練し どのような x からも この形の出力ボリューム y を出すようにすることだ このアルゴリズムの利点は ニューラルネットワークが 次のようにして 正確な境界箱を出力することだ テスト時は 入力画像 x を喰わせて 順伝播させて 出力 y を得る それから ９つの出力のそれぞれにおいて 出力の 3 x 3 位置のそれぞれにおいて 1 か 0 を読み取れる この９つの位置のどこに 物体があるか 分かる そして 物体があれば それが何という物体か 分かる そして その格子セルのどこに 物体の境界箱があるか 分かる 各格子セルが ２つ以上の物体を含まない限り このアルゴリズムは うまく働く 格子セルに 複数の物体を含む場合の問題は 後で扱う 比較的小さな 3 x 3 格子を使うと 実際には もっと細かいのを使うだろうけど 19 x 19 とかをね そうしたら 19 x 19 x 8 になるね それから 格子を 細かくすると 同じ格子セルに 複数の物体が入る可能性が 減る ちょっと思い出して欲しいんだけど 物体を格子セルに紐つける方法を 物体の中心点を見つけて それから その物体を 中心点を含む 格子セルに紐つける よって 各物体は たとえ 複数の格子セルに跨っていても ９つの格子セル内の１つにだけ 紐付く 3 x 3 内の１つに もしくは 19 x 19 格子セルの１つに 19 x 19 格子のアルゴリズムでは ２つの物体の中心点が 同じ格子セルに 紐付く確率は ほんの少しだ ２つのことに気付くでしょ 最初は これは 今週の最初のビデオで話した 画像分類と位置決めアルゴリズムに 良く似ている それは 境界箱の座標を明示的に出力するけどね そして 今回のは ニューラルネットワークが 境界箱を どんなアスペクト比のでも出力できるようにするし もっと正確な座標も出力できるようにする それは スライディング ウィンドウ分類器の ストライドサイズで決まる座標より正確だ ２番目は これは 畳み込み実行であって このアルゴリズムを 3 x 3 格子で９回行うわけではない
19 x 19 格子なら 19^2=361回だ 同じアルゴリズムを 361回 19^2回 実行するのではない そうではなく これは １回の畳み込み処理だ １つの ConvNet を使い 3 x 3 や 19 x 19 格子セル全てに 必要な 全ての計算で その多くを共有する つまり これは とても効率的なアルゴリズムだ 事実 YOLOアルゴリズムの良い点は それは 常に人気のアルゴリズムだけど
それが 畳み込み処理をしているからで 事実 とても速いからだ だから これは リアルタイムの物体検出でも機能する では まとめに入る前に もう１つ 共有しておきたいことがある それは どのようにして この bx by bh bw を符号化するかだ 次のスライドで議論しよう ２つの車がある 3 x 3 格子にしたのだった この右の車を例に取ろう この格子セルには 物体があるので 目的ラベル y は 1 Pc = 1 それから bx by bh bw そして 0 1 0 では どのように境界箱を特定する？ YOLO アルゴリズムでは この四角に相対的に ここの左上の点を (0, 0) とし 右下を (1, 1) にする よって この中心点を特定するには このオレンジの点だ
bx は x は 大体 0.4 に見える 右に向かって 0.4 くらいでしょ それから y は 多分 0.3 それから 境界箱の高さは
(訳注: 幅の言い間違い) この箱の全幅の比で 指定する この赤い箱の幅は 青線の 90%くらいだろう よって bh は 0.9 (訳注: bwの言い間違い)
そして 高さは 格子セルの高さの半分くらいだ よって この場合 bw は 0.5 (訳注: bhの言い間違い) 別の言葉で言えば bx by bh bw は 格子セルとの比で表される そして bx と by は 0 と 1 の間になる 分かるよね？ なぜなら 定義でそう決まるから オレンジの点は それが紐付く格子セルの境界内だからだ もし それが 0 と 1 の間に無い場合は 四角の外にあることになる そうなら 違う格子セルに紐付いたはずだ でも これらは １より大きくなり得る 特に 境界箱が こんな風になる車があれば 境界箱の高さと幅は １よりも大きくなり得る 境界箱を特定する方法は複数ある でも これは とても合理的なやり方だ もし YOLO研究論文を読めば YOLO関連の研究では 他のパラメータを使い 少しだけ良い結果を得ている でも これは ちゃんと機能する合理的な方法だと思うよ ただし より複雑なパラメータ化の方法があり そこでは 0 と 1 の間になることが保証される sigmoid 関数を使っている それに 指数パラメータを使い 非負を保証している 0.9 と 0.5 は ０以上になるべきだから 他にも多くの 先進的パラメータ化があり それで 少しだけ良くなる でも ここで見たやり方で十分なはずだ これが YOLO "You Only Look Once" アルゴリズムだ 次からの数本のビデオでは このアルゴリズムを より良くするための 他のアイデアを見せる その間 もし そうしたければ YOLO論文を見ることができる さっきまで使っていた何枚かのスライドの下に参照があるから でも １つだけ忠告を もし これらの論文を読む場合 YOLO論文は 読むのが難しい方だ 最初にこの論文を読んだ時を 覚えているけど 何が起きているのか 理解するのが大変だった そして 何人かの友人に 聞いて回った とても優れた研究者が 私が理解するのを助けてくれた 彼らでさえ この論文の詳細のいくつかは 理解するのに苦労した だから もし この論文を読むのなら それを理解するのが難しくても問題無い そういうのは 滅多に無いといいんだけど 悲しいことに あまり無いわけではない 上級研究者でさえ 研究論文を読んで 詳細を理解するのに苦しむことがある そして オープンソース コードを見て もしくは 著者に連絡を取って もしくは 何か他の事をして その成果の詳細を把握するんだ でも 望むのなら その研究論文を読むのを止めないよ 難しいけどね とにかく YOLOアルゴリズムの基礎は理解しただろう このアルゴリズムを もっと良くするために いくつか追加していこう