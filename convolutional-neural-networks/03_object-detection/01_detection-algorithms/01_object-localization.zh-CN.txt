大家好 欢迎回来 这周我们学习对象检测 这是计算机视觉中的一个极速发展的领域， 效果比几年前好很多。 为了建立对象检测，你需要先学习对象定位。 我们先来看一下定义。 你已经对图像分类有所了解， 图像分类的这种算法可以，比如，通过这张图片，识别出这是辆车。 这就是图像分类。 在接下来的视频中，要解决的问题是学习建立网络， 即分类并定位。 意味着你不仅仅要识别出，比如这辆车， 并且算法也负责生成一个边框， 或者是在图中车的周围画一个红色矩形。 这就是所谓的分类并定位问题。 在这里，术语“定位“指的是在这个图片中， 找到你检测到的车的位置。 这周后面，你会学到对象检测， 如何检测在一张图片里的多个对象， 你必须能够把它们全部检测出来并且定位它们。 如果你做这个是为自动驾驶应用， 那么你可能需要检测的就不仅仅是其他车辆， 还有其他可能的行人和摩托车，甚至其他的一些对象。 这周后面你会了解到这些。 所以在我们这周所用的术语中，对于图像分类 和分类并定位问题，通常他们只有一个对象。 通常是你要识别一个图片正中央的一个明显的对象。 或者识别并定位。 相比之下，在对象检测问题中，可能会有很多对象。 事实上，可能是来自多个不同的类别的多个对象， 都出现在一张图片中。 你在图像分类中学习的方法将会对 分类并定位也有用处。 然后你学习到的定位的方法， 将会对物体检测有帮助。 所以让我们来了解一下图像分类并定位。 你已经对图像分类有所了解，你可能 在多层卷积网络中输入一张图片， 这会导致我们的卷积网络有一个特征向量， 将特征向量传给一个可能是softmax，输出预测的结果。 所以，如果你要制作一辆自动驾驶的车辆， 那么你的对象类别有以下几项， 有行人，车辆，摩托车，或者一个背景环境。 背景将不属于上面的任何一类。 所以如果没有行人， 没有车，没有摩托，那么你就只有输出背景。 所以，这些是你的分类类别，他们是一个有四个结果的softmax。 这就是标准的图像分类流程。 如果你也想要定位图中的汽车， 为了实现这个，你可以改变你的神经网络， 通过得到更多的输出单位，使得这个神经网络可以输出一个边框。 所以，具体地说，你的神经网络要输出额外4个数字， 我们可以叫他们bx，by，bh和bw。 这四个数字将确定检测对象的边框的参数。 所以在这个系列的视频中，我会使用以下的符号表达方式， 图片左上角，我会标为坐标（0，0), 右下角标为(1，1)。 所以，为了指定图中红色长方形边框， 我们需要指定边框的中点。 所以我们需要点bx，by 和高度，bh (h＝height)， 还有宽度，bw (w＝width)。 所以如果你的训练集不仅仅是包含对象列别标签， 就是神经网络需要预测的内容，而且 也包含4个额外的数字。 给出边界框，你可以用监督式学习来让你的算法 输出不仅仅是类标签，还有4个变量 来告诉你所检测到的对象的边界框。 所以，在这个例子中，理想的bx可能 大约是0.5，因为这个大约是到图片右边的一半。 by可能大约0.7。因为这个大约距离图片下方70%。 bh可能大约0.3因为这个红色矩形的高度 大约占是整个图片的30%。 bw可能大约是0.4，比如因为红色的方框的宽度 大约占整体图片的40%。 所以再形式化一点，根据我们如何定义目标标签 y作为监督氏学习任务。 稍微提示一下，这些是4个类， 神经网络现在可以输出这4个数字，还有类标签， 或者是类标签的概率。 所以，目标标签y的定义如下。 会是个向量 那是否有个对象？ 所以，如果对象是，类1，2或者3，pc会等于1。 并且如果这个是背景类的话，那么 即没有包含任何你需要检测的类别 你可以把pc想成代表 这里包含一个对象的概率。 你努力检测的其中一个类在的概率。 即除背景类之外的其他东西。 其次，如果有一个对象，你想要输出bx, by,bh和bw，你所检测的对象的边界框。 最后，如果确实有一个对象，所以如果pc等于1， 你也想输出c1,c2和 c3,这些告诉我们是类1，类2或者类3。 所以这是一个行人，一辆汽车或者摩托车。 记住在我们解决的问题中， 我们假定你的图片只有一个对象。 即在分类并定位的问题中， 最多有其中的一个对象出现在图片中 让我们来看一些例子 如果这是一个训练集合图像，所以如果这是x,那么y将是 第一个部分的pc将等于1，因为有个对象，bx,by, bh,和bw将标出边界框。 所以你标记的训练集需要在标签上的边界框。 最后这是一辆车，所以是类2。 所以c1将是0因为这不是行人。 c2会是1因为这是车，c3会是0因为这不是摩托车。 所以在c1,c2和c3中，最多有一个会是等于1。 这是针对图中有一个对象的情况。 如果图中没有对象呢？ 如果我们有个训练的例子，x等于这种情况？ 这种情况下，pc会等于0，并且 其余的元素，都会是不关紧要的， 所以我会写个？在剩下的元素。 所以这是一个无关紧要，因为如果图中没有对象， 那么你无需关心神经网络输出的边界框是什么，也不会关心 这3个对象，c1,c2,c3会是什么。 所以给一系列的训练例子，这就是你如何构造x, 输入图片以及y，类别标签，对于 图片中有一个对象和图片中没有对象的情况。 这个的集合定义了你的训练集。 最后，下面介绍你所用来训练神经网络的 损失函数。 所以准确标签是y,神经网络输出的y^。 那么损失什么？ 如果你用的是均方差（squared error） 那么损失会是(y1^-y1)2 +(y2^-y2)2+ ...+(y8^-y8)2. 注意这里的y有8个部分。 所以这些是元素平方差的和。 这就是损失，如果y1=1. 这是确实有对象的情况。 所以y1=pc. 所以，pc=1，那么图片中有一个对象 那么损失值是元素平方差之和。 另外一种情况，如果y1=0, 所以如果pc=0 这种情况下，损失值只是(y1^-y1)2, 因为在第二种情况下，剩余的元素都是无所谓的。 所以你所要关注的就是神经网络 输出的pc有多准确。 所以小总结以下，如果y1=1,这种情况下， 你可以用均方差penalize预测的平方偏差 并且从8个组件的数据输出。 然而如果y1=0,那么从第二个到第八个元素我都不关心。 你所要关心的就是神经网络预测y1 有多准确，也就是y1=pc的准确度。 仅是作为一个侧论，对于那些想要知道更多细节的， 我在这用均方差是为了简化描述。 在现实中，你也可能用log likelihood特征损失 对于c1,c2,c3 softmax输出。 其中之一的元素，你通常可以用均方差或者 一些类似均方差针对边界框的坐标，并且 如果pc你可以用类似逻辑回归损失。 而且即使你只是用均方差，效果可能也是不错的 所以这就是你如何运用神经网络来分类一个对象，也可以用来 定位它。 让神经网络输出一堆数字的想法 可以告诉你图片中的东西位置，被证明是一个非常强大的想法。 在下一个教程，我会和你 分享一些让神经网络输出一系列数字想法的其他应用，几乎相当于回归任务， 强大到也可以应用到计算机视觉的其他地方。 让我们继续下一期教程