1
00:00:00,000 --> 00:00:03,235
如果你看过目标检测的相关文献

2
00:00:03,235 --> 00:00:06,790
你可能看到过一类称为候选区域的思想

3
00:00:06,790 --> 00:00:10,995
这类思想在计算机视觉中也非常流行

4
00:00:10,995 --> 00:00:14,460
我把这个视频作为选修是因为

5
00:00:14,460 --> 00:00:19,275
我使用候选区域这类算法的时候要少一些

6
00:00:19,275 --> 00:00:22,170
但是，这个方法有着众多的研究应用

7
00:00:22,170 --> 00:00:25,675
而且也可能是你在自己的工作中会想到的方法

8
00:00:25,675 --> 00:00:29,640
让我们看看例子。回忆一下移动窗口的思想

9
00:00:29,640 --> 00:00:33,225
你会使用到交火训练并且

10
00:00:33,225 --> 00:00:37,695
在所有不同的窗口中运行它，并运行探测器来检测汽车

11
00:00:37,695 --> 00:00:40,190
行人，或者摩托车

12
00:00:40,190 --> 00:00:42,515
不过，你也可以用卷积的算法来进行检测

13
00:00:42,515 --> 00:00:45,570
但是卷积的一个缺陷是

14
00:00:45,570 --> 00:00:49,410
它交火了许多区域，但是那儿可能并没有清晰的目标

15
00:00:49,410 --> 00:00:52,569
比如，下面的这个矩形框可以说什么目标都没有

16
00:00:52,569 --> 00:00:55,658
对分类来说，确实没有什么有趣的东西

17
00:00:55,658 --> 00:00:58,610
此外，算法可能会也在这个矩形框内运行

18
00:00:58,610 --> 00:01:01,365
你知道的，这个框内也没有啥有趣的东西

19
00:01:01,365 --> 00:01:04,275
所以在 Russ Girshik, Jeff Donahue, Trevor Darell

20
00:01:04,275 --> 00:01:06,548
Jitendra Malik 的这篇论文中

21
00:01:06,548 --> 00:01:07,905
也就是我在这张幻灯片底部引用的这篇论文

22
00:01:07,905 --> 00:01:10,470
里面有他们提出的 R-CNN 算法

23
00:01:10,470 --> 00:01:15,915
它的意思是，伴随区域的卷积网络或者伴随区域的CNN

24
00:01:15,915 --> 00:01:18,330
这个算法所做的是，它会尝试选取

25
00:01:18,330 --> 00:01:22,925
仅仅是少许有意义的区域，用来运行你的整块区域的交火

26
00:01:22,925 --> 00:01:27,505
所以，相较于运行每一个你的移动窗口

27
00:01:27,505 --> 00:01:30,330
你可以用选取少许窗口的方式来代替

28
00:01:30,330 --> 00:01:33,570
通过仅仅在少许的窗口运行整个区域的交火

29
00:01:33,570 --> 00:01:35,205
他们所用的方法

30
00:01:35,205 --> 00:01:40,425
来运行区域候选，是通过运行所谓的分割算法来实现的

31
00:01:40,425 --> 00:01:42,915
运行的输出结果如右图所示

32
00:01:42,915 --> 00:01:46,170
为了理解哪些部分可能是目标

33
00:01:46,170 --> 00:01:50,306
所以，比如说，分割算法在这里找到了一个一团区域

34
00:01:50,306 --> 00:01:53,625
你可能会选取这个对象，并且说

35
00:01:53,625 --> 00:01:55,680
“让我们在这团东西上运行交火”

36
00:01:55,680 --> 00:01:58,730
这就好像这个小绿色区域找到的一团东西一样

37
00:01:58,730 --> 00:02:00,960
同样你可能会在这个矩形区域上运行交火

38
00:02:00,960 --> 00:02:04,650
看看是否有有意思的目标在这儿

39
00:02:04,650 --> 00:02:06,000
在这种情况下

40
00:02:06,000 --> 00:02:08,830
如果你在这个蓝色区域运行交火

41
00:02:08,830 --> 00:02:10,793
你可能会找到行人

42
00:02:10,793 --> 00:02:13,575
如果你在这块浅蓝绿色的区域运行交火

43
00:02:13,575 --> 00:02:16,120
你可能会找到一辆车，也能可不是汽车

44
00:02:16,120 --> 00:02:17,535
我不太确定。所以这里面的细节是

45
00:02:17,535 --> 00:02:20,080
这个所谓的分割算法

46
00:02:20,080 --> 00:02:25,410
你所需要做的是，找到大约2000个这样的颜色区域

47
00:02:25,410 --> 00:02:31,544
在他们上面放置边界框，并在这些颜色区域运行交火，求值

48
00:02:31,544 --> 00:02:34,380
这个方法进行ConvNet交火所涉及的

49
00:02:34,380 --> 00:02:37,529
位置的数目要少很多

50
00:02:37,529 --> 00:02:40,935
相较于在整个图像的每一个位置都运行交火

51
00:02:40,935 --> 00:02:44,172
有一个特殊的情况，如果你要在整个区域运行

52
00:02:44,172 --> 00:02:48,055
不仅仅是矩形区域

53
00:02:48,055 --> 00:02:51,870
还有高瘦区域，以寻找行人

54
00:02:51,870 --> 00:02:57,915
在宽广区域运行以找到汽车，
以及在其他各种尺寸的区域运行

55
00:02:57,915 --> 00:03:02,170
所以，这就是 R-CNN 或者叫伴随区域的CNN

56
00:03:02,170 --> 00:03:04,380
一个 CNN 区域特征的想法

57
00:03:04,380 --> 00:03:08,305
现在，事实证明，R-CNN 算法还是非常慢的

58
00:03:08,305 --> 00:03:13,320
所以，有一系列的工作来探索如何加速这个算法

59
00:03:13,320 --> 00:03:16,920
基础的 R-CNN 算法结合某种算法实现的候选区域

60
00:03:16,920 --> 00:03:20,933
之后同时在候选区域一起运行交火

61
00:03:20,933 --> 00:03:22,380
对每一个区域

62
00:03:22,380 --> 00:03:23,844
会输出这个标签

63
00:03:23,844 --> 00:03:25,960
是一辆车吗？还是一个行人？

64
00:03:25,960 --> 00:03:27,580
这里有一个摩托车吗？

65
00:03:27,580 --> 00:03:30,090
同时输出一个边界框

66
00:03:30,090 --> 00:03:36,510
这样如果区域内真有目标，你就能得到一个准确的边界框

67
00:03:36,510 --> 00:03:37,645
明确一下

68
00:03:37,645 --> 00:03:42,075
这个 R-CNN 算法并不仅仅确信给定的边界框

69
00:03:42,075 --> 00:03:44,540
它还会输出一个边界框

70
00:03:44,540 --> 00:03:46,620
b_x, b_y, b_h, b_w

71
00:03:46,620 --> 00:03:51,045
以得到一个更为准确的边界框，并且无关于

72
00:03:51,045 --> 00:03:56,070
分割算法给它的颜色区域周围是什么

73
00:03:56,070 --> 00:03:58,705
所以，它可以得到一个非常准确的边界框

74
00:03:58,705 --> 00:04:03,425
现在，R-CNN 的一个缺陷是，它真的非常慢

75
00:04:03,425 --> 00:04:04,470
所以，这些年

76
00:04:04,470 --> 00:04:08,295
R-CNN 算法有一些改进

77
00:04:08,295 --> 00:04:12,180
Russ Girshik 提出了一个快速 R-CNN 算法

78
00:04:12,180 --> 00:04:15,150
这个算法本质上是一个 R-CNN 算法，但是会

79
00:04:15,150 --> 00:04:18,290
伴随一个应用于移动窗口的卷积

80
00:04:18,290 --> 00:04:23,745
所以原始的应用实际上会同时对区域进行分类

81
00:04:23,745 --> 00:04:28,955
但是快速R-CNN 是在移动窗口中应用卷积

82
00:04:28,955 --> 00:04:35,550
这和本周的第四个视频内容中的想法很类似

83
00:04:35,550 --> 00:04:39,850
这个可以加快一点 R-CNN 的速度

84
00:04:40,390 --> 00:04:46,680
事实证明，快速 R-CNN 算法的一个问题是

85
00:04:46,680 --> 00:04:53,270
候选区域的聚类步骤还是很慢，所以另一个团队

86
00:04:53,270 --> 00:04:56,025
Shaoqing Ren, Kaiming He, Ross Girshick, 和 Jian Son,

87
00:04:56,025 --> 00:04:59,043
提出了一个更快速 R-CNN 算法

88
00:04:59,043 --> 00:05:02,520
使用了卷积神经网络，而不是

89
00:05:02,520 --> 00:05:07,550
那个更为传统的分割算法，用于在这些区域内提出候选色团

90
00:05:07,550 --> 00:05:12,487
并且它的运行速度比快速 R-CNN 算法要快一些

91
00:05:12,487 --> 00:05:15,810
我认为，虽然R-CNN 的速度被进一步提高

92
00:05:15,810 --> 00:05:21,730
但大部分的应用中通常还是会比 YOLO 算法慢一些

93
00:05:21,730 --> 00:05:27,090
总结一下，候选区域的思想在计算机视觉中非常流行

94
00:05:27,090 --> 00:05:32,995
我希望你了解这些想法，是因为你可以看到其他人在使用

95
00:05:32,995 --> 00:05:35,595
对于我自己，这是我的个人观点

96
00:05:35,595 --> 00:05:38,893
并不代表整个计算机视觉的研究群体

97
00:05:38,893 --> 00:05:44,100
我认为，候选区域是一个有趣的想法，而且不需要两个步骤

98
00:05:44,100 --> 00:05:45,630
首先，候选区域，然后交火

99
00:05:45,630 --> 00:05:49,800
在同一时间做更多的事情

100
00:05:49,800 --> 00:05:53,085
类似于 YOLO (You Only Look Once) 算法

101
00:05:53,085 --> 00:05:56,885
这对于我来说，是一个长期内很有希望的研究方向

102
00:05:56,885 --> 00:05:58,995
但这只是我个人的观点

103
00:05:58,995 --> 00:06:01,865
并且不是整个计算机视觉研究群体的观点

104
00:06:01,865 --> 00:06:04,868
所以你大可自由理解我的话

105
00:06:04,868 --> 00:06:07,550
但是我认为 R-CNN 想法

106
00:06:07,550 --> 00:06:10,438
你可能会遇到其他人在用它

107
00:06:10,438 --> 00:06:14,460
所以学习这个同样可以让你更好理解别人的算法

108
00:06:14,460 --> 00:06:21,565
所以，我们现在要结束这周的目标检测材料了

109
00:06:21,565 --> 00:06:25,133
我希望你在做本周的练习题中得到快乐

110
00:06:25,133 --> 00:06:27,000
我也很期待下周见到你
GTC字幕组翻译