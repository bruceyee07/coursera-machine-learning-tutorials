1
00:00:00,000 --> 00:00:03,900
이미 대부분의 객체 감지 구성 요소를 보았습니다.

2
00:00:03,900 --> 00:00:06,690
이 강의에서는 모든 구성 요소를 결합하여

3
00:00:06,690 --> 00:00:10,850
YOLO 객체 감지 알고리즘을 구성 해 보겠습니다.

4
00:00:10,850 --> 00:00:14,130
먼저, 트레이닝 세트를 구성하는 방법을 살펴 보겠습니다.

5
00:00:14,130 --> 00:00:16,380
보행자, 자동차 및 오토바이의 세 가지 객체를 탐지하는

6
00:00:16,380 --> 00:00:19,425
알고리즘을 학습시킨다고 가정합니다

7
00:00:19,425 --> 00:00:23,262
그리고 명시적으로 전체 배경 클래스를 가져야 하므로

8
00:00:23,262 --> 00:00:25,390
여기에 클래스 레이블 만 넣으면 됩니다.

9
00:00:25,390 --> 00:00:28,305
두 개의 앵커 박스를 사용하는 경우

10
00:00:28,305 --> 00:00:33,495
아웃풋 y는 3 x 3이 되겠죠, 이는 3 x 3 그리드 셀을 사용하기 때문입니다.

11
00:00:33,495 --> 00:00:36,225
그리고 여기 x2, 이것은 앵커의 개수입니다.

12
00:00:36,225 --> 00:00:39,880
x8, 이는 여기 있는 이 디멘션을 가리키는 것입니다.

13
00:00:39,880 --> 00:00:45,650
8은 사실 5 인데요, 여기에 클래스의 숫자 3을 더한 것입니다.

14
00:00:45,650 --> 00:00:49,533
Pc와 여기 바운딩 박스를 더하면

15
00:00:49,533 --> 00:00:53,505
여기 5개 되는 것이고, 그리고 나서 C1, C2, C3.

16
00:00:53,505 --> 00:00:56,340
이것의 디멘션은 클래스의 개수와 동일합니다.

17
00:00:56,340 --> 00:00:59,535
3 x 3 x 2 x 8 이든 3 x 3 x 16

18
00:00:59,535 --> 00:01:03,310
이 둘 중 하나를 볼 수 있는 것입니다.

19
00:01:03,310 --> 00:01:05,415
따라서 트레이닝 세트를 구성하기 위해서는,

20
00:01:05,415 --> 00:01:11,160
이 9개 그리드 셀 각각을 살펴보고 적합한 타겟 벡터 Y를 만들면 됩니다.

21
00:01:11,160 --> 00:01:13,050
이 첫 번째 그리드 셀을 가지고 와서,

22
00:01:13,050 --> 00:01:16,470
이 그리드 셀에서는 감지할만한 것이 없군요.

23
00:01:16,470 --> 00:01:19,410
보행자, 자동차, 오토바이, 이 세 클래스 중에 그 어느 것도

24
00:01:19,410 --> 00:01:22,680
왼쪽 상단 그리드에는 보이지 않습니다.

25
00:01:22,680 --> 00:01:27,870
그래서 이 그리드셀에 상응하는 타겟은 이것과 동일할 것입니다.

26
00:01:27,870 --> 00:01:31,276
첫 번째 앵커박스에 있는 Pc는 0인데요,

27
00:01:31,276 --> 00:01:34,215
첫 번째 앵커박스와 관련된 것이 아무것도 없기 때문입니다.

28
00:01:34,215 --> 00:01:37,830
그리고 또한 두 번째 앵커박스도 0 이고,

29
00:01:37,830 --> 00:01:42,355
이런 식으로 되어 여기 이 다른 값들도 신경 쓸 필요 없는 것들이 되죠.

30
00:01:42,355 --> 00:01:45,227
대부분의 그리드 셀들은 이 안에 아무것도 없습니다.

31
00:01:45,227 --> 00:01:47,790
하지만 이 쪽에 있는 이 박스는

32
00:01:47,790 --> 00:01:53,550
이 타겟 벡터 Y를 가지고 있습니다.

33
00:01:53,550 --> 00:01:58,680
여러분의 트레이닝세트가 이 자동차에 대해서 바운딩 박스를 가진다고 추측해볼 수 있습니다.

34
00:01:58,680 --> 00:02:01,560
높이보다는 옆으로 좀 더 넓게 되어있군요.

35
00:02:01,560 --> 00:02:04,005
그리고 만약 여러분의 앵커박스가 있는데,

36
00:02:04,005 --> 00:02:05,475
이것이 앵커박스 1이고,

37
00:02:05,475 --> 00:02:07,191
이건 앵커박스 2라면,

38
00:02:07,191 --> 00:02:12,475
이 빨간 박스는 앵커박스 2를 가진 약간만 더 높은 IoU를 가지고 있어서,

39
00:02:12,475 --> 00:02:17,320
이 자동차는 이 벡터의 아래쪽 부분과 연관되는 것입니다.

40
00:02:17,320 --> 00:02:22,435
앵커박스 1과 연관된 Pc는 0이고,

41
00:02:22,435 --> 00:02:24,965
이 모든 요소들을 전부 신경 쓸 필요 없는 것들이므로,

42
00:02:24,965 --> 00:02:28,005
이 Pc 는 0 이 됩니다.

43
00:02:28,005 --> 00:02:33,390
그리고 빨간색 바운딩 박스의 위치를 구체화시키기 위해서는 이것들을 사용해야 하는 것이죠.

44
00:02:33,390 --> 00:02:38,820
그리고 이 옳은 객체가 클래스 2라고 구체화 시키십시오.

45
00:02:38,820 --> 00:02:41,865
이것이 자동차가 맞습니다.

46
00:02:41,865 --> 00:02:44,010
따라서 이렇게 진행하시면,

47
00:02:44,010 --> 00:02:47,485
각각의 9 그리드 위치, 3 x 3 그리드 위치에서

48
00:02:47,485 --> 00:02:50,085
여러분은 이런 벡터를 얻게 될 것이고,

49
00:02:50,085 --> 00:02:52,299
16개차원의 벡터를 얻게 될 것입니다.

50
00:02:52,299 --> 00:02:59,375
그러므로, 최종 아웃풋 볼륨은 3 x 3 x 16이 될 것입니다.

51
00:02:59,375 --> 00:03:04,530
아, 그리고 평소와 같이 슬라이드의 단순화를 위해, 3 x 3 그리드를 사용했습니다.

52
00:03:04,530 --> 00:03:09,540
실제로는 19 x 19 x 6에 가까울 수도 있습니다

53
00:03:09,540 --> 00:03:12,265
실제로 앵커 박스를 더 많이 사용하면

54
00:03:12,265 --> 00:03:17,363
19 x 19 x 5 x 8 이 될 텐데요, 5 x 8은 40이므로

55
00:03:17,363 --> 00:03:20,405
19 x 19 x 40이됩니다.

56
00:03:20,405 --> 00:03:23,475
5 개의 앵커 박스를 사용하면

57
00:03:23,475 --> 00:03:30,080
이것이 바로 학습이죠, 이제 100 x 100 x 3 이미지를 인풋해서

58
00:03:30,080 --> 00:03:32,395
컨볼네트를 학습시키십시오.

59
00:03:32,395 --> 00:03:39,565
그러면 컨볼네트는 마침내 예제와 같이 3 x 3 x 16 혹은 3 x 2 x 8 의

60
00:03:39,565 --> 00:03:43,204
아웃풋 볼륨을 출력하게 될 것입니다.

61
00:03:43,204 --> 00:03:47,505
알고리즘이 예측을 어떻게 내릴 수 있는지 살펴보십시오.

62
00:03:47,505 --> 00:03:53,445
이미지가 주어지면 신경망은 이것을 3 x 3 x x2x 8 크기로 출력합니다

63
00:03:53,445 --> 00:03:57,690
9 개의 그리드 셀 각각에 대해 이와 같은 벡터를 얻을 수 있죠.

64
00:03:57,690 --> 00:04:00,795
따라서 왼쪽 위에 있는 그리드 셀의 경우

65
00:04:00,795 --> 00:04:02,925
여기에 객체가 없으면

66
00:04:02,925 --> 00:04:06,150
여기와 여기에서는 0을 출력하고

67
00:04:06,150 --> 00:04:08,990
여기서는다른 값을 출력할 것입니다.

68
00:04:08,990 --> 00:04:11,080
신경망은 물음표를 출력 할 수 없으며

69
00:04:11,080 --> 00:04:12,540
신경 쓰지 않아도 된다는 표시를 하지 못합니다.

70
00:04:12,540 --> 00:04:15,205
그러니 제가 이 나머지에 숫자를 넣도록 하겠습니다.

71
00:04:15,205 --> 00:04:17,400
이 숫자들은 기본적으로 무시되 버릴 것입니다.

72
00:04:17,400 --> 00:04:20,580
신경망이 여기에 객체가 없다고 알려주고 있으니까요.

73
00:04:20,580 --> 00:04:23,910
아웃풋이 바운딩박스인지 아니면 자동차인지 그 여부는 중요하지 않습니다.

74
00:04:23,910 --> 00:04:28,170
기본적으로 숫자의 세트, 더 많거나 적은 노이즈만 있습니다.

75
00:04:28,170 --> 00:04:32,370
대조적으로, 이 상자에 대해서는,

76
00:04:32,370 --> 00:04:37,308
왼쪽 하단의 상자에 대한 Y 값은

77
00:04:37,308 --> 00:04:40,850
바운딩 상자 1에 대해 0 일 것입니다.

78
00:04:40,850 --> 00:04:43,650
그리고 나서 노이즈처럼 숫자들을 쓰고,

79
00:04:43,650 --> 00:04:47,880
아마도, 자동차에 대해 정확한 바운딩 박스를 구체화시키는

80
00:04:47,880 --> 00:04:52,980
숫자 세트를 출력할 수 있을 것입니다.

81
00:04:52,980 --> 00:04:56,970
이것이 바로 신경망이 예측을 하는 방법입니다.

82
00:04:56,970 --> 00:05:00,675
마지막으로 non-max 억제를 통해 이를 실행합니다.

83
00:05:00,675 --> 00:05:02,240
이것을 좀 더 재미있게 하기 위해서,

84
00:05:02,240 --> 00:05:04,740
새로운 테스트 세트 이미지를 살펴 보겠습니다.

85
00:05:04,740 --> 00:05:08,280
다음은 non-max 억제를 실행하는 방법입니다.

86
00:05:08,280 --> 00:05:10,680
두 개의 앵커 상자를 사용하는 경우

87
00:05:10,680 --> 00:05:12,690
각 그리드가 아닌 셀에 대해

88
00:05:12,690 --> 00:05:15,445
두 개의 예측된 바운딩 박스를 얻으십시오.

89
00:05:15,445 --> 00:05:17,835
그 중 일부는 매우 낮은 확률

90
00:05:17,835 --> 00:05:20,760
매우 낮은 Pc를 갖지만

91
00:05:20,760 --> 00:05:24,235
9 개의 그리드 셀에 각각에 대해 2 개의 예상 바운딩박스를 여전히 얻으면 됩니다.

92
00:05:24,235 --> 00:05:27,540
이것들이 여러분이 얻게 될 바운딩박스입니다.

93
00:05:27,540 --> 00:05:30,060
그리고 바운딩박스 중 일부는

94
00:05:30,060 --> 00:05:34,645
그리드 셀의 높이와 너비 바깥쪽으로 나갈 수 있습니다

95
00:05:34,645 --> 00:05:38,725
그런 다음 낮은 확률 예측을 제거합니다.

96
00:05:38,725 --> 00:05:41,635
그래서 신경망이 객체는 아마도 거기에 존재하지 않을 거라고

97
00:05:41,635 --> 00:05:44,025
말하는 것조차 없애 버려야합니다

98
00:05:44,025 --> 00:05:45,855
그러니 이건 제거합시다.

99
00:05:45,855 --> 00:05:49,868
그리고 마침내 당신이 감지하고 싶은 세 가지 클래스가 있고,

100
00:05:49,868 --> 00:05:53,665
보행자, 자동차 및 오토바이를 감지하고 싶으면

101
00:05:53,665 --> 00:05:56,655
세 클래스 각각에 대해,

102
00:05:56,655 --> 00:05:59,760
그 클래스에서 올 것으로 예측되었던 객체들에 대해

103
00:05:59,760 --> 00:06:03,010
non-max 억제를 독립적으로 실행하십시오.

104
00:06:03,010 --> 00:06:07,620
보행자 클래스의 예측에 대해 non-max 억제를 사용하고

105
00:06:07,620 --> 00:06:10,080
자동차 클래스에 대해 non-max 억제를 실행하고,

106
00:06:10,080 --> 00:06:13,100
motorcycle 클래스에 대해 non-max 억제를 실행합니다.

107
00:06:13,100 --> 00:06:17,865
기본적으로 세 번 실행하여 최종 예측을 생성하십시오.

108
00:06:17,865 --> 00:06:20,970
그리고 이 아웃풋은 이 이미지에 있는

109
00:06:20,970 --> 00:06:25,465
모든 자동차와 모든 보행자를 감지했을 것입니다.

110
00:06:25,465 --> 00:06:29,170
이것이 YOLO 객체 탐지 ??알고리즘을위한 것이고,

111
00:06:29,170 --> 00:06:33,170
실제로 가장 효과적인 객체 감지 알고리즘 중 하나입니다.

112
00:06:33,170 --> 00:06:36,560
이는 또한 객체 감지와 관련된 전체 컴퓨터 비전 문헌을 통틀어

113
00:06:36,560 --> 00:06:41,275
가장 많은 훌륭한 아이디어 들를 아우릅니다.

114
00:06:41,275 --> 00:06:46,056
그리고 이번 주에 실시되는 문제 연습에서

115
00:06:46,056 --> 00:06:47,840
이것의 많은 구성 요소 실행을 실습 할 수 있는 기회를 갖게 됩니다.

116
00:06:47,840 --> 00:06:51,520
이번 주 연습문제를 즐기시기 바랍니다.

117
00:06:51,520 --> 00:06:54,120
이 강의 뒤에 선택강의가 하나 있는데요

118
00:06:54,120 --> 00:06:57,010
봐도 좋고 보지 않아도 되는 것이지만

119
00:06:57,010 --> 00:07:01,000
어느 쪽을 선택하시던 다음 강의에서는 꼭 만나 뵙기를 바랍니다.