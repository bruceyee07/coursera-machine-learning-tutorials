1
00:00:00,000 --> 00:00:01,380
前回の動画では

2
00:00:01,380 --> 00:00:06,300
スライディング ウィンドウの畳み込み実装を学んだ

3
00:00:06,300 --> 00:00:08,780
それは より効率的に計算することだった

4
00:00:08,780 --> 00:00:14,130
しかし 非常に正確な境界箱を出力するわけではない無いという問題が残っている

5
00:00:14,130 --> 00:00:16,710
このビデオでは どのように

6
00:00:16,710 --> 00:00:19,520
境界箱を もっと正確にできるかを見ていく

7
00:00:19,520 --> 00:00:21,495
スライディング ウィンドウでは

8
00:00:21,495 --> 00:00:26,190
予め特定された複数の場所で 一斉射撃を行う

9
00:00:26,190 --> 00:00:27,825
この例では

10
00:00:27,825 --> 00:00:32,636
車の位置に 完全に適合する箱が無い

11
00:00:32,636 --> 00:00:35,900
おそらく この箱が一番合う

12
00:00:35,900 --> 00:00:38,465
そして また これは 正確に描かれたように見えるが

13
00:00:38,465 --> 00:00:41,585
完璧な境界箱は 正確な正方形ではない

14
00:00:41,585 --> 00:00:48,750
それは 少し幅広の四角で 少し水平アスペクト比が高い

15
00:00:48,750 --> 00:00:53,975
では このアルゴリズムに 正確な境界箱を出力させる方法はあるのか？

16
00:00:53,975 --> 00:00:59,275
このような より正確な境界箱を出力するいい方法は YOLO アルゴリズムだ

17
00:00:59,275 --> 00:01:03,225
YOLO は ”You Only Look Once" の略だ

18
00:01:03,225 --> 00:01:06,195
このアルゴリズムは Joseph Redmon,

19
00:01:06,195 --> 00:01:07,975
Santosh Divvala, Ross Girshick そして Ali Farhadi によるものだ

20
00:01:07,975 --> 00:01:10,735
それは こういう風にやる

21
00:01:10,735 --> 00:01:14,230
入力画像が 100 x 100 だとする

22
00:01:14,230 --> 00:01:17,175
この画像を格子にする

23
00:01:17,175 --> 00:01:19,425
描きやすくするため

24
00:01:19,425 --> 00:01:21,780
3 x 3 格子を使うけど

25
00:01:21,780 --> 00:01:23,640
実際の実装では

26
00:01:23,640 --> 00:01:24,840
もっと 細かいのを使う

27
00:01:24,840 --> 00:01:27,880
19 x 19 格子とかをね

28
00:01:27,880 --> 00:01:30,660
基本的なアイデアは

29
00:01:30,660 --> 00:01:36,345
前に見た 画像分類と位置決めアルゴリズムを使い

30
00:01:36,345 --> 00:01:40,165
この９つの格子に適用する

31
00:01:40,165 --> 00:01:47,910
今週の初めに見た

32
00:01:47,910 --> 00:01:52,170
画像分類と 位置決めアルゴリズムを使い

33
00:01:52,170 --> 00:01:58,440
この画像の９つの格子 それぞれに適用する

34
00:01:58,440 --> 00:01:59,851
より具体的に

35
00:01:59,851 --> 00:02:05,171
学習に使うラベルの定義方法を 見よう

36
00:02:05,171 --> 00:02:08,070
９つの格子の各セルに ラベル y を付ける

37
00:02:08,070 --> 00:02:14,561
ラベル y は ８次元のベクトルだ

38
00:02:14,561 --> 00:02:16,470
前に見た通りだ

39
00:02:16,470 --> 00:02:19,610
最初の出力は Pc で 0 か 1 を取り

40
00:02:19,610 --> 00:02:24,170
それは 格子セルの中の ある画像の有無によって決まる それから

41
00:02:24,170 --> 00:02:30,800
bx by bh bw は ある画像がある場合の境界箱を示す

42
00:02:30,800 --> 00:02:33,348
その格子セルに 物体があればね

43
00:02:33,348 --> 00:02:36,320
それから C1 C2 C3 だ

44
00:02:36,320 --> 00:02:40,935
もし ３クラスを認識しようとしているのならね 背景クラスは入れてない

45
00:02:40,935 --> 00:02:43,120
つまり 歩行者クラス

46
00:02:43,120 --> 00:02:45,110
バイククラス そして 背景クラス(訳注: 背景は 車の言い間違いと思われる)で

47
00:02:45,110 --> 00:02:47,720
C1 C2 C3 は 歩行者

48
00:02:47,720 --> 00:02:50,570
車 そして バイク クラスとかになる

49
00:02:50,570 --> 00:02:52,505
よって この画像には

50
00:02:52,505 --> 00:02:53,870
９つの格子がある

51
00:02:53,870 --> 00:02:59,105
よって 各格子セル毎に このようなベクトルを持つ

52
00:02:59,105 --> 00:03:02,316
では 左上の格子セルから 始めよう

53
00:03:02,316 --> 00:03:03,955
この上にあるやつだ

54
00:03:03,955 --> 00:03:06,115
ここには 物体が無い

55
00:03:06,115 --> 00:03:11,960
左上格子セルの ラベル ベクトル y は 0 となるだろう

56
00:03:11,960 --> 00:03:16,655
その他は 気にしない

57
00:03:16,655 --> 00:03:20,707
この格子セルの 出力ラベル y は 同じになる

58
00:03:20,707 --> 00:03:24,640
この格子セルも この格子セルにも 何も無い

59
00:03:24,640 --> 00:03:27,845
そこには 対象とする物体は存在しない

60
00:03:27,845 --> 00:03:32,435
では この格子セルはどうだ？

61
00:03:32,435 --> 00:03:34,385
少し詳細を言えば

62
00:03:34,385 --> 00:03:36,355
この画像には ２つの物体がある

63
00:03:36,355 --> 00:03:40,270
YOLO アルゴリズムは この２つの物体の

64
00:03:40,270 --> 00:03:45,690
中心点を取り それを含む格子セルに 物体を紐付ける

65
00:03:45,690 --> 00:03:49,900
よって 左の車は この格子セルに紐付き

66
00:03:49,900 --> 00:03:51,445
右の車は

67
00:03:51,445 --> 00:03:53,140
ここに中心点があって

68
00:03:53,140 --> 00:03:57,265
この格子セルに紐付く

69
00:03:57,265 --> 00:04:02,510
そして 中央の格子セルは 両方の車の一部を含むけど

70
00:04:02,510 --> 00:04:06,175
中央の格子セルには 何の物体も無いとして

71
00:04:06,175 --> 00:04:11,560
クラス ラベル y は 物体無しの このベクトルのようになる

72
00:04:11,560 --> 00:04:13,450
最初の要素 Pc は こうなって

73
00:04:13,450 --> 00:04:15,000
後は 気にしない

74
00:04:15,000 --> 00:04:17,091
一方 このセルでは

75
00:04:17,091 --> 00:04:21,005
左の緑で囲ったセルでは

76
00:04:21,005 --> 00:04:23,765
目的ラベル y は 次のようになる

77
00:04:23,765 --> 00:04:25,085
物体がある

78
00:04:25,085 --> 00:04:26,770
それから bx by bh bw で

79
00:04:26,770 --> 00:04:32,830
境界箱の位置を指定する

80
00:04:32,830 --> 00:04:34,870
それから ええっと

81
00:04:34,870 --> 00:04:38,680
もし クラス１が歩行者なら それは 0 だ

82
00:04:38,680 --> 00:04:40,420
クラス２が車なら 1 だ

83
00:04:40,420 --> 00:04:43,960
クラス３がバイクなら 0

84
00:04:43,960 --> 00:04:45,900
それから 同じく

85
00:04:45,900 --> 00:04:48,415
右のセルには 物体がある

86
00:04:48,415 --> 00:04:52,690
やはり あるベクトルになる

87
00:04:52,690 --> 00:04:58,325
それは 右の格子セルに対応した目的ラベルだ

88
00:04:58,325 --> 00:05:00,715
この９つの各格子セルには

89
00:05:00,715 --> 00:05:04,815
結局 ８次元の 出力ベクトルがあることになる

90
00:05:04,815 --> 00:05:08,415
なぜなら 3 x 3 格子で

91
00:05:08,415 --> 00:05:09,863
９つの格子セルがあるからだ

92
00:05:09,863 --> 00:05:17,435
出力の総ボリュームは 3 x 3 x 8 だ

93
00:05:17,435 --> 00:05:24,760
つまり 目的とする出力は 3 x 3 x 8 になる なぜなら 3 x 3 格子だからだ

94
00:05:24,760 --> 00:05:28,045
この 3 x 3 格子セルの各々に対し

95
00:05:28,045 --> 00:05:32,790
８次元の y ベクトルを持つ

96
00:05:32,790 --> 00:05:36,250
結局 目的とする出力ボリュームは 3 x 3 x 8 だ

97
00:05:36,250 --> 00:05:41,245
例えば この 左上の 1 x 1 x 8 ボリュームは

98
00:05:41,245 --> 00:05:42,970
９つの格子セルの

99
00:05:42,970 --> 00:05:47,770
左上への 出力ベクトルに 対応する

100
00:05:47,770 --> 00:05:50,710
それから 3 x 3 の各々に対し

101
00:05:50,710 --> 00:05:52,345
この９つのセル それぞれに対し

102
00:05:52,345 --> 00:05:58,180
出力したい ８次元の目的ベクトル ｙ がある

103
00:05:58,180 --> 00:05:59,610
その中のいくつかは 気にしなくていい

104
00:05:59,610 --> 00:06:01,010
物体が無いならね

105
00:06:01,010 --> 00:06:03,360
結局 全ての目的とする出力

106
00:06:03,360 --> 00:06:08,635
この画像の出力ラベルは 3 x 3 x 8 ボリュームになる

107
00:06:08,635 --> 00:06:11,245
では ニューラルネットワークを訓練するには

108
00:06:11,245 --> 00:06:17,475
入力は 100 x 100 x 3 で

109
00:06:17,475 --> 00:06:19,015
これが 入力画像だ

110
00:06:19,015 --> 00:06:22,795
それから 普通の ConvNet が来る

111
00:06:22,795 --> 00:06:27,690
畳み込み層 最大プーリング層 等々

112
00:06:27,690 --> 00:06:28,870
最後は

113
00:06:28,870 --> 00:06:34,440
畳み込み層と 最大プーリング層等 を選び

114
00:06:34,440 --> 00:06:42,320
次第に 3 x 3 x 8 出力ボリュームに写像する

115
00:06:42,320 --> 00:06:46,470
つまり 行うのは このような入力画像 x から

116
00:06:46,470 --> 00:06:50,125
3 x 3 x 8 の目的ラベルを得ることで

117
00:06:50,125 --> 00:06:54,160
誤差逆伝播を使い このニューラルネットワークを訓練し

118
00:06:54,160 --> 00:06:58,565
どのような x からも この形の出力ボリューム y を出すようにすることだ

119
00:06:58,565 --> 00:07:01,360
このアルゴリズムの利点は

120
00:07:01,360 --> 00:07:07,228
ニューラルネットワークが 次のようにして 正確な境界箱を出力することだ

121
00:07:07,228 --> 00:07:08,320
テスト時は

122
00:07:08,320 --> 00:07:10,930
入力画像 x を喰わせて

123
00:07:10,930 --> 00:07:14,255
順伝播させて 出力 y を得る

124
00:07:14,255 --> 00:07:16,735
それから ９つの出力のそれぞれにおいて

125
00:07:16,735 --> 00:07:19,480
出力の 3 x 3 位置のそれぞれにおいて

126
00:07:19,480 --> 00:07:22,810
1 か 0 を読み取れる

127
00:07:22,810 --> 00:07:27,153
この９つの位置のどこに 物体があるか 分かる

128
00:07:27,153 --> 00:07:29,590
そして 物体があれば それが何という物体か 分かる

129
00:07:29,590 --> 00:07:36,065
そして その格子セルのどこに 物体の境界箱があるか 分かる

130
00:07:36,065 --> 00:07:39,118
各格子セルが ２つ以上の物体を含まない限り

131
00:07:39,118 --> 00:07:41,810
このアルゴリズムは うまく働く

132
00:07:41,810 --> 00:07:43,900
格子セルに 複数の物体を含む場合の問題は

133
00:07:43,900 --> 00:07:46,600
後で扱う

134
00:07:46,600 --> 00:07:51,985
比較的小さな 3 x 3 格子を使うと

135
00:07:51,985 --> 00:07:54,470
実際には もっと細かいのを使うだろうけど

136
00:07:54,470 --> 00:07:56,160
19 x 19 とかをね

137
00:07:56,160 --> 00:07:58,900
そうしたら 19 x 19 x 8 になるね

138
00:07:58,900 --> 00:08:02,315
それから 格子を 細かくすると

139
00:08:02,315 --> 00:08:07,180
同じ格子セルに 複数の物体が入る可能性が 減る

140
00:08:07,180 --> 00:08:08,800
ちょっと思い出して欲しいんだけど

141
00:08:08,800 --> 00:08:11,590
物体を格子セルに紐つける方法を

142
00:08:11,590 --> 00:08:14,290
物体の中心点を見つけて それから

143
00:08:14,290 --> 00:08:19,930
その物体を 中心点を含む 格子セルに紐つける

144
00:08:19,930 --> 00:08:23,926
よって 各物体は たとえ 複数の格子セルに跨っていても

145
00:08:23,926 --> 00:08:27,410
９つの格子セル内の１つにだけ 紐付く

146
00:08:27,410 --> 00:08:29,018
3 x 3 内の１つに

147
00:08:29,018 --> 00:08:31,565
もしくは 19 x 19 格子セルの１つに

148
00:08:31,565 --> 00:08:33,584
19 x 19 格子のアルゴリズムでは

149
00:08:33,584 --> 00:08:36,715
２つの物体の中心点が

150
00:08:36,715 --> 00:08:41,445
同じ格子セルに 紐付く確率は ほんの少しだ

151
00:08:41,445 --> 00:08:44,043
２つのことに気付くでしょ 最初は

152
00:08:44,043 --> 00:08:46,930
これは 今週の最初のビデオで話した

153
00:08:46,930 --> 00:08:51,530
画像分類と位置決めアルゴリズムに 良く似ている

154
00:08:51,530 --> 00:08:55,380
それは 境界箱の座標を明示的に出力するけどね

155
00:08:55,380 --> 00:08:58,235
そして 今回のは ニューラルネットワークが 境界箱を

156
00:08:58,235 --> 00:09:02,440
どんなアスペクト比のでも出力できるようにするし

157
00:09:02,440 --> 00:09:05,690
もっと正確な座標も出力できるようにする

158
00:09:05,690 --> 00:09:10,530
それは スライディング ウィンドウ分類器の ストライドサイズで決まる座標より正確だ

159
00:09:10,530 --> 00:09:12,220
２番目は

160
00:09:12,220 --> 00:09:17,320
これは 畳み込み実行であって このアルゴリズムを

161
00:09:17,320 --> 00:09:25,540
3 x 3 格子で９回行うわけではない
19 x 19 格子なら 19^2=361回だ

162
00:09:25,540 --> 00:09:31,090
同じアルゴリズムを 361回 19^2回 実行するのではない

163
00:09:31,090 --> 00:09:34,285
そうではなく これは １回の畳み込み処理だ

164
00:09:34,285 --> 00:09:39,610
１つの ConvNet を使い 3 x 3 や 19 x 19 格子セル全てに

165
00:09:39,610 --> 00:09:46,780
必要な 全ての計算で その多くを共有する

166
00:09:46,780 --> 00:09:49,135
つまり これは とても効率的なアルゴリズムだ

167
00:09:49,135 --> 00:09:52,720
事実 YOLOアルゴリズムの良い点は

168
00:09:52,720 --> 00:09:57,445
それは 常に人気のアルゴリズムだけど
それが 畳み込み処理をしているからで

169
00:09:57,445 --> 00:09:58,930
事実 とても速いからだ

170
00:09:58,930 --> 00:10:02,530
だから これは リアルタイムの物体検出でも機能する

171
00:10:02,530 --> 00:10:03,915
では まとめに入る前に

172
00:10:03,915 --> 00:10:06,610
もう１つ 共有しておきたいことがある

173
00:10:06,610 --> 00:10:12,495
それは どのようにして この bx by bh bw を符号化するかだ

174
00:10:12,495 --> 00:10:16,135
次のスライドで議論しよう

175
00:10:16,135 --> 00:10:18,610
２つの車がある

176
00:10:18,610 --> 00:10:21,465
3 x 3 格子にしたのだった

177
00:10:21,465 --> 00:10:25,120
この右の車を例に取ろう

178
00:10:25,120 --> 00:10:32,220
この格子セルには 物体があるので 目的ラベル y は 1

179
00:10:32,220 --> 00:10:34,270
Pc = 1

180
00:10:34,270 --> 00:10:37,060
それから bx by

181
00:10:37,060 --> 00:10:40,970
bh bw そして 0 1 0

182
00:10:40,970 --> 00:10:43,790
では どのように境界箱を特定する？

183
00:10:43,790 --> 00:10:48,310
YOLO アルゴリズムでは この四角に相対的に

184
00:10:48,310 --> 00:10:51,545
ここの左上の点を

185
00:10:51,545 --> 00:10:56,180
(0, 0) とし 右下を (1, 1) にする

186
00:10:56,180 --> 00:10:59,155
よって この中心点を特定するには

187
00:10:59,155 --> 00:11:02,715
このオレンジの点だ
bx は

188
00:11:02,715 --> 00:11:05,980
x は 大体 0.4 に見える

189
00:11:05,980 --> 00:11:09,760
右に向かって 0.4 くらいでしょ

190
00:11:09,760 --> 00:11:15,945
それから y は 多分 0.3

191
00:11:15,945 --> 00:11:19,380
それから 境界箱の高さは
(訳注: 幅の言い間違い)

192
00:11:19,380 --> 00:11:24,090
この箱の全幅の比で 指定する

193
00:11:24,090 --> 00:11:30,931
この赤い箱の幅は 青線の 90%くらいだろう

194
00:11:30,931 --> 00:11:35,030
よって bh は 0.9 (訳注: bwの言い間違い)
そして 高さは

195
00:11:35,030 --> 00:11:42,075
格子セルの高さの半分くらいだ

196
00:11:42,075 --> 00:11:46,670
よって この場合 bw は 0.5 (訳注: bhの言い間違い)

197
00:11:46,670 --> 00:11:49,455
別の言葉で言えば bx by bh bw

198
00:11:49,455 --> 00:11:53,690
は 格子セルとの比で表される

199
00:11:53,690 --> 00:11:55,505
そして bx と by は

200
00:11:55,505 --> 00:11:58,455
0 と 1 の間になる 分かるよね？

201
00:11:58,455 --> 00:12:01,055
なぜなら 定義でそう決まるから

202
00:12:01,055 --> 00:12:04,340
オレンジの点は それが紐付く格子セルの境界内だからだ

203
00:12:04,340 --> 00:12:08,509
もし それが 0 と 1 の間に無い場合は 四角の外にあることになる

204
00:12:08,509 --> 00:12:11,680
そうなら 違う格子セルに紐付いたはずだ

205
00:12:11,680 --> 00:12:14,495
でも これらは １より大きくなり得る

206
00:12:14,495 --> 00:12:18,785
特に 境界箱が こんな風になる車があれば

207
00:12:18,785 --> 00:12:21,045
境界箱の高さと幅は

208
00:12:21,045 --> 00:12:23,440
１よりも大きくなり得る

209
00:12:23,440 --> 00:12:27,007
境界箱を特定する方法は複数ある

210
00:12:27,007 --> 00:12:30,710
でも これは とても合理的なやり方だ

211
00:12:30,710 --> 00:12:33,710
もし YOLO研究論文を読めば

212
00:12:33,710 --> 00:12:35,970
YOLO関連の研究では

213
00:12:35,970 --> 00:12:39,040
他のパラメータを使い 少しだけ良い結果を得ている

214
00:12:39,040 --> 00:12:44,925
でも これは ちゃんと機能する合理的な方法だと思うよ

215
00:12:44,925 --> 00:12:47,690
ただし より複雑なパラメータ化の方法があり

216
00:12:47,690 --> 00:12:51,980
そこでは 0 と 1 の間になることが保証される sigmoid 関数を使っている

217
00:12:51,980 --> 00:12:57,185
それに 指数パラメータを使い 非負を保証している

218
00:12:57,185 --> 00:13:01,245
0.9 と 0.5 は ０以上になるべきだから

219
00:13:01,245 --> 00:13:03,915
他にも多くの 先進的パラメータ化があり

220
00:13:03,915 --> 00:13:05,457
それで 少しだけ良くなる

221
00:13:05,457 --> 00:13:09,635
でも ここで見たやり方で十分なはずだ

222
00:13:09,635 --> 00:13:14,775
これが YOLO "You Only Look Once" アルゴリズムだ

223
00:13:14,775 --> 00:13:17,115
次からの数本のビデオでは

224
00:13:17,115 --> 00:13:21,470
このアルゴリズムを より良くするための 他のアイデアを見せる

225
00:13:21,470 --> 00:13:23,170
その間 もし そうしたければ

226
00:13:23,170 --> 00:13:24,445
YOLO論文を見ることができる

227
00:13:24,445 --> 00:13:29,667
さっきまで使っていた何枚かのスライドの下に参照があるから

228
00:13:29,667 --> 00:13:31,325
でも １つだけ忠告を

229
00:13:31,325 --> 00:13:33,530
もし これらの論文を読む場合

230
00:13:33,530 --> 00:13:37,425
YOLO論文は 読むのが難しい方だ

231
00:13:37,425 --> 00:13:40,265
最初にこの論文を読んだ時を 覚えているけど

232
00:13:40,265 --> 00:13:43,325
何が起きているのか 理解するのが大変だった

233
00:13:43,325 --> 00:13:46,356
そして 何人かの友人に 聞いて回った

234
00:13:46,356 --> 00:13:48,950
とても優れた研究者が 私が理解するのを助けてくれた

235
00:13:48,950 --> 00:13:53,125
彼らでさえ この論文の詳細のいくつかは 理解するのに苦労した

236
00:13:53,125 --> 00:13:54,845
だから もし この論文を読むのなら

237
00:13:54,845 --> 00:13:58,195
それを理解するのが難しくても問題無い

238
00:13:58,195 --> 00:14:00,885
そういうのは 滅多に無いといいんだけど

239
00:14:00,885 --> 00:14:02,795
悲しいことに あまり無いわけではない

240
00:14:02,795 --> 00:14:05,130
上級研究者でさえ

241
00:14:05,130 --> 00:14:08,840
研究論文を読んで 詳細を理解するのに苦しむことがある

242
00:14:08,840 --> 00:14:10,895
そして オープンソース コードを見て

243
00:14:10,895 --> 00:14:12,005
もしくは 著者に連絡を取って

244
00:14:12,005 --> 00:14:15,610
もしくは 何か他の事をして その成果の詳細を把握するんだ

245
00:14:15,610 --> 00:14:19,715
でも 望むのなら その研究論文を読むのを止めないよ

246
00:14:19,715 --> 00:14:21,700
難しいけどね

247
00:14:21,700 --> 00:14:25,975
とにかく YOLOアルゴリズムの基礎は理解しただろう

248
00:14:25,975 --> 00:14:31,000
このアルゴリズムを もっと良くするために いくつか追加していこう