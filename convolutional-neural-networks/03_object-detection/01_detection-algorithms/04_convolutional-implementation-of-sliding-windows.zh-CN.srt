1
00:00:00,000 --> 00:00:01,440
上个视频中

2
00:00:01,440 --> 00:00:03,705
你学到了滑动窗口(sliding windows)目标检测算法

3
00:00:03,705 --> 00:00:08,170
它运用了卷积神经网络(ConvNet)<br />但是我们看到了它的速度太慢

4
00:00:08,170 --> 00:00:13,090
在这个视频中<br />你将学习如何用卷积的形式(convolutionally)来实现这个算法

5
00:00:13,090 --> 00:00:14,640
让我们一起来看看为什么这么说

6
00:00:14,640 --> 00:00:20,040
为了搭建一个用卷积实现的滑动窗口，让我们先来看一下

7
00:00:20,040 --> 00:00:25,590
如何将神经网络中的全连接(Fully-Connected)层转化成卷积层

8
00:00:25,590 --> 00:00:28,620
我们先在这张幻灯片上介绍（概念），然后在下一张上

9
00:00:28,620 --> 00:00:33,600
我们会用这张幻灯片上的概念，来展示如果进行卷积实现

10
00:00:33,600 --> 00:00:39,560
假设你的目标检测算法的输入是14x14x3的图像

11
00:00:39,560 --> 00:00:42,240
这是个很小的图像，只是用来说明

12
00:00:42,240 --> 00:00:45,650
假设算法用5x5的滤波器

13
00:00:45,650 --> 00:00:52,155
然后假设用16个滤波器<br />也就是把14x14x3映射到10x10x16上

14
00:00:52,155 --> 00:00:56,970
然后做一个2x2的最大池化(max pooling)<br /> 把它缩小到5x5x16

15
00:00:56,970 --> 00:01:01,700
随后有一个全连接层连接到400个(神经)单元上

16
00:01:01,700 --> 00:01:07,425
然后另一个全连接层，最后用一个Softmax单元输出一个y

17
00:01:07,425 --> 00:01:11,220
为了做我们马上要做出的改变

18
00:01:11,220 --> 00:01:14,100
我要修改一下这张图

19
00:01:14,100 --> 00:01:18,105
我将输出y改为4个数字

20
00:01:18,105 --> 00:01:21,035
分别代表分类到softmax分类单元

21
00:01:21,035 --> 00:01:26,050
所区分的4个类别中每一类的概率

22
00:01:26,050 --> 00:01:31,405
这4个类别可以是

23
00:01:31,405 --> 00:01:35,609
行人、汽车、摩托车和背景，或者其他东西

24
00:01:35,609 --> 00:01:38,530
现在我想做的是展示

25
00:01:38,530 --> 00:01:43,030
如何将这些层转化成卷积层

26
00:01:43,030 --> 00:01:47,710
这是一个卷积神经网络，前几层和之前相同

27
00:01:47,710 --> 00:01:51,010
现在，实现这一层全连接层的一个方式

28
00:01:51,010 --> 00:01:55,030
是用5x5的滤波器

29
00:01:55,030 --> 00:02:02,625
让我们用400个5x5的滤波器

30
00:02:02,625 --> 00:02:08,950
如果你拿一个和5x5x16的图像<br />和一个5x5的滤波器做卷积操作

31
00:02:08,950 --> 00:02:13,450
还记得，<br />一个5x5的滤波器实现时是用5x5x16的滤波器

32
00:02:13,450 --> 00:02:19,240
因为按照惯例，这个滤波器要作用于全部16个通道

33
00:02:19,240 --> 00:02:25,375
所以这个16和这个16要匹配，这样输出就必须是1x1

34
00:02:25,375 --> 00:02:30,445
如果你有400个这样的5x5x16的滤波器

35
00:02:30,445 --> 00:02:36,056
那么输出的维度就是1x1x400

36
00:02:36,056 --> 00:02:41,016
所以与其只是把这400个看做一组节点

37
00:02:41,016 --> 00:02:44,602
我们将把它看做一个1x1x400的体

38
00:02:44,602 --> 00:02:50,260
数学操作上来讲，这和一个全连接层是一样的

39
00:02:50,260 --> 00:02:57,154
因为这400个节点中的每一个<br />都对应一个维度为5x5x16的滤波器

40
00:02:57,154 --> 00:02:59,770
也就是说这400个值中的每一个都是

41
00:02:59,770 --> 00:03:07,705
这5x5x16个前一层的激活值，<br />输入某个任意的线性方程的结果

42
00:03:07,705 --> 00:03:10,654
接下来，为了实现下一个卷积层

43
00:03:10,654 --> 00:03:14,230
我们将实现一个1x`1的卷积

44
00:03:14,230 --> 00:03:18,500
如果你有400个1x1的滤波器

45
00:03:18,500 --> 00:03:24,955
那么下一层(的维度)也是1x1x400

46
00:03:24,955 --> 00:03:29,030
这就得到了这个全连接层

47
00:03:29,030 --> 00:03:35,215
最后我们还将用一个1x1的滤波器

48
00:03:35,215 --> 00:03:37,360
然后是Softmax激活

49
00:03:37,360 --> 00:03:40,140
以输出一个1x1x4的(数据)卷

50
00:03:40,140 --> 00:03:46,115
以对应(上面的)这个网络输出的4个数字

51
00:03:46,115 --> 00:03:50,035
这个过程，展示了如何将全连接网络层

52
00:03:50,035 --> 00:03:54,310
用卷积层来实现

53
00:03:54,310 --> 00:03:57,815
从而可以将这些单元

54
00:03:57,815 --> 00:04:02,680
转化为1x1x400和1x1x4的(数据)卷

55
00:04:02,680 --> 00:04:06,580
在这一转化之后

56
00:04:06,580 --> 00:04:11,400
让我们来看一下你怎么样用卷积的形式来实现<br />滑动窗口目标识别

57
00:04:11,400 --> 00:04:16,850
这个幻灯片上展示的内容根据是OverFeat论文

58
00:04:16,850 --> 00:04:18,650
引用在底部，作者是Pierre Sermanet

59
00:04:18,650 --> 00:04:21,010
David Eigen, Xiang Zhang

60
00:04:21,010 --> 00:04:24,290
Michael Mathieu, Rob Fergus 和 Yann LeCun

61
00:04:24,290 --> 00:04:31,385
假设你的滑动窗口卷积神经网络的输入是14x14x3的图像

62
00:04:31,385 --> 00:04:35,495
同样我在幻灯片里用小的尺寸，比如14x14的图像

63
00:04:35,495 --> 00:04:40,790
主要是为了简化示范

64
00:04:40,790 --> 00:04:44,450
与之前相同，你有一个这样的神经网路

65
00:04:44,450 --> 00:04:49,100
最终的输出是一个1x1x14的体

66
00:04:49,100 --> 00:04:52,465
也就是Softmax单元的输出

67
00:04:52,465 --> 00:04:54,815
同样，为了简化绘图

68
00:04:54,815 --> 00:05:01,185
虽然14x14x3严格来讲是一卷，5x5x10

69
00:05:01,185 --> 00:05:02,530
或者10x10x16也应该是体

70
00:05:02,530 --> 00:05:04,490
不过为了简化幻灯片上的绘图

71
00:05:04,490 --> 00:05:07,620
我就只画出这些体的前向的面

72
00:05:07,620 --> 00:05:10,940
不画出1x1x400的体

73
00:05:10,940 --> 00:05:14,480
只画1x1的部分

74
00:05:14,480 --> 00:05:19,368
也就是丢掉这些绘图里的3维部分

75
00:05:19,368 --> 00:05:23,810
假设你的卷积神经网络的输入14x14的图像

76
00:05:23,810 --> 00:05:29,035
或者是说14x14x3的图像<br />而你的测试集里的图像(的维度)是16x16x3

77
00:05:29,035 --> 00:05:33,615
也就是现在把这条黄色的边加到图像的边缘

78
00:05:33,615 --> 00:05:36,335
在原来的滑动窗口算法中

79
00:05:36,335 --> 00:05:41,150
你可以把蓝色的区域输入到卷积神经网络中

80
00:05:41,150 --> 00:05:46,485
运行一次来得到分类结果0或1，然后向下滑动一点

81
00:05:46,485 --> 00:05:54,020
这里我们用两个像素点的步长<br />然后你可以向右滑动

82
00:05:54,020 --> 00:05:56,090
两个像素，将这个绿色的矩形区域

83
00:05:56,090 --> 00:05:59,130
输入到卷积神经网络中

84
00:05:59,130 --> 00:06:02,945
然后完整运算一次卷积神经网络来得到又一个标记0或1

85
00:06:02,945 --> 00:06:05,180
之后你可以输入

86
00:06:05,180 --> 00:06:12,595
这个橙色的区域，然后再运行一次来得到标记

87
00:06:12,595 --> 00:06:21,634
第四次，也是最后一次，输入右下角这个紫色矩形的区域

88
00:06:21,634 --> 00:06:26,115
也就是说<br />在这个相当小的16x16x3的图像上进行滑动窗口运算

89
00:06:26,115 --> 00:06:32,065
你就需要运行这个卷积神经网络4次来得到4个标记

90
00:06:32,065 --> 00:06:34,685
不过事实上，这里面的很多

91
00:06:34,685 --> 00:06:38,345
运行卷积神经网络的计算是重复的

92
00:06:38,345 --> 00:06:42,485
所以对滑动窗口的卷积方式的实现

93
00:06:42,485 --> 00:06:48,150
是让这4次卷积神经网络的前向(forward pass)运算<br />共享计算过程

94
00:06:48,150 --> 00:06:49,955
具体来说，你可以这么做

95
00:06:49,955 --> 00:06:54,170
你可以运行这个卷积神经网络，用同样的参数

96
00:06:54,170 --> 00:06:56,731
相同的5x5滤波器

97
00:06:56,731 --> 00:07:00,230
运行同样的16个5x5的滤波器

98
00:07:00,230 --> 00:07:04,850
现在你得到一个12x12x16的输出

99
00:07:04,850 --> 00:07:07,280
然后像之前一样，做最大池化(max pool)

100
00:07:07,280 --> 00:07:09,210
得到一个6x6x16(维度)

101
00:07:09,210 --> 00:07:18,093
使用相同的400个5x5的滤波器<br />得到一个2x2x40的卷

102
00:07:18,093 --> 00:07:24,835
也就不再是一个1x1x400的卷

103
00:07:24,835 --> 00:07:29,105
而是得到一个2x2x400的卷

104
00:07:29,105 --> 00:07:32,870
再经过一个1x1滤波器(卷积)

105
00:07:32,870 --> 00:07:37,260
得到另一个2x2x400，而不是1x1x400(的体)

106
00:07:37,260 --> 00:07:40,220
再做一次，你就得到一个

107
00:07:40,220 --> 00:07:44,320
维度为2x2x4的输出体，而不是1x1x4

108
00:07:44,320 --> 00:07:49,250
可以发现，这个蓝色的1x1x4的子域

109
00:07:49,250 --> 00:07:54,368
包含的就是对(输入中)左上的这个14x14的部分图像<br />做(原来的)卷积运算的结果

110
00:07:54,368 --> 00:08:01,215
这个右上角的1x1x4的体包含右上部分的结果

111
00:08:01,215 --> 00:08:04,820
左下包含的是

112
00:08:04,820 --> 00:08:08,660
对左下部分14x14的部分做卷积神经网络运算的结果

113
00:08:08,660 --> 00:08:13,310
右下1x1x4的数据体包含的是

114
00:08:13,310 --> 00:08:18,040
和对右下部分图像14x14的部分<br />做卷积神经网络运算一样的结果

115
00:08:18,040 --> 00:08:20,990
如果你一步一步经过所有的运算过程

116
00:08:20,990 --> 00:08:23,110
例如让我们来看一下绿色的部分

117
00:08:23,110 --> 00:08:25,850
如果你只裁剪出这个部分

118
00:08:25,850 --> 00:08:29,120
然后让它经过卷积神经网络的运算

119
00:08:29,120 --> 00:08:34,105
那么第一层的激活值会刚好在这个区域里

120
00:08:34,105 --> 00:08:37,037
下一层最大池化后得到的激活值就会

121
00:08:37,037 --> 00:08:40,490
刚好在这个区域

122
00:08:40,490 --> 00:08:43,460
下一层、下下一层，以此类推

123
00:08:43,460 --> 00:08:44,805
那么这个过程所做的

124
00:08:44,805 --> 00:08:47,216
也就是这个卷积形式的实现做的

125
00:08:47,216 --> 00:08:50,345
就是不去强行在输入图像的4个子图像上分别

126
00:08:50,345 --> 00:08:54,635
进行前向传播(forward propagation)

127
00:08:54,635 --> 00:08:58,730
而是把4个合并成一个前向传播(forward prop)运算

128
00:08:58,730 --> 00:09:02,713
从而利用这4个14x14的图像块的共同区域

129
00:09:02,713 --> 00:09:07,895
共享了大量的运算

130
00:09:07,895 --> 00:09:09,935
现在让我们来看一个更大的例子

131
00:09:09,935 --> 00:09:14,845
假设你想在一个28x28x3的图像上使用滑动窗口

132
00:09:14,845 --> 00:09:16,820
事实证明

133
00:09:16,820 --> 00:09:21,410
如果你用同样的方式进行前向传播<br />你会得到一个8x8x4的输出

134
00:09:21,410 --> 00:09:27,735
这对应的是对这个14x14的区域使用滑动窗口算法

135
00:09:27,735 --> 00:09:33,380
这对应的是对这个区域使用滑动窗口算法

136
00:09:33,380 --> 00:09:36,496
得到和左上角(区域)相对应的输出

137
00:09:36,496 --> 00:09:39,661
然后用两个像素的步长将窗口移动一次

138
00:09:39,661 --> 00:09:43,775
再移动一次、再移动一次，<br />如此下去一共有8个位置

139
00:09:43,775 --> 00:09:48,830
这样得到第一行(的结果)，<br />然后当你在图像中继续进行下去

140
00:09:48,830 --> 00:09:53,350
你可以得到所有8x8x4的输出

141
00:09:53,350 --> 00:09:58,760
并且因为使用了2x2的最大池化

142
00:09:58,760 --> 00:10:04,055
这个过程相当于在原来的图像上以2为步长<br />运行神经网络

143
00:10:04,055 --> 00:10:05,335
复习一下

144
00:10:05,335 --> 00:10:07,853
为了实现滑动窗口

145
00:10:07,853 --> 00:10:11,715
之前的方法是，裁剪出一个区域

146
00:10:11,715 --> 00:10:14,750
我们假设这是14x14

147
00:10:14,750 --> 00:10:18,811
让它通过卷积神经网络 <br />然后对旁边下一个区域如法炮制

148
00:10:18,811 --> 00:10:21,604
接着是下一个14x14的区域

149
00:10:21,604 --> 00:10:23,210
然后下一个区域、下一个区域

150
00:10:23,210 --> 00:10:25,700
下一个区域、下一个区域

151
00:10:25,700 --> 00:10:29,070
直到有可能这个(区域)识别出一辆车

152
00:10:29,070 --> 00:10:31,610
但是现在，我们不顺序进行运输

153
00:10:31,610 --> 00:10:35,540
利用之前幻灯片上展示的卷积形式的实现

154
00:10:35,540 --> 00:10:37,745
你可以实现对整张图像

155
00:10:37,745 --> 00:10:42,890
比如整个28x28的区域，<br />以卷积操作的形式

156
00:10:42,890 --> 00:10:46,270
进行一次这个大的卷积神经网络的前向传播 <br />同时得到得到所有的预测

157
00:10:46,270 --> 00:10:50,357
然后就有可能识别出这辆车的位置

158
00:10:50,357 --> 00:10:53,490
这就是如何用卷积的形式实现滑动窗口算法

159
00:10:53,490 --> 00:10:57,700
这使得整个过程高效了很多

160
00:10:57,700 --> 00:10:59,960
不过，这个算法仍然有一个弱点

161
00:10:59,960 --> 00:11:04,585
那就是窗口边框的定位并不精确

162
00:11:04,585 --> 00:11:05,786
在下一节视频中

163
00:11:05,786 --> 00:11:08,030
让我们看看你可以怎样解决这个问题
GTC字幕组翻译