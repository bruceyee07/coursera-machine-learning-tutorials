1
00:00:00,000 --> 00:00:03,235
如果你去看物件偵測的文獻

2
00:00:03,235 --> 00:00:06,790
有一類的想法叫 Region Proposals (候選區域)

3
00:00:06,790 --> 00:00:10,995
在電腦視覺的領域也很有影響力

4
00:00:10,995 --> 00:00:14,460
我把這部影片變成選修，因為

5
00:00:14,460 --> 00:00:19,275
我不大常用 Region Proposal 一類的演算法。儘管如此

6
00:00:19,275 --> 00:00:22,170
這研究一直很有影響力

7
00:00:22,170 --> 00:00:25,675
在你自己的研究可能也會碰到的一種想法，

8
00:00:25,675 --> 00:00:29,640
就讓我們看看吧。如果你還記得滑動視窗的概念

9
00:00:29,640 --> 00:00:33,225
你會拿個訓練好的分類器，讓他跑過

10
00:00:33,225 --> 00:00:37,695
所有這些不同的範圍，執行偵測器，看看有沒有車、

11
00:00:37,695 --> 00:00:40,190
路人、或是機車

12
00:00:40,190 --> 00:00:42,515
那麼，你可以用卷積化的方式跑這演算法

13
00:00:42,515 --> 00:00:45,570
不過這演算法的一個缺點是，他會去

14
00:00:45,570 --> 00:00:49,410
辨別很多個顯然就沒有物件的區域

15
00:00:49,410 --> 00:00:52,569
所以下面這個長方形算是空白的

16
00:00:52,569 --> 00:00:55,658
那邊顯然沒有任何有趣的東西可以拿來分類

17
00:00:55,658 --> 00:00:58,610
也許，他也會跑過這個長方形區域

18
00:00:58,610 --> 00:01:01,365
而裡面看起來沒啥感興趣的。

19
00:01:01,365 --> 00:01:04,275
於是，Ross Girshick, Jeff Donahue, Trevor Darrell,

20
00:01:04,275 --> 00:01:06,548
和 Jitendra Malik 在這篇論文提出了

21
00:01:06,548 --> 00:01:07,905
— 投影片下方引用的

22
00:01:07,905 --> 00:01:10,470
是一個叫 R-CNN 的演算法

23
00:01:10,470 --> 00:01:15,915
代表卷積網路的區域、regions with CNNs

24
00:01:15,915 --> 00:01:18,330
他所做的是，嘗試只挑一些區域

25
00:01:18,330 --> 00:01:22,925
一些在上面跑 ConvNet 分類才有意義的區域

26
00:01:22,925 --> 00:01:27,505
所以並不是在每一個視窗上跑滑動視窗

27
00:01:27,505 --> 00:01:30,330
而是只選擇一些視窗範圍

28
00:01:30,330 --> 00:01:33,570
只在那些視窗上跑 ConvNet 分類器。

29
00:01:33,570 --> 00:01:35,205
而候選出區域的方式

30
00:01:35,205 --> 00:01:40,425
是跑一個叫「分割」的演算法 (segmentation)

31
00:01:40,425 --> 00:01:42,915
得到像右邊的結果

32
00:01:42,915 --> 00:01:46,170
藉以了解什麼可能是物件。

33
00:01:46,170 --> 00:01:50,306
例如，分割演算法在這裡發現一團東西

34
00:01:50,306 --> 00:01:53,625
所以你可能挑出那個邊界框，然後說

35
00:01:53,625 --> 00:01:55,680
「讓我們在那一團東西上跑個分類」

36
00:01:55,680 --> 00:01:58,730
看起來那邊有個小小綠綠的，我們找到了一團

37
00:01:58,730 --> 00:02:00,960
所以你也可能會跑個分類器

38
00:02:00,960 --> 00:02:04,650
在那一個長方形上，看看那邊是否有好玩的東西

39
00:02:04,650 --> 00:02:06,000
以這個例子而言

40
00:02:06,000 --> 00:02:08,830
這一團藍色的，如果他在上面跑個分類

41
00:02:08,830 --> 00:02:10,793
我們期望你會找到一位行人

42
00:02:10,793 --> 00:02:13,575
而如果你跑在這團青色的東西上

43
00:02:13,575 --> 00:02:16,120
你可能會找到一輛車，也可能不會，

44
00:02:16,120 --> 00:02:17,535
所以這個的細節

45
00:02:17,535 --> 00:02:20,080
這叫分割演算法

46
00:02:20,080 --> 00:02:25,410
你所做的是找出大約2000團東西，然後

47
00:02:25,410 --> 00:02:31,544
在那些周圍放置邊界框，僅在這兩千團東西上執行分類

48
00:02:31,544 --> 00:02:34,380
這樣的話，需要執行 ConvNet 分類的地方

49
00:02:34,380 --> 00:02:37,529
其數量就會非常少

50
00:02:37,529 --> 00:02:40,935
— 跟掃過圖片的每一個位置比較的話

51
00:02:40,935 --> 00:02:44,172
特別是當你要跑你的 ConvNet

52
00:02:44,172 --> 00:02:48,055
不只在方形的區域，也跑在

53
00:02:48,055 --> 00:02:51,870
瘦瘦高高的區域以試著找到路人，或者

54
00:02:51,870 --> 00:02:57,915
跑在寬寬胖胖的區域上以找到汽車、
甚至跑在多種大小規模的區域上

55
00:02:57,915 --> 00:03:02,170
那麼這就是 R-CNN，或稱 CNN 的區域

56
00:03:02,170 --> 00:03:04,380
有卷積特徵的區域

57
00:03:04,380 --> 00:03:08,305
然而， R-CNN 演算法仍然頗慢

58
00:03:08,305 --> 00:03:13,320
所以有一系列的研究去探索要如何加速這方法

59
00:03:13,320 --> 00:03:16,920
基本的 R-CNN 演算法，利用某個方法找出候選區域

60
00:03:16,920 --> 00:03:20,933
然後一次分類一個候選區域

61
00:03:20,933 --> 00:03:22,380
而對於每一個區域

62
00:03:22,380 --> 00:03:23,844
他會輸出一個標籤

63
00:03:23,844 --> 00:03:25,960
有沒有車？有沒有行人？

64
00:03:25,960 --> 00:03:27,580
那裡有沒有機車？

65
00:03:27,580 --> 00:03:30,090
然後也會輸出一個邊界框

66
00:03:30,090 --> 00:03:36,510
所以如果那區域真的有物件，你能得到一個準確的邊界框

67
00:03:36,510 --> 00:03:37,645
只是要釐清一下

68
00:03:37,645 --> 00:03:42,075
R-CNN 演算法不會全然信任你給他的邊界框

69
00:03:42,075 --> 00:03:44,540
他也會輸出一個邊界框

70
00:03:44,540 --> 00:03:46,620
b_x, b_y, b_h, b_w

71
00:03:46,620 --> 00:03:51,045
為了能得到更準確的邊界框

72
00:03:51,045 --> 00:03:56,070
來框住分割演算法給他的一團東西

73
00:03:56,070 --> 00:03:58,705
所以他可以得到滿準確的邊界框

74
00:03:58,705 --> 00:04:03,425
那麼，一個 R-CNN 演算法的缺點是：他頗慢

75
00:04:03,425 --> 00:04:04,470
所以這些年來

76
00:04:04,470 --> 00:04:08,295
R-CNN 法有很多的改良

77
00:04:08,295 --> 00:04:12,180
Russ Girshik 提出了 "fast R-CNN" (快速R-CNN)

78
00:04:12,180 --> 00:04:15,150
基本上他是 R-CNN，但是

79
00:04:15,150 --> 00:04:18,290
利用了卷積化的滑動視窗

80
00:04:18,290 --> 00:04:23,745
所以原本的作法其實只會一次分類一個區域

81
00:04:23,745 --> 00:04:28,955
而快速 R-CNN 用了卷積化的滑動視窗實作

82
00:04:28,955 --> 00:04:35,550
基本上和這周第四部影片的概念類似

83
00:04:35,550 --> 00:04:39,850
這讓 R-CNN 加速了不少

84
00:04:40,390 --> 00:04:46,680
然而，其實快速 R-CNN 其中一個問題是

85
00:04:46,680 --> 00:04:53,270
為了挑出候選區域的群集步驟仍然很慢，所以另一群人

86
00:04:53,270 --> 00:04:56,025
Shaoqing Ren, Kaiming He, Ross Girshick 和 Jian Sun

87
00:04:56,025 --> 00:04:59,043
提出了 "faster R-CNN" (更快速R-CNN)

88
00:04:59,043 --> 00:05:02,520
利用了卷積網路而非傳統的

89
00:05:02,520 --> 00:05:07,550
分割演算法來選出那一堆的區域

90
00:05:07,550 --> 00:05:12,487
而這樣最終能比「快速R-CNN」更快速

91
00:05:12,487 --> 00:05:15,810
雖然，我覺得「更快速R-CNN」

92
00:05:15,810 --> 00:05:21,730
絕大部分的實作通常還是比 YOLO 演算法慢一些

93
00:05:21,730 --> 00:05:27,090
那麼，「候選區域」這個想法在電腦視覺的領域
一直有著影響力

94
00:05:27,090 --> 00:05:32,995
我想讓你知道這些概念，因為你能發現其他人仍然在使用

95
00:05:32,995 --> 00:05:35,595
至於我，這只是我個人的意見

96
00:05:35,595 --> 00:05:38,893
並不是整個研究電腦視覺的社群的意見

97
00:05:38,893 --> 00:05:44,100
我覺得候選區域是個有趣的想法。但是，如果能不花兩步

98
00:05:44,100 --> 00:05:45,630
— 第一先選出區域，然後再分類之

99
00:05:45,630 --> 00:05:49,800
如果能做得更多，能夠同時做到

100
00:05:49,800 --> 00:05:53,085
類似像 YOLO「你只需看一次」演算法

101
00:05:53,085 --> 00:05:56,885
這種方向就長遠來看比較有希望

102
00:05:56,885 --> 00:05:58,995
不過這只是個人意見，並不一定是

103
00:05:58,995 --> 00:06:01,865
整個電腦視覺社群的意見

104
00:06:01,865 --> 00:06:04,868
所以也可以聽聽參考就好

105
00:06:04,868 --> 00:06:07,550
但我認為 R-CNN 這種想法

106
00:06:07,550 --> 00:06:10,438
你可能會碰到其他人在用

107
00:06:10,438 --> 00:06:14,460
所以也值得一學，這樣你就能更瞭解其他的演算法

108
00:06:14,460 --> 00:06:21,565
那麼，這禮拜物件偵測的課程就到這邊

109
00:06:21,565 --> 00:06:25,133
我希望你能喜歡這禮拜的程式練習

110
00:06:25,133 --> 00:06:27,000
也期待在下禮拜見到你