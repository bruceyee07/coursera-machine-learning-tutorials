1
00:00:00,000 --> 00:00:01,380
上个视频中

2
00:00:01,380 --> 00:00:06,300
您学习了如何使用卷积实现滑动窗口方法

3
00:00:06,300 --> 00:00:08,780
虽然这在计算上更有效率

4
00:00:08,780 --> 00:00:14,130
但它依然存在无法精确输出边界框的问题

5
00:00:14,130 --> 00:00:16,710
在这个视频中 我们将学习

6
00:00:16,710 --> 00:00:19,520
如何更精确地预测边界框

7
00:00:19,520 --> 00:00:21,495
使用滑动窗口

8
00:00:21,495 --> 00:00:26,190
你通过这些预先决定的窗口来扫过整个图像

9
00:00:26,190 --> 00:00:27,825
在这种情况下

10
00:00:27,825 --> 00:00:32,636
没有一个边框与车的位置恰好吻合

11
00:00:32,636 --> 00:00:35,900
所以 也许这个边框是最吻合的

12
00:00:35,900 --> 00:00:38,465
另一方面 看上去一个更为精确的边界框

13
00:00:38,465 --> 00:00:41,585
实际上并不是一个正方形

14
00:00:41,585 --> 00:00:48,750
它是一个较宽的长方形 长宽比稍扁平

15
00:00:48,750 --> 00:00:53,975
所以 是否有一个算法可以给出更精确的边界框？

16
00:00:53,975 --> 00:00:59,275
YOLO算法就是一个比较好的能精确输出边界框的算法

17
00:00:59,275 --> 00:01:03,225
YOLO的全称是You Only Look Once

18
00:01:03,225 --> 00:01:06,195
这个算法是由Joseph Redmon

19
00:01:06,195 --> 00:01:07,975
Santosh Divvala、 Ross Girshick和Ali Farhadi提出

20
00:01:07,975 --> 00:01:10,735
下面是具体的做法

21
00:01:10,735 --> 00:01:14,230
假设你有一张100乘100的图片作为输入

22
00:01:14,230 --> 00:01:17,175
接着你要将其用网格划分

23
00:01:17,175 --> 00:01:19,425
出于演示的目的

24
00:01:19,425 --> 00:01:21,780
我将使用3乘3的网格

25
00:01:21,780 --> 00:01:23,640
虽然在实际的操作中

26
00:01:23,640 --> 00:01:24,840
你会使用更细分的网格

27
00:01:24,840 --> 00:01:27,880
比如19乘19的网格

28
00:01:27,880 --> 00:01:30,660
基本思路是你将把

29
00:01:30,660 --> 00:01:36,345
几个视频以前学习的图像分类及定位的算法

30
00:01:36,345 --> 00:01:40,165
应用到这九个网格中的每一个

31
00:01:40,165 --> 00:01:47,910
基本思路是你将把

32
00:01:47,910 --> 00:01:52,170
本周第一个视频中学习的图像分类及定位的算法

33
00:01:52,170 --> 00:01:58,440
应用到这九个网格中的每一个

34
00:01:58,440 --> 00:01:59,851
所以具体来说

35
00:01:59,851 --> 00:02:05,171
下面是你要如何定义用于训练的标签

36
00:02:05,171 --> 00:02:08,070
对于这九个网格中的每一个 你要给定一个标签Y

37
00:02:08,070 --> 00:02:14,561
这里标签Y是一个8维的向量

38
00:02:14,561 --> 00:02:16,470
和之前你学到的一样

39
00:02:16,470 --> 00:02:19,610
第一个输出值Pc(0或1)取决于

40
00:02:19,610 --> 00:02:24,170
那一个网格元中是否有目标物

41
00:02:24,170 --> 00:02:30,800
如果在那个网格元中有目标物

42
00:02:30,800 --> 00:02:33,348
bx by bh和bw将指定边界框的位置

43
00:02:33,348 --> 00:02:36,320
最后需要包括C1 C2和C3

44
00:02:36,320 --> 00:02:40,935
如果你想要识别三种类型的目标物 不包括背景

45
00:02:40,935 --> 00:02:43,120
比如你想要识别行人 汽车

46
00:02:43,120 --> 00:02:45,110
摩托车和背景

47
00:02:45,110 --> 00:02:47,720
那么C1 C2和C3就可以代表行人

48
00:02:47,720 --> 00:02:50,570
汽车和摩托车

49
00:02:50,570 --> 00:02:52,505
所以在这个图像中

50
00:02:52,505 --> 00:02:53,870
我们有9个网格元

51
00:02:53,870 --> 00:02:59,105
所以每一个网格元你都会有一个这样的向量

52
00:02:59,105 --> 00:03:02,316
让我们从左上角的网格元开始

53
00:03:02,316 --> 00:03:03,955
这里这个

54
00:03:03,955 --> 00:03:06,115
在这个网格中 没有目标物

55
00:03:06,115 --> 00:03:11,960
所以左上角这个网格元的标签Y会是0

56
00:03:11,960 --> 00:03:16,655
然后不考虑其他的元素

57
00:03:16,655 --> 00:03:20,707
这个网格元和所有不包含目标物

58
00:03:20,707 --> 00:03:24,640
不包含感兴趣的目标物的网格元

59
00:03:24,640 --> 00:03:27,845
的输出标签Y都会是一样的，这样的

60
00:03:27,845 --> 00:03:32,435
那么这个网格元是怎么样的呢？

61
00:03:32,435 --> 00:03:34,385
详细地说

62
00:03:34,385 --> 00:03:36,355
这张图像有两个目标物

63
00:03:36,355 --> 00:03:40,270
YOLO算法是将这两个目标物分别分配到

64
00:03:40,270 --> 00:03:45,690
包含它们的中心点的网格元中

65
00:03:45,690 --> 00:03:49,900
所以左边的汽车被分到了这个网格元中

66
00:03:49,900 --> 00:03:51,445
而右边的汽车

67
00:03:51,445 --> 00:03:53,140
这是它的中心点

68
00:03:53,140 --> 00:03:57,265
被分到了这个网格元中

69
00:03:57,265 --> 00:04:02,510
所以即使中间的网格元包含这两辆车的一部分

70
00:04:02,510 --> 00:04:06,175
我们会假设中间的网格元不包含感兴趣的目标物

71
00:04:06,175 --> 00:04:11,560
所以中间的网格元会有这样不包含目标物的标签Y

72
00:04:11,560 --> 00:04:13,450
所以有第一个元素Pc

73
00:04:13,450 --> 00:04:15,000
然后其他的元素都不重要

74
00:04:15,000 --> 00:04:17,091
而这个网格元

75
00:04:17,091 --> 00:04:21,005
在左边的这个我用绿色框圈出的网格元

76
00:04:21,005 --> 00:04:23,765
它的目标标签Y会如下所示

77
00:04:23,765 --> 00:04:25,085
它包含一个目标物

78
00:04:25,085 --> 00:04:26,770
然后你写出bx by bh和bw

79
00:04:26,770 --> 00:04:32,830
来给出这个边界框的位置

80
00:04:32,830 --> 00:04:34,870
然后你需要指出

81
00:04:34,870 --> 00:04:38,680
如果第一类是行人 那么它是0

82
00:04:38,680 --> 00:04:40,420
第二类是汽车 它是1

83
00:04:40,420 --> 00:04:43,960
第三类是摩托车 它是0

84
00:04:43,960 --> 00:04:45,900
类似的 右边这个网格元

85
00:04:45,900 --> 00:04:48,415
由于它包含一个目标物

86
00:04:48,415 --> 00:04:52,690
它也会有一个像这样的向量

87
00:04:52,690 --> 00:04:58,325
来作为与其对应的目标标签

88
00:04:58,325 --> 00:05:00,715
所以 对于这9个网格元中的每一个

89
00:05:00,715 --> 00:05:04,815
你都会有一个8维的输出向量

90
00:05:04,815 --> 00:05:08,415
由于你有3乘3个网格元

91
00:05:08,415 --> 00:05:09,863
一共是9个网格元

92
00:05:09,863 --> 00:05:17,435
输出的总大小将会是3乘3乘8

93
00:05:17,435 --> 00:05:24,760
因此输出目标将会是3乘3乘8 因为你有3乘3个网格元

94
00:05:24,760 --> 00:05:28,045
然后这3乘3个网格元中的每一个

95
00:05:28,045 --> 00:05:32,790
你都有一个8维的Y向量

96
00:05:32,790 --> 00:05:36,250
所以输出目标的总量是3乘3乘8

97
00:05:36,250 --> 00:05:41,245
举个例子 这个位于左上角的

98
00:05:41,245 --> 00:05:42,970
1乘1乘8的输出块就对应着

99
00:05:42,970 --> 00:05:47,770
这9个网格元中位于左上角的这个的输出向量

100
00:05:47,770 --> 00:05:50,710
所以这3乘3个位置中的每一个

101
00:05:50,710 --> 00:05:52,345
对于这9个网格中的每一个

102
00:05:52,345 --> 00:05:58,180
这都对应着一个你要输出的8维目标向量Y

103
00:05:58,180 --> 00:05:59,610
如果那个网格元中不包含目标物

104
00:05:59,610 --> 00:06:01,010
其中的一些元素可以是不重要的

105
00:06:01,010 --> 00:06:03,360
这就是为什么总的目标输出

106
00:06:03,360 --> 00:06:08,635
即这个图像的输出标签现在是3乘3乘8的

107
00:06:08,635 --> 00:06:11,245
所以现在 为了训练你的神经网络

108
00:06:11,245 --> 00:06:17,475
输入的大小是100乘100乘3

109
00:06:17,475 --> 00:06:19,015
也就是输入的图像

110
00:06:19,015 --> 00:06:22,795
然后是一个普通的卷积神经网络

111
00:06:22,795 --> 00:06:27,690
包括卷积层、最大池化层等等

112
00:06:27,690 --> 00:06:28,870
最终

113
00:06:28,870 --> 00:06:34,440
你需要选择这些卷积层和最大池化层等等

114
00:06:34,440 --> 00:06:42,320
使得它逐渐映射到3乘3乘8的输出上

115
00:06:42,320 --> 00:06:46,470
所以你要做的是 你有一个像这样的图像输入X

116
00:06:46,470 --> 00:06:50,125
和这些3乘3乘8的目标标签Y

117
00:06:50,125 --> 00:06:54,160
然后你用反向传播来训练神经网络

118
00:06:54,160 --> 00:06:58,565
来将任一输入值X映射到输出值Y上

119
00:06:58,565 --> 00:07:01,360
这个算法的优势在于

120
00:07:01,360 --> 00:07:07,228
该神经网络可以精确地输出如下的边界框

121
00:07:07,228 --> 00:07:08,320
所以在测试时

122
00:07:08,320 --> 00:07:10,930
你需要做的是给进输入图像X

123
00:07:10,930 --> 00:07:14,255
然后运行前向传播直到得到输出向量Y

124
00:07:14,255 --> 00:07:16,735
然后对于这9个向量中的每一个

125
00:07:16,735 --> 00:07:19,480
也就是这3乘3个位置中的每一个

126
00:07:19,480 --> 00:07:22,810
你可以读到1或者0

127
00:07:22,810 --> 00:07:27,153
说明了在这9个中的某一个是否包含目标物

128
00:07:27,153 --> 00:07:29,590
以及如果包含目标物 那么那个目标物是什么

129
00:07:29,590 --> 00:07:36,065
还有该网格元中的目标物的边界框

130
00:07:36,065 --> 00:07:39,118
所以只要在每个网格中有不超过一个目标物

131
00:07:39,118 --> 00:07:41,810
这个算法应该没有问题

132
00:07:41,810 --> 00:07:43,900
而在某个网格中有多于一个目标物的问题

133
00:07:43,900 --> 00:07:46,600
我们将在之后提及

134
00:07:46,600 --> 00:07:51,985
但在实际操作中 相比这里使用的相对较少的3乘3的网格

135
00:07:51,985 --> 00:07:54,470
你可能会使用更精细的网格

136
00:07:54,470 --> 00:07:56,160
可能是19乘19的网格

137
00:07:56,160 --> 00:07:58,900
所以最终你会得到19乘19乘8的结果

138
00:07:58,900 --> 00:08:02,315
由于使用了更精细的网格

139
00:08:02,315 --> 00:08:07,180
这会减少同一个网格元中有多个目标物的可能性

140
00:08:07,180 --> 00:08:08,800
值得提醒的是

141
00:08:08,800 --> 00:08:11,590
将目标物分配到网格元中的方式

142
00:08:11,590 --> 00:08:14,290
即先找到目标物的中心点

143
00:08:14,290 --> 00:08:19,930
再根据中心点的位置将它分配到包含该中心点的网格中

144
00:08:19,930 --> 00:08:23,926
所以对于每一个目标物 即使它跨越了多个网格

145
00:08:23,926 --> 00:08:27,410
它也只会被分配给这九个网格元中的一个

146
00:08:27,410 --> 00:08:29,018
或者说这3乘3个网格元中的一个

147
00:08:29,018 --> 00:08:31,565
或者19乘19个网格元中的一个

148
00:08:31,565 --> 00:08:33,584
而使用19乘19的网格的算法

149
00:08:33,584 --> 00:08:36,715
两个目标物的中心

150
00:08:36,715 --> 00:08:41,445
出现在同一个网格元中的概率会稍小

151
00:08:41,445 --> 00:08:44,043
所以值得注意的有两点

152
00:08:44,043 --> 00:08:46,930
第一 这种算法和本周的第一个视频中讲到的

153
00:08:46,930 --> 00:08:51,530
图像识别和定位算法十分相似

154
00:08:51,530 --> 00:08:55,380
它会直接输出边界框的坐标位置

155
00:08:55,380 --> 00:08:58,235
以及它允许你的神经网络输出

156
00:08:58,235 --> 00:09:02,440
任意长宽比的边界框

157
00:09:02,440 --> 00:09:05,690
同时输出的坐标位置也更为精确

158
00:09:05,690 --> 00:09:10,530
而不会受限于滑动窗口的步长

159
00:09:10,530 --> 00:09:12,220
第二 这个算法是

160
00:09:12,220 --> 00:09:17,320
通过卷积实现的 你不需要在3乘3的网格上

161
00:09:17,320 --> 00:09:25,540
执行这个算法9次 如果你使用19乘19的网格 19的平方是361

162
00:09:25,540 --> 00:09:31,090
所以你不需要运行同样的算法361次 或者说19的平方次

163
00:09:31,090 --> 00:09:34,285
与此不同的是 这个算法是一整个卷积实现的

164
00:09:34,285 --> 00:09:39,610
你只需要用一个卷积网络 使得所有3乘3或19乘19个网格

165
00:09:39,610 --> 00:09:46,780
所需的计算被大量地共享

166
00:09:46,780 --> 00:09:49,135
所以 这是一个非常有效率的算法

167
00:09:49,135 --> 00:09:52,720
事实上 YOLO算法的一个好处

168
00:09:52,720 --> 00:09:57,445
也是它一直很流行的原因是它是通过卷积实现的

169
00:09:57,445 --> 00:09:58,930
它实际上运行起来非常快

170
00:09:58,930 --> 00:10:02,530
所以它甚至可以运用在实时的目标识别上

171
00:10:02,530 --> 00:10:03,915
现在 在总结前

172
00:10:03,915 --> 00:10:06,610
我还想和你们分享一个细节

173
00:10:06,610 --> 00:10:12,495
那就是如何决定边界框的参数bx by bh和bw

174
00:10:12,495 --> 00:10:16,135
我们会在下一张幻灯片中讨论

175
00:10:16,135 --> 00:10:18,610
所以 给定图像中的这两辆车

176
00:10:18,610 --> 00:10:21,465
还记得我们有3乘3的网格

177
00:10:21,465 --> 00:10:25,120
让我们以右边的汽车为例

178
00:10:25,120 --> 00:10:32,220
在这个网格元中有一个目标物 所以它的目标标签Y会是1

179
00:10:32,220 --> 00:10:34,270
也就是Pc等于1

180
00:10:34,270 --> 00:10:37,060
然后是bx by

181
00:10:37,060 --> 00:10:40,970
bh bw 最后是0 1 0

182
00:10:40,970 --> 00:10:43,790
所以该如何指定边界框呢？

183
00:10:43,790 --> 00:10:48,310
在YOLO算法中 相对于这个正方形

184
00:10:48,310 --> 00:10:51,545
我将按惯例把左上角的点

185
00:10:51,545 --> 00:10:56,180
定为0 0 而把右下角的点定为1 1

186
00:10:56,180 --> 00:10:59,155
所以 要指定中心点的位置

187
00:10:59,155 --> 00:11:02,715
也就是那个橙色的点的位置 bx可能是

188
00:11:02,715 --> 00:11:05,980
x看上去在0.4左右

189
00:11:05,980 --> 00:11:09,760
因为它大概在距离左边0.4左右的位置<br />（译者：Andrew原话说到右边0.4左右，应该是口误）

190
00:11:09,760 --> 00:11:15,945
然后y看上去在0.3左右

191
00:11:15,945 --> 00:11:19,380
然后边界框的高度是通过它和

192
00:11:19,380 --> 00:11:24,090
整个网格宽度的比例来指定的

193
00:11:24,090 --> 00:11:30,931
所以这个红色方框的宽度大概是那条蓝色线段的90%

194
00:11:30,931 --> 00:11:35,030
所以bh就是0.9 然后它的高度

195
00:11:35,030 --> 00:11:42,075
大概是整个网格元的一半

196
00:11:42,075 --> 00:11:46,670
那么bw大概是0.5

197
00:11:46,670 --> 00:11:49,455
换句话说 这里的bx by bh bw

198
00:11:49,455 --> 00:11:53,690
是相对网格来指定的

199
00:11:53,690 --> 00:11:55,505
所以 bx by

200
00:11:55,505 --> 00:11:58,455
一定会在0到1之间 对吧？

201
00:11:58,455 --> 00:12:01,055
因为根据定义

202
00:12:01,055 --> 00:12:04,340
那个橙色的点一定是在包含它的网格元中的

203
00:12:04,340 --> 00:12:08,509
如果它们不在0到1之间 那它就在那个正方形外部了

204
00:12:08,509 --> 00:12:11,680
那么它将会被分配到另一个网格元中

205
00:12:11,680 --> 00:12:14,495
但是这两个量可以大于1

206
00:12:14,495 --> 00:12:18,785
特别是 如果有一辆车 它有像这样的边界框

207
00:12:18,785 --> 00:12:21,045
那么它的边界框的高度和宽度

208
00:12:21,045 --> 00:12:23,440
可以大于1

209
00:12:23,440 --> 00:12:27,007
所以虽然有很多种指定边界框的方式

210
00:12:27,007 --> 00:12:30,710
但依据这种惯例是一种较为合理的方式

211
00:12:30,710 --> 00:12:33,710
虽然 当你阅读YOLO算法的研究论文时

212
00:12:33,710 --> 00:12:35,970
那些关于YOLO的研究会用到

213
00:12:35,970 --> 00:12:39,040
其他更好一些的参数化

214
00:12:39,040 --> 00:12:44,925
但我希望可以提供这种较为合理 效果也不错的形式给大家

215
00:12:44,925 --> 00:12:47,690
虽然 有一些更复杂的参数化

216
00:12:47,690 --> 00:12:51,980
会用到S型(sigmoid)函数来保证这些参数介于0到1之间

217
00:12:51,980 --> 00:12:57,185
还会用到指数参数来保证这些是非负的

218
00:12:57,185 --> 00:13:01,245
因为0.9 0.5 这些必须是大于等于0的

219
00:13:01,245 --> 00:13:03,915
还有一些更高级的参数化

220
00:13:03,915 --> 00:13:05,457
效果会更好一些

221
00:13:05,457 --> 00:13:09,635
但我们所讲的这一种效果也不错

222
00:13:09,635 --> 00:13:14,775
所以 关于YOLO (You Only Lool Once)算法 我们就讲到这里

223
00:13:14,775 --> 00:13:17,115
在接下来的几个视频中 我会向你展示

224
00:13:17,115 --> 00:13:21,470
其他几种使得这个算法更优的想法

225
00:13:21,470 --> 00:13:23,170
同时 如果你愿意的话

226
00:13:23,170 --> 00:13:24,445
你可以读一下

227
00:13:24,445 --> 00:13:29,667
在前几页幻灯片的下方 我列出的关于YOLO算法的参考文献

228
00:13:29,667 --> 00:13:31,325
需要注意的是

229
00:13:31,325 --> 00:13:33,530
当你读这些论文(你会发现)

230
00:13:33,530 --> 00:13:37,425
YOLO的论文是较难读懂的论文之一

231
00:13:37,425 --> 00:13:40,265
我还记得我第一次读这些论文的时候

232
00:13:40,265 --> 00:13:43,325
我真的很难搞懂这些论文在说些什么

233
00:13:43,325 --> 00:13:46,356
于是我问了几个做研究很棒的朋友

234
00:13:46,356 --> 00:13:48,950
来帮我弄清楚

235
00:13:48,950 --> 00:13:53,125
甚至他们也很难理解这篇论文中的一些细节

236
00:13:53,125 --> 00:13:54,845
所以 当你读这篇文章

237
00:13:54,845 --> 00:13:58,195
并发现它很难理解 这都是正常的

238
00:13:58,195 --> 00:14:00,885
我希望这不那么常见

239
00:14:00,885 --> 00:14:02,795
但不幸的是 这并不少见

240
00:14:02,795 --> 00:14:05,130
即使是审阅论文的

241
00:14:05,130 --> 00:14:08,840
资深研究人员也很难完全理解其中的一些细节

242
00:14:08,840 --> 00:14:10,895
他们不得不查看源代码

243
00:14:10,895 --> 00:14:12,005
或者联系作者本人

244
00:14:12,005 --> 00:14:15,610
或通过其他的方式来弄清楚这些结果的细节

245
00:14:15,610 --> 00:14:19,715
但如果你想读的话 不要因问我刚才的话而退怯

246
00:14:19,715 --> 00:14:21,700
但这的确是一篇较难的文章

247
00:14:21,700 --> 00:14:25,975
所以 你现在已经理解了YOLO算法的基本概念

248
00:14:25,975 --> 00:14:31,000
让我们继续学习使得这个算法更优化的一些其他的部分