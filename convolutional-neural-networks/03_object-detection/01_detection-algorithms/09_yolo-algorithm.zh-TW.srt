1
00:00:00,000 --> 00:00:03,900
你已經見過了物件偵測大部分的要素

2
00:00:03,900 --> 00:00:06,690
在這部影片，讓我們集結所有要素

3
00:00:06,690 --> 00:00:10,850
組成 YOLO 物件偵測演算法

4
00:00:10,850 --> 00:00:14,130
首先，讓我們看看如何建造訓練集

5
00:00:14,130 --> 00:00:16,380
假設你想訓練演算法去偵測

6
00:00:16,380 --> 00:00:19,425
三種物件：路人、汽車和機車

7
00:00:19,425 --> 00:00:23,262
你不用特別把背景類別寫出來

8
00:00:23,262 --> 00:00:25,390
所以用這些標籤就好。

9
00:00:25,390 --> 00:00:28,305
如果你用兩個錨框

10
00:00:28,305 --> 00:00:33,495
那麼輸出 y 會是 3乘3 — 因為你用 3乘3 格子

11
00:00:33,495 --> 00:00:36,225
— 乘以2，這是錨框的數量

12
00:00:36,225 --> 00:00:39,880
— 乘以8，因為是這邊的維度

13
00:00:39,880 --> 00:00:45,650
8 其實是 5 再加上類別的數量

14
00:00:45,650 --> 00:00:49,533
而 5 是因為你有 p_c 還有邊界框

15
00:00:49,533 --> 00:00:53,505
這樣是 5；然後是 c_1, c_2, c_3

16
00:00:53,505 --> 00:00:56,340
— 這等於類別的數量。

17
00:00:56,340 --> 00:00:59,535
你可以把這看成是 3乘3乘2乘8

18
00:00:59,535 --> 00:01:03,310
或是 3乘3乘16。

19
00:01:03,310 --> 00:01:05,415
那麼，要建出訓練集

20
00:01:05,415 --> 00:01:11,160
你對於 9 個格子的每一格，做出適當的目標向量 y

21
00:01:11,160 --> 00:01:13,050
所以拿第一格

22
00:01:13,050 --> 00:01:16,470
這一格裡沒有值得偵測的東西

23
00:01:16,470 --> 00:01:19,410
行人汽車機車都沒有

24
00:01:19,410 --> 00:01:22,680
在左上角這格出現，所以

25
00:01:22,680 --> 00:01:27,870
這一格對應的目標 y 會等於這個

26
00:01:27,870 --> 00:01:31,276
其中第一個錨框的 p_c

27
00:01:31,276 --> 00:01:34,215
是 0，因為沒有任何物件和這個錨框有關聯

28
00:01:34,215 --> 00:01:37,830
第二個錨框也是 0

29
00:01:37,830 --> 00:01:42,355
所以其他的值都是「無關」。

30
00:01:42,355 --> 00:01:45,227
那麼，大部分的格子裡面都沒東西

31
00:01:45,227 --> 00:01:47,790
不過呢，對於那一個格子

32
00:01:47,790 --> 00:01:53,550
你會有這一個目標向量 y

33
00:01:53,550 --> 00:01:58,680
假設你的訓練資料對於這輛車有這樣的邊界框

34
00:01:58,680 --> 00:02:01,560
他稍微寬一點、不是高的

35
00:02:01,560 --> 00:02:04,005
所以如果你的錨框是這樣

36
00:02:04,005 --> 00:02:05,475
這是錨框1

37
00:02:05,475 --> 00:02:07,191
這是錨框2

38
00:02:07,191 --> 00:02:12,475
那麼這紅色框框跟錨框2的 IoU 比較大

39
00:02:12,475 --> 00:02:17,320
於是這輛車會連結到向量的下半部

40
00:02:17,320 --> 00:02:22,435
所以注意到錨框1的 p_c 是 0

41
00:02:22,435 --> 00:02:24,965
所以這邊都是「無關」

42
00:02:24,965 --> 00:02:28,005
然後，這個 p_c 等於 1

43
00:02:28,005 --> 00:02:33,390
然後你要用這些值代表紅色邊界框的位置

44
00:02:33,390 --> 00:02:38,820
然後，你要指定這物件的正確類別是類別2

45
00:02:38,820 --> 00:02:41,865
這是一輛車。

46
00:02:41,865 --> 00:02:44,010
所以你照這樣子做，對於

47
00:02:44,010 --> 00:02:47,485
9 格位置的每一格、3乘3格子的每一格

48
00:02:47,485 --> 00:02:50,085
你會算出像這樣的向量

49
00:02:50,085 --> 00:02:52,299
給出 16 維的向量，

50
00:02:52,299 --> 00:02:59,375
這就是為什麼最終的輸出容積是 3乘3乘16

51
00:02:59,375 --> 00:03:04,530
照例地為了簡便，我用的是 3乘3 的格子

52
00:03:04,530 --> 00:03:09,540
實務上這比較像是 19乘19乘16

53
00:03:09,540 --> 00:03:12,265
或者實際上，如果你使用更多錨框

54
00:03:12,265 --> 00:03:17,363
可能會是 19乘19乘5乘8 — 5乘8是40

55
00:03:17,363 --> 00:03:20,405
所以會是 19乘19乘40

56
00:03:20,405 --> 00:03:23,475
如果用五個錨框會是這樣。

57
00:03:23,475 --> 00:03:30,080
那麼，這就是訓練。你訓練一個 ConvNet，輸入一張圖

58
00:03:30,080 --> 00:03:32,395
可能是 100乘100乘3

59
00:03:32,395 --> 00:03:39,565
而 ConvNet 最後輸出這樣的容積，在我們的例子是

60
00:03:39,565 --> 00:03:43,204
3乘3乘16，或是 3乘3乘2乘8。

61
00:03:43,204 --> 00:03:47,505
接下來，讓我們看看你的演算法怎麼做預測

62
00:03:47,505 --> 00:03:53,445
給一張圖片，你的神經網路會輸出這 3乘3乘2乘8 的容積

63
00:03:53,445 --> 00:03:57,690
其中，九格的每一格會有像這樣的向量

64
00:03:57,690 --> 00:04:00,795
所以對於左上角的這格

65
00:04:00,795 --> 00:04:02,925
如果沒有物件

66
00:04:02,925 --> 00:04:06,150
希望你的神經網路會在這邊輸出 0

67
00:04:06,150 --> 00:04:08,990
這邊放 0，然後其他輸出某些值

68
00:04:08,990 --> 00:04:11,080
你的神經網路無法輸出問號

69
00:04:11,080 --> 00:04:12,540
沒辦法輸出「無關」項

70
00:04:12,540 --> 00:04:15,205
所以其餘的地方我會放某些數字

71
00:04:15,205 --> 00:04:17,400
不過基本上那些數字會被忽略

72
00:04:17,400 --> 00:04:20,580
因為神經網路告訴我們沒有物件

73
00:04:20,580 --> 00:04:23,910
所以無論輸出什麼邊界框、輸出是不是車，這些都不重要

74
00:04:23,910 --> 00:04:28,170
基本上就是某些數字，算是種噪音。

75
00:04:28,170 --> 00:04:32,370
相較之下，對於這一格，我們希望

76
00:04:32,370 --> 00:04:37,308
那一格輸出的 y 的值

77
00:04:37,308 --> 00:04:40,850
希望對於第一個邊界框會像是 0

78
00:04:40,850 --> 00:04:43,650
然後一堆數字、噪音

79
00:04:43,650 --> 00:04:47,880
然後希望，你也會輸出一些數字

80
00:04:47,880 --> 00:04:52,980
能夠準確地對應到車子的邊界框。

81
00:04:52,980 --> 00:04:56,970
這就是神經網路如何做預測。

82
00:04:56,970 --> 00:05:00,675
最後，你會跑過「抑制非最大值」

83
00:05:00,675 --> 00:05:02,240
為了更有趣

84
00:05:02,240 --> 00:05:04,740
我們來看一張新的測試圖片

85
00:05:04,740 --> 00:05:08,280
你會這樣子跑抑制非最大值：

86
00:05:08,280 --> 00:05:10,680
如果你用兩個錨框

87
00:05:10,680 --> 00:05:12,690
那麼對於九格中每一格

88
00:05:12,690 --> 00:05:15,445
你得到兩個預測的邊界框

89
00:05:15,445 --> 00:05:17,835
他們有一些會有非常低的機率

90
00:05:17,835 --> 00:05:20,760
非常低的 p_c，不過你仍然得到

91
00:05:20,760 --> 00:05:24,235
兩個邊界框的預測，對於這九格的每一格。

92
00:05:24,235 --> 00:05:27,540
所以假設這些是你拿到的邊界框

93
00:05:27,540 --> 00:05:30,060
注意到一些邊界框的長寬

94
00:05:30,060 --> 00:05:34,645
會超出他所在的格子。

95
00:05:34,645 --> 00:05:38,725
接下來，你丟掉機率低的預測

96
00:05:38,725 --> 00:05:41,635
丟掉那些神經網路覺得

97
00:05:41,635 --> 00:05:44,025
「天啊這物件大概不在這」的預測

98
00:05:44,025 --> 00:05:45,855
所以，丟掉那些。

99
00:05:45,855 --> 00:05:49,868
最後呢，如果你想偵測的類別有三種

100
00:05:49,868 --> 00:05:53,665
你想偵測行人、汽車跟機車

101
00:05:53,665 --> 00:05:56,655
你要做的是，對於三個類別的每一類

102
00:05:56,655 --> 00:05:59,760
各自獨立跑抑制非最大值

103
00:05:59,760 --> 00:06:03,010
跑在那些被預測成同一類的物件們

104
00:06:03,010 --> 00:06:07,620
對預測成路人的，做抑制非最大值

105
00:06:07,620 --> 00:06:10,080
對預測成汽車類別的，跑抑制非最大值

106
00:06:10,080 --> 00:06:13,100
對預測成機車類別的，跑抑制非最大值

107
00:06:13,100 --> 00:06:17,865
基本上跑過三次，生出最後的預測。

108
00:06:17,865 --> 00:06:20,970
這個輸出，我們希望你能偵測到

109
00:06:20,970 --> 00:06:25,465
這張圖裡所有的汽車和行人。

110
00:06:25,465 --> 00:06:29,170
那麼，這就是 YOLO 物件偵測演算法

111
00:06:29,170 --> 00:06:33,170
他是最有效的物件偵測演算法之一

112
00:06:33,170 --> 00:06:36,560
他也包含很多非常棒的想法

113
00:06:36,560 --> 00:06:41,275
包括眾多和物件偵測有關的電腦視覺文獻

114
00:06:41,275 --> 00:06:46,056
而現在，你有機會練習自己實作裡面很多的元件

115
00:06:46,056 --> 00:06:47,840
就在這禮拜的程式作業。

116
00:06:47,840 --> 00:06:51,520
所以我希望你能享受這禮拜的程式練習

117
00:06:51,520 --> 00:06:54,120
這部影片後還有一部選修的影片

118
00:06:54,120 --> 00:06:57,010
你可以選擇看或不看

119
00:06:57,010 --> 00:07:01,000
不過無論如何，我很期待我們下禮拜的見面