1
00:00:01,100 --> 00:00:02,740
こんにちは そしておかえりなさい

2
00:00:02,740 --> 00:00:05,368
今週は 物体検出について学ぶ

3
00:00:05,368 --> 00:00:08,980
それは ここ２～３年前で 急成長して

4
00:00:08,980 --> 00:00:12,460
非常にうまく 動くようになった コンピュータ ビジョンの１分野だ

5
00:00:12,460 --> 00:00:18,430
物体検出を作り上げるために 最初に学ぶのは 物体の位置決めだ

6
00:00:18,430 --> 00:00:20,595
その意味を定義することから始めよう

7
00:00:20,595 --> 00:00:25,760
あなたは 既に 画像分類には詳しいね
そのアルゴリズムは

8
00:00:25,760 --> 00:00:30,500
この写真を見て これは車だ と言う任を負っている

9
00:00:30,500 --> 00:00:31,920
これが分類だった

10
00:00:34,560 --> 00:00:38,964
このビデオの後の方で ニューラルネットワークの作り方を学ぶ問題は

11
00:00:38,964 --> 00:00:41,550
位置決め付きの分類だ

12
00:00:41,550 --> 00:00:45,659
つまり これは車だ とラベル付けするだけでなく

13
00:00:45,659 --> 00:00:49,758
アルゴリズムは 画像中の車の周りに

14
00:00:49,758 --> 00:00:55,090
境界箱を置いたり 赤い四角形を描いたりする必要がある

15
00:00:55,090 --> 00:00:59,310
だから これは 位置決め付き分類問題ということになる

16
00:00:59,310 --> 00:01:03,790
位置決めという用語は 写真のどこに

17
00:01:03,790 --> 00:01:05,760
見つけた車があるか ハッキリさせることだ

18
00:01:05,760 --> 00:01:09,530
今週後半で 検出問題について学ぶ

19
00:01:09,530 --> 00:01:13,590
その際は 複数の物体が写真の中にあって

20
00:01:13,590 --> 00:01:17,900
それらを全て検出し 位置を全て特定しなくてはならない

21
00:01:17,900 --> 00:01:21,820
もし これを 自動運転アプリケーションのために 行うのなら

22
00:01:21,820 --> 00:01:24,480
他の車を検出するだけでなく

23
00:01:24,480 --> 00:01:29,310
歩行者 バイク その他の物体も 検出しなくてはならないだろう

24
00:01:29,310 --> 00:01:31,090
それは 今週後半でね

25
00:01:31,090 --> 00:01:36,220
さて 今週使う用語では 分類と

26
00:01:36,220 --> 00:01:42,130
位置決め付き分類では 単独の物体を使う

27
00:01:42,130 --> 00:01:45,930
大抵は 画像の中央にある １つの大きな物体を

28
00:01:45,930 --> 00:01:47,600
検出するか 検出と位置決めを行うことになる

29
00:01:47,600 --> 00:01:53,150
対照的に 検出問題では 複数の物体がある

30
00:01:53,150 --> 00:01:57,450
実際 異なる分野の複数の物体になるだろう

31
00:01:57,450 --> 00:01:59,110
単一画像の中で

32
00:01:59,110 --> 00:02:03,195
画像分類について 学んできたアイデアは

33
00:02:03,195 --> 00:02:04,815
位置決め付きの分類に 有効だ

34
00:02:04,815 --> 00:02:06,885
それから 位置決めで学ぶアイデアが

35
00:02:06,885 --> 00:02:10,795
検出で有効だということも明らかになるだろう

36
00:02:10,795 --> 00:02:14,245
では 位置決め付き分類についての話から始めよう

37
00:02:15,255 --> 00:02:20,535
画像分類問題には 既に詳しいよね

38
00:02:20,535 --> 00:02:26,210
写真を 複数層の ConvNet に
我らの ConvNet に入力し

39
00:02:26,210 --> 00:02:31,348
結果は 特徴ベクトルとなり

40
00:02:31,348 --> 00:02:38,170
それを ソフトマックスユニットに喰わせて 予測クラスを出力する

41
00:02:38,170 --> 00:02:41,070
もし 自動運転車を作っているのなら

42
00:02:41,070 --> 00:02:44,370
多分 物体のカテゴリは 次のようだろう

43
00:02:44,370 --> 00:02:49,740
歩行者 車 バイク もしくは 背景

44
00:02:49,740 --> 00:02:51,660
これは 上のどれでも無いという意味だ

45
00:02:51,660 --> 00:02:53,160
つまり 歩行者も

46
00:02:53,160 --> 00:02:57,735
車も バイクも いない場合
出力は "背景" になるだろう

47
00:02:57,735 --> 00:03:03,755
４つのクラスがあるので ソフトマックスが４種類の出力を行う

48
00:03:03,755 --> 00:03:07,775
これは 標準的な分類パイプラインだ

49
00:03:07,775 --> 00:03:12,585
写真中の車の位置決めもしたい場合は どうだろう

50
00:03:12,585 --> 00:03:17,156
それを行うにのに ニューラルネットワークを変更して

51
00:03:17,156 --> 00:03:21,940
境界箱出力のための 出力ユニットを少し増やすことができる

52
00:03:21,940 --> 00:03:27,179
特に ニューラルネットワーク出力に 数を４つ多く持つことができる

53
00:03:27,179 --> 00:03:32,236
それらを bx by bh そして bw と呼ぼう

54
00:03:32,236 --> 00:03:40,110
この４つの数は 検出物体の境界箱を示すパラメータだ

55
00:03:40,110 --> 00:03:44,820
このビデオでは こんな表記を使うつもりだ

56
00:03:44,820 --> 00:03:49,610
画像の左上は 座標 (0, 0) と示す

57
00:03:49,610 --> 00:03:52,660
右下は (1, 1)

58
00:03:52,660 --> 00:03:55,442
よって 境界箱を指定する際は

59
00:03:55,442 --> 00:04:00,060
赤い箱を指定する際は 中央の点を指定する

60
00:04:00,060 --> 00:04:03,057
それは (bx, by) で

61
00:04:03,057 --> 00:04:08,193
高さは bh

62
00:04:08,193 --> 00:04:14,300
幅は bw だ
この境界箱のね

63
00:04:14,300 --> 00:04:19,868
そして 学習セットは 物体のクラスラベルだけでなく

64
00:04:19,868 --> 00:04:23,950
それは ニューラルネットワークが予測しようとしているものだけど

65
00:04:23,950 --> 00:04:26,740
４つの追加の数も含んでいる

66
00:04:26,740 --> 00:04:31,430
境界箱を与えてくれる数だ
教師有り学習を使って アルゴリズムが

67
00:04:31,430 --> 00:04:35,910
クラスラベルだけでなく ４つのパラメータも出力するようにする

68
00:04:35,910 --> 00:04:39,830
そして 検出した物体の境界箱がどこかを教えてくれる

69
00:04:39,830 --> 00:04:42,415
この例では 理想の bx は

70
00:04:42,415 --> 00:04:47,254
0.5 程だ なぜなら 画像の右に半分程度行った所にあるから

71
00:04:47,254 --> 00:04:55,863
by は 約 0.7 だろう なぜなら 70% 程下がった所にあるから

72
00:04:55,863 --> 00:05:00,620
bh は 約 0.3 だろう なぜなら この赤い四角の高さは

73
00:05:00,620 --> 00:05:04,960
画像全体の高さの 30% 程だから

74
00:05:04,960 --> 00:05:10,170
そして bw は 約 0.4 だろう なぜなら 赤い箱の

75
00:05:10,170 --> 00:05:14,510
幅が 画像全体の幅の 0.4 程度だからだ

76
00:05:15,940 --> 00:05:20,905
じゃあ どのように 目的ラベル y を定義するかということについて
これを ちょっと 定式化してみよう 

77
00:05:20,905 --> 00:05:24,581
教師有り学習のタスクとしてね

78
00:05:24,581 --> 00:05:29,195
覚えているだろうけど ４つのクラスがあって

79
00:05:29,195 --> 00:05:34,775
ニューラルネットワークによって 今度は この４つの数が クラスラベルと同じく 出力される

80
00:05:36,035 --> 00:05:39,195
クラスラベルは クラスの確率かもしれない

81
00:05:40,530 --> 00:05:47,710
目的ラベル y を次のように定義しよう

82
00:05:47,710 --> 00:05:53,480
それは ベクトルになる 最初の要素 Pc は

83
00:05:53,480 --> 00:05:54,560
物体があるか だ

84
00:05:55,930 --> 00:06:02,140
もし 物体が 分類 １ ２ もしくは３ なら Pc = 1 だ

85
00:06:02,140 --> 00:06:04,477
もし 背景なら

86
00:06:04,477 --> 00:06:09,018
つまり 検出しようとしている物体が存在しなければ Pc は 0 となる

87
00:06:09,018 --> 00:06:11,973
Pc は 物体の存在確率を

88
00:06:11,973 --> 00:06:15,020
表すと考えられる

89
00:06:15,020 --> 00:06:19,320
ここで 検出しようとしている クラスの何かである確率だ

90
00:06:19,320 --> 00:06:22,640
つまり 背景 以外のクラスだ

91
00:06:22,640 --> 00:06:28,338
次に もし 物体が存在するなら 検知した物体の

92
00:06:28,338 --> 00:06:35,010
境界箱 bx by bh そして bw

93
00:06:35,010 --> 00:06:40,436
そして 最後に もし 物体が存在するなら もし Pc = 1 なら

94
00:06:40,436 --> 00:06:44,054
c1 c2 そして c3 を出力して

95
00:06:44,054 --> 00:06:49,610
それが クラス１ クラス２ もしくは クラス３かを知らせて欲しい

96
00:06:49,610 --> 00:06:53,030
それが 歩行者か 車か バイクか だ

97
00:06:53,030 --> 00:06:56,340
我々が 注視している問題を思い起こせば

98
00:06:56,340 --> 00:06:59,450
画像には たった１つの物体が含まれている

99
00:06:59,450 --> 00:07:03,040
最大でも 写真には これらの物体の内の１つしかない

100
00:07:03,040 --> 00:07:06,490
この 位置決め付き分類問題ではね

101
00:07:06,490 --> 00:07:09,240
それじゃ 何個か例を見てみよう

102
00:07:09,240 --> 00:07:16,310
これが 学習セットの画像だ
これが x だとすると y は

103
00:07:16,310 --> 00:07:22,650
最初の要素 Pc は = 1 になる なぜなら 物体があるから
それから

104
00:07:22,650 --> 00:07:27,870
bx by by そして bw が 境界箱を示す

105
00:07:27,870 --> 00:07:32,260
よって ラベル付けした学習セットは ラベルとして 境界箱を必要とする

106
00:07:32,260 --> 00:07:35,570
それから 最後に これは車だ よって クラス２

107
00:07:35,570 --> 00:07:38,680
つまり C1 は 0 なぜなら これは 歩行者じゃないから

108
00:07:38,680 --> 00:07:44,640
c2 は 1 になる なぜなら 車だから
c3 は 0 になる なぜなら バイクじゃないから

109
00:07:44,640 --> 00:07:50,630
つまり c1 c2 そして c3 の中で 最大で １つが １ になる

110
00:07:50,630 --> 00:07:54,010
これが 画像に物体がある場合だ

111
00:07:54,010 --> 00:07:55,890
画像に物体が無い場合は どうなるだろう？

112
00:07:55,890 --> 00:07:59,957
この学習例の場合 x は何になるか？

113
00:07:59,957 --> 00:08:03,807
この場合 Pc は 0 と等しくなる

114
00:08:03,807 --> 00:08:08,979
残りの要素は

115
00:08:08,979 --> 00:08:13,940
気にしない つまり これら全てに ? マークを書く

116
00:08:13,940 --> 00:08:18,318
これは 気にしないということだ

117
00:08:18,318 --> 00:08:23,074
画像に物体が無ければ ニューラルネットワークが出力する境界箱がどうなるかも

118
00:08:23,074 --> 00:08:27,280
３つの物体 c1 c2 c3 のどれになるかも 気にしない

119
00:08:27,280 --> 00:08:33,870
ラベル付けした学習セットができた
これが x 入力画像 と

120
00:08:33,870 --> 00:08:38,680
y クラスラベルを

121
00:08:38,680 --> 00:08:42,880
物体がある時と 無い時の 両方の画像に対して 作る方法だ

122
00:08:42,880 --> 00:08:45,660
そして このセットが 学習セットを定義する

123
00:08:47,100 --> 00:08:51,520
最後に 次に 損失関数を定義しよう

124
00:08:51,520 --> 00:08:53,930
ニューラルネットワークの訓練に使うからね

125
00:08:53,930 --> 00:08:59,070
真値のラベルは y で ニューラルネットワークの出力は yハットだった

126
00:08:59,070 --> 00:09:01,010
損失はどうなるべきだろうか？

127
00:09:01,010 --> 00:09:05,484
ええと もし ２乗誤差を使うなら

128
00:09:05,484 --> 00:09:10,105
(y1ハット - y1) ^ 2

129
00:09:10,105 --> 00:09:15,026
+ (y2ハット - y2) ^ 2 + ...

130
00:09:15,026 --> 00:09:19,810
+ (y8ハット - y8) ^ 2

131
00:09:19,810 --> 00:09:23,970
ここでは y に ８つの要素があるよね

132
00:09:23,970 --> 00:09:28,200
だから 異なる要素の２乗の合計で こうなる

133
00:09:28,200 --> 00:09:33,650
これが y1 = 1 の時の損失だ

134
00:09:33,650 --> 00:09:36,690
つまり 物体がある場合のだ

135
00:09:36,690 --> 00:09:39,671
つまり y1 = Pc の時のだ

136
00:09:39,671 --> 00:09:43,685
Pc = 1 だ
画像中に物体があれば

137
00:09:43,685 --> 00:09:47,475
そうなら 損失は 全ての異なる要素の２乗和とすることができる

138
00:09:48,675 --> 00:09:53,418
もう１つの場合 もし y1 = 0 なら

139
00:09:53,418 --> 00:09:57,790
つまり もし Pc = 0 なら

140
00:09:57,790 --> 00:10:04,930
その場合は 損失は 単に (y1ハット - y1) ^ 2 としてよい

141
00:10:04,930 --> 00:10:11,170
なぜなら この２番目のケースでは
残りの要素全て 気にしなくてよいからだ

142
00:10:11,170 --> 00:10:16,068
気にすればよいのは この場合 どのくらい正確に ニューラルネットワークが

143
00:10:16,068 --> 00:10:19,390
Pc を出力するかということだけだ

144
00:10:19,390 --> 00:10:23,304
要は もし y1 = 1 この場合は

145
00:10:23,304 --> 00:10:28,343
２乗誤差を使うことができる
８つの要素の

146
00:10:28,343 --> 00:10:33,402
予測値と 真値から出した２乗偏差を課すことができる

147
00:10:33,402 --> 00:10:39,749
一方 y1 = 0 の時 ２番目では ８つの要素は気にしないで

148
00:10:39,749 --> 00:10:44,698
気にすればいいのは ニューラルネットワークが どのくらい正確に y1 を見積もれるかで

149
00:10:44,698 --> 00:10:48,880
それは Pc のことだ

150
00:10:48,880 --> 00:10:53,554
詳細を全て知りたい人用に ちょっとだけ追加のコメントを

151
00:10:53,554 --> 00:10:57,760
ここでは 記述を簡単にするため ２乗誤差を使った

152
00:10:57,760 --> 00:11:02,840
実際には 多分 c1 c2 c3 ソフトマックス出力には

153
00:11:02,840 --> 00:11:06,438
対数尤度 損失を使うだろう

154
00:11:06,438 --> 00:11:10,118
これらの要素の1つには 通常 ２乗誤差や

155
00:11:10,118 --> 00:11:14,414
２乗誤差のようなものを使う可能性がある 境界箱の座標にはね

156
00:11:14,414 --> 00:11:19,200
そして Pc には ロジスティック リグレッション損失のようなものを使うだろう

157
00:11:19,200 --> 00:11:22,830
でも ２乗誤差を使っても 多分 OK だ

158
00:11:22,830 --> 00:11:27,030
これが どのようにニューラルネットワークで 物体の分類だけでなく

159
00:11:27,030 --> 00:11:29,140
位置決めも行う方法だ

160
00:11:29,140 --> 00:11:33,270
ニューラルネットワーに 多くの実数を出力させるというアイデアは

161
00:11:33,270 --> 00:11:38,040
物が写真の中のどこになるか教える 非常に強力なアイデアだと分かる

162
00:11:38,040 --> 00:11:42,940
次のビデオでは この ニューラルネットワークに 一連の実数を出力させるというアイデア

163
00:11:42,940 --> 00:11:48,180
の使用例を いくつか共有したい
それは ほぼ回帰タスクとして

164
00:11:48,180 --> 00:11:51,980
コンピュータ ビジョンのあらゆる場所で 非常に強力に使われている

165
00:11:51,980 --> 00:11:53,360
では次のビデオにいきましょう