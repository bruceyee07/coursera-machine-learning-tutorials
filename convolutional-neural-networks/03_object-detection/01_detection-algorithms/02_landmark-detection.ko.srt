1
00:00:00,000 --> 00:00:01,440
이전 강의에서 여러분에게

2
00:00:01,440 --> 00:00:06,410
이전 강의에서는 신경망이 로컬라이즈 시켜야 할 객체의 바운딩박스를 지정하기 위해서

3
00:00:06,410 --> 00:00:08,850
bx, by, bh 및 bw의 네 가지

4
00:00:08,850 --> 00:00:12,840
숫자를 출력하여 신경망으로 아웃풋 시키는 방법을 살펴 보았습니다.

5
00:00:12,840 --> 00:00:14,753
좀 더 일반적인 경우에는,

6
00:00:14,753 --> 00:00:17,400
신경망이 이미지의 주요 지점을 X와

7
00:00:17,400 --> 00:00:20,700
Y 좌표를 아웃풋 하게 만들 수 있습니다,

8
00:00:20,700 --> 00:00:24,960
이걸 때로는 랜드마크라고 부립니다.

9
00:00:24,960 --> 00:00:26,451
몇 가지 예제를 보시죠.

10
00:00:26,451 --> 00:00:31,095
얼굴 인식 응용프로그램을 만들고 있다고 가정해봅시다.

11
00:00:31,095 --> 00:00:36,835
알고리즘이 사람 눈의 코너부분이 어디에 있는지를 인식하기를 원한다면,

12
00:00:36,835 --> 00:00:40,530
이 지점이 X, Y 좌표를 가지게 되죠.

13
00:00:40,530 --> 00:00:43,310
그래서 신경망에

14
00:00:43,310 --> 00:00:48,235
마지막 레이어가 생기도록 하고, 두 개의 숫자를 아웃풋 하도록 할 수 있습니다.

15
00:00:48,235 --> 00:00:51,804
사람 눈 모퉁이 부분의 좌표를 알려주는 것을

16
00:00:51,804 --> 00:00:56,730
lx 와 ly 라고 부르겠습니다.

17
00:00:56,730 --> 00:01:01,680
자, 두 눈의 네 모퉁이 전부를 알고 싶다면

18
00:01:01,680 --> 00:01:03,595
어떻게 해야 할까요?

19
00:01:03,595 --> 00:01:06,360
이 지점들을 왼쪽부터 오른쪽으로, 첫 번째, 두 번째,

20
00:01:06,360 --> 00:01:08,640
세 번째, 네 번째 라고 한다면,

21
00:01:08,640 --> 00:01:13,585
첫 번째 지점은 l1x 와 l1y 로,

22
00:01:13,585 --> 00:01:17,975
두 번째 지점은 l2x 와 l2y 등… 으로 아웃풋 하도록

23
00:01:17,975 --> 00:01:22,140
신경망을 수정할 수 있을 것입니다.

24
00:01:22,140 --> 00:01:25,015
그러면 신경망은 사람 얼굴의

25
00:01:25,015 --> 00:01:29,590
이 네 지점의 예상되는 위치를 아웃풋 할 수 있겠죠.

26
00:01:29,590 --> 00:01:31,500
하지만 네 가지 지점만 원하는 게 아니라면 어떨까요?

27
00:01:31,500 --> 00:01:33,195
만약 이 눈을 따라서 여기, 여기, 여기, 여기

28
00:01:33,195 --> 00:01:36,885
이 모든 지점을 아웃풋하고 싶다면 어떻게 해야 할까요?

29
00:01:36,885 --> 00:01:39,945
제가 입을 따라서 주요 지점들을 표시하면,

30
00:01:39,945 --> 00:01:44,205
여러분은 입 모양을 찾아내서 이 사람이 웃고 있는지 인상 쓰고 있는지 말할 수 있을 것입니다.

31
00:01:44,205 --> 00:01:47,250
아니면, 코의 가장자리를 따라서 주요 지점들을 찾아낼 수 있을 것입니다.

32
00:01:47,250 --> 00:01:50,175
하지만 몇 개 숫자들로 이것을 정의 내릴 수도 있을 텐데요

33
00:01:50,175 --> 00:01:57,080
우리의 논의를 위해서, 64개 지점, 즉 64개 랜드마크가 얼굴에 있다고 가정해보죠.

34
00:01:57,080 --> 00:02:02,020
얼굴 가장자리, 턱 선을 정의하는 데 도움이 되는 몇 가지 점도 있지만

35
00:02:02,020 --> 00:02:06,480
랜드마크 숫자를 선택하고

36
00:02:06,480 --> 00:02:11,415
이 모든 랜드마크를 포함하는 레이블 트레이닝 세트를 생성함으로써

37
00:02:11,415 --> 00:02:14,240
신경망이 어디에 주요 지점, 즉

38
00:02:14,240 --> 00:02:19,045
얼굴의 주요 랜드마크가 있는지 알려주도록 할 수 있습니다.

39
00:02:19,045 --> 00:02:21,305
인풋으로서의

40
00:02:21,305 --> 00:02:23,755
이 사람 얼굴 이미지가

41
00:02:23,755 --> 00:02:28,564
컨볼네트를 거쳐서 , 이 컨볼네트가

42
00:02:28,564 --> 00:02:32,160
피쳐 세트를 갖도록 하십시오.

43
00:02:32,160 --> 00:02:34,285
아마 얼굴에 수정사항이 있는지 없는지에 따라 아웃풋은 0 이나 1 이 될 것이고,

44
00:02:34,285 --> 00:02:40,605
또한 l1x, 그리고 l1y 이렇게 아웃풋하고

45
00:02:40,605 --> 00:02:48,675
이런 식으로 쭉 아래로 이어지다가 l64x 와 l64y 가 되게 하시면 됩니다.

46
00:02:48,675 --> 00:02:52,065
랜드마크라고 표시하려고 l을 사용하고 있습니다.

47
00:02:52,065 --> 00:02:59,905
이 예시는 129개의 아웃풋 유닛을 가지게 될 것입니다.

48
00:02:59,905 --> 00:03:02,005
하나는 얼굴인지 아닌지에 대한 것이고,

49
00:03:02,005 --> 00:03:04,020
64개 랜드마크가 있으면,

50
00:03:04,020 --> 00:03:05,520
64 x 2가 되므로

51
00:03:05,520 --> 00:03:09,600
128 + 1 아웃풋 유닛이 됩니다.

52
00:03:09,600 --> 00:03:14,450
이것은 얼굴 자체뿐만 아니라 그 위의 모든 랜드마크를 알려줄 수 있는 것이죠.

53
00:03:14,450 --> 00:03:19,225
따라서, 이것은 얼굴로부터 감정을 인식하기 위한

54
00:03:19,225 --> 00:03:25,020
기본적인 빌딩블럭입니다. 만약 스냅챗이나 다른 엔터테인먼트,

55
00:03:25,020 --> 00:03:28,635
그리고 스냅챗 사진들이 얼굴 위에 왕관을 그리고 다른 효과를 표현할 수 있는 것처럼

56
00:03:28,635 --> 00:03:33,635
AR 증강현실 필터들을 사용한다면 말이죠.

57
00:03:33,635 --> 00:03:36,565
얼굴에 이러한 랜드마크를 감지할 수 있으려면,

58
00:03:36,565 --> 00:03:41,949
얼굴이 휘어지게 한다던가, 사람에게 왕관이나 모자를 씌운다던 지, 다양한 특수 효과를 그려낼 수 있는

59
00:03:41,949 --> 00:03:48,125
컴퓨터 그래픽 효과를 위한 핵심 빌딩블럭이 있습니다.

60
00:03:48,125 --> 00:03:50,600
물론, 이렇게 네트워크를 다루기 위해서는

61
00:03:50,600 --> 00:03:52,995
레이블 트레이닝 세트가 필요할 것입니다.

62
00:03:52,995 --> 00:03:57,455
우리는 일련의 이미지들과 레이블 Y를 가지고 있습니다.

63
00:03:57,455 --> 00:04:00,350
여기엔 누군가 이 모든 랜드마크에

64
00:04:00,350 --> 00:04:04,925
수고스럽게 주석을 달아 줄 것입니다.

65
00:04:04,925 --> 00:04:11,870
마지막 예시입니다. 여러분이 사람의 포즈 감지에 관심이 있다면,

66
00:04:11,870 --> 00:04:17,110
가슴의 중간 지점, 왼쪽 어깨, 왼쪽 팔꿈치, 팔목 이런 부분 같은

67
00:04:17,110 --> 00:04:21,807
몇 가지 핵심 위치들을 정의 내릴 수 있을 것입니다.

68
00:04:21,807 --> 00:04:24,936
그리고 신경망이 사람의 포즈에도 핵심포인트를

69
00:04:24,936 --> 00:04:34,195
주석을 달도록 하십시오. 그리고 제가 주석을 달고 있는 이 지점들을

70
00:04:34,195 --> 00:04:36,743
신경망이 아웃풋 하도록 시키십시오.

71
00:04:36,743 --> 00:04:42,685
그렇게 하면 이 사람의 포즈를 신경망이 아웃풋 하도록 만들 수 있습니다.

72
00:04:42,685 --> 00:04:47,325
그리고 물론 그렇게 하기 위해서는,

73
00:04:47,325 --> 00:04:50,775
여러분은 이 랜드마크를 지정할 필요가 있습니다.

74
00:04:50,775 --> 00:04:55,395
l1x 와 l1y 가 가슴의 중간지점이고, 이런 식으로 아래로 내려가면

75
00:04:55,395 --> 00:05:01,840
32 좌표를 사용해서 사람의 포즈를 지정한다면, l32x와 l32y 가 되겠지요.

76
00:05:01,840 --> 00:05:06,690
따라서 이 아이디어는 인식하고자 하는 여러 랜드마크 X, Y 좌표를 아웃풋 하는 것이

77
00:05:06,690 --> 00:05:12,200
몇몇 아웃풋 유닛을 추가하는 것만큼이나 간단하게 보일 지도 모르겠습니다.

78
00:05:12,200 --> 00:05:16,290
명확하게 말하자면, 랜드마크 1의 정체는

79
00:05:16,290 --> 00:05:18,525
다른 이미지를 통틀어 일관성이 있어야만 합니다.

80
00:05:18,525 --> 00:05:21,368
랜드마크 1은 언제나 눈의 모퉁이 라던지,

81
00:05:21,368 --> 00:05:23,535
랜드마크 2는 언제나 이쪽 눈의 모퉁이 라던지,

82
00:05:23,535 --> 00:05:25,650
랜드마크 3, 랜드마크 4, 이런 식으로 말이죠.

83
00:05:25,650 --> 00:05:29,475
따라서 레이블들은 다른 이미지를 통틀어 일관적이어야만 합니다.

84
00:05:29,475 --> 00:05:34,350
하지만 레이블링 기계를 쓰거나 여러분 스스로 충분히 큰 데이터 세트를 레이블 한다면,

85
00:05:34,350 --> 00:05:38,368
신경망을 이 모든 랜드마크를 아웃풋 할 수 있습니다.

86
00:05:38,368 --> 00:05:43,440
그리고 이것은 사람의 포즈 같은 다른 흥미로운 효과를 수행하는 데에 사용되어 지기도 하고,

87
00:05:43,440 --> 00:05:47,935
사진만 가지고도 사람의 감정을 인식하는 데에도 사용될 것입니다.

88
00:05:47,935 --> 00:05:50,460
랜드마크 감지는 여기까지입니다.

89
00:05:50,460 --> 00:05:53,280
다음으로는 이 빌딩블럭을

90
00:05:53,280 --> 00:05:56,280
객체 인식 구현을 시작할 수 있게 하는데 사용해 보도록 하겠습니다.