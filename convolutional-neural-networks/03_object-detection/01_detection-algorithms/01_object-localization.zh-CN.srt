1
00:00:01,100 --> 00:00:02,740
大家好 欢迎回来

2
00:00:02,740 --> 00:00:05,368
这周我们学习对象检测

3
00:00:05,368 --> 00:00:08,980
这是计算机视觉中的一个极速发展的领域，

4
00:00:08,980 --> 00:00:12,460
效果比几年前好很多。

5
00:00:12,460 --> 00:00:18,430
为了建立对象检测，你需要先学习对象定位。

6
00:00:18,430 --> 00:00:20,595
我们先来看一下定义。

7
00:00:20,595 --> 00:00:25,760
你已经对图像分类有所了解，

8
00:00:25,760 --> 00:00:30,500
图像分类的这种算法可以，比如，通过这张图片，识别出这是辆车。

9
00:00:30,500 --> 00:00:31,920
这就是图像分类。

10
00:00:34,560 --> 00:00:38,964
在接下来的视频中，要解决的问题是学习建立网络，

11
00:00:38,964 --> 00:00:41,550
即分类并定位。

12
00:00:41,550 --> 00:00:45,659
意味着你不仅仅要识别出，比如这辆车，

13
00:00:45,659 --> 00:00:49,758
并且算法也负责生成一个边框，

14
00:00:49,758 --> 00:00:55,090
或者是在图中车的周围画一个红色矩形。

15
00:00:55,090 --> 00:00:59,310
这就是所谓的分类并定位问题。

16
00:00:59,310 --> 00:01:03,790
在这里，术语“定位“指的是在这个图片中，

17
00:01:03,790 --> 00:01:05,760
找到你检测到的车的位置。

18
00:01:05,760 --> 00:01:09,530
这周后面，你会学到对象检测，

19
00:01:09,530 --> 00:01:13,590
如何检测在一张图片里的多个对象，

20
00:01:13,590 --> 00:01:17,900
你必须能够把它们全部检测出来并且定位它们。

21
00:01:17,900 --> 00:01:21,820
如果你做这个是为自动驾驶应用，

22
00:01:21,820 --> 00:01:24,480
那么你可能需要检测的就不仅仅是其他车辆，

23
00:01:24,480 --> 00:01:29,310
还有其他可能的行人和摩托车，甚至其他的一些对象。

24
00:01:29,310 --> 00:01:31,090
这周后面你会了解到这些。

25
00:01:31,090 --> 00:01:36,220
所以在我们这周所用的术语中，对于图像分类

26
00:01:36,220 --> 00:01:42,130
和分类并定位问题，通常他们只有一个对象。

27
00:01:42,130 --> 00:01:45,930
通常是你要识别一个图片正中央的一个明显的对象。

28
00:01:45,930 --> 00:01:47,600
或者识别并定位。

29
00:01:47,600 --> 00:01:53,150
相比之下，在对象检测问题中，可能会有很多对象。

30
00:01:53,150 --> 00:01:57,450
事实上，可能是来自多个不同的类别的多个对象，

31
00:01:57,450 --> 00:01:59,110
都出现在一张图片中。

32
00:01:59,110 --> 00:02:03,195
你在图像分类中学习的方法将会对

33
00:02:03,195 --> 00:02:04,815
分类并定位也有用处。

34
00:02:04,815 --> 00:02:06,885
然后你学习到的定位的方法，

35
00:02:06,885 --> 00:02:10,795
将会对物体检测有帮助。

36
00:02:10,795 --> 00:02:14,245
所以让我们来了解一下图像分类并定位。

37
00:02:15,255 --> 00:02:20,535
你已经对图像分类有所了解，你可能

38
00:02:20,535 --> 00:02:26,210
在多层卷积网络中输入一张图片，

39
00:02:26,210 --> 00:02:31,348
这会导致我们的卷积网络有一个特征向量，

40
00:02:31,348 --> 00:02:38,170
将特征向量传给一个可能是softmax，输出预测的结果。

41
00:02:38,170 --> 00:02:41,070
所以，如果你要制作一辆自动驾驶的车辆，

42
00:02:41,070 --> 00:02:44,370
那么你的对象类别有以下几项，

43
00:02:44,370 --> 00:02:49,740
有行人，车辆，摩托车，或者一个背景环境。

44
00:02:49,740 --> 00:02:51,660
背景将不属于上面的任何一类。

45
00:02:51,660 --> 00:02:53,160
所以如果没有行人，

46
00:02:53,160 --> 00:02:57,735
没有车，没有摩托，那么你就只有输出背景。

47
00:02:57,735 --> 00:03:03,755
所以，这些是你的分类类别，他们是一个有四个结果的softmax。

48
00:03:03,755 --> 00:03:07,775
这就是标准的图像分类流程。

49
00:03:07,775 --> 00:03:12,585
如果你也想要定位图中的汽车，

50
00:03:12,585 --> 00:03:17,156
为了实现这个，你可以改变你的神经网络，

51
00:03:17,156 --> 00:03:21,940
通过得到更多的输出单位，使得这个神经网络可以输出一个边框。

52
00:03:21,940 --> 00:03:27,179
所以，具体地说，你的神经网络要输出额外4个数字，

53
00:03:27,179 --> 00:03:32,236
我们可以叫他们bx，by，bh和bw。

54
00:03:32,236 --> 00:03:40,110
这四个数字将确定检测对象的边框的参数。

55
00:03:40,110 --> 00:03:44,820
所以在这个系列的视频中，我会使用以下的符号表达方式，

56
00:03:44,820 --> 00:03:49,610
图片左上角，我会标为坐标（0，0),

57
00:03:49,610 --> 00:03:52,660
右下角标为(1，1)。

58
00:03:52,660 --> 00:03:55,442
所以，为了指定图中红色长方形边框，

59
00:03:55,442 --> 00:04:00,060
我们需要指定边框的中点。

60
00:04:00,060 --> 00:04:03,057
所以我们需要点bx，by

61
00:04:03,057 --> 00:04:08,193
和高度，bh (h＝height)，

62
00:04:08,193 --> 00:04:14,300
还有宽度，bw (w＝width)。

63
00:04:14,300 --> 00:04:19,868
所以如果你的训练集不仅仅是包含对象列别标签，

64
00:04:19,868 --> 00:04:23,950
就是神经网络需要预测的内容，而且

65
00:04:23,950 --> 00:04:26,740
也包含4个额外的数字。

66
00:04:26,740 --> 00:04:31,430
给出边界框，你可以用监督式学习来让你的算法

67
00:04:31,430 --> 00:04:35,910
输出不仅仅是类标签，还有4个变量

68
00:04:35,910 --> 00:04:39,830
来告诉你所检测到的对象的边界框。

69
00:04:39,830 --> 00:04:42,415
所以，在这个例子中，理想的bx可能

70
00:04:42,415 --> 00:04:47,254
大约是0.5，因为这个大约是到图片右边的一半。

71
00:04:47,254 --> 00:04:55,863
by可能大约0.7。因为这个大约距离图片下方70%。

72
00:04:55,863 --> 00:05:00,620
bh可能大约0.3因为这个红色矩形的高度

73
00:05:00,620 --> 00:05:04,960
大约占是整个图片的30%。

74
00:05:04,960 --> 00:05:10,170
bw可能大约是0.4，比如因为红色的方框的宽度

75
00:05:10,170 --> 00:05:14,510
大约占整体图片的40%。

76
00:05:15,940 --> 00:05:20,905
所以再形式化一点，根据我们如何定义目标标签

77
00:05:20,905 --> 00:05:24,581
y作为监督氏学习任务。

78
00:05:24,581 --> 00:05:29,195
稍微提示一下，这些是4个类，

79
00:05:29,195 --> 00:05:34,775
神经网络现在可以输出这4个数字，还有类标签，

80
00:05:36,035 --> 00:05:39,195
或者是类标签的概率。

81
00:05:40,530 --> 00:05:47,710
所以，目标标签y的定义如下。

82
00:05:47,710 --> 00:05:53,480
会是个向量

83
00:05:53,480 --> 00:05:54,560
那是否有个对象？

84
00:05:55,930 --> 00:06:02,140
所以，如果对象是，类1，2或者3，pc会等于1。

85
00:06:02,140 --> 00:06:04,477
并且如果这个是背景类的话，那么

86
00:06:04,477 --> 00:06:09,018
即没有包含任何你需要检测的类别

87
00:06:09,018 --> 00:06:11,973
你可以把pc想成代表

88
00:06:11,973 --> 00:06:15,020
这里包含一个对象的概率。

89
00:06:15,020 --> 00:06:19,320
你努力检测的其中一个类在的概率。

90
00:06:19,320 --> 00:06:22,640
即除背景类之外的其他东西。

91
00:06:22,640 --> 00:06:28,338
其次，如果有一个对象，你想要输出bx,

92
00:06:28,338 --> 00:06:35,010
by,bh和bw，你所检测的对象的边界框。

93
00:06:35,010 --> 00:06:40,436
最后，如果确实有一个对象，所以如果pc等于1，

94
00:06:40,436 --> 00:06:44,054
你也想输出c1,c2和

95
00:06:44,054 --> 00:06:49,610
c3,这些告诉我们是类1，类2或者类3。

96
00:06:49,610 --> 00:06:53,030
所以这是一个行人，一辆汽车或者摩托车。

97
00:06:53,030 --> 00:06:56,340
记住在我们解决的问题中，

98
00:06:56,340 --> 00:06:59,450
我们假定你的图片只有一个对象。

99
00:06:59,450 --> 00:07:03,040
即在分类并定位的问题中，

100
00:07:03,040 --> 00:07:06,490
最多有其中的一个对象出现在图片中

101
00:07:06,490 --> 00:07:09,240
让我们来看一些例子

102
00:07:09,240 --> 00:07:16,310
如果这是一个训练集合图像，所以如果这是x,那么y将是

103
00:07:16,310 --> 00:07:22,650
第一个部分的pc将等于1，因为有个对象，bx,by,

104
00:07:22,650 --> 00:07:27,870
bh,和bw将标出边界框。

105
00:07:27,870 --> 00:07:32,260
所以你标记的训练集需要在标签上的边界框。

106
00:07:32,260 --> 00:07:35,570
最后这是一辆车，所以是类2。

107
00:07:35,570 --> 00:07:38,680
所以c1将是0因为这不是行人。

108
00:07:38,680 --> 00:07:44,640
c2会是1因为这是车，c3会是0因为这不是摩托车。

109
00:07:44,640 --> 00:07:50,630
所以在c1,c2和c3中，最多有一个会是等于1。

110
00:07:50,630 --> 00:07:54,010
这是针对图中有一个对象的情况。

111
00:07:54,010 --> 00:07:55,890
如果图中没有对象呢？

112
00:07:55,890 --> 00:07:59,957
如果我们有个训练的例子，x等于这种情况？

113
00:07:59,957 --> 00:08:03,807
这种情况下，pc会等于0，并且

114
00:08:03,807 --> 00:08:08,979
其余的元素，都会是不关紧要的，

115
00:08:08,979 --> 00:08:13,940
所以我会写个？在剩下的元素。

116
00:08:13,940 --> 00:08:18,318
所以这是一个无关紧要，因为如果图中没有对象，

117
00:08:18,318 --> 00:08:23,074
那么你无需关心神经网络输出的边界框是什么，也不会关心

118
00:08:23,074 --> 00:08:27,280
这3个对象，c1,c2,c3会是什么。

119
00:08:27,280 --> 00:08:33,870
所以给一系列的训练例子，这就是你如何构造x,

120
00:08:33,870 --> 00:08:38,680
输入图片以及y，类别标签，对于

121
00:08:38,680 --> 00:08:42,880
图片中有一个对象和图片中没有对象的情况。

122
00:08:42,880 --> 00:08:45,660
这个的集合定义了你的训练集。

123
00:08:47,100 --> 00:08:51,520
最后，下面介绍你所用来训练神经网络的

124
00:08:51,520 --> 00:08:53,930
损失函数。

125
00:08:53,930 --> 00:08:59,070
所以准确标签是y,神经网络输出的y^。

126
00:08:59,070 --> 00:09:01,010
那么损失什么？

127
00:09:01,010 --> 00:09:05,484
如果你用的是均方差（squared error）

128
00:09:05,484 --> 00:09:10,105
那么损失会是(y1^-y1)2

129
00:09:10,105 --> 00:09:15,026
+(y2^-y2)2+

130
00:09:15,026 --> 00:09:19,810
...+(y8^-y8)2.

131
00:09:19,810 --> 00:09:23,970
注意这里的y有8个部分。

132
00:09:23,970 --> 00:09:28,200
所以这些是元素平方差的和。

133
00:09:28,200 --> 00:09:33,650
这就是损失，如果y1=1.

134
00:09:33,650 --> 00:09:36,690
这是确实有对象的情况。

135
00:09:36,690 --> 00:09:39,671
所以y1=pc.

136
00:09:39,671 --> 00:09:43,685
所以，pc=1，那么图片中有一个对象

137
00:09:43,685 --> 00:09:47,475
那么损失值是元素平方差之和。

138
00:09:48,675 --> 00:09:53,418
另外一种情况，如果y1=0,

139
00:09:53,418 --> 00:09:57,790
所以如果pc=0

140
00:09:57,790 --> 00:10:04,930
这种情况下，损失值只是(y1^-y1)2,

141
00:10:04,930 --> 00:10:11,170
因为在第二种情况下，剩余的元素都是无所谓的。

142
00:10:11,170 --> 00:10:16,068
所以你所要关注的就是神经网络

143
00:10:16,068 --> 00:10:19,390
输出的pc有多准确。

144
00:10:19,390 --> 00:10:23,304
所以小总结以下，如果y1=1,这种情况下，

145
00:10:23,304 --> 00:10:28,343
你可以用均方差penalize预测的平方偏差

146
00:10:28,343 --> 00:10:33,402
并且从8个组件的数据输出。

147
00:10:33,402 --> 00:10:39,749
然而如果y1=0,那么从第二个到第八个元素我都不关心。

148
00:10:39,749 --> 00:10:44,698
你所要关心的就是神经网络预测y1

149
00:10:44,698 --> 00:10:48,880
有多准确，也就是y1=pc的准确度。

150
00:10:48,880 --> 00:10:53,554
仅是作为一个侧论，对于那些想要知道更多细节的，

151
00:10:53,554 --> 00:10:57,760
我在这用均方差是为了简化描述。

152
00:10:57,760 --> 00:11:02,840
在现实中，你也可能用log likelihood特征损失

153
00:11:02,840 --> 00:11:06,438
对于c1,c2,c3 softmax输出。

154
00:11:06,438 --> 00:11:10,118
其中之一的元素，你通常可以用均方差或者

155
00:11:10,118 --> 00:11:14,414
一些类似均方差针对边界框的坐标，并且

156
00:11:14,414 --> 00:11:19,200
如果pc你可以用类似逻辑回归损失。

157
00:11:19,200 --> 00:11:22,830
而且即使你只是用均方差，效果可能也是不错的

158
00:11:22,830 --> 00:11:27,030
所以这就是你如何运用神经网络来分类一个对象，也可以用来

159
00:11:27,030 --> 00:11:29,140
定位它。

160
00:11:29,140 --> 00:11:33,270
让神经网络输出一堆数字的想法

161
00:11:33,270 --> 00:11:38,040
可以告诉你图片中的东西位置，被证明是一个非常强大的想法。

162
00:11:38,040 --> 00:11:42,940
在下一个教程，我会和你

163
00:11:42,940 --> 00:11:48,180
分享一些让神经网络输出一系列数字想法的其他应用，几乎相当于回归任务，

164
00:11:48,180 --> 00:11:51,980
强大到也可以应用到计算机视觉的其他地方。

165
00:11:51,980 --> 00:11:53,360
让我们继续下一期教程