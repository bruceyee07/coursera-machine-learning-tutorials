哈囉！歡迎回來 這禮拜你會學到物件偵測 (object detection) 這是電腦視覺這幾年來 其中一個百花齊放、進步許多的領域 為了要作到物件偵測，你得先學物件定位 (object localization) 讓我們先從定義來談起 你已經對圖片分類很熟了吧：有個演算法 看了這圖片後，會說這是一輛車 所以這是分類 (classification) 而等等你會學到用神經網路來解決另個問題： 分類且定位 (classification with localization) 也就是，你不但要標示這是車， 演算法還需要放一個「邊界框」(bounding box) 也就是在車子的所在周圍畫一個紅色的長方形 所以這問題叫「分類且定位」 「定位」(localization) 意味著，去尋找你偵測到的車子 是在圖片的哪裡 這禮拜後面你會學到「偵測」(detection) 的問題 也就是一張圖片可能有多個物件 你必須全部偵測出來，而且全部定位之。 如果你要做自動駕駛車的應用 那你不但要偵測出車子 也可能要偵測路人、機車、甚至其他物體 之後你在這禮拜會看到。 那麼，以我們這禮拜的術語 「分類」和「分類且定位」通常有一個物件 通常是一個大的物件，在圖片的中間 你想辨認且定位之 相比之下，在「偵測」的問題裡，會有多個物件 實際上甚至是不同類別的多個物件 就在同一張圖片內 因此，你在圖片「分類」所學到的概念，會有助於 「分類且定位」， 而你在「分類且定位」學到的 實際上也會對「偵測」有用。 所以，就讓我們先談談分類且定位 你已經對圖片分類的問題很熟了 你可能把一張圖片餵進很多層的 ConvNet
— 這個是我們的 ConvNet 然後結果會是一個特徵的向量， 可能餵給一個 Softmax，來輸出預測的類別 所以如果你在做自駕車 你物件的分類可能會像這樣 你可能有路人、汽車、機車，或是背景 也就是以上皆非 所以如果也沒人 也沒車沒機車，那你會輸出「背景」 所以分類有這四個，你的 Softmax 會有四個可能的輸出 那麼，這是標準的分類流程 如果你也想定位圖片中的車子，該怎麼做呢？ 要做的話，你可以改變你的神經網路 讓他多幾個輸出單元，來輸出一個邊界框 (bounding box) 特別是，你可以讓神經網路多輸出四個數字 我要叫他們 b_x, b_y, b_h 和 b_w 這四個數字描繪了要找的物件的邊界框 那麼在課堂的影片中，我會用這樣的慣例： 圖片左上角是座標 (0,0) 而右下角是 (1,1) 要指定邊界框 這紅色長方形的話，你需要指定中間點 這點是 (b_x, b_y)， 而且你還需要邊界框的 高度 b_h、和寬度 b_w。 所以，如果你的訓練資料不但含有物件的類別 — 就是神經網路的這個點想預測的 — 也包含了額外四個數字來表示邊界框 這樣的話你就能用監督式學習，來讓你的演算法 輸出類別以及四個參數 來告訴你偵測到的物件的邊界框在哪裡 那麼，在這個例子，理想上 b_x 應該是 0.5 因為這大概是圖片中的一半 b_y 大概是 0.7，因為這大概是圖片往下約 70% 之處 b_h 大概是 0.3，因為紅色長方形的高 大約是整張圖片的 30% 而 b_w 大概是 0.4，因為它的寬度 紅色長方形的寬大約是整張圖片寬的 0.4 倍 那麼，讓我們更正式一點，來定義目標的標籤 y 在這個監督式學習的問題中。 提醒一下，這是我們的四個類別 而神經網路會輸出這4個數字、以及類別 或者可能是這些類別的機率 所以我們定義目標標籤 y 如下： 這會是個向量，第一項 p_c 會是 「有沒有物件呢？」 所以如果物件屬於類別 1, 2 或 3，p_c 會等於 1 如果是背景類別 如果你想偵測的物件都不在，那 p_c 會是 0 你可以想做 p_c 是表示 會有物件的機率 有你想要偵測的類別的機率 也就是除了「背景」類別以外的。 接下來，如果有物件，那你要輸出 b_x, b_y, b_h 和 b_w，也就是物件的邊界框 最後，如果有物件，p_c 等於 1 時 你也要輸出 c_1, c_2 和 c_3 表示這是類別 1, 2 還是 3 也就是路人、汽車或機車呢 請記得在我們的問題中 我們假設圖片裡面只有一個物件 圖片中最多只會出現一個這裡的物件 如果是分類且定位的問題 那讓我們來看幾個例子： 如果這是訓練資料的一張圖，如果這是 x，那麼 y 就會是 第一維 p_c 會等於 1，因為有物件。然後 b_x, b_y b_h 和 b_h 表示著邊界框 所以訓練資料的標籤必須含有邊界框 最後，這是輛汽車，是類別 2 所以 c_1 會是 0，因為不是行人； c_2 是 1，因為是汽車；c_3 會是 0，因為不是機車 所以 c_1, c_2, c_3 當中，最多只有一個會是 1 那麼，這是當圖片有一個物件的時候 那如果沒有物件的時候呢？ 萬一你的訓練資料 x 等於這個呢？ 在這樣情況下，p_c 會等於 0 而剩下其他的維度會是「無關」(don't cares) 所以我把他們都填問號 所以這是 don't care (無關)，因為如果沒物件 那麼無論你的神經網路輸出什麼邊界框 無論認為是 c_1, c_2, c_3 的哪一種，這都是沒有關係的 所以給定一個有標籤的訓練集，你就根據這樣建出 x， 輸入的圖片，以及 y，類別的標籤 無論圖片裡有物件還是沒有物件 這一堆的集合，就會是你的訓練集 最後呢，讓我們描述你訓練這個 神經網路時，所用的損失函數 (loss function) 假設正確答案的標籤是 y，而神經網路輸出某個 y hat 損失是多少呢？ 如果你用平方誤差 那損失會是 (y hat_1 - y_1)平方 加 (y hat_2 - y_2)平方... 加 (y hat_8 - y_8)平方 注意到我們有八個元素 所以這是每個維度差異的平方和 如果 y_1 = 1，這就是損失 也就是有物件的情況下 y_1 是 p_c 所以 p_c = 1 表示圖片有個物件 那麼損失會是各個維度差異的平方和 另外一個情況是，如果 y_1 = 0 也就是如果 p_c 是 0 在這情況下，損失只有 (y hat_1 - y_1) 的平方 因為在這第二個例子，其他的維度都「無關」 所以在這例子唯一有關係的，是神經網路 能多準確輸出 p_c 回顧一下，如果 y_1 = 1，是這個例子 那你可以用平方誤差來懲罰 預測值和真正答案所有 8 個元素的差異 而如果 y_1 = 0，那從第 2 到第 8 個元素是什麼都沒關係 所以唯一有關的是你的神經網路 估計 y_1 能夠多準，也就是 p_c 如果你想知道細節的話，這只是題外話 我用平方誤差的原因單純是為了簡單起見 實務上你或許可拿對數似然 (log likelihood) 損失 用在 softmax 輸出項 c_1, c_2, c_3 上； 而邊界框座標的這幾項 你通常可以用平方誤差； 至於 p_c，你可以用像是羅吉斯回歸損失
(logistic regression loss) 雖然就算你用平方誤差的話，應該也能有不錯的表現 所以這就是如何用神經網路來分類物件 而且還能定位之 這個概念 — 關於神經網路輸出一堆數字 來表示東西在圖片何處 — 這個概念其實非常厲害 在下一部影片，我想分享其他可以使用這概念的情況 也就是神經網路輸出一堆實數，像是個迴歸問題 這種在電腦視覺其他問題上也非常有用 讓我們進入下一段影片