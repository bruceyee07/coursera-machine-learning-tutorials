1
00:00:03,576 --> 00:00:06,447
嗨，Yann，長久以來您一直是深度學習的領導者

2
00:00:06,447 --> 00:00:08,730
非常感謝您來一起聊聊，>> 謝謝

3
00:00:08,730 --> 00:00:09,852
讓我有這個機會

4
00:00:09,852 --> 00:00:12,820
您已經在神經網路上工作很久

5
00:00:12,820 --> 00:00:17,260
我想要知道您個人的故事，您如何開始從事人工智慧

6
00:00:17,260 --> 00:00:22,097
您是如何開始從事神經網路？>>我一直對於

7
00:00:22,097 --> 00:00:27,957
智慧很有興趣，人類本身的智慧

8
00:00:27,957 --> 00:00:32,127
從小對於人類的演化很有興趣

9
00:00:32,127 --> 00:00:33,060
>>在法國時？

10
00:00:33,060 --> 00:00:33,862
>>是的，在法國時

11
00:00:33,862 --> 00:00:37,690
我在中學時

12
00:00:37,690 --> 00:00:42,484
我對於工程，太空等等都有興趣

13
00:00:42,484 --> 00:00:44,840
我最喜歡的電影是 2001 太空漫遊 (2001: Space Odyssey)

14
00:00:44,840 --> 00:00:48,438
您有智慧機器，太空旅行跟

15
00:00:48,438 --> 00:00:53,495
人類進化這些東西，令我著迷

16
00:00:53,495 --> 00:00:57,160
智慧機器的概念很吸引我

17
00:00:57,160 --> 00:01:00,820
然後我學習了電機工程

18
00:01:00,820 --> 00:01:05,086
當我在學校時，我在工程學院的二年級時

19
00:01:05,086 --> 00:01:08,554
無意中看了一本書，其實是哲學的書

20
00:01:08,554 --> 00:01:14,181
是有關介於 Noam Chomsky 麻省理工學院的計算語言學者

21
00:01:14,181 --> 00:01:18,112
跟 Jean Piaget 一位心理認知科學家

22
00:01:18,112 --> 00:01:22,210
瑞士兒童發展心理學家的議論

23
00:01:22,210 --> 00:01:25,934
基本上是有關先天與後天的爭論

24
00:01:25,934 --> 00:01:31,026
而 Chomsky 認為語言有很多的先天的結構

25
00:01:31,026 --> 00:01:34,220
而 Piaget 認為很多是學習而來的

26
00:01:34,220 --> 00:01:40,218
而在 Piaget 這邊節錄了一個人的說法

27
00:01:40,218 --> 00:01:48,670
每一邊的人都找了一堆人來為自己這邊辯護

28
00:01:48,670 --> 00:01:53,280
在 Piaget 這邊找來了麻省理工的 Seymour Papert

29
00:01:53,280 --> 00:01:57,382
他在感知模型上用了第一個可以跑的機器

30
00:01:57,382 --> 00:02:00,273
我從來沒聽說過感知器，但當我讀了這篇文章說

31
00:02:00,273 --> 00:02:02,535
機器可以跑，聽起來很棒

32
00:02:02,535 --> 00:02:07,011
所以我開始到幾個大學圖書館，尋找

33
00:02:07,011 --> 00:02:11,926
任何有關於感知器的相關知識，發現到

34
00:02:11,926 --> 00:02:16,615
在 50 年代有很多論文，但似乎在 60 年代中斷了

35
00:02:16,615 --> 00:02:20,480
找到一本書由 Seymour Papert  一起合著的

36
00:02:20,480 --> 00:02:21,490
>> 是哪一年？

37
00:02:21,490 --> 00:02:22,792
>> 是 1980年

38
00:02:22,792 --> 00:02:23,920
大約吧？

39
00:02:23,920 --> 00:02:28,470
>> 所以我做了幾個專案跟

40
00:02:28,470 --> 00:02:32,060
一些數學教授在學校的時候，做一些基本的神經網路

41
00:02:32,060 --> 00:02:35,118
但那時候我找不到
做這種工作的人可以談

42
00:02:35,118 --> 00:02:38,596
因為基本上這個領域在那時候中斷了

43
00:02:38,596 --> 00:02:40,616
自從 1980 年，沒有人做這方面的研究

44
00:02:42,791 --> 00:02:45,363
自己嘗試了一下

45
00:02:45,363 --> 00:02:50,740
寫一些不同種類的模擬軟體，讀一些神經科學

46
00:02:52,090 --> 00:02:58,120
當我完成工程學位時，我學的是晶片設計

47
00:02:58,120 --> 00:03:01,710
那時我擅長的是半導體設計，所以跟現在完全不同

48
00:03:01,710 --> 00:03:05,340
當我完成時，我真的想要研究這方面

49
00:03:05,340 --> 00:03:09,442
我發現到那時候最重要的問題是您如何訓練

50
00:03:09,442 --> 00:03:10,630
多層的神經網路

51
00:03:10,630 --> 00:03:15,152
在 60 年代的論文中相當清楚
說明了那是最重要的

52
00:03:15,152 --> 00:03:20,040
問題還未解決，有關階層跟所有的觀念

53
00:03:20,040 --> 00:03:24,152
我讀過 Fukushima (福島）的 Neocognitron 論文

54
00:03:24,152 --> 00:03:29,951
是一種階層的架構非常類似於今日

55
00:03:29,951 --> 00:03:36,765
稱為卷積網路的，但沒有真正的反向傳播學習演算法

56
00:03:36,765 --> 00:03:43,822
我認識了在法國一個小的獨立俱樂部的一些人

57
00:03:43,822 --> 00:03:47,796
他們對於當時稱為自動機 (Automata) 網路很有興趣

58
00:03:47,796 --> 00:03:50,040
他們給我一些論文

59
00:03:50,040 --> 00:03:54,782
一些功能網路(functional networks)論文，現在已經不流行

60
00:03:54,782 --> 00:03:59,888
但那是第一個將記憶與神經網路相關連的，而那份論文重新激起了

61
00:03:59,888 --> 00:04:04,715
一些研究團體進入神經網路的興趣，在 80 年代早期

62
00:04:04,715 --> 00:04:09,732
由大部分是物理學家，跟凝聚態物理學家跟

63
00:04:09,732 --> 00:04:14,558
一些心理學家，但對於工程師跟

64
00:04:14,558 --> 00:04:18,464
電腦科學家還無法談論神經網路

65
00:04:18,464 --> 00:04:23,566
他們也讓我看另一份論文剛剛發布為

66
00:04:23,566 --> 00:04:28,590
預先列印版，標題是最佳知覺推論 (Optimal Perceptual Inference)

67
00:04:28,590 --> 00:04:32,675
那是第一份玻爾茲曼機論文，作者是 Geoffery Hinton 跟

68
00:04:32,675 --> 00:04:33,811
Terry Sejnowski

69
00:04:33,811 --> 00:04:34,801
它談到有關於隱藏單元

70
00:04:34,801 --> 00:04:40,401
談到基本上，學習的一部份

71
00:04:40,401 --> 00:04:46,702
多層神經網路等等
不僅僅能做分類器

72
00:04:46,702 --> 00:04:47,697
所以我說

73
00:04:47,697 --> 00:04:51,350
我必須見這些人『笑』>> 喔

74
00:04:51,350 --> 00:04:52,093
>> 因為他們真的

75
00:04:52,093 --> 00:04:53,230
對於對的問題有興趣

76
00:04:54,756 --> 00:05:00,330
一些年後，我開始了我的博士學位，我參加了

77
00:05:00,330 --> 00:05:06,020
一個在 Le Juch 的研討會，由跟我一起工作的人所組織的

78
00:05:06,020 --> 00:05:10,630
而 Terry 是研討會中的一位演講者

79
00:05:10,630 --> 00:05:13,216
我那時遇見了他, >> 那是 80 年代早期？

80
00:05:13,216 --> 00:05:15,862
>> 那是 1985, 那年年初

81
00:05:15,862 --> 00:05:19,777
所以我 1985 年遇見 Terry Sejnowski 
在法國的 Le Juch 研討會上

82
00:05:19,777 --> 00:05:23,881
很多人在場，早期的神經網路創始人，跳躍領域

83
00:05:23,881 --> 00:05:27,820
很多人從事於理論神經科學跟相關類似工作

84
00:05:27,820 --> 00:05:29,930
那是一個很棒的研討會

85
00:05:29,930 --> 00:05:36,260
我也遇見了一些從貝爾實驗室來的人，
最終他們雇用了我

86
00:05:36,260 --> 00:05:38,590
這在我完成博士學位之前幾年

87
00:05:38,590 --> 00:05:42,821
我告訴 Terry Sejnowski 有關我從事的工作

88
00:05:42,821 --> 00:05:45,479
有關一些反向傳播的版本

89
00:05:45,479 --> 00:05:49,559
這在正式反向傳播論文提出前

90
00:05:49,559 --> 00:05:54,030
Terry 那時正在研究 NETtalk

91
00:05:55,430 --> 00:05:57,212
那是在 Rumelhart 

92
00:05:57,212 --> 00:06:00,453
Hinton, William 反向傳播的論文出版之前

93
00:06:00,453 --> 00:06:04,158
但他是 Geoff 的朋友，這樣的資訊流傳著

94
00:06:04,158 --> 00:06:07,733
他當時已經試著在 NETtalk 成功使用（反向傳播）

95
00:06:07,733 --> 00:06:10,804
但他沒告訴我 >> 了解

96
00:06:10,804 --> 00:06:11,848
>> 然後他回到美國

97
00:06:11,848 --> 00:06:14,882
告訴 Geoff 有個法國小孩正在進行

98
00:06:14,882 --> 00:06:16,672
跟我們做同樣的事，>> 了解

99
00:06:16,672 --> 00:06:19,117
>> 『笑』幾個月後

100
00:06:19,117 --> 00:06:25,120
六月，有另一場會議在法國，Geoff 是主演講者

101
00:06:26,160 --> 00:06:28,250
他講的主題是玻爾茲曼機

102
00:06:28,250 --> 00:06:30,920
當然，他也正在進行反向傳播論文

103
00:06:32,060 --> 00:06:34,230
然後他講完了主題

104
00:06:34,230 --> 00:06:37,520
然後大約有將近 50 個人在他身邊想要跟他講話

105
00:06:37,520 --> 00:06:40,210
而他對召集人講的第一件事是

106
00:06:40,210 --> 00:06:41,380
您認識 Yann LeCun 這個傢伙嗎？

107
00:06:41,380 --> 00:06:45,025
因為他讀過我正在進行中用法語寫

108
00:06:45,025 --> 00:06:45,900
的論文

109
00:06:45,900 --> 00:06:47,890
他可以略懂法語，他可以看那些數學

110
00:06:47,890 --> 00:06:51,600
他可以理解大約是什麼樣的反向傳播
我們一起吃午餐

111
00:06:51,600 --> 00:06:53,496
然後我們變成好朋友
>>了解

112
00:06:53,496 --> 00:06:54,319
[笑聲]

113
00:06:54,319 --> 00:06:56,583
>> 那是因為很多團體

114
00:06:56,583 --> 00:07:00,700
正在獨立改造或發明類似的反向傳播

115
00:07:00,700 --> 00:07:02,906
>>是的，我們意識到

116
00:07:02,906 --> 00:07:06,878
整個連鎖律的觀念或者最佳化控制人們稱為連結狀態

117
00:07:06,878 --> 00:07:10,870
實際上是反向傳播真正發明的主旨

118
00:07:10,870 --> 00:07:14,105
這種最佳化控制的主旨要會到 60年代早期

119
00:07:14,105 --> 00:07:19,649
這種觀念讓您可以使用梯度下降，基本上使用在多重階段

120
00:07:19,649 --> 00:07:26,160
這是反向傳播真正的東西，出現在不同的時間不同的場合

121
00:07:26,160 --> 00:07:30,849
但我想 Rumelhart, Hinton, Williams 的論文是

122
00:07:30,849 --> 00:07:35,560
讓它真正普及，
>> 了解，真酷

123
00:07:35,560 --> 00:07:39,800
然後快速前進幾年，當您待在貝爾實驗室

124
00:07:39,800 --> 00:07:45,865
在那裡您發明了眾多項目之一的 LeNet, 我們在課程中提到過

125
00:07:45,865 --> 00:07:49,301
我記得之前，我在貝爾實驗室擔任暑期實習生時

126
00:07:49,301 --> 00:07:51,981
當時我跟 Michael Kerns 及一些人一起工作時

127
00:07:51,981 --> 00:07:54,093
當時已經聽說了有關您的工作

128
00:07:54,093 --> 00:07:57,509
告訴我們有關您在 AT&T 的 LeNet 工作經驗

129
00:07:57,509 --> 00:07:58,810
>> 好的，實際上

130
00:07:58,810 --> 00:08:04,400
我實際上從事於卷積網路當我在做博士後研究時

131
00:08:04,400 --> 00:08:06,090
在多倫多大學，跟著 Geoffrey Hinton

132
00:08:07,180 --> 00:08:09,075
我做的第一個實驗，寫的程式是

133
00:08:09,075 --> 00:08:10,849
做的第一個實驗，顯示了

134
00:08:10,849 --> 00:08:11,953
如果您有的是一個小的資料集

135
00:08:11,953 --> 00:08:16,995
我訓練用的資料集，幾乎沒有或者在當時有類似的東西

136
00:08:16,995 --> 00:08:20,195
所以我用滑鼠畫了一堆的字元

137
00:08:20,195 --> 00:08:23,285
我有一台 Amiga 一台個人電腦，是當時最棒的電腦

138
00:08:23,285 --> 00:08:27,425
我畫了一堆的字元，然後使用它們

139
00:08:27,425 --> 00:08:30,345
我做了資料擴充來增加資料

140
00:08:30,345 --> 00:08:32,635
然後使用那個來測試性能

141
00:08:32,635 --> 00:08:35,125
我用它來跟全連結網路做比較

142
00:08:35,125 --> 00:08:36,935
沒有共用權重的局部連結網路

143
00:08:36,935 --> 00:08:38,190
然後權重共享網路

144
00:08:38,190 --> 00:08:40,000
基本上這是第一個指令

145
00:08:40,000 --> 00:08:46,090
而這對相對小的資料集作用得很好，可以顯示您獲得

146
00:08:46,090 --> 00:08:50,320
較佳的效能，不會在常規架構下有的過度訓練

147
00:08:50,320 --> 00:08:53,481
當我在 1988 十月到貝爾實驗室的時候

148
00:08:53,481 --> 00:08:57,212
我做的第一件事是放大那個網路

149
00:08:57,212 --> 00:09:01,935
因為在我去貝爾實驗室之前幾個月，他們有了快速電腦

150
00:09:01,935 --> 00:09:06,501
我那時的老闆 Larry Jackal 變成貝爾實驗室部門主管

151
00:09:06,501 --> 00:09:09,920
說我們應該在您來之前先訂一台電腦

152
00:09:09,920 --> 00:09:10,450
您要什麼樣的電腦？

153
00:09:10,450 --> 00:09:15,860
我說在多倫多，這裡有 Sun 4 小小立方體工作站不錯

154
00:09:15,860 --> 00:09:17,432
如果我們有一個就好了

155
00:09:17,432 --> 00:09:21,450
他們就為我定了一台

156
00:09:21,450 --> 00:09:24,660
在多倫多大學整個部門只有一台，是吧？

157
00:09:24,660 --> 00:09:25,840
這裡我可以自己用一台？

158
00:09:25,840 --> 00:09:30,030
Larry 告訴我說，貝爾實驗室不是因為省錢

159
00:09:30,030 --> 00:09:30,866
而有名，>> 『笑』

160
00:09:30,866 --> 00:09:34,483
>> 那真的很棒，他們已經

161
00:09:34,483 --> 00:09:39,810
在字元辨識工作了一段時間

162
00:09:39,810 --> 00:09:44,883
他們已經有了一套資料集稱為 USPS，有 5,000 個訓練例子

163
00:09:44,883 --> 00:09:51,700
『笑』我馬上訓練了一個卷積網路，基本上也就是 LeNet-1

164
00:09:51,700 --> 00:09:53,645
在這個資料集上訓練

165
00:09:53,645 --> 00:09:58,320
得到很好的結果，比任何方法的結果都好

166
00:09:58,320 --> 00:10:04,150
他們也試了，其他人也在這個資料集試過

167
00:10:04,150 --> 00:10:07,430
我們知道我們已經開始有了相當棒的東西

168
00:10:07,430 --> 00:10:11,420
這些都是在我加入貝爾實驗室
三個月內發生的

169
00:10:11,420 --> 00:10:14,690
所以這是第一個卷積網路版本

170
00:10:14,690 --> 00:10:19,580
我們的卷積網路有跨步，但我們沒有分開的子抽樣 (subsampling)

171
00:10:19,580 --> 00:10:21,240
池層>>嗯

172
00:10:21,240 --> 00:10:23,690
>> 所以每個卷積層基本上都是子抽樣 (subsampling)

173
00:10:23,690 --> 00:10:24,390
直接

174
00:10:24,390 --> 00:10:25,050
而主要原因是

175
00:10:25,050 --> 00:10:30,130
我們用不起在每個區域做卷積

176
00:10:30,130 --> 00:10:32,299
因為這樣會用太多的計算, >> 了解

177
00:10:32,299 --> 00:10:35,839
>> [咳嗽] 第二個版本有

178
00:10:35,839 --> 00:10:42,040
分別的卷積，池層跟子抽樣

179
00:10:43,720 --> 00:10:47,070
我猜這個才應該稱為 LeNet-1

180
00:10:47,070 --> 00:10:53,380
我們發表了一些論文在 NIPS 學術會議

181
00:10:53,380 --> 00:10:57,270
一個有趣的故事，當我在 NIPS 談這份論文時

182
00:10:58,460 --> 00:11:01,580
Geoffrey Hinton 在觀眾席裡，而當我回到座位時

183
00:11:01,580 --> 00:11:05,920
我就坐在他旁邊，他說，在您演講中有一個訊息

184
00:11:05,920 --> 00:11:08,570
就是，如果您做了所有合理的事情

185
00:11:08,570 --> 00:11:10,503
它就會可行，>> 『笑』

186
00:11:10,503 --> 00:11:12,871
>> 那天過了不久

187
00:11:12,871 --> 00:11:16,820
那份論文改寫了歷史，因為它被大量採納

188
00:11:16,820 --> 00:11:18,540
這個觀念被廣泛採納在

189
00:11:18,540 --> 00:11:20,570
支票辨識上，>> 是的

190
00:11:20,570 --> 00:11:26,200
在 AT&A 內部有最大採用價值但外面還沒有

191
00:11:26,200 --> 00:11:29,368
對我實在難以

192
00:11:29,368 --> 00:11:34,560
理解，簡單的因素可能是

193
00:11:34,560 --> 00:11:40,360
那是在 80 年代後期，沒有網際網路

194
00:11:40,360 --> 00:11:45,110
我們有電子郵件，我們有 FTP, 但沒有網際網路

195
00:11:45,110 --> 00:11:48,450
沒有任何兩個實驗室使用相同的軟體跟硬體平台，對吧？

196
00:11:48,450 --> 00:11:51,270
有些人用 Sun 工作站，有些人用其他機器

197
00:11:51,270 --> 00:11:52,980
有些人使用個人電腦，或者其他

198
00:11:52,980 --> 00:11:56,360
那時沒有 Python 或者 Matlab 或者類似的東西

199
00:11:56,360 --> 00:11:58,430
人們自己寫程式

200
00:11:58,430 --> 00:12:01,510
我花了將近一年半的時間，基本上

201
00:12:01,510 --> 00:12:04,442
我和 Leon Bottou 當他還是學生的時候

202
00:12:04,442 --> 00:12:07,330
我們一起合作，我們花了一年半的時間

203
00:12:07,330 --> 00:12:10,580
基本上寫了神經網路模擬器

204
00:12:12,030 --> 00:12:14,360
那個時候還沒跟 Python 配在一起

205
00:12:14,360 --> 00:12:16,040
您寫您自己的直譯器，對吧？

206
00:12:16,040 --> 00:12:16,920
用來控制它

207
00:12:16,920 --> 00:12:19,070
我們想要有自己的 Lisp 直譯器

208
00:12:19,070 --> 00:12:24,160
所有網路都是用 Lisp 寫的，使用數值電腦當後端

209
00:12:24,160 --> 00:12:27,830
非常類似於我們現在用的，有可以連結的區塊

210
00:12:27,830 --> 00:12:31,380
但不是像很多我們現在熟悉的

211
00:12:31,380 --> 00:12:36,250
Torch, PyTorch, TensorFlow 等這些東西

212
00:12:37,400 --> 00:12:41,160
我們開發了一堆應用程式

213
00:12:41,160 --> 00:12:45,110
我們跟一群工程師在一起

214
00:12:46,460 --> 00:12:47,440
很聰明的人

215
00:12:48,880 --> 00:12:52,230
他們中有一些人是理論

216
00:12:52,230 --> 00:12:56,186
物理學家，他們在貝爾實驗室變成工程師

217
00:12:57,280 --> 00:13:00,070
Chris Dodgers 是其中一位，他後來

218
00:13:01,900 --> 00:13:04,095
在微軟研究院有很棒的成果

219
00:13:04,095 --> 00:13:04,766
還有 Krieg Nolan

220
00:13:04,766 --> 00:13:09,447
還有一些人，我們共同合作讓

221
00:13:09,447 --> 00:13:12,300
這個技術更加實用，>> 了解

222
00:13:12,300 --> 00:13:12,830
>> 所以

223
00:13:12,830 --> 00:13:17,840
我們一起開發了字元辨識系統

224
00:13:17,840 --> 00:13:22,614
意思是整合了卷積網路跟

225
00:13:22,614 --> 00:13:27,471
類似我們現在稱為 CRF (Conditional Random Field) 的解譯

226
00:13:27,471 --> 00:13:30,830
系列的字元，而非個別的 >> 是的

227
00:13:30,830 --> 00:13:33,710
是的那份論文部分是在神經網路領域

228
00:13:33,710 --> 00:13:37,630
部分在自動機領域 >> 是的，擺在一起

229
00:13:37,630 --> 00:13:38,230
>> 是的，非常正確。

230
00:13:38,230 --> 00:13:41,310
是的前半部是在卷積網路

231
00:13:41,310 --> 00:13:43,080
大部分的論文引用這半段

232
00:13:43,080 --> 00:13:45,205
而後半段，很少人讀過它

233
00:13:45,205 --> 00:13:49,530
『笑』它是有關於系列等級，差別運算

234
00:13:49,530 --> 00:13:53,900
基本上是不使用正規化的結構預測

235
00:13:53,900 --> 00:13:57,060
實際上它是非常類似於 CRF >> 讚

236
00:13:57,060 --> 00:14:00,790
>> PC 上的 CRF 已經多年了

237
00:14:00,790 --> 00:14:06,770
那是非常成功的，除了那天我們正在

238
00:14:08,290 --> 00:14:12,300
慶祝這套系統在主要的銀行部署

239
00:14:13,450 --> 00:14:17,708
前面提到過的我們一起合作的團隊

240
00:14:17,708 --> 00:14:19,640
做整套系統的工程師們

241
00:14:19,640 --> 00:14:23,650
跟另一個產品團隊在不同地方

242
00:14:23,650 --> 00:14:25,940
屬於 AT&T 的子公司稱為 NCR

243
00:14:25,940 --> 00:14:26,480
所以是 >> NCR

244
00:14:26,480 --> 00:14:29,280
>> National Cash Register 是的

245
00:14:29,280 --> 00:14:32,610
他們也做大型的 ATM 機器

246
00:14:32,610 --> 00:14:36,250
他們為銀行建立了大型的支票閱讀機器

247
00:14:36,250 --> 00:14:38,220
所以算是我們的客戶

248
00:14:38,220 --> 00:14:41,100
他們使用了我們的支票閱讀系統

249
00:14:41,100 --> 00:14:43,570
他們將機器部署到銀行

250
00:14:43,570 --> 00:14:45,300
我記不得是哪間銀行

251
00:14:45,300 --> 00:14:47,490
他們也部署 ATM 機器到法國銀行

252
00:14:47,490 --> 00:14:51,979
機器可以讀存款時的支票，而我們在

253
00:14:51,979 --> 00:14:56,804
一間豪華的餐廳慶祝部署成功這件事

254
00:14:56,804 --> 00:15:00,982
當時公司宣布將 AT&T 打散

255
00:15:00,982 --> 00:15:02,311
那是 1995 年

256
00:15:02,311 --> 00:15:06,970
AT&T 宣布將分拆成三個公司

257
00:15:06,970 --> 00:15:11,370
所以變成 AT&T, 然後 Lucent Technologies 跟 NCR

258
00:15:11,370 --> 00:15:14,670
所以 NCR 被拆出去，Lucent Technologies 被分拆出去

259
00:15:14,670 --> 00:15:17,090
原本的工程師團隊在 Lucent Technologies, 而 產品團隊

260
00:15:17,090 --> 00:15:18,210
當然跟著 NCR

261
00:15:19,770 --> 00:15:24,620
不幸的是 AT&T 的律師們使用無限的智慧

262
00:15:24,620 --> 00:15:29,090
來取得專利，當時卷積網路是有專利的

263
00:15:29,090 --> 00:15:31,991
謝天謝地已經過期了 >> 了解

264
00:15:31,991 --> 00:15:33,650
>> 『笑』在 2007 年過期

265
00:15:33,650 --> 00:15:36,370
大約 10 年前

266
00:15:36,370 --> 00:15:41,100
他們將專利給了 NCR, 但幾乎沒有人在 NCR

267
00:15:41,100 --> 00:15:44,710
知道究竟什麼是卷積網路

268
00:15:44,710 --> 00:15:48,470
所以專利就在不知所以然的人手上

269
00:15:48,470 --> 00:15:51,254
我們在不同的公司，但不能開發

270
00:15:51,254 --> 00:15:54,187
這份技術，因為我們跟工程師在不同的公司

271
00:15:54,187 --> 00:15:56,724
因為我們去了 AT&T，而工程師去了 Lucent

272
00:15:56,724 --> 00:15:58,140
產品團隊去了 NCR

273
00:15:58,140 --> 00:16:04,190
所以是有一點點沮喪『笑』>> 除了早期這些工作

274
00:16:04,190 --> 00:16:08,980
現在神經網路非常熱門，您一直持續堅持在神經網路

275
00:16:08,980 --> 00:16:12,020
即使在神經網路冬天的時候

276
00:16:12,020 --> 00:16:15,126
所以那是什麼樣的心境？>> 我堅持但

277
00:16:15,126 --> 00:16:16,884
某方面也沒堅持

278
00:16:16,884 --> 00:16:21,555
我一直相信最終這些技術會回到

279
00:16:21,555 --> 00:16:26,369
群組，一些人會找出如何使用它們

280
00:16:26,369 --> 00:16:27,650
它會很有用

281
00:16:27,650 --> 00:16:30,901
這一直在我腦海中

282
00:16:30,901 --> 00:16:33,661
但在 1996 年，當 AT&T 分拆的時候

283
00:16:33,661 --> 00:16:36,750
所有在字元辨識的努力，基本上

284
00:16:36,750 --> 00:16:40,627
也拆散了，因為部分的群組拆開了

285
00:16:40,627 --> 00:16:45,490
我當時升為部門主管，我需要弄清楚該做什麼

286
00:16:45,490 --> 00:16:49,597
而那是在網路網路早期，在 1995 年時

287
00:16:49,597 --> 00:16:53,836
我有一個想法，一個大問題是

288
00:16:53,836 --> 00:16:58,175
在網際網路的出現會帶來所有

289
00:16:58,175 --> 00:17:03,120
在紙上的知識變成數位化

290
00:17:03,120 --> 00:17:07,193
所以我開始了一個計畫，稱為 DjVu, D-J-V-U

291
00:17:07,193 --> 00:17:10,694
基本上是壓縮掃瞄的檔案，讓

292
00:17:10,694 --> 00:17:13,635
它們可以在網際網路上流傳

293
00:17:13,635 --> 00:17:17,528
這個專案在一段時間內很好玩，也有一些成效，雖然 AT&T

294
00:17:17,528 --> 00:17:21,443
真的不知道這個可以做什麼，>>呀，我記得，真正幫助了

295
00:17:21,443 --> 00:17:24,790
線上研究論文的傳播，>> 是的

296
00:17:24,790 --> 00:17:28,830
我們掃描了整個 NIPS 的進展，我們把它們放到線上

297
00:17:28,830 --> 00:17:30,110
>> 是的，我記得這件事

298
00:17:30,110 --> 00:17:31,590
>> 為了展示這個技術如何使用

299
00:17:31,590 --> 00:17:35,736
我們可以壓縮高解析的論文成為幾個 kb

300
00:17:35,736 --> 00:17:36,502
>> 所以卷積網路

301
00:17:36,502 --> 00:17:39,988
從一開始您早期的工作，到現在

302
00:17:39,988 --> 00:17:43,336
在電腦視覺中幾乎完全使用卷積網路

303
00:17:43,336 --> 00:17:46,980
然後甚至開始進入其他領域

304
00:17:46,980 --> 00:17:50,407
告訴我您怎麼看這整個過程？

305
00:17:50,407 --> 00:17:51,446
>>『笑』

306
00:17:51,446 --> 00:17:55,150
告訴您我早期時怎麼想的

307
00:17:55,150 --> 00:17:59,178
首先，我一直相信這會成功

308
00:17:59,178 --> 00:18:04,074
它是需要快速的電腦跟很多資料，但我一直相信

309
00:18:04,074 --> 00:18:07,160
這將會是正確的事

310
00:18:07,160 --> 00:18:11,695
當初我在貝爾實驗室的時後，最開始時，我想這會是一種

311
00:18:11,695 --> 00:18:16,392
持續的進展隨著機器越來越強大

312
00:18:16,392 --> 00:18:20,874
我們貝爾實驗室甚至設計了一個晶片
讓卷積網路在上面跑

313
00:18:20,874 --> 00:18:25,566
實際上在高速的圖片上分別用兩種不同的晶片

314
00:18:25,566 --> 00:18:28,593
來跑卷積網路，效能很棒

315
00:18:28,593 --> 00:18:33,186
我們當時在想這應該會開始流行

316
00:18:33,186 --> 00:18:37,882
應該會逐漸被重視，然後持續有進展

317
00:18:37,882 --> 00:18:41,860
但實際上，因為對於這種神經網路的興趣

318
00:18:41,860 --> 00:18:45,470
幾乎在 90 年代中期中斷，這並沒有發生

319
00:18:45,470 --> 00:18:51,444
那可以說是一段黑暗時期大約有六到七年，介於 1995 到

320
00:18:51,444 --> 00:18:55,351
大約 2002, 幾乎沒有人做這個

321
00:18:55,351 --> 00:18:57,192
實際上，是有一點點工作

322
00:18:57,192 --> 00:19:01,971
那是微軟在 2000 年早期使用

323
00:19:01,971 --> 00:19:06,401
卷積網路在中文字元的辨識

324
00:19:08,676 --> 00:19:11,676
>> 是的

325
00:19:11,676 --> 00:19:14,844
是有一些小工作在臉部識別

326
00:19:14,844 --> 00:19:19,780
在法國發生，跟一些地方，但都很小

327
00:19:19,780 --> 00:19:24,400
我最近才發現，一群人

328
00:19:24,400 --> 00:19:27,320
有一些想法基本上非常類似卷積網路，但

329
00:19:27,320 --> 00:19:31,370
從沒有發表，像在醫學影像分析一樣

330
00:19:31,370 --> 00:19:33,880
這些大部分在商業系統下進行

331
00:19:33,880 --> 00:19:37,310
所以從沒有讓它變得很流行

332
00:19:37,310 --> 00:19:42,343
我的意思是，在我們個卷積網路之後，他們並沒

333
00:19:42,343 --> 00:19:47,475
意識到卷積網路，有點像是平行開發

334
00:19:47,475 --> 00:19:52,764
很多人在很多年區間有類似的想法

335
00:19:52,764 --> 00:19:56,950
但我真正驚訝的是

336
00:19:56,950 --> 00:20:01,250
在 ImageNet  之後，大家開始發生極大興趣 >> 2012 年

337
00:20:01,250 --> 00:20:03,646
>>在 2012 年，2012 年底

338
00:20:03,646 --> 00:20:07,707
那真是一個很有趣的事件在 ECCV

339
00:20:07,707 --> 00:20:12,389
在佛羅倫斯，有 ImageNet 的一場研討會

340
00:20:12,389 --> 00:20:19,552
他們已經知道 Geoffrey Hinton, Alex Krizhevsky 跟 Ilya Sutskever 以巨大幅度領先

341
00:20:19,552 --> 00:20:21,004
每個人都等待  Alex Krizhevsky 的演講

342
00:20:21,004 --> 00:20:25,717
大部分在電腦視覺的人不知道什麼是

343
00:20:25,717 --> 00:20:26,281
卷積網路

344
00:20:26,281 --> 00:20:27,210
意思是，他們或許聽過

345
00:20:27,210 --> 00:20:32,181
我實際上被邀請在 2000 年 CVPR 中談過

346
00:20:32,181 --> 00:20:35,560
但大部分的人並不太注意它

347
00:20:35,560 --> 00:20:37,822
資深人員知道，他們知道那是做什麼的

348
00:20:37,822 --> 00:20:41,607
但社群中資淺的人實在對它完全沒有概念

349
00:20:41,607 --> 00:20:45,654
所以當 Alex Krizhevsky 演講時，
他並沒有解釋什麼是卷積網路

350
00:20:45,654 --> 00:20:47,824
因為他假設每個人都懂

351
00:20:47,824 --> 00:20:53,093
因為他來自於機器學習，所以當他說，這是如何全部連結

352
00:20:53,093 --> 00:20:56,753
我們如何轉換資料，我們得到什麼結果

353
00:20:56,753 --> 00:20:59,450
假設每個人都懂這些是什麼

354
00:20:59,450 --> 00:21:02,198
很多人都非常驚訝

355
00:21:02,198 --> 00:21:07,112
當他演講時
您可以看到人們的觀念正在改變

356
00:21:07,112 --> 00:21:11,946
特別是很資深的人們 
>> 所以您覺得那場研討會

357
00:21:11,946 --> 00:21:16,058
對於電腦視覺者個社群帶來很大的震撼

358
00:21:16,058 --> 00:21:16,724
>> 是的，絕對是

359
00:21:16,724 --> 00:21:17,572
>> 是的

360
00:21:17,572 --> 00:21:18,874
>> 就在那時候發生

361
00:21:18,874 --> 00:21:23,370
在那裡 >> 在今日，您是一位教授

362
00:21:23,370 --> 00:21:27,998
在紐約大學，
同時您也領導臉書人工智慧研究院 FAIR (Facebook AI Research)

363
00:21:27,998 --> 00:21:32,241
我知道您有相當獨特的觀點在於企業研究

364
00:21:32,241 --> 00:21:33,230
要如何進行

365
00:21:33,230 --> 00:21:34,530
你想分享一下嗎？

366
00:21:34,530 --> 00:21:37,688
>> 一件美妙的事情在

367
00:21:37,688 --> 00:21:44,105
我過去這四年來管理臉書的工作上，我被給予了

368
00:21:44,105 --> 00:21:50,128
相當大的自由度
用我覺得適當的方式來建立 FAIR

369
00:21:50,128 --> 00:21:56,010
因為這是在臉書裡第一個研究單位

370
00:21:56,010 --> 00:21:58,910
臉書是一個工程導向的公司

371
00:21:58,910 --> 00:22:03,007
目前為止都在忙著生存跟短期的事情

372
00:22:03,007 --> 00:22:10,714
而臉書已經十歲了，也成功的上市 (IPO)

373
00:22:10,714 --> 00:22:14,220
會開始想著下一個十年，對吧？

374
00:22:14,220 --> 00:22:18,188
意思是，馬克，祖克白會想著

375
00:22:18,188 --> 00:22:19,341
未來十年最重要的是什麼？

376
00:22:19,341 --> 00:22:21,917
而公司的生存已經不再是問題

377
00:22:21,917 --> 00:22:26,343
所以這種轉換對於大的公司會開始想，

378
00:22:26,343 --> 00:22:28,846
或許當時並不是一間大公司

379
00:22:28,846 --> 00:22:34,003
臉書有大約 5,000 名員工，但已經可以

380
00:22:34,003 --> 00:22:39,837
想著未來十年，什麼科技是最重要的

381
00:22:39,837 --> 00:22:45,069
而馬克跟他的團隊認為人工智慧會是

382
00:22:45,069 --> 00:22:52,372
在“連結人群”裡重要的元素，而這是臉書的使命

383
00:22:52,372 --> 00:22:55,303
所以他們探索了一些方式來建立人工智慧

384
00:22:55,303 --> 00:22:57,808
他們有一個小型內部團隊，工程師團隊

385
00:22:57,808 --> 00:23:01,459
實驗著卷積網路用在

386
00:23:01,459 --> 00:23:05,450
人臉辨識跟其他分面有很好的效果，激起了他們的興趣

387
00:23:05,450 --> 00:23:08,724
他們探索著是雇用一堆年輕的研究人員來

388
00:23:08,724 --> 00:23:10,820
還是收購公司，這類的事

389
00:23:10,820 --> 00:23:14,200
他們最終決定雇用這領域中資深的人來

390
00:23:14,200 --> 00:23:18,097
建立了這樣的研究單位

391
00:23:20,210 --> 00:23:23,340
剛開始有一點文化衝擊，因為

392
00:23:23,340 --> 00:23:26,750
在公司做研究的方式會非常不同於一般工程師，對吧？

393
00:23:26,750 --> 00:23:29,250
會有很長的時間跟區間

394
00:23:29,250 --> 00:23:32,672
而研究人員通常對於他們想要工作方向

395
00:23:32,672 --> 00:23:33,821
的選擇是很保守的

396
00:23:33,821 --> 00:23:38,552
我很早就清楚地表明, 研究需要開放

397
00:23:38,552 --> 00:23:43,034
研究人員不僅需要鼓勵出版, 而且

398
00:23:43,034 --> 00:23:45,110
甚至被要求要出版

399
00:23:45,110 --> 00:23:50,970
也用同樣的評估方式類似

400
00:23:50,970 --> 00:23:56,440
我們在學院做研究的評估方式

401
00:23:56,440 --> 00:24:01,644
所以馬克跟 Mike Schroepfer 公司的 CTO

402
00:24:01,644 --> 00:24:07,140
現在是我的老闆，說，臉書是一個很開放的公司

403
00:24:07,140 --> 00:24:09,890
我們發表了很多開源的東西

404
00:24:13,188 --> 00:24:14,799
CTO Schroepfer

405
00:24:14,799 --> 00:24:17,910
就是從開源社群來的　>> Mozilla

406
00:24:17,910 --> 00:24:19,890
>> 他是從 Mozilla 過來的

407
00:24:19,890 --> 00:24:21,260
很多人從那邊過來

408
00:24:21,260 --> 00:24:24,440
所以是這間公司的 DNA, 這讓我

409
00:24:24,440 --> 00:24:28,390
有相當把握可以設置成一個開放的研究機構

410
00:24:28,390 --> 00:24:34,941
實際上這間公司不會對於專利太過癡迷跟強迫像

411
00:24:34,941 --> 00:24:41,397
其他一些公司，這樣跟大學的合作變得比較容易

412
00:24:41,397 --> 00:24:46,774
可以安排一些人一腳在企業界

413
00:24:46,774 --> 00:24:49,555
一腳在學院 >> 您覺得這樣很有價值

414
00:24:49,555 --> 00:24:52,630
>> 當然，是的

415
00:24:52,630 --> 00:24:56,261
所以您看過去四年我的出版

416
00:24:56,261 --> 00:24:59,696
絕大部分的出版品來自於

417
00:24:59,696 --> 00:25:01,170
我紐約大學的學生 >>了解

418
00:25:01,170 --> 00:25:03,190
>> 因為在臉書

419
00:25:03,190 --> 00:25:07,016
我做了很多組織實驗室，雇用人

420
00:25:07,016 --> 00:25:12,029
設定方向，提建議，等等這些事情

421
00:25:12,029 --> 00:25:16,345
但我並不參與企業的個別研究專案，讓我的名字

422
00:25:16,345 --> 00:25:16,910
出現在這些論文上

423
00:25:16,910 --> 00:25:20,478
我已經不關心是否把我的名字放在論文上

424
00:25:20,478 --> 00:25:21,666
>> 也就是不再派人去做一些

425
00:25:21,666 --> 00:25:23,580
您的研究工作，而是自己做自己的研究工作

426
00:25:23,580 --> 00:25:24,590
>> 確實是，您不要把自己...

427
00:25:24,590 --> 00:25:27,390
您要留在幕後

428
00:25:27,390 --> 00:25:30,539
您不想要讓自己跟您實驗室的人競爭

429
00:25:30,539 --> 00:25:32,721
>> 我想您可能被問過很多次

430
00:25:32,721 --> 00:25:35,760
但也希望您可以讓
看到這段影片的人得到答案

431
00:25:36,830 --> 00:25:40,719
對於想加入人工智慧的人，您有何建議？

432
00:25:40,719 --> 00:25:42,459
進入人工智慧 >> 『笑』意思是

433
00:25:42,459 --> 00:25:46,470
現在已經是完全不同的世界
比起我剛開始的時後

434
00:25:46,470 --> 00:25:51,820
但我想現在很棒的是
人們可以很容易地開始一定層度的參與

435
00:25:51,820 --> 00:25:57,030
現在現有的工具已經很容易使用，像是 TensorFlow, PyTorch 等等

436
00:25:57,030 --> 00:26:01,928
您可以在家裡臥室用很便宜的電腦來跑『笑』

437
00:26:01,928 --> 00:26:06,905
基本上來訓練您的卷積網路或是遞迴網路等等

438
00:26:06,905 --> 00:26:09,140
有很多的工具

439
00:26:09,140 --> 00:26:16,190
您也可以從線上材料學習到很多，不會太繁重

440
00:26:16,190 --> 00:26:19,860
您已經見到中學生開始在玩這些，對吧？

441
00:26:19,860 --> 00:26:24,930
這很棒，我想會有越來越多的興趣

442
00:26:24,930 --> 00:26:29,730
來自於學生群體，學習機器學習，人工智慧

443
00:26:29,730 --> 00:26:36,820
很興奮看到這許多年輕人，我覺得很棒

444
00:26:36,820 --> 00:26:42,430
我的建議是，如果您像要進入這個領域，
讓您自己變得有用

445
00:26:42,430 --> 00:26:45,260
舉個例子，貢獻您自己到開源專案

446
00:26:45,260 --> 00:26:49,810
或者建置一些標準的演算法，您無法在線上找到程式

447
00:26:49,810 --> 00:26:54,600
但您願意提供給其他人使用

448
00:26:54,600 --> 00:26:56,610
所以拿一份論文，您覺得很重要

449
00:26:56,610 --> 00:27:01,080
重新建置它的演算法，然後放在開源的程式庫中

450
00:27:01,080 --> 00:27:04,260
或者對於這些開源程式庫做一些貢獻

451
00:27:04,260 --> 00:27:09,132
而如果您寫的東西有趣且有用，您會被注意到

452
00:27:09,132 --> 00:27:14,030
或許您可以去您想去的公司，得到很棒的工作

453
00:27:14,030 --> 00:27:18,580
或許您所喜歡的博士計畫被接受，這類的事

454
00:27:18,580 --> 00:27:19,950
我想這會是很好的方式

455
00:27:19,950 --> 00:27:20,962
來開始 >>

456
00:27:20,962 --> 00:27:24,973
開源貢獻是一個好的方式來進入這個社群，進而開始學習

457
00:27:24,973 --> 00:27:26,368
>> 是的

458
00:27:26,368 --> 00:27:29,651
>> 謝謝 Yann，這真的很棒

459
00:27:29,651 --> 00:27:32,520
我認識您很多年了，聽到這些細節

460
00:27:32,520 --> 00:27:34,813
這些故事經過了這麼多年，還是很迷人

461
00:27:34,813 --> 00:27:37,248
>> 是的，很多這樣的故事

462
00:27:37,248 --> 00:27:41,895
回想過去的時候，當它發生的時候，您並不清楚

463
00:27:41,895 --> 00:27:45,380
那會在 10 年 20 年後變得這麼重要

464
00:27:45,380 --> 00:27:47,113
>>  是的，謝謝

465
00:27:47,113 --> 00:27:48,678
>> 謝謝