1
00:00:00,000 --> 00:00:02,335
除卷积层之外

2
00:00:02,335 --> 00:00:07,130
ConvNets通常还使用池化层来减少展示量

3
00:00:07,130 --> 00:00:08,510
以此来提高计算速度

4
00:00:08,510 --> 00:00:12,020
并使一些特征的检测功能更强大

5
00:00:12,020 --> 00:00:16,390
我们来看一个池化的例子

6
00:00:16,390 --> 00:00:20,205
然后我们会讨论一下为什么要这么做

7
00:00:20,205 --> 00:00:24,300
假设你有一个4x4的输入

8
00:00:24,300 --> 00:00:28,675
并且你想使用一种池化类型，称作max pooling

9
00:00:28,675 --> 00:00:30,320
这个max pooling的输出

10
00:00:30,320 --> 00:00:34,375
将会是一个2x2的输出。

11
00:00:34,375 --> 00:00:37,270
实现它的做法非常简单

12
00:00:37,270 --> 00:00:40,310
将4*4的输入划分为不同的区域

13
00:00:40,310 --> 00:00:44,280
如图所示，我将给四个区域赋予不同的颜色

14
00:00:44,280 --> 00:00:46,130
然后 在它的输出里

15
00:00:46,130 --> 00:00:47,480
一个2x2的输出

16
00:00:47,480 --> 00:00:53,240
每个输出值将会是其对应颜色区域的最大值

17
00:00:53,240 --> 00:00:54,680
所以在左上角

18
00:00:54,680 --> 00:00:57,900
这四个数字的最大值是9

19
00:00:57,900 --> 00:01:01,760
右上角蓝色背景数字的最大值是2

20
00:01:01,760 --> 00:01:04,273
左下角最大的数字是6

21
00:01:04,273 --> 00:01:08,050
而右下角最大的数字是3

22
00:01:08,050 --> 00:01:10,737
所以当计算右手边每一个格子里的数字时

23
00:01:10,737 --> 00:01:13,400
我们选取那些2x2区域的最大值

24
00:01:13,400 --> 00:01:18,740
这如同你使用了一个大小为2的过滤器

25
00:01:18,740 --> 00:01:25,290
因为你选取一个2x2的区域，并且使用的步长为2

26
00:01:25,290 --> 00:01:30,825
这些实际上就是max pooling的超参数

27
00:01:30,825 --> 00:01:36,540
因为我们是从这个过滤器大小开始的

28
00:01:36,540 --> 00:01:39,650
这就像一个2x2的区域给出最大值9

29
00:01:39,650 --> 00:01:45,580
然后向前走两步来看看个区域 给出2

30
00:01:45,580 --> 00:01:46,880
然后来到下一行

31
00:01:46,880 --> 00:01:49,580
你向下走两步 这里给出的是6

32
00:01:49,580 --> 00:01:52,570
再向右走两步得到3

33
00:01:52,570 --> 00:01:54,620
然后因为这些方块是2x2 f就等于2

34
00:01:54,620 --> 00:01:58,070
又因为你的步长时2

35
00:01:58,070 --> 00:02:00,210
s就等于2

36
00:02:00,210 --> 00:02:09,526
这里来说一下max pooling背后的机制

37
00:02:09,526 --> 00:02:15,050
如果你把这个4x4的区域看作某个特征的集合

38
00:02:15,050 --> 00:02:19,204
即神经网络某个层中的激活状态

39
00:02:19,204 --> 00:02:20,490
那么 一个大的数字

40
00:02:20,490 --> 00:02:23,670
意味着它或许检测到了一个特定的特征

41
00:02:23,670 --> 00:02:26,495
所以 左侧上方的四分之一区域有这样的特征

42
00:02:26,495 --> 00:02:32,470
它或许是一个垂直的边沿 亦或一个更高或更弱

43
00:02:32,470 --> 00:02:34,820
显然 左侧上方的四分之一区域有那个特征

44
00:02:34,820 --> 00:02:40,055
然而这个特征 或许它不是猫眼检测

45
00:02:40,055 --> 00:02:43,975
但是 右侧上方的四分之一区域没有这个特征

46
00:02:43,975 --> 00:02:47,764
所以 max pooling做的是 检测到所有地方的特征

47
00:02:47,764 --> 00:02:53,504
四个特征中的一个被保留在max pooling的输出中

48
00:02:53,504 --> 00:02:56,265
所以，max pooling作所做的其实是

49
00:02:56,265 --> 00:02:59,780
如果在滤波器中任何地方检测到了这些特征

50
00:02:59,780 --> 00:03:01,348
就保留最大的数值

51
00:03:01,348 --> 00:03:03,510
但是 如果这个特征没有被检测到

52
00:03:03,510 --> 00:03:07,690
可能左侧上方的四分之一区域就没有这个特征

53
00:03:07,690 --> 00:03:11,090
于是 那些数值的最大值仍然相当小

54
00:03:11,090 --> 00:03:15,252
这或许就是max pooling背后的解释

55
00:03:15,252 --> 00:03:16,535
但是 不得不承认

56
00:03:16,535 --> 00:03:19,550
我认为大家使用max pooling的主要原因是

57
00:03:19,550 --> 00:03:23,627
因为在很多实验中发现它的效果很好

58
00:03:23,627 --> 00:03:25,646
以及我刚刚描述的机制

59
00:03:25,646 --> 00:03:27,375
尽管它经常被引用

60
00:03:27,375 --> 00:03:33,020
我不知道是否有人完全了解这是真正的根本原因

61
00:03:33,020 --> 00:03:34,655
也不知道有谁知道这是否是

62
00:03:34,655 --> 00:03:39,930
max pooling在卷积网络中效果很好的根本原因

63
00:03:39,930 --> 00:03:43,490
max pooling的一个有趣的特性是

64
00:03:43,490 --> 00:03:47,770
它有一套超参 但是它没有任何参数需要学习

65
00:03:47,770 --> 00:03:50,293
实际上 没有任何需要梯度相加算法学习的东西

66
00:03:50,293 --> 00:03:51,780
一旦确定了 f 和 s

67
00:03:51,780 --> 00:03:56,876
就确定了计算 而且梯度下降算法不会对其有任何改变

68
00:03:56,876 --> 00:04:00,810
让我们来看一个有某些不同超参的例子

69
00:04:00,810 --> 00:04:04,675
这里我们打算使用一个5x5的输入

70
00:04:04,675 --> 00:04:10,290
并且为max pooling应用一个大小为3x3的过滤器

71
00:04:10,290 --> 00:04:13,815
于是 f 等于3 并且我们使用步长为1

72
00:04:13,815 --> 00:04:18,190
在这个例子中 输出的大小将会是3x3

73
00:04:18,190 --> 00:04:20,570
我们在之前的视频中用来计算卷基层输出的大小

74
00:04:20,570 --> 00:04:23,945
而推到出的公式

75
00:04:23,945 --> 00:04:27,345
那些公式对max pooling同样适用

76
00:04:27,345 --> 00:04:34,345
那个公式是 n 加上 2p 减去 s 的 f 次方再加 1

77
00:04:34,345 --> 00:04:38,458
这个公式同样可用于计算max pooling的输出的大小

78
00:04:38,458 --> 00:04:41,820
但在这个例子中 让我们来计算这个3x3输出的每一个元素

79
00:04:41,820 --> 00:04:45,080
左侧上方的元素

80
00:04:45,080 --> 00:04:46,670
我们要来看看那个区域

81
00:04:46,670 --> 00:04:48,735
注意到这是一个3x3的区域

82
00:04:48,735 --> 00:04:51,695
因为滤波器的大小是3 并取其最大值

83
00:04:51,695 --> 00:04:53,715
所以输出应该是9

84
00:04:53,715 --> 00:04:57,920
然后我们移动一列 因为步长是1

85
00:04:57,920 --> 00:05:00,960
于是 蓝色方块中的最大值是9

86
00:05:00,960 --> 00:05:03,695
让我们再向右移动一列

87
00:05:03,695 --> 00:05:06,235
蓝色方块中最大值是5

88
00:05:06,235 --> 00:05:09,710
让我们去道下一行 步长为1

89
00:05:09,710 --> 00:05:12,465
所以 我们仅仅向下走一步

90
00:05:12,465 --> 00:05:16,520
那个区域的最大值是9 这个区域的最大值是9

91
00:05:16,520 --> 00:05:19,970
再来看这个区域的最大

92
00:05:19,970 --> 00:05:22,516
现在有两个5 所以有多个最大值都是5

93
00:05:22,516 --> 00:05:26,130
最后，这个区域的最大值是8

94
00:05:26,130 --> 00:05:28,965
这里的最大值是6

95
00:05:28,965 --> 00:05:31,350
以及这个区域的最大值是9

96
00:05:31,350 --> 00:05:35,810
到此，这个集合的超参有 f 等于3

97
00:05:35,810 --> 00:05:40,007
s 等于1，给出如图所示的输出

98
00:05:40,007 --> 00:05:44,975
截至目前，我演示了在二维输入上的max pooling

99
00:05:44,975 --> 00:05:47,370
如果有一个三维输入

100
00:05:47,370 --> 00:05:53,245
则输出会具有同样的维数

101
00:05:53,245 --> 00:05:56,765
例如，如有有一个5x5x2的输入

102
00:05:56,765 --> 00:06:02,360
则输出将是3x3x2，并且

103
00:06:02,360 --> 00:06:05,045
计算最大值采样的方法是使用

104
00:06:05,045 --> 00:06:08,368
我们刚刚描述的每个通道的计算过程

105
00:06:08,368 --> 00:06:11,960
所以，第一个通道，即和这里显示的顶层一样

106
00:06:11,960 --> 00:06:13,790
然后第二个通道，我猜测

107
00:06:13,790 --> 00:06:15,790
这个我刚画在底下的通道

108
00:06:15,790 --> 00:06:19,250
你应该在那一层上做相同的操作

109
00:06:19,250 --> 00:06:24,365
这样会给出第二层

110
00:06:24,365 --> 00:06:29,300
更一般得来讲，假如输入是5乘5乘一些通道数

111
00:06:29,300 --> 00:06:34,395
输出应该是3乘3乘同样的通道数

112
00:06:34,395 --> 00:06:44,541
并且最大值采样计算是在这些 N_C 个通道上独立进行的

113
00:06:44,541 --> 00:06:46,520
这就是最大值采样(max pooling)

114
00:06:46,520 --> 00:06:49,815
这个是一类并非很常使用的采样

115
00:06:49,815 --> 00:06:52,870
但是我会简要提一下均值采样

116
00:06:52,870 --> 00:06:56,395
它所做的基本上是你所预期的

117
00:06:56,395 --> 00:06:59,080
不是在每个滤波器中取最大值

118
00:06:59,080 --> 00:07:02,040
而是取其平均值

119
00:07:02,040 --> 00:07:03,250
在这个例子里

120
00:07:03,250 --> 00:07:07,540
紫色区域中数值的均值是3.75

121
00:07:07,540 --> 00:07:09,940
然后是1.25

122
00:07:09,940 --> 00:07:12,930
然后是4和2

123
00:07:12,930 --> 00:07:17,020
这是均值采样，其超参为 f 等于2

124
00:07:17,020 --> 00:07:21,795
s 等于2，我们也可以选择其它超参

125
00:07:21,795 --> 00:07:24,640
目前，最大值采样的使用

126
00:07:24,640 --> 00:07:28,340
通常比均值采样多得多，唯一的例外

127
00:07:28,340 --> 00:07:32,125
是有时候在深度非常大的神经网络

128
00:07:32,125 --> 00:07:36,670
你也许可以使用均值采样来合并表示

129
00:07:36,670 --> 00:07:40,290
例如从7x7x1000

130
00:07:40,290 --> 00:07:42,755
将它们整体取一个均值

131
00:07:42,755 --> 00:07:45,625
得到1x1x1000

132
00:07:45,625 --> 00:07:47,475
我们稍后会看到这样的一个例子

133
00:07:47,475 --> 00:07:54,085
但是你看，在神经网络中最大值采样比均值采样用的更多

134
00:07:54,085 --> 00:07:56,305
总结一下

135
00:07:56,305 --> 00:08:00,100
采样的超参是滤波器的大小 f

136
00:08:00,100 --> 00:08:02,840
以及步长 s

137
00:08:02,840 --> 00:08:07,360
或许常见的参数选择可能是 f 等于2，s 等于2

138
00:08:07,360 --> 00:08:11,045
这个相当常用并且其效果是

139
00:08:11,045 --> 00:08:15,925
近似得把高度和宽度缩小了两倍以上

140
00:08:15,925 --> 00:08:21,150
并且一个被普遍选用的超参可能是 f 等于2，s 等于2

141
00:08:21,150 --> 00:08:23,530
它的效果是将表示的

142
00:08:23,530 --> 00:08:28,440
高度和宽度缩小了两倍

143
00:08:28,440 --> 00:08:32,094
我还见过 f 等于3，s 等于2

144
00:08:32,094 --> 00:08:37,150
而其它的超参就像一个二进制位元

145
00:08:37,150 --> 00:08:40,120
指示你是使用最大值采样还是均值采样

146
00:08:40,120 --> 00:08:43,380
如果你愿意，你可以增加一个额外的补位超参

147
00:08:43,380 --> 00:08:48,140
尽管这个是极其罕见被使用的

148
00:08:48,140 --> 00:08:50,080
当你做最大值采样时，通常情况下

149
00:08:50,080 --> 00:08:51,685
不会做任何补位

150
00:08:51,685 --> 00:08:55,025
尽管有一个例外，这个我们下周会看到

151
00:08:55,025 --> 00:08:57,160
但是，对于最大值采样的绝大多数部分

152
00:08:57,160 --> 00:08:59,710
通常情况下，是不进行任何的补位

153
00:08:59,710 --> 00:09:05,345
所以，截至目前 p 最为常用的取值是 p 等于零

154
00:09:05,345 --> 00:09:13,215
最大值采样的输入是，你输入一个大小为

155
00:09:13,215 --> 00:09:14,945
N_H 乘 N_W 乘 N_C 的体数据

156
00:09:14,945 --> 00:09:21,265
它会输出一个如下所述大小的体数据

157
00:09:21,265 --> 00:09:29,465
假设没有大小为 N_W 减去 s 的 f 次方的补位

158
00:09:29,465 --> 00:09:32,015
这个是 N_C

159
00:09:32,015 --> 00:09:35,295
因此，输入通道的数量等于输出通道的数量

160
00:09:35,295 --> 00:09:40,555
因为采样是独立地应用于每一个通道

161
00:09:40,555 --> 00:09:47,205
关于采样，一个值得注意的是，它没有需要学习的参数

162
00:09:47,205 --> 00:09:50,470
所以，在实现剪切的时候

163
00:09:50,470 --> 00:09:55,645
你会发现，没有参数需要通过最大值采样进行调整

164
00:09:55,645 --> 00:09:58,400
反而是，这里只有这些超参需要你设定一次

165
00:09:58,400 --> 00:10:01,485
或许是人工设定或者使用交叉检验

166
00:10:01,485 --> 00:10:03,710
除此之外，你就不用做什么了

167
00:10:03,710 --> 00:10:07,140
它就是一个神经网络在其中一层计算的确定函数

168
00:10:07,140 --> 00:10:09,829
而这里实际上没有任何需要学习的

169
00:10:09,829 --> 00:10:11,999
它仅仅是一个确定的函数

170
00:10:11,999 --> 00:10:13,350
这就是采样的所有内容

171
00:10:13,350 --> 00:10:15,460
现在你知道如何构建卷积层和采样层

172
00:10:15,460 --> 00:10:18,095
这里这个

173
00:10:18,095 --> 00:10:20,830
让我们看一个更为复杂的卷积网络的例子

174
00:10:20,830 --> 00:10:25,000
这个例子还会让我们引入全连结曾