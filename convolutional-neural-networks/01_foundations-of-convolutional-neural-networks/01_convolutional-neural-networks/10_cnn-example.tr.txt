Şuan, bir evrişimsel sinir ağı kurmanın temel taşlarını büyük ölçüde biliyorsunuz. Bir örneğe bakalım. Diyelim ki, girdi olarak 32x32x3 boyutlarında bir görüntü<br />kullanıyorsunuz yani bu bir RGB(kırmızı-yeşil-mavi) görüntü ve<br /> siz de bir "el yazısı rakam tanıma" yapmaya çalışıyorsunuz. Örneğin, 32x32 boyutlarında RGB(kırmızı-yeşil-mavi) bir <br />7 rakamını, 0'dan 9'a hangi rakam olduğunu<br /> bulmak için verelim. Bunu yapması için bir sinir ağı kullanalım. Ve bu slaytta kullanacağım şey, yıllar önce Yann LeCun tarafından oluşturulmuş LeNet-5 adlı klasik sinir ağlarına oldukça benzer. Burada göstereceğim şey tam olarak LeNet-5 değil ancak çoğu katsayı seçimleri ondan esinlenmiş. 32x32x3 boyutunda bi girdi ile, diyelim ki; katman 5x5 boyutunda filtre, 1 birimlik adım<br /> (stride) kullanılıyor ve dolgulama(padding) yok. Eğer 6 filtre kullanıyorsanız bu katmanın çıktısı 28x28x6 boyutunda olacak ve bu katmana "conv 1" adını vereceğiz. Eğer 6 filtre, yanlılık(bias) ve<br /> doğrusal olmama (non-linearity) eklersek, ki bu "relu" olabilir, <br />"conv1"in çıktısını elde ederiz. Şimdi bir örnekleme katmanı uygulayalım. Burada maksimum örnekleme (max pooling) <br />uygulayacağım. f=2, s=2 diyelim. Dolgulama kullanmadığım zaman dolgulamayı<br /> sıfıra eşitleyin. (padding=0) Şimdi bir örnekleme katmanı uygulayalım, 2'ye 2 filtreli bir maksimum örnekleme ve <br />2 birimlik adım (stride) kullanacağım Bu, görselin yüksekliğini ve genişliğini 2 kat azaltacaktır. Yani 28 x 28 boyutu 14 x 14 olacak, kanal sayısı aynı kalacak (14 x 14 x 14) ve buna Pool 1'in çıktısı diyeceğiz. Literatürde, evrişimsel ağlarda neye "katman" denileceği hakkında iki farklı eğilim var. Biri, bu bir katmandır diyor. Yani bu sinir ağının ilk katmanı oluyor, diğeri ise buradaki "Conv" ve "Pool" katmanlarını <br />ayrı ayrı katmanlar olarak kabul ediyor. İnsanlar sinir ağındaki katman sayısını <br />raporlayacaklarında genellikle ağırlık (weight) ve katsayısı olan katmanları raporlarlar. Örnekleme katmanının ağırlığı ve birkaç üst-değişkenden <br />başka katsayısı olmadığından; Conv1 ve Pool1 katmanlarını tek katman olarak kabul edeceğim. Ona "Katman 1" diyeceğim, ama <br />siz eğer bazı makaleleri okursanız, evrişim katmanı ve örnekleme katmanının ayrı ayrı ele alındığını görebilirsiniz. Bunlar birbirlerinden biraz farklı gösterimler olabilir ancak ben katmanları sayarken, <br />sadece ağırlığı olan katmanları sayacağım. Böylece bu ikisi birlikte bir katman olmuş oluyor. Ve burada isimlendirdiğim "Conv1" ve "Pool1" sinir ağımızın Katman 1(Layer 1)'deki parçaları oluyor. "Pool1", Katman 1'in içinde gruplandı<br /> çünkü kendine ait ağırlıkları yok. Şimdi, elimizdeki 14x14x6 boyutundaki girdiye, başka bir evrişimsel katman uygulayalım ve<br />bu sefer 5 x 5 boyutunda bir filtre, adım olarak 1 ve 10 adet filtre kullanalım. 10x10x10'lik bir boyut elde etmiş olduk. Buna "Conv1" diyelim ve ve bu ağın içinde f=2, s=2 olan bir maksimum örnekleme yapalım. f=2 ve s=2 olduğu için yüksekliğin ve genişliğin 2 kat azalacağını ve çıktının boyutunun 5x5x10 olacağını muhtemelen tahmin ediyorsunuzdur. Ve şimdi buna "Pool2" diyeceğim ve kuralımıza göre buna da sinir ağımızın <br />Katman 2'si (Layer 2) diyeceğim. Şimdi buna başka bir evrişimsel katman uygulayalım. 5x5'lik bir filtre kullanacağım yani f=5 olacak, adım 1 olacak ve dolgulama için bir şey<br /> yazmayacağım yani dolgulama olamayacak. Ve bu size "Conv2" çıktısını ve 16 filtreyi vermiş olacak. Böylece 10x10x16 boyutunda bir çıktımız olacak. Gördüğünüz üzere bu "Conv2" katmanı. Ve şimdi f=2, s=2 olan bir maksimum<br /> örnekleme katmanı uygulayalım. Muhtemelen bunun çıktısını tahmin edebiliyorsunuz. 10x10x16 boyutunda bir girdimiz var ve f ve s 2'ye eşit. Bu yükseklik ve genişliği yarıya indirecek. Sonucu tahmin edebiliyorsunuz değil mi? f=2 ve s=2 olan bir maksimum örnekleme. Bu yüksekliği ve genişliği yarıya indirmeli ve 5x5x16 boyutunda, kanal sayısı öncekine <br />eşit olan bir çıktı elde etmeliyiz. Buna "Pool 2" diyeceğiz. Ve kuralımıza göre buna Katman 2 diyeceğim çünkü "Conv2" katmanında bir ağırlık kümesi var. Şuan 5x5x16 olan boyut hesapladığımızda 400 ediyor. Şimdi "Pool 2"yi 400 x 1'lik tek boyutlu<br /> bir vektör olarak düzleştirelim Bunu bir nöron kümesi olacak şekilde<br /> düzleştirdiğimizi düşünebilirsiniz. Şimdi bu 400 birim ile yapacağımız şey, bunları alıp 120 birimden oluşan yeni bir katman oluşturmak. Açıkçası bu bizim ilk tam bağlı katmanımız. Buna "FC3" diyeceğim çünkü, 400 birim 120 birime ağırlıklı olarak bağlı. Bu tam bağlı katman aynı Kurs 1 ve 2'de gördüğünüz tek sinir ağı katmanı gibi. Bu, 120 x 400 boyutundaki ağırlık matrisini<br /> "W3" olarak adlandırdığımız standart bir sinir ağı. Ve buna tam bağlı diyoruz çünkü buradaki her 400 birim buradaki 120 birime bağlı, ve ayrıca 120 boyutlu yanlılık katsayıları var. Ve son olarak 120 birimi alalım ve<br /> başka bir katman ekleyelim ancak bu sefer daha küçük, 84 birimimiz var diyelim, buna tam bağlı katman 4 (FC4) adını vereceğim Ve sonunda bir softmax fonksiyonuna koyabileceğiniz <br />84 reel sayımız var. Ve eğer 0'dan 9'a rakamları tanımak için el yazısı rakam tanıma yapmaya çalışıyorsanız; Bu 10 çıktılı bir softmax olmalı. Bu makul derecede bir evrişimsel sinir ağının nasıl görünebileceğinin tipi bir örneği. Ve bunun çok fazla üst-katsayı içeriyor<br /> gibi göründüğünün farkındayım Daha sonra bu üst-katsayıları nasıl belirleyeceğiniz hakkında tavsiyeler vereceğim. Belki bir prensip olarak, kendi üst-katsayı <br />ayarlarımızı icat etmektense literatürü inceleyip başkalarının üst-katsayı seçimlerinin<br /> nasıl çalıştığını görebilirsiniz Ve sonra, daha önce başkasının iyi<br /> çalışmış bir mimarisini seçin bunun sizin uygulamanızda çalışması da muhtemel olacaktır. Gelecek hafta bunun hakkında daha çok şey göreceğiz. Ama şimdilik şuna dikkat çekmek istiyorum; <br />bir sinir ağında derine gittiğinizde nh ve nw yani yükseklik ve genişlik azalır. Bundan daha önce bahsetmiştim. 32x32'den<br /> 20x20'ye sonra 14x14'e sonra 10x10'a ve 5x5'e. Yani derinleştikçe genellikle yükseklik ve genişlik azalacaktır ve kanal sayısı artacaktır. 3'ten 6'ya oradan da 16'ya ve <br />en son olarak da tam bağlı katmana. Sinir ağlarında bir başka oldukça sık görülen bir model ise bir veya birden fazla evrişim katmanı ve<br /> onu takip eden örnekleme katmanı ve sonra bir veya daha fazla evrişim katmanı ve<br /> onu takip eden örnekleme katmanı. Ve en sonda birkaç tam bağlı katman ve son olarak da bir softmax olabilir. Bu da sinir ağlarında bir başka oldukça sık rastlanan model. Şimdi de bu sinir ağınının başka detaylarını; aktivasyon şeklini, aktivasyon boyutunu ve bu ağdaki katsayıların miktarını inceleyelim. Girdimiz 32x30x3 ve bu sayıları çarparsak 3072 elde ederiz. Böylece aktivasyon a0 3072 boyutlu olur. Bu gerçekten 32x32x32. Ve girdi katmanında hiç katsayı yok. Ve diğer katmanlara bakarsanız, detayları kendi kendinize çalışmakta rahat olun. Bunlar diğer katmanların aktivasyon şekli ve aktivasyon boyutları. Bir kaç şeye dikkat çekmem gerekirse İlk olarak; maksimum örnekleme <br />katmanlarının katsayıları yok, İkinci olarak, diğer videolarda bahsettiğimiz üzere evrişim katmanları göreli olarak daha<br /> az katsayıya sahip olma eğiliminde. Ve aslına bakılırsa birçok katsayı da sinir ağının tam bağlı katmanlarında olma eğiliminde. Eğer dikkat ettiyseniz aktivasyon boyutu da sinir ağında derine inildikçe gitgide azalma eğiliminde. Eğer çok çabuk azalırsa genellikle iyi performans göstermez. Yani burada ilk olarak 6000'den başlıyor sonra 1600'e ve sonra yavaşça 84'e iniyor ve son <br />olarak da softmax çıktımız var. Buna benzer özellikler ve kalıplar bulabilirsiniz. Sinir ağlarının, evrişimsel sinir ağlarının <br />temel yapı taşlarından olan evrişim katmanı, örnekleme katmanı ve tam bağlı katmanı görmüş oldunuz. Birçok araştırmacı daha etkili bir sinir ağı kurabilmek için bu temel yapı taşlarının nasıl bir <br />araya geleceğini bulmaya çalışıyor. Bunları bir araya koymak aslında biraz sezgi gerektiriyor. Bence sezgi kazanmanın en iyi yollarından biri başka somut örnekler görmek ve başkalarının onları nasıl yaptığını öğrenmektir. Bu yüzden önümüzdeki hafta bundan başka somut örneklerle insanların nasıl başarılı bir şekilde bu parçaları birleştirip etkili bir sinir ağı kurduğunu göstereceğim. Ve umuyorum ki bu videolarla birlikte bunları oluşturmak için gereken sezgilerinizi geliştireceksiniz. Ve verilen somut örneklerdeki mimarileri <br />olduğu gibi kullanabilirsiniz ya da kendi uygulamanızı kullanabilirsiniz. Bunu önümüzdeki hafta yapacağız ama bu haftanın videosunu kapamadan önce neden evrişime ihtiyaç duyabileceğimiz<br /> hakkında konuşmak istiyorum. Evrişimi kullanmanın bazı yararları ve avantajları ve onları nasıl bir araya getirebileceğimiz ve az önce gördüğümüz gibi bir sinir ağını nasıl eğitiriz ve bir görüntü tanıma işinde kullabiliriz. Şimdi bu haftanın son videosuyla devam edelim.