1
00:00:00,630 --> 00:00:04,090
ストライドした畳み込みは

2
00:00:04,090 --> 00:00:09,550
畳み込みニューラルネットワークで使われる
畳み込みの構成要素のもう一つのピースだ

3
00:00:09,550 --> 00:00:11,156
例を見てみよう

4
00:00:11,156 --> 00:00:16,709
この 7 x 7 画像を この 3 x 3 フィルターで畳み込むとしよう

5
00:00:16,709 --> 00:00:19,290
ただし 通常のやり方ではなく

6
00:00:19,290 --> 00:00:23,795
それを２ストライドで行う

7
00:00:23,795 --> 00:00:29,260
それが意味するのは 要素毎の掛け算は普通に行い

8
00:00:29,260 --> 00:00:35,725
この左上の 3 x 3 領域を掛け算と足し算を行い 91 を得る

9
00:00:35,725 --> 00:00:39,010
しかし この青い箱を１ステップ動かす代わりに

10
00:00:39,010 --> 00:00:41,545
２ステップ動かす

11
00:00:41,545 --> 00:00:45,996
つまり こんな風に ２ステップ跳ばす

12
00:00:45,996 --> 00:00:51,130
左上角は この点から この点へ

13
00:00:51,130 --> 00:00:52,825
1つ飛ばしでジャンプする

14
00:00:52,825 --> 00:00:59,290
そして 通常の要素毎の掛け算と合計を行い 100 を得る

15
00:00:59,290 --> 00:01:00,580
そして また それを行っていく

16
00:01:00,580 --> 00:01:04,390
青い箱を２ステップジャンプさせる

17
00:01:04,390 --> 00:01:08,105
この位置に来ることになり 83 を得る

18
00:01:08,105 --> 00:01:11,125
では 次の行に行こう

19
00:01:11,125 --> 00:01:13,810
再び １ステップの代わりに

20
00:01:13,810 --> 00:01:17,870
２ステップ取り 青い箱をここに動かす

21
00:01:17,870 --> 00:01:24,953
位置を1つ跨いで 今度は 69 を得る

22
00:01:24,953 --> 00:01:27,740
そして また ２ステップ動かす

23
00:01:27,740 --> 00:01:31,775
今度は 91 を得て 続けて 127

24
00:01:31,775 --> 00:01:38,250
そして 最終行では 44 72 74

25
00:01:38,250 --> 00:01:43,615
この例では 7 x 7 行列を畳み込んだ

26
00:01:43,615 --> 00:01:49,530
この 3 x 3 行列で そして 3 x 3 出力を得た

27
00:01:49,530 --> 00:01:54,207
入力と出力の次元は 次の式に支配される

28
00:01:54,207 --> 00:01:56,080
もし n x n 画像があり

29
00:01:56,080 --> 00:02:00,202
f x f フィルターで畳み込むなら

30
00:02:00,202 --> 00:02:09,835
また パディング p と ストライド s を使うなら この例では

31
00:02:09,835 --> 00:02:17,633
s = 2 なので 出力は n + 2p - f

32
00:02:17,633 --> 00:02:20,755
そして 一度に s ステップ動かす

33
00:02:20,755 --> 00:02:22,455
これは １ステップ動かした場合ので

34
00:02:22,455 --> 00:02:29,423
今度は s で割り そして 1 を足す
そして 同じことを行う

35
00:02:29,423 --> 00:02:37,165
我々の例では 7 + 0 - 3

36
00:02:37,165 --> 00:02:44,920
割る 2 ｓストライド + 1 は ええっと

37
00:02:44,920 --> 00:02:49,705
これは 4 ÷ 2 + 1 = 3

38
00:02:49,705 --> 00:02:54,062
だから 3 x 3 出力を得ることになった

39
00:02:54,062 --> 00:03:02,115
では 最後の詳細を1つ この分数が整数にならなかったら？

40
00:03:02,115 --> 00:03:04,405
その場合は それを丸める

41
00:03:04,405 --> 00:03:10,775
この記法は 切り捨てを意味する

42
00:03:10,775 --> 00:03:14,395
これは floor(Z) と呼ばれる

43
00:03:14,395 --> 00:03:18,075
これは Zを丸めて 最も近い整数に切り捨てする

44
00:03:18,075 --> 00:03:21,640
これを実装する方法は 

45
00:03:21,640 --> 00:03:26,230
この種の青い箱の掛け算を 青い箱全てが 画像内に収まるか

46
00:03:26,230 --> 00:03:29,740
画像＋パディング内に収まる限りにおいて 行う

47
00:03:29,740 --> 00:03:32,590
そして もし この青い箱の一部でも

48
00:03:32,590 --> 00:03:35,935
外にはみ出すようなら 計算をしない

49
00:03:35,935 --> 00:03:41,080
よって 3 x 3 フィルターが

50
00:03:41,080 --> 00:03:44,955
画像内 もしくは 画像＋パディング内に

51
00:03:44,955 --> 00:03:47,110
完全に収まって初めて

52
00:03:47,110 --> 00:03:50,020
対応する出力が生成される
これが規約となっている

53
00:03:50,020 --> 00:03:55,670
よって 出力次元を計算する正しい方法は

54
00:03:55,670 --> 00:04:01,990
この (n + 2p - f) / s が整数で無い場合は切り捨てる

55
00:04:01,990 --> 00:04:04,205
次元数についてまとめよう

56
00:04:04,205 --> 00:04:07,780
n x n 行列 もしくは n x n 画像があり

57
00:04:07,780 --> 00:04:12,620
f x f 行列 もしくは f x f フィルターと
パティング p , ストライド s で畳み込むならば

58
00:04:12,620 --> 00:04:16,993
出力サイズはこの次元になる

59
00:04:16,993 --> 00:04:21,000
整数になるように これらの数を選ぶこともできる

60
00:04:21,000 --> 00:04:27,660
最も 時にはそうする必要は無いし 切り捨てしまってもよい

61
00:04:27,660 --> 00:04:32,900
しかし n f の値の例を処理するのは気軽に考えて欲しい

62
00:04:32,900 --> 00:04:35,850
p と s については あなたが欲しい

63
00:04:35,850 --> 00:04:41,331
出力サイズに対して正しい式となるようにする

64
00:04:41,331 --> 00:04:45,880
では 続ける前に 技術的な注意事項を挙げておきたい

65
00:04:45,880 --> 00:04:49,480
それは 相互相関と畳み込みに関するもので

66
00:04:49,480 --> 00:04:53,735
畳み込みニューラルネットワーを実装するためのものだ

67
00:04:53,735 --> 00:04:59,790
もし 別の 数学や信号処理の教科書を読むと

68
00:04:59,790 --> 00:05:05,690
表記が同じでないことに気付くかもしれない

69
00:05:05,690 --> 00:05:07,850
典型的な数学の教科書では

70
00:05:07,850 --> 00:05:12,650
畳み込みが 要素毎の掛け算と合計を行う前に 定義されている

71
00:05:12,650 --> 00:05:16,370
そこには 初めに行う もう一つの別のステップがある

72
00:05:16,370 --> 00:05:20,550
それは この 6 x 6 行列を 3 x 3 フィルターで畳み込むことなんだけど

73
00:05:20,550 --> 00:05:24,980
最初に この 3 x 3 フィルターをひっくり返して

74
00:05:24,980 --> 00:05:30,280
水平と垂直の軸を入れ替えることだ
そうすると この 3 4 5 1 0 2 -1 9 7 は

75
00:05:30,280 --> 00:05:38,580
こうなる
3 はここに 4 はここに

76
00:05:38,580 --> 00:05:43,070
5 はここに
そして2番目の行は ここで

77
00:05:43,070 --> 00:05:49,660
1 0 2, -1 9 7

78
00:05:49,660 --> 00:05:53,120
これは 3 x 3 フィルターを取り出し それを ナローイングしている

79
00:05:53,120 --> 00:05:58,218
垂直軸と水平軸 両方について

80
00:05:58,218 --> 00:06:04,225
じゃぁ このひっくり返した行列を コピーしてここに置く

81
00:06:04,225 --> 00:06:06,175
出力を完了させるのに

82
00:06:06,175 --> 00:06:08,650
2 x 7 して

83
00:06:08,650 --> 00:06:10,045
+ 3 x 2

84
00:06:10,045 --> 00:06:15,275
+ 7 x 5 等々としていく

85
00:06:15,275 --> 00:06:19,910
このひっくり返した行列を掛け合わせなくはならない

86
00:06:19,910 --> 00:06:25,415
このような 4 x 4 出力の左上の要素を計算するのに

87
00:06:25,415 --> 00:06:31,425
次に これら９つの数を

88
00:06:31,425 --> 00:06:35,916
１つずつ ずらしていく

89
00:06:35,916 --> 00:06:38,990
我々が このビデオで 畳み込み処理として定義したやり方では

90
00:06:38,990 --> 00:06:43,495
この ナローイング処理を省略した

91
00:06:43,495 --> 00:06:45,930
技術的には 我々が 実際にしていること

92
00:06:45,930 --> 00:06:49,360
これまでのビデオで使ってきた処理は

93
00:06:49,360 --> 00:06:54,180
時には 畳み込みではなく 相互相関 と見なされる

94
00:06:54,180 --> 00:06:57,645
しかし ディープラーニング文献の慣例では

95
00:06:57,645 --> 00:07:01,760
これを 単に 畳み込み処理と呼ぶ

96
00:07:01,760 --> 00:07:06,215
まとめると 機械学習の慣例では

97
00:07:06,215 --> 00:07:10,730
このひっくり返す処理には関わらない

98
00:07:10,730 --> 00:07:15,200
技術的には この処理は 相互相関と呼ぶべきだが

99
00:07:15,200 --> 00:07:20,165
ディープラーニング文献では 単に畳み込み処理と呼ぶ

100
00:07:20,165 --> 00:07:23,430
このコースのビデオでは 同じく この慣例を使う

101
00:07:23,430 --> 00:07:28,155
そして もし たくさんの機械学習の文献を読めば

102
00:07:28,155 --> 00:07:30,320
多くの人々が このひっくり返しを使うことを気にせずに

103
00:07:30,320 --> 00:07:35,490
単に これを 畳み込み処理と呼んでいる のに気付くだろう

104
00:07:35,490 --> 00:07:40,120
信号処理やある種の数学の分野における

105
00:07:40,120 --> 00:07:43,615
畳み込みの定義では このひっくり返しを行う

106
00:07:43,615 --> 00:07:49,870
なぜなら 畳み込み演算子に この有益な性質を持たせたいから

107
00:07:49,870 --> 00:07:53,320
(A * B) C = A * (B * C)

108
00:07:53,320 --> 00:07:58,505
これは 数学では 結合律 と呼ばれる

109
00:07:58,505 --> 00:08:02,080
これは 信号処理を行うアプリケーションでは 有益なことがある

110
00:08:02,080 --> 00:08:05,860
しかし ディープニューラルネットワークにとっては 意味が無い

111
00:08:05,860 --> 00:08:08,680
よって この２重の反転を省略し コードを簡単にした方が

112
00:08:08,680 --> 00:08:14,450
ニューラルネットワークには 却って良い

113
00:08:14,450 --> 00:08:18,380
そして 慣例では 我々の殆どが これを 畳み込みと呼ぶ

114
00:08:18,380 --> 00:08:24,240
また 数学者でさえも この相互相関を そう呼ぶのを好むことがある

115
00:08:24,240 --> 00:08:28,352
また あなたが 演習問題を実装するのに

116
00:08:28,352 --> 00:08:31,860
何の影響も無いし

117
00:08:31,860 --> 00:08:38,222
ディープラーニングの文献を読んで理解する能力にも影響しない

118
00:08:38,222 --> 00:08:41,600
さぁ これで 畳み込みを行う方法が 理解できたでしょう

119
00:08:41,600 --> 00:08:45,715
そして パディングやストライドを 畳み込みに使う方法も分かったでしょう

120
00:08:45,715 --> 00:08:49,795
ただし ここまでは 畳み込みを行列に使ってきた

121
00:08:49,795 --> 00:08:51,545
6 x 6 行列とかに

122
00:08:51,545 --> 00:08:55,670
次のビデオでは 畳み込みをボリュームに対して行う方法を見る
(訳注:ボリュームは ２次元配列の行列に対し ３次元配列のことを指している)

123
00:08:55,670 --> 00:08:59,730
これにより 畳み込みが 本当に非常に強力だ と感じられることでしょう

124
00:08:59,730 --> 00:09:01,580
次のビデオに進みましょう