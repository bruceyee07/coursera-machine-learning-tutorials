DNN을 구축하기 위해, 기본적인 컨볼루션 연산에 한 가지 변형을 여러분이 할 줄 알아야 하는데요, 그것은 바로 패딩입니다. 어떻게 작동하는지 보시죠. 지난 영상에서 본 것은 6x6 이미지를 3x3 필터와 합성했을 때, 4x4 행렬로 된 4x4 아웃풋이 나온다는 것이었습니다. 이게 가능한 이유는 3x3필터로 된 가능한 위치에 놓이는 숫자들이 있기 때문입니다. 이는 4x4에만 가능한 위치가 있다는 뜻이죠. 6x6매트릭스에 맞는 3x3필터가 있기 때문이기도 합니다. 수학적으로 봤을 때, n x n 이미지를 f x f 필터로 합성시키면 아웃풋의 차원은 (n-f+1) x (n-f+1) 이 될 것입니다. 이 예시에서, 6-3+1 = 4 입니다. 이것이 4x4 아웃풋을 갖게 되는 이유입니다. 여기엔 두 가지의 단점이 있는데요, 하나는 이겁니다. 컨벌루션 연산을 적용할 때 마다 이미지가 축소됩니다. 6x6에서 4x4로 줄어든다면, 여러분의 이미지가 정말 작아지기 전에 <br />단 몇 번의 연산만 수행할 수밖에 없습니다. 1x1 정도로 줄어드는 그 때 정도까지만 말이죠. 그러니, 모서리를 감지할 때마다 이미지가 줄어들지 않게 하거나 다른 피쳐를 그 위에 얹고자 할 때엔, 그게 하나의 단점이 되는 것이죠. 두 번째 단점은 이겁니다. 코너나 모서리에 있는 픽셀을 보면 이 작은 픽셀이 아웃풋의 하나로서만 사용되도록 터치되어집니다. 왜냐하면 이게 3x3영역을 건드리기 때문이죠. 반면에 가운데에 있는 픽셀을 고르면, <br />(이 픽셀이라고 치면) 그럼 그 픽셀과 겹쳐지는 3x3 영역이 많아지게 되고, 다시 말해, 코너나 모서리에 있는 픽셀들이<br />아웃풋에서 훨씬 적게 사용된다고 볼 수 있습니다. 따라서 이미지 가장자리 쪽의 <br />많은 정보를 버리는 것과 같습니다. 이러한 두 가지 문제점을 해결하기 위해서 축소되는 아웃풋과 여러분이 정말 여러 층으로 이루어진 인공 신경망을 만들 때 단계마다 이미지가 왜 줄어들면 안 되는지 살펴보세요. <br />왜냐하면 만약 여러분이 100개의 레이어로 된 deep net을 가지고 있고, 각 레이어마다 이미지 크기가 줄어든다면, 100 레이어 이후에는 매우 작은 이미지만 남게 될 것이기 때문입니다. 그래서 이게 첫 번째 문제점이었고, 또 다른 문제는 이미지의 가장자리에서 <br />많은 정보를 버리고 있다는 것입니다. 따라서 이 두 가지 문제점을 해결하기 위해 여러분이 할 수 있는 것은 <br />컨벌루션 연산을 최대로 적용하는 것입니다. 이미지를 덧붙일 수 있습니다. 이 경우, 이미지에 <br />추가적인 경계선을 덧댄다고 생각해봅시다. 모든 모서리 둘레에 하나의 픽셀을 추가해서 경계선을 그리는 거죠. 그렇게 하면, 6x6 이미지 대신에, 이걸 덧붙여서 8x8 이미지를 만들게 되고, 이 8x8 이미지를 3x3 필터와 컨볼브하게 되면,<br /> 이러한 결과를 만들어내게 됩니다. 자, 4x4 이미지가 대신 6x6 이미지가 생기고, 이제 원래의 6x6 인풋 사이즈를 유지하게 됩니다. 따라서 습관적으로 패딩할 때 0으로 패딩하고, p 크기만큼 패딩한다면 이러한 경우, p=1과 같습니다. 왜냐하면 픽셀의 추가적인 경계선으로 모든 테두리를 덧붙이고 있기 때문입니다. 그리고 아웃풋은 (n+2p-f+1) x (n+2p-f+1) 이므로, 이는 (6+2-3+1) x (6+2-3+1) 가 됩니다. 따라서 (6+2-3+1) 은 6이 됩니다. 원본 사이즈를 보존한 6x6 이미지를 얻게 되는 것입니다. 이 픽셀의 존재는 실제로 아웃풋의 모든 셀에 영향을 주고, 정보를 허비하는 게 아니라 덜 셈으로서 이미지의 코너의 모서리나 이미지의 가장자리에 있는 정보는 줄어들게 됩니다. 여기 보여드리는 것처럼, 하나의 픽셀을 deep border를 덧붙이는 효과인데요, 원한다면 두 개의 픽셀을 경계에 붙일 수도 있습니다. 이런 경우엔 또 다른 경계 면에 붙일 수도 있는데요, 여러분이 선택한 만큼 더 많은 픽셀을 붙일 수도 있겠죠. 제 생각엔 여기 그리고 있는 건, 이건 덧붙여진 건 2개, 즉 p=2이죠 얼마나 많이 덧붙일 수 있는가에 대해서는, 공통적으로 불리는 2개가 있는데요 Valid Convolution과 Same Convolution입니다. 대단한 이름은 아니지만, Valid Convolution에서는 기본적으로 패딩이 없는 것을 의미합니다. 이 경우, n x n 이미지를 f x f 필터로 컨볼브해서 이는 (n-f+1) (n-f+1) x (n-f+1) 의 아웃풋을 산출하게 됩니다. 이것은 이전 영상에서 보았던 예시와 같은 것인데요, n x n 이미지를 3 x 3 필터로 컨볼브 해서 4x4 아웃풋을 도출했었습니다. 또 다른 일반적인 선택지는 Same Convolution인데요, 이것은 패드를 해서 아웃풋 사이즈가 인풋 사이즈와 같은 경우를 뜻합니다. 실제로 이 공식을 보시면, p 픽셀로 패드를 할 때, 이는 마치 n+2p 그리고 나서 이 나머지인 거죠, 그렇죠? -f+1 nxn 이미지와 온 테두리를 p 픽셀로 패딩하였다면, 이 아웃풋의 차원은 n +2p-f+1을 곱한 것과 같습니다. 따라서 만약 n+2p-f+1이 n이 되려면 즉, 아웃풋 사이즈가 인풋 사이즈와 같아지려면, 이걸 계산하면 양변에 n 을 지워주고, p에 대해 풀어보면 p는 2분의 f-1 이 됩니다. f가 홀수이면 다음과 같이 패딩 크기를 결정해서 아웃풋 사이즈가 인풋사이즈와 같다는 것을 확인할 수 있습니다, 그렇게 때문에 예를 들어 이전 슬라이드에서 봤던 것처럼 필터가 3x3이면 아웃풋 크기와 인풋 크기를 같게 하는 패딩은 2분의 3-1, 즉 1 입니다. 또 다른 예를 들어보면, 필터가 5x5 이고 즉, f=5이라면 이걸 방정식에 대입하면, 2만큼의 패딩이 아웃풋 크기를 인풋 크기와 똑같게 만들어줍니다. 필터가 5x5일때 말이죠. 그리고 컴퓨터 비전 분야의 관습에 따르면 f는 주로 홀수이며, 사실 대부분 항상 홀수입니다, 짝수로 된 필터는 보기도 어렵습니다. 필터는 컴퓨터 비전을 사용해서 작동합니다. 그리고 제 생각에 그 이유는 두 가지 입니다. 첫째로, f가 짝수이면 몇 가지 비대칭적인 패딩을 해야 합니다. 따라서 f가 홀수여서 이 Same Convolution 유형이 자연적인 패딩 영역을 주기만 한다면 패딩이 왼쪽엔 더 많고 오른쪽엔 더 적다거나 혹은 불규칙적이지 않고 사방에 같은 dimension이 있을 것이다. 두 번째 이유는, 홀수 차원의 필터를 사용한다면 예를 들어 3x3 이나 5x5와 같이 중앙 포지션을 가지고 있고 때로는 컴퓨터 비전분야에 있어서 특징점을 가지고 있다는 것은 좋은 점입니다. 픽셀을 가지고 있으면 좋습니다, 중앙의 픽셀을 칭할 수 있고 필터의 포지션에 대해 이야기할 수 있습니다. 맞습니다, 어느 것도 f 가 거의 항상 홀수로 사용되는 데 있어 좋은 이유가 될 수는 없습니다. 하지만 컨벌루션 문헌에 보면, 3x3 필터가 매우 흔하다는 걸 보게 됩니다. 또는 5x5, 7x7을 보게 되기도 하고, 실제로 때로는, 1x1 필터에 대해 알아보고 그게 어떻게 가능한지도 살펴보겠습니다. 하지만 관행적으로, 홀수 필터를 사용하기를 권장합니다. 제 생각엔 아마 가능할 것 같습니다. f에 짝수 값을 사용한다 하더라도 좋은 성능을 낼 수 있을 것 같습니다. 하지만 여러분이 아직 컴퓨터 비전 관행에 매여있다면, 저는 대개 홀수 f를 사용합니다, <br />자, 여러분은 Padded Convolution을 사용하는 방법을 살펴보았습니다. 컨벌루션 연산을 위해 패딩을 더 알고 싶다면 p 값을 구체화하거나 Valid Convolution이라고 하면 되는데요, 이는 p=0 임을 의미하는 것이죠. <br />아니면 Same Convolution, 즉, 아웃풋이 인풋과 같은 차원을 가지는 패딩도 있습니다. 여기까지 패딩에 대해 보았습니다. 다음 강좌에서는, Strided Convolution를 실행하는 법에 대해 알아보겠습니다.