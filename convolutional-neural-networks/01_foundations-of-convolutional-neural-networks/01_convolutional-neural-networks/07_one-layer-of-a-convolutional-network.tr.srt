1
00:00:03,945 --> 00:00:07,666
Şimdi evrişimsel bir sinir ağının
 nasıl oluşturulacağını göreceğiz,

2
00:00:07,666 --> 00:00:09,223
bir örnek üzerinden gidelim.

3
00:00:12,432 --> 00:00:17,146
Bir önceki videoda,
 nasıl 3 boyutlu bir hacmi alıp iki farklı 

4
00:00:17,146 --> 00:00:20,670
filtre ile evriştirileceğini gördünüz.

5
00:00:21,810 --> 00:00:25,861
Ve sonuçta iki farklı 4e 4lük çıktı aldık.

6
00:00:30,891 --> 00:00:35,548
Ilk fıltreyle evriştirdiğimizde

7
00:00:35,548 --> 00:00:40,769
bu 4'e 4'lük çıktıyı elde ediyoruz,

8
00:00:40,769 --> 00:00:49,108
ikinci filtre ile evriştirdiğimizde ise
 4'e 4'lük farklı bir çıktı veriyor.

9
00:00:49,108 --> 00:00:55,574
Bunu evrişimsel bir sinir ağına çevirmek
için yapmamız gereken son şey ise

10
00:00:55,574 --> 00:01:00,566
her ikisine de reel bir

11
00:01:00,566 --> 00:01:03,980
yanlılık ekleyeceğiz.

12
00:01:03,980 --> 00:01:08,840
Python'da olduğu gibi,
 aynı sayıyı

13
00:01:08,840 --> 00:01:11,750
buradaki 16 elemanın hepsine ekliyoruz.

14
00:01:11,750 --> 00:01:16,805
Ardından doğrusal olmayan bir
 fonksiyona uyguluyoruz

15
00:01:16,805 --> 00:01:23,430
ki bu örnekte ReLu fonksiyonuna karşılık geliyor
ve bu size 4'e 4'lük bir çıktı verıyor.

16
00:01:23,430 --> 00:01:27,295
Yanlılığı ekledikten ve doğrusal olmayan fonksiyona soktuktan sonra

17
00:01:27,295 --> 00:01:31,894
alttaki için de aynı şeyleri yapıyoruz, 
 farklı bir yanlılık değeri ekliyoruz

18
00:01:31,894 --> 00:01:33,154
b2 de reel bir sayı.

19
00:01:33,154 --> 00:01:36,473
Bunu 16 sayının hepsine ekliyoruz, ve

20
00:01:36,473 --> 00:01:40,934
ardından doğrusal olmayan fonksiyona sokuyoruz
ReLu fonksiyonu olsun.

21
00:01:40,934 --> 00:01:47,369
Ve bu da 4'e 4'lük farklı bir çıktı veriyor.

22
00:01:47,369 --> 00:01:52,461
Daha önce de yaptığımız gibi
bunu alır ve

23
00:01:52,461 --> 00:01:59,698
şu şekilde birleştirirsek
4x4x2'lik çıktıyı elde ediyoruz.

24
00:01:59,698 --> 00:02:06,326
6x6x3'lük hacimden 4x4x2'lik hacime ulaştğımız
 tüm bu hesaplamalar neticesinde

25
00:02:06,326 --> 00:02:11,303
evrişimsel sinir ağımızın
bir katmanını elde etmiş oluyoruz.

26
00:02:11,303 --> 00:02:15,634
Yani bunu eslemek icin 

27
00:02:15,634 --> 00:02:18,832
standart sinir ağındaki ileri yayılımın bir katmanına eşlemek için,

28
00:02:18,832 --> 00:02:23,155
Hatırlarsanız yayılımdan öncekı adımlardan biri şu şekilde idi, değil mi?

29
00:02:23,155 --> 00:02:28,461
z1=w1 çarpı a[0], a[0] da x'e eşitti,

30
00:02:28,461 --> 00:02:31,265
artı b[1].

31
00:02:31,265 --> 00:02:38,121
Daha sonra, a[1]'i elde etmek için doğrusal olmayan fonksiyon uyguluyoruz ve bu da g(z[1])'e eşitç

32
00:02:38,121 --> 00:02:43,400
Buradaki girdi(input), bu benzetmede bu a[0].

33
00:02:44,770 --> 00:02:48,076
Buradaki filtreler de

34
00:02:48,076 --> 00:02:52,488
w[1]'e benzeyen bir rol üstlenir.

35
00:02:52,488 --> 00:02:56,377
Hatırlarsanız evriştirme işlemi sırasında, bu 27 sayıyı alıp,

36
00:02:56,377 --> 00:03:01,149
aslında 27 çarpı 2 çünkü iki filtre var burada.

37
00:03:01,149 --> 00:03:03,900
Tüm bu sayıları alıp çarpıyorsunuz.

38
00:03:03,900 --> 00:03:09,631
Bu 4x4 matrisi elde edebilmek için doğrusal bir fonksiyon hesaplıyorsunuz.

39
00:03:09,631 --> 00:03:15,048
Bu 4x4 matris, evriştirme işleminin çıktısı,

40
00:03:15,048 --> 00:03:19,245
bu w[1] çarpı a[0] gibi bir rol üstlenir.

41
00:03:19,245 --> 00:03:25,340
Bu gerçekten de bu 4x4 ün aynı zamanda bu 4x4'ün çıktısıdır.

42
00:03:25,340 --> 00:03:29,599
Diğer yaptığınız şey ise yanlılğı eklemek.

43
00:03:29,599 --> 00:03:35,138
ReLU fonksıyonunu uygulamadan önceki buradaki ifade

44
00:03:35,138 --> 00:03:38,939
z'ye benzeyen bır rol üstlenir.

45
00:03:38,939 --> 00:03:43,848
En sonunda doğrusal olmayan fonksiyonu uyguuyoruz, bu da bir nevi buna eşit.

46
00:03:43,848 --> 00:03:49,740
Bu da sizin bir sonraki katman için

47
00:03:49,740 --> 00:03:53,390
aktivasyonunuz olur.

48
00:03:53,390 --> 00:03:58,794
a[0]'dan başlayarak a[1]'e işte bu şekilde ulaşıyoruz, ilk başta doğrusal işlemler

49
00:03:58,794 --> 00:04:02,192
evriştirme işlemi çarpımlardan oluşuyor.

50
00:04:02,192 --> 00:04:05,507
Bu yüzden evriştirmeyi doğrusal bir işleme tabi tutmak olarak düşünebiliriz ve

51
00:04:05,507 --> 00:04:08,437
yanlılığı ekliyoruz ve ReLU fonksiyonu uyguluyoruz.

52
00:04:08,437 --> 00:04:14,107
6x6x3 boyutundaki a[0]'dan başlayarak

53
00:04:14,107 --> 00:04:18,210
sinir ağının bir katmanı aracılığı ile,

54
00:04:18,210 --> 00:04:22,693
4x4x2'lik a[1]'i elde ettik.

55
00:04:22,693 --> 00:04:27,144
6x6x3'ten 4x4x2'e gittik.

56
00:04:27,144 --> 00:04:30,860
Bu evrişimsel sinir ağının bir katmanı.

57
00:04:33,697 --> 00:04:40,504
Bu örnekte 2 filtremiz var, iki öznitelik,

58
00:04:40,504 --> 00:04:45,270
4x4x2 boyutlu çıktı elde etmemizin sebebi de bu,

59
00:04:45,270 --> 00:04:49,248
Fakat eğer 2 filtre yerine 10 filtre olsaydı,

60
00:04:49,248 --> 00:04:54,396
çıktının hacmi 4x4x10 olurdu.

61
00:04:54,396 --> 00:05:00,334
çünkü bunlardan 10 tane olacaktı sadece 2 değil ve bunları yığdığımızda

62
00:05:00,334 --> 00:05:05,598
4x4x10'luk çıktı hacmi elde edecektik ve a[1] bu olacaktı.

63
00:05:05,598 --> 00:05:09,630
Peki, bunu anladığınızdan emin olmak için bir örnek üzerinden gidelim.

64
00:05:09,630 --> 00:05:14,655
Sinir ağının bır katmanında sadece 2 filtre değil de boyutları 3x3x3 olan 10 filtre olduğunu varsayalım,

65
00:05:14,655 --> 00:05:19,600
Bu katmanda kaç tane parametre vardır?

66
00:05:21,000 --> 00:05:22,984
Hadi bunu bulalım.

67
00:05:22,984 --> 00:05:29,439
Her filtrenin, hacmi 3x3x3

68
00:05:29,439 --> 00:05:35,318
her filtre 27 parametreye sahip, değil mi?

69
00:05:35,318 --> 00:05:39,800
Öğrenilmesi gereken 27 sayı var ve bir de yanlılık.

70
00:05:42,210 --> 00:05:46,818
Bu b parametresiydi, toplamda 28 yaptı.

71
00:05:50,125 --> 00:05:54,456
Düşünün önceki slaytda 2 filtre vardı

72
00:05:54,456 --> 00:05:58,329
şimdi ise 10 tane fıltre var.

73
00:05:58,329 --> 00:06:01,747
1, 2, ...., 10 tane

74
00:06:01,747 --> 00:06:06,942
hepsi birlikte 28 çarpı 10 

75
00:06:06,942 --> 00:06:10,753
ve sonuçta 280 parametre ediyor.

76
00:06:10,753 --> 00:06:16,316
Bunun hakkında dikkat edilmesi gereken önemli bir husus da
giriş resminiz ne kadar büyük olursa olsun,

77
00:06:16,316 --> 00:06:22,051
giriş resminiz 1000'e 1000 ya da 
5,000'e 5,000 de olabilir,

78
00:06:22,051 --> 00:06:26,973
ama parametre sayısı hala 280 olarak kalır.

79
00:06:26,973 --> 00:06:31,453
Ve bu 10 filtreyi kullanarak birtakım özellikleri tespit edebilirsiniz, yatay kenar çizgilerini,

80
00:06:31,453 --> 00:06:35,485
dikey kenar çizgilerini belki diğer
başka özellikleri, çok çok büyük bir resmin herhangi bir yerindeki bile

81
00:06:35,485 --> 00:06:39,240
sadece az sayıda parametre ile tespit edebilirsiniz.

82
00:06:40,920 --> 00:06:44,410
Bu sinirsel ağları aşırı uyumluluğa(overfitting) daha az

83
00:06:44,410 --> 00:06:48,000
yatkın hale getiren bir özellik.

84
00:06:48,000 --> 00:06:51,450
Yani 10 tane çalışan öznitelik saptayıcısı öğrendiğinizde,

85
00:06:51,450 --> 00:06:54,770
bunu çok büyük bir resme bile uygulayabilirsiniz.

86
00:06:54,770 --> 00:06:58,300
Ve parametre sayısı hala sabit ve nispeten az,

87
00:06:58,300 --> 00:07:00,494
mesela bu örnekte 280.

88
00:07:00,494 --> 00:07:05,130
Pekala, bu videoyu bir özetlersek 

89
00:07:05,130 --> 00:07:09,766
hadi evrişimli sinir ağlarını özetlemek için evrişimli katmanı tanımlayalım

90
00:07:09,766 --> 00:07:11,980
temel yapı taşlarından biridir

91
00:07:11,980 --> 00:07:14,302
Yani l katmanı bir evrişimli katmansa

92
00:07:14,302 --> 00:07:18,555
filtre boyutunu ifade etmek için f üzeri [l] kullanacağım.

93
00:07:18,555 --> 00:07:23,219
Önceden filtrelerimizin boyutlarını
ifade etmek için f x f kullanıyorduk

94
00:07:23,219 --> 00:07:28,163
Şimdiyse [l] ile sadece l katmanının filtre boyutlarının
 f x f olduğunu

95
00:07:28,163 --> 00:07:31,074
ifade ediyoruz.

96
00:07:31,074 --> 00:07:35,767
Önceden de olduğu gibi, üzeri [l] ifadesini,
l katmanından bahsettiğimizi

97
00:07:35,767 --> 00:07:37,611
belirtmek için kullanıyoruz.

98
00:07:39,812 --> 00:07:42,809
Doldurma miktarını belirtmek için p[l] ifadesini
kullanacağız.

99
00:07:42,809 --> 00:07:47,363
Ve yine, doldurma miktarını, yalnızca
'valid'(geçerli) evrişim istediğimizi belirterek,

100
00:07:47,363 --> 00:07:50,135
sıfır olarak ayarlayabiliriz.

101
00:07:50,135 --> 00:07:53,240
Ya da 'same'(aynı) evrişim istediğimizi belirterek
dolgunun, çıktıyla girdinin yükseklik

102
00:07:53,240 --> 00:07:57,910
ve genişliğinin aynı olacağı şekilde ayarlanmasını
sağlayabiliriz.

103
00:07:59,000 --> 00:08:01,590
Kaydırma adımını belirtmek için s[l] kullanacağız.

104
00:08:03,250 --> 00:08:09,450
Bu katmanın girdisinin belli bir boyu olacak. O da

105
00:08:09,450 --> 00:08:18,590
n x n x bir önceki katmanın kanal sayısı
olacak.

106
00:08:18,590 --> 00:08:21,162
Şimdi bu ifade şeklini biraz değiştireceğim.

107
00:08:21,162 --> 00:08:25,385
n üzeri [l-1] kullanacağım 

108
00:08:25,385 --> 00:08:29,902
çünkü bu bir önceki katmanın aktivasyonu.

109
00:08:29,902 --> 00:08:35,594
n[l-1] x n[l-1] x nc[l-1]

110
00:08:35,594 --> 00:08:40,966
Şimdiye kadarki örneklerimizde aynı yükseklik
ve genişliğe sahip resimleri kullanıyorduk

111
00:08:40,966 --> 00:08:43,990
Ama yükseklik ve genişlik farklı olabileceği için

112
00:08:43,990 --> 00:08:48,528
Bir önceki katmanın girdisinin genişliğini ve yüksekliğini
ifade etmek için

113
00:08:48,528 --> 00:08:51,949
_h (height/yükseklik) ve _w (width/genişlik) kullanacağım.

114
00:08:51,949 --> 00:08:56,418
Yani l katmanındaki hacmin büyüklüğü

115
00:08:56,418 --> 00:09:01,134
n_h x n_w x n_c üzeri [l] olacak

116
00:09:01,134 --> 00:09:05,597
l katmanının girdisi, bir önceki katmandan geldiği için

117
00:09:05,597 --> 00:09:09,451
l-1 kullanıyoruz.

118
00:09:09,451 --> 00:09:16,730
Sonra yapay sinir ağının bu katmanının bir de 
kendi çıktısı olacak.

119
00:09:16,730 --> 00:09:23,065
O da n_h[l] x n_w[l] x n_c

120
00:09:23,065 --> 00:09:28,495
boyutunda olacak.

121
00:09:28,495 --> 00:09:34,941
Böylece önceden çıktının büyüklüğü için,
en azından yüksekliği

122
00:09:34,941 --> 00:09:40,657
ve genişliği için şu formülü kullanıp aşağı yuvarlarken:

123
00:09:40,657 --> 00:09:47,971
(n + 2p - f/s)+1

124
00:09:47,971 --> 00:09:55,605
Bu yeni gösterimde, l katmanının çıktısı

125
00:09:55,605 --> 00:10:00,891
önceki katmandaki boyutlar n[l-1]

126
00:10:00,891 --> 00:10:05,471
artı şu anki l katmanında kullandığımız
doldurma (padding) p[l]

127
00:10:05,471 --> 00:10:11,760
eksi l katmanının filtre büyüklüğü f[l], ve bunun gibi...

128
00:10:11,760 --> 00:10:16,580
Ve tekik olarak bu yükseklik için geçerli,
değil mi?

129
00:10:16,580 --> 00:10:21,510
Yani çıktı hacminin yüksekliği bu formülle veriliyor, 
sağdaki formülle bunu hesaplayabilirsiniz.

130
00:10:21,510 --> 00:10:24,680
Aynısı genişlik için de geçerli

131
00:10:24,680 --> 00:10:26,670
h'nin üstünü çizip

132
00:10:26,670 --> 00:10:30,780
w yazarsak aynı formülle genişliği elde edebiliriz.

133
00:10:30,780 --> 00:10:34,775
Yani bu aynı formülü kullanarak çıktının
yüksekliğini veya genişliğini hesaplayabiliriz.

134
00:10:36,570 --> 00:10:44,024
n_h[l-1]'la n_h[l] ve n_w[l-1] ve n_w[l] bu şekilde
ilişkilendirilebilirler.

135
00:10:44,024 --> 00:10:48,105
Peki ya kanalların sayısı? O sayı nereden
geliyor ona bakalım.

136
00:10:48,105 --> 00:10:52,784
Eğer çıktı hacmi bu derinliğe sahipse,

137
00:10:52,784 --> 00:10:57,662
bunun bu katmandaki filtrelerin sayısına eşit
olduğunu

138
00:10:57,662 --> 00:11:02,167
önceki örneklerden biliyoruz değil mi?

139
00:11:02,167 --> 00:11:07,017
Mesela 2 filtremiz vardıysa, çıktımız 
4x4x2, 2 boyutlu oluyordu.

140
00:11:07,017 --> 00:11:11,097
Ya da 10 filtremiz olduğunda,
çıktı hacmi 4x4x10 oluyordu.

141
00:11:11,097 --> 00:11:15,744
Yani bu, çıktı hacmindeki kanal sayısı,

142
00:11:15,744 --> 00:11:23,098
yalnızca sinir ağının bu katmanında kullandığımız
filtre sayısını gösteriyor.

143
00:11:23,098 --> 00:11:26,849
Sırada, bu filtrenin büyüklüğü ne olmalı?

144
00:11:26,849 --> 00:11:33,057
Her bir filtre f[l] x f[l] x bir sayı olacak
değil mi?

145
00:11:33,057 --> 00:11:34,704
Peki bu son sayı nedir?

146
00:11:34,704 --> 00:11:39,465
6x6x3 bir resmi 3x3x3 bir filtreyle

147
00:11:39,465 --> 00:11:41,580
evriştirmemiz gerektiğini görmüştük.

148
00:11:43,070 --> 00:11:48,150
Yani filtrenizdeki kanalların sayısı
girdinizdeki kanalların sayısına eşit olmalı.

149
00:11:48,150 --> 00:11:54,360
Bu sayı, bu sayıyla aynı olmalı.

150
00:11:54,360 --> 00:12:02,627
Bu nedenle her filtrenin büyüklüğü
f[l] x f[l] x n_c[l-1] olacak.

151
00:12:02,627 --> 00:12:07,875
Bu katmanın çıktısı, yanlılığı ekleyip
doğrusal olmayan fonksiyona soktuktan sonra

152
00:12:07,875 --> 00:12:11,745
bu a[l] katmanının aktivasyonları olacak

153
00:12:11,745 --> 00:12:15,115
Ve de bunun, bu boyutlarda olacağını
gördük değil mi?

154
00:12:15,115 --> 00:12:20,451
a[l], n_h[l] x n_w[l] x n_c[l] boyutlarında

155
00:12:20,451 --> 00:12:25,556
3 boyutlu bir hacim olacak.

156
00:12:25,556 --> 00:12:31,082
Ve de vektörize bir uyarlama yapıyorsanız, 
ya da Toplu Gradyan İniş (Batch Gradient Descent)

157
00:12:31,082 --> 00:12:36,891
ya da Mini Toplu Gradyan (mini batch GD) İniş 
kullanıyorsanız ve m örneğiniz varsa,

158
00:12:36,891 --> 00:12:41,387
m sayıda aktivasyona karşılık gelen 
A[l] çıktınız olacak demek.

159
00:12:41,387 --> 00:12:48,275
Yani m x n_h[l] x n_w[l] x n_c[l]

160
00:12:48,275 --> 00:12:51,375
Diyelim ki, eğer sert bir gradyan inişi kullanıyorsanız ve

161
00:12:51,375 --> 00:12:55,999
programlama boyutlarında bu değişkenlerin sıralanması olacaktır.

162
00:12:55,999 --> 00:12:59,962
Ve bizim önce dizin ve izleyen örneklerimiz var,

163
00:12:59,962 --> 00:13:02,384
Ve sonra da bu üç değişken.

164
00:13:02,384 --> 00:13:07,618
Peki sonra ağırlılar veya parametreler veya bir çeşit w parametresi ne olacak?

165
00:13:07,618 --> 00:13:10,264
Pekala, daha önce filtre boyutunun ne olduğunu görmüştük.

166
00:13:10,264 --> 00:13:16,258
Evet, filtreler f[l] ye f[l] ye nc[l-1] olacaklardır,

167
00:13:16,258 --> 00:13:20,230
ama bu bir filtrening boyutu.

168
00:13:20,230 --> 00:13:22,247
Kaç filtremiz var?

169
00:13:22,247 --> 00:13:25,097
Bu kullandığımız filtrelerin sayısı, yani

170
00:13:25,097 --> 00:13:30,029
tüm filtreler bir araya gelince oluşan ağırlığın boyutu bununla

171
00:13:30,029 --> 00:13:33,513
ifade edilir, çarpı filtrelerin toplam sayısı, değil mi?

172
00:13:33,513 --> 00:13:38,625
Çünkü bu, l katmanındaki son nicelik

173
00:13:38,625 --> 00:13:43,750
filtrelerin sayısıdır.

174
00:13:45,680 --> 00:13:48,710
Ve son olarak, yanlılık parametreleriniz var, ve

175
00:13:48,710 --> 00:13:54,100
her bir filtre için bir gerçek sayı olarak bir yanlılık parametreniz var.

176
00:13:54,100 --> 00:13:57,970
Yani, yanlılık parametresinin bu kadar değişkeni olacak ve

177
00:13:57,970 --> 00:14:00,810
bu sadece bu boyun bir vektörü olacak.

178
00:14:00,810 --> 00:14:05,052
Her ne kadar kodun daha sonra 1 e 1 e 1 e nc[l] olarak dört boyutlu

179
00:14:05,052 --> 00:14:09,813
bir dizeyde veya dört boyutlu bir tensörde ifade edilmesinin

180
00:14:09,813 --> 00:14:14,790
daha uygun olacağını görecek olsak da.

181
00:14:16,430 --> 00:14:19,408
Evet, biliyorum bu oldukça fazla formüldü, ve

182
00:14:19,408 --> 00:14:23,303
ve bu çoğu kısım için kullanacağım düzen.

183
00:14:23,303 --> 00:14:27,498
Sadece belirtmek isterim ki, eğer çevrimiçi olarak araştıracak olursanız ve açık kaynak koduna bakarsanız

184
00:14:27,498 --> 00:14:32,311
yükseklik, genişlik ve kanal'ın sıralaması hakkında evresel olarak geçerli

185
00:14:32,311 --> 00:14:34,260
standart bir uygulama yok.

186
00:14:34,260 --> 00:14:39,142
Yani eğer GitHub'ta kaynak koduna bakarsanız veya bu açık kaynak uygulamalarda,

187
00:14:39,142 --> 00:14:43,873
göreceksiniz ki bazı yazarlar bunun yerine, önceki kanalı koyduğunuz bu

188
00:14:43,873 --> 00:14:48,631
sıralamayı kullanıyorlar, ve bazen değişkenlerin bu sıralamasını görürsünüz.

189
00:14:48,631 --> 00:14:52,154
Ve aslında bazı genel çatılarda, aslında çoklu genel çatılarda,

190
00:14:52,154 --> 00:14:54,155
aslında bir değişken veya bir parametre var.

191
00:14:54,155 --> 00:14:57,652
Bu hacimleri dizinlerken neden kanalların sayısını ilk listelemek istiyorsunuz,

192
00:14:57,652 --> 00:15:02,000
veya kanalların sayısını son listelemek istiyorsunuz.

193
00:15:02,000 --> 00:15:08,137
Bence tutarlı olduğunuz sürece bu uygulamaların her ikisi de doğru çalışıyor.

194
00:15:08,137 --> 00:15:13,049
Ve maalesef belki bu bir çeşit ek açıklama olacak,

195
00:15:13,049 --> 00:15:17,772
derin öğrenme literatüründe bir fikir birliği yok, ama

196
00:15:17,772 --> 00:15:21,752
bu videolar için boy ve en ve sonra kanal sayısını son olarak

197
00:15:24,681 --> 00:15:30,769
listelediğimiz bu formülü kullanacağım.

198
00:15:30,769 --> 00:15:34,327
Evet, biliyorum ki kesinlikle kullanabileceğiniz oldukça fazla formül vardı,

199
00:15:34,327 --> 00:15:38,027
ama vay diye düşünüyorsunuz, bu oldukça uzun bir formül ve bunların hepsini nasıl hatırlaycağım?

200
00:15:38,027 --> 00:15:41,994
Bunu endişe etmeyin, bu formüllerin hepsini hatırlamanız gerekmiyor, ve

201
00:15:41,994 --> 00:15:46,036
bu haftanın egzersizleri süresince daha aşina olacaksınız.

202
00:15:46,036 --> 00:15:49,116
Ancak bu videodan alacağınızı umduğum kilit nokta,

203
00:15:49,116 --> 00:15:52,694
konvansiyonel sinir ağlarının nasıl çalıştığına dair sadece bir katman.

204
00:15:52,694 --> 00:15:57,006
Ve bir katmanın aktivasyonlarını almak ile ilgili olan hesaplamalar ve

205
00:15:57,006 --> 00:16:00,052
bunları bir sonraki katmanın aktivasyonlarına eşlemek.

206
00:16:00,052 --> 00:16:04,063
Ve daha sonra, şimdi bileşimsel sinir ağının bir katmanının nasıl çalıştığını bildiğinize göre,

207
00:16:04,063 --> 00:16:07,740
bunlardan bir demeti bir araya getirip daha derin bileşimsel bir

208
00:16:07,740 --> 00:16:09,040
sinir ağı oluşturalım.

209
00:16:09,040 --> 00:16:10,200
Bir sonraki videoya gidip görelim.