1
00:00:00,000 --> 00:00:02,385
在这周的最后一个视频

2
00:00:02,385 --> 00:00:05,520
咱们来谈谈为什么把卷积

3
00:00:05,520 --> 00:00:08,990
放在神经网络中会如此有用

4
00:00:08,990 --> 00:00:13,890
最后，我们简要说一下如何把卷积和神经网络合在一起，以及

5
00:00:13,890 --> 00:00:20,160
如果你有一个标签的训练数据集，如何用它来训练这个卷积神经网络

6
00:00:20,160 --> 00:00:23,610
我觉得卷积层和

7
00:00:23,610 --> 00:00:29,091
只用完全连接的神经层比起来有两个优势

8
00:00:29,091 --> 00:00:34,075
参数共享和连接的稀疏性

9
00:00:34,075 --> 00:00:36,097
让我来进一步解释这一原理

10
00:00:36,097 --> 00:00:42,915
比如说，你有一个32×32x3维的图片

11
00:00:42,915 --> 00:00:49,040
事实上这来自于上一个视频的例子

12
00:00:49,040 --> 00:00:54,945
但比如说你有6个5×5的滤网

13
00:00:54,945 --> 00:01:04,887
然后这就给你一个28×28×6维的输出结果

14
00:01:04,887 --> 00:01:07,938
所以32×32×3是3072

15
00:01:07,938 --> 00:01:17,320
然后28×28×6，如果你把这些数字乘起来就是4704

16
00:01:17,320 --> 00:01:24,049
所以，如果你是创建一个一层有3072个单元的神经网络

17
00:01:24,049 --> 00:01:27,995
下一层是4704个单元

18
00:01:27,995 --> 00:01:31,205
然后你会连接每一个这些神经元

19
00:01:31,205 --> 00:01:32,650
接着是权重矩阵

20
00:01:32,650 --> 00:01:35,624
在权重矩阵，这些参数的总数是3072

21
00:01:35,624 --> 00:01:42,175
乘以4704，结果大约是1400万个

22
00:01:42,175 --> 00:01:44,950
所以这样就有很多参数需要训练

23
00:01:44,950 --> 00:01:49,455
当然如今你可以训练比1400万更多参数的神经网络

24
00:01:49,455 --> 00:01:52,543
但是，考虑到这仅仅是很小的图像

25
00:01:52,543 --> 00:01:54,985
却有如此多的参数需要训练

26
00:01:54,985 --> 00:02:00,030
而且，如果说有一个1000×1000的图像

27
00:02:00,030 --> 00:02:04,920
那么这个权重矩阵将会变得非常大

28
00:02:04,920 --> 00:02:10,020
但是如果你看看这个卷积层的参数总数

29
00:02:10,020 --> 00:02:12,710
每个滤网是5x5

30
00:02:12,710 --> 00:02:15,385
因此每个滤网有25个参数

31
00:02:15,385 --> 00:02:19,120
而且一个偏置参数对每个滤网会错过26个参数

32
00:02:19,120 --> 00:02:21,280
你有6个滤网

33
00:02:21,280 --> 00:02:23,800
所以总共的参数总数

34
00:02:23,800 --> 00:02:26,605
就等于156个参数

35
00:02:26,605 --> 00:02:31,360
所以这个卷积层的参数总数仍然很少

36
00:02:31,360 --> 00:02:37,965
卷积神经网络参数很少的原因有两个

37
00:02:37,965 --> 00:02:40,110
一个是参数共享

38
00:02:40,110 --> 00:02:43,915
参数共享是源于

39
00:02:43,915 --> 00:02:47,575
在特征检测器中，例如垂直边缘检测对于

40
00:02:47,575 --> 00:02:51,098
图像的一部分是有用的，那么对于另一部分可能也是有用的

41
00:02:51,098 --> 00:02:52,435
这意味着

42
00:02:52,435 --> 00:02:56,635
如果你发现用一个3×3的滤网来检测垂直边缘

43
00:02:56,635 --> 00:03:01,765
那么你就能够在这里用这个3×3滤网

44
00:03:01,765 --> 00:03:03,755
然后到下一个位置

45
00:03:03,755 --> 00:03:06,220
然后用再下一个位置，一直进行下去

46
00:03:06,220 --> 00:03:09,040
所以对于所有这些特征检测器

47
00:03:09,040 --> 00:03:13,510
所有这些输出结果可以在你的输入图像

48
00:03:13,510 --> 00:03:17,140
许多不同的位置使用相同的参数

49
00:03:17,140 --> 00:03:21,825
来检测比如说一个垂直的边缘或其他一些特征

50
00:03:21,825 --> 00:03:25,885
我认为这对简单的特征 例如边缘

51
00:03:25,885 --> 00:03:28,990
以及更高层次的特征

52
00:03:28,990 --> 00:03:32,865
比如检测眼睛，脸，猫，或其他东西 都是可以的

53
00:03:32,865 --> 00:03:34,640
但是共享参数在这个例子里面

54
00:03:34,640 --> 00:03:39,455
用相同的9个参数来计算所有16个输出结果

55
00:03:39,455 --> 00:03:43,620
是减少参数个数的方法之一

56
00:03:43,620 --> 00:03:47,590
而且，直观的来看，像垂直的边缘探测器

57
00:03:47,590 --> 00:03:52,075
这类功能探测器来计算它图片的左上角

58
00:03:52,075 --> 00:03:55,476
相同的特征可能会在后面有用处

59
00:03:55,476 --> 00:03:59,280
当用在右下角，这个特征有可能也会有用

60
00:03:59,280 --> 00:04:00,910
所以，你可能不需要学习

61
00:04:00,910 --> 00:04:02,320
分开的的特征探测器

62
00:04:02,320 --> 00:04:05,140
在图片的左上角和右下角

63
00:04:05,140 --> 00:04:07,435
如果你有一个数据集

64
00:04:07,435 --> 00:04:12,087
在左上角和右下角有不同的分布

65
00:04:12,087 --> 00:04:15,660
这两块也许看上去不同，但是它们可能已经足够相似

66
00:04:15,660 --> 00:04:20,185
它们可以共用相同的特征探测器，效果是一样的

67
00:04:20,185 --> 00:04:23,800
第二种卷积神经网络避免

68
00:04:23,800 --> 00:04:27,485
只有相对少的参数方法是建立稀疏的联系

69
00:04:27,485 --> 00:04:28,779
我的意思是

70
00:04:28,779 --> 00:04:30,400
如果你看着这个0

71
00:04:30,400 --> 00:04:32,980
这个是通过一个3×3的卷积算出来的

72
00:04:32,980 --> 00:04:38,350
所以，它只是根据这个3×3格子的输入来决定的

73
00:04:38,350 --> 00:04:43,900
所有这个右边输出单元

74
00:04:43,900 --> 00:04:50,155
只和这个9分之36 （6×6=36）个特征所相连

75
00:04:50,155 --> 00:04:54,015
以及所有剩下的像素（格子）值

76
00:04:54,015 --> 00:05:02,395
这个像素值对其他输出值没有任何的影响

77
00:05:02,395 --> 00:05:04,945
这就是我所说的稀疏式联系

78
00:05:04,945 --> 00:05:15,585
另一个例子，这个输出值只和这9个特征输入值有关

79
00:05:15,585 --> 00:05:20,293
所以，只有这个9个特征输入值和这个输出值相连

80
00:05:20,293 --> 00:05:23,431
其他的像素（格子）更不会影响到这个输出值

81
00:05:23,431 --> 00:05:25,825
所以，通过这两个机理

82
00:05:25,825 --> 00:05:30,310
一个只有很少的参数神经网络

83
00:05:30,310 --> 00:05:35,380
可以用少于30个单元的训练数据集来训练（大于30就不好了）

84
00:05:35,380 --> 00:05:37,445
有时你也会听说

85
00:05:37,445 --> 00:05:42,245
卷积神经网络会被用来捕捉平移不变

86
00:05:42,245 --> 00:05:44,725
我们可以观察到

87
00:05:44,725 --> 00:05:48,170
一张猫的图片，它的像素格从右边移动了几格

88
00:05:48,170 --> 00:05:50,735
还是一个非常清晰的猫的图片

89
00:05:50,735 --> 00:05:58,715
卷积结构帮助神经网络编译了

90
00:05:58,715 --> 00:06:02,600
当一张图面移动了几个像素格，它同样还应该产生非常相似的特征

91
00:06:02,600 --> 00:06:07,515
应该给它一个相同的标签

92
00:06:07,515 --> 00:06:10,468
同时，因为你使用了相同的滤网

93
00:06:10,468 --> 00:06:13,130
这张图片的各个部分

94
00:06:13,130 --> 00:06:16,255
平移之前和平移之后的图层

95
00:06:16,255 --> 00:06:20,060
帮助神经网络自然而然地学会更稳定

96
00:06:20,060 --> 00:06:28,320
或者更佳的捕捉到平移不变所需要的特性

97
00:06:28,320 --> 00:06:32,415
以上就是几个卷积，或者卷积神经网络

98
00:06:32,415 --> 00:06:37,320
为什么在计算机视觉方面表现好的原因

99
00:06:37,320 --> 00:06:43,150
最后，让我们把综上所述，看看我们如何来训练这样一个卷积神经网络

100
00:06:43,150 --> 00:06:45,980
假设你想建立一个猫探测器, 你

101
00:06:45,980 --> 00:06:48,715
有一个标记的训练集如下

102
00:06:48,715 --> 00:06:52,180
现在, X 是一个图像

103
00:06:52,180 --> 00:06:54,650
y 可以是二进制标签

104
00:06:54,650 --> 00:06:57,645
或者其中之一的诱因

105
00:06:57,645 --> 00:07:02,090
假设你选择了一个卷积神经网络结构

106
00:07:02,090 --> 00:07:06,468
插入图像, 然后有神经卷积，拉层

107
00:07:06,468 --> 00:07:09,310
和全连接层

108
00:07:09,310 --> 00:07:13,880
接着是一个软件的输出, 控制y^

109
00:07:13,880 --> 00:07:20,165
卷积神经网络层和完全连通层将有各种参数

110
00:07:20,165 --> 00:07:23,213
W和偏差B

111
00:07:23,213 --> 00:07:26,780
所以任何参数的设置 

112
00:07:26,780 --> 00:07:32,540
让你定义一个类似我们以前课程中所看到的成本函数

113
00:07:32,540 --> 00:07:37,648
我们随机初始化 W 和 B 的参数

114
00:07:37,648 --> 00:07:40,237
你可以计算J的值

115
00:07:40,237 --> 00:07:46,645
作为整个训练集的神经网络预测损失的总和

116
00:07:46,645 --> 00:07:50,880
也可以除以 m

117
00:07:50,880 --> 00:07:52,555
来训练这个神经网络

118
00:07:52,555 --> 00:07:56,210
你所需要做的是使用梯度下降或一些类似的算法

119
00:07:56,210 --> 00:07:59,795
比如梯度下降动量

120
00:07:59,795 --> 00:08:03,447
或者 RMSProp，Adam，或者别的什么

121
00:08:03,447 --> 00:08:05,900
为了优化所有的神经网络参数

122
00:08:05,900 --> 00:08:09,220
来试图降低成本函数 J

123
00:08:09,220 --> 00:08:11,110
这样做你会发现

124
00:08:11,110 --> 00:08:18,759
你可以建立一个非常有效的猫探测器或其他检测器

125
00:08:18,759 --> 00:08:21,700
到此 恭喜你完成了本周的视频

126
00:08:21,700 --> 00:08:25,550
你现在已经看到了卷积神经网络的所有基本构件

127
00:08:25,550 --> 00:08:30,415
以及如何将它们组合成一个有效的图像识别系统

128
00:08:30,415 --> 00:08:32,095
在本周的节目练习中

129
00:08:32,095 --> 00:08:34,310
我想所有这些事情都会变得更加具体

130
00:08:34,310 --> 00:08:36,610
你会有机会练习实施

131
00:08:36,610 --> 00:08:39,805
这些算法并看到这些算法的结果

132
00:08:39,805 --> 00:08:43,835
下周, 我们将继续深入研究卷积神经网络

133
00:08:43,835 --> 00:08:45,730
我刚才提到

134
00:08:45,730 --> 00:08:48,115
卷积神经网络中有许多超参数

135
00:08:48,115 --> 00:08:49,420
所以我下周

136
00:08:49,420 --> 00:08:52,000
会展示一些具体的例子

137
00:08:52,000 --> 00:08:54,680
和一些最有效的卷积神经网络

138
00:08:54,680 --> 00:08:57,010
这样你可以开始从中识别到规律

139
00:08:57,010 --> 00:09:00,055
知道哪些类型的网络体系结构是有效的

140
00:09:00,055 --> 00:09:04,360
人们经常做的一件事就是

141
00:09:04,360 --> 00:09:05,885
利用其他人已经发现并发表的

142
00:09:05,885 --> 00:09:08,995
研究论文的框架 拿到自己的应用程序中使用

143
00:09:08,995 --> 00:09:12,055
所以 我们下周再看一些具体的例子

144
00:09:12,055 --> 00:09:15,470
你也可以学习如何做的更好

145
00:09:15,470 --> 00:09:16,690
除此之外

146
00:09:16,690 --> 00:09:21,520
我们还会学到卷积神经网络高效的背后机制

147
00:09:21,520 --> 00:09:23,160
然后在余下的课程中

148
00:09:23,160 --> 00:09:27,475
我们还将看到各种其他计算机视觉应用

149
00:09:27,475 --> 00:09:30,170
比如对象检测和神经存储传输

150
00:09:30,170 --> 00:09:34,070
他们如何使用这些算法来创建新的艺术品

151
00:09:34,070 --> 00:09:35,564
所以 这就是这周的课程

152
00:09:35,564 --> 00:09:37,530
希望你们能顺利做完课后练习

153
00:09:37,530 --> 00:09:39,660
非常期待在下周见到大家