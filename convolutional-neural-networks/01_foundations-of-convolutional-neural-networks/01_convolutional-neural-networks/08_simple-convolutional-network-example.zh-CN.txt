在上一节课中,
你看到了一层神经网络的的构造 ConvNet中的一个卷积层 现在我们来研究一个深度卷积神经网络的实例。 这将会让你再次熟悉一些我们在 上一节课中靠近结尾的部分引入的一些概念和符号。 假设我们有一张图像 并且你想做图像分类，或图像识别 输入为一个图像, x ,
然后判断这是不是一只猫，0或1 所以这是一个分类问题。 让我们构建一个可用于此任务的ConvNet范例。 为举例起见,我将使用一个相当小的图像。 假设这个图像是 39 x 39 x 3。 这个假设只是为了使得有些计算更加简单 因此，第0层中的nH（高度）和nW（宽度）都 因此，第0层中的nH和nW都为39 然后通道数为3 假设第一层使用一组3乘3过滤器 来检测特征,所以，f=3，或写成f1=3, 因为我们使用的是一个3x3的过程 假设我们使用为1的步长（stride）
不使用填充（padding） 使用相同的卷积,假设你有10过滤器 那神经网络下一层的激活数 将会是37 x 37 x 10 这里10因为你使用了10个过滤器。 37来自以下公式 n + 2p - f除以 s，再 + 1 对吧，那你有 39 + 0 - 3 除以 1，在 + 1，得到37 所以这就是为什么输出是 37 x 37 ,
这是一个有效的卷积 并且这就是输出的大小 因此,用我们的符号，你有nh[1]=nw[1]=37 以及nc[1]=10 nc[1]同时也等于第一层的过滤器的数量 因此,这就是第一层的激活的维度。 假设你现在有另一个卷积层 而且假设这次你使用 5 x 5 个过滤器 所以,用我们的符号表示，
下一个层神经网络的 f[2] = 5, 假设这次使用2作为步长 没有填充（padding） 和20个过滤器 那这次的输出的纬度将会是 17 x 17 x 20 请注意,因为你现在使用的步长为2 维度收缩得更快 37 x 37下降因子稍微超过2， 到 17 x 17。 因为使用20个过滤器,所以现在的通道数是20。 所以这里的激活a2 将是这个维度 并且nh[2] = nw[2] = 17， nc [2] = 20 好,让我们再加最后一个卷积层。 假设你还是使用 5 x 5 过滤器 同时步长为2 如果你这样做, 通过计算，你将得到7 x 7, 假设您使用40过滤器, 
没有填充, 40 过滤器 你将会得到 7 x 7 x 40 所以现在你所做的是，把39 x 39 x 3的输入图像 计算出此图像的 7 x 7 x 40 特征。 最后,通常会做的是, 如果你把这个 7 x 7 x 40, 7乘以7乘以40实际上是1960 现在，我们可以把这些特征 展开为1960个单元，对吧 扁平化成一个向量, 然后将其输入到一个逻辑回归
或 softmax 单元。 取决于你是在试图识别
“有猫“或者“无猫“（二元） 或者试图识别任意的k种东西（多元） 这就会给出神经网络的最终预测输出 所以,要清楚,
这最后一步只是采取所有这些数字, 所有1960数字,并展开他们成为一个非常长的矢量。 所以,你只是有一个长的向量,
你可以输送到softmax, 直到它是 为了做出最终预测输出的一个回归 所以这将是一个非常典型的 ConvNet 的例子。 卷积神经网络设计中的许多工作是选择 像这样的超参数（hyperparameter）：
总单元数是多少？ 步长是什么？ padding是多少和使用了多少过滤器？ 在本周晚些时候以及下周, 
我们将给一些 关于如何做出这些选择的一些建议和指导方针。 但是就目前而言，我们要记住的一件事是
随着你建的神经网络越来越深， 通常你开始的时候，
图像都是比较大的，例如39乘39 高度和宽度在保持不变一阵子后 随着你在神经网络中的深入, 逐渐变小 在我们的这个例子里，它从39到37到17到14。 不好意思，是39到37到17到7 而频道的数目一般会增加。 它已经从3到10到20到40, 而你会在许多其他卷积神经网络中
看到这样的一种常见的趋势 因此, 我们将在以后的视频中给出
更多如何设计这些参数的指导。 但你现在已经看到了一个卷积神经网络的第一个例子, 或者简称为ConvNet 恭喜你 事实证明, 在一个典型的 ConvNet, 通常有三种类型的层。 一个是卷积层, 通常我们会将其表示为一个Conv层 这就是我们在前面的网络中使用的。 事实证明, 还有两种常见的层类型, 你没有看到，但是我们会在后面的几个视频中讲到 一个称为 "池" 层, 通常我会直接称为池。 最后是一个完全连通的层称为 FC。 虽然我们可能只是使用 卷积层来设计一个相当好的神经网络,
大多数神经网络架构也将有几个池层 和几个完全连接层。 幸运的是池层和 完全连接层比卷积层要简单一些。 因此, 我们将在下两节课中做简单的介绍, 你将对卷积神经网络中所有常见的层都有一个感觉 你将会够构建比我们刚刚展示的 更强大的神经网络 再次恭喜你看到你的第一个完整的卷积神经网络。 我们还将在本周晚些时候讨论
如何训练这些网络, 但是在那之前，我们会先简单地
谈谈池层和完全连接层。 我们将使用熟悉的反向传播 来练这些网络 但在下一节课中,让我们快速了解如何实现 ConvNet中的一个池层
GTC字幕组翻译