1
00:00:00,000 --> 00:00:02,385
今週の最後のビデオでは

2
00:00:02,385 --> 00:00:05,520
なぜ 畳み込みが そんなに使えるのかについて話す

3
00:00:05,520 --> 00:00:08,990
ニューラルネットワークに組み込んだ場合にね

4
00:00:08,990 --> 00:00:13,890
そして最後に これらを全部まとめ上げる方法と

5
00:00:13,890 --> 00:00:20,160
ラベル付き学習データで どのようにして
畳み込みニューラルネットワークを学習させるかについて 簡単に話す

6
00:00:20,160 --> 00:00:23,610
畳み込み層には 単に全結合層を使う場合に対し

7
00:00:23,610 --> 00:00:29,091
主な利点が２つある

8
00:00:29,091 --> 00:00:34,075
その利点とは パラメータ共有と結合のスパース(疎)化だ

9
00:00:34,075 --> 00:00:36,097
例を使って説明しよう

10
00:00:36,097 --> 00:00:42,915
ここに 32 x 32 x 3 次元の画像がある

11
00:00:42,915 --> 00:00:49,040
これは 実は 前のビデオの例から取ってきたものだ

12
00:00:49,040 --> 00:00:54,945
5 x 5 フィルターを６個使おう

13
00:00:54,945 --> 00:01:04,887
そうすれば 28 x 28 x 6 次元の出力を得る

14
00:01:04,887 --> 00:01:07,938
32 x 32 x 3 = 3,072 で

15
00:01:07,938 --> 00:01:17,320
28 x 28 x 6 は 全部掛けると 4,704 だ

16
00:01:17,320 --> 00:01:24,049
もし １層に 3,072 ユニットあるニューラルネットワークを作成すると

17
00:01:24,049 --> 00:01:27,995
もし 次の層に 4,704 ユニットあるものだと

18
00:01:27,995 --> 00:01:31,205
そして これらのニューロン個々を全て結合すると

19
00:01:31,205 --> 00:01:32,650
重み行列は

20
00:01:32,650 --> 00:01:35,624
重み行列のパラメータ数は

21
00:01:35,624 --> 00:01:42,175
3,072 x 4,704 これは約14百万だ

22
00:01:42,175 --> 00:01:44,950
これだと 大変な数のパラメータを学習させねばならない

23
00:01:44,950 --> 00:01:49,455
今日では 14百万よりも多くのパラメータを持つニューラルネットワークを学習できるが

24
00:01:49,455 --> 00:01:52,543
これは かなり小さな画像に過ぎない

25
00:01:52,543 --> 00:01:54,985
これは 学習するには大量のパラメータだ

26
00:01:54,985 --> 00:02:00,030
勿論 これが 1000 x 1000 画像だったら

27
00:02:00,030 --> 00:02:04,920
表示した行列は 見えないくらい巨大になるだろう

28
00:02:04,920 --> 00:02:10,020
しかし もし この畳み込み層のパラメータ数を見てみれば

29
00:02:10,020 --> 00:02:12,710
各フィルターは 5 x 5 で

30
00:02:12,710 --> 00:02:15,385
つまり 各フィルターには 25個のパラメータがあり

31
00:02:15,385 --> 00:02:19,120
バイアスパラメータを加えて フィルターあたり 26個のパラメータだ

32
00:02:19,120 --> 00:02:21,280
そして ６個のフィルターがあるから

33
00:02:21,280 --> 00:02:23,800
パラメータの合計数は

34
00:02:23,800 --> 00:02:26,605
156 パラメータだ

35
00:02:26,605 --> 00:02:31,360
よって この畳み込み層のパラメータ数は 非常に小さい

36
00:02:31,360 --> 00:02:37,965
ConvNet が相対的に少ないパラメータしか持たない理由は ２つある

37
00:02:37,965 --> 00:02:40,110
１つがパラメータ共有だ

38
00:02:40,110 --> 00:02:43,915
パラメータ共有は 観測から 引き出された

39
00:02:43,915 --> 00:02:47,575
垂直エッジ検出器のような特徴検出器は

40
00:02:47,575 --> 00:02:51,098
画像の一部で有効なら 多分 画像の他の部分でも有効だ

41
00:02:51,098 --> 00:02:52,435
これが意味することは こうだ

42
00:02:52,435 --> 00:02:56,635
もし 例えば 垂直エッジ検出に 3 x 3 フィルターを見つけたら

43
00:02:56,635 --> 00:03:01,765
その 3 x 3 フィルターを ここに適用できて

44
00:03:01,765 --> 00:03:03,755
そして 次の位置にも

45
00:03:03,755 --> 00:03:06,220
その次の位置にも 次々に

46
00:03:06,220 --> 00:03:09,040
よって 各特徴検出器は

47
00:03:09,040 --> 00:03:13,510
ここの各出力に対して 同じパラメータを

48
00:03:13,510 --> 00:03:17,140
入力画像の多くの異なる位置で 使うことができる

49
00:03:17,140 --> 00:03:21,825
垂直エッジや 他の特徴を検出するのに

50
00:03:21,825 --> 00:03:25,885
私は これは エッジのような低レベルの特徴に対しては正しいと思うし

51
00:03:25,885 --> 00:03:28,990
より高レベルの特徴 例えば

52
00:03:28,990 --> 00:03:32,865
顔を示す目や 猫や その他 の検出についても正しいだろう

53
00:03:32,865 --> 00:03:34,640
共有すること
この場合

54
00:03:34,640 --> 00:03:39,455
この出力の１６個を計算するための同じ９つのパラメータ

55
00:03:39,455 --> 00:03:43,620
は パラメータ数を減らすための１つの方法だ

56
00:03:43,620 --> 00:03:47,590
これは 直観的でもある
特徴検出器が

57
00:03:47,590 --> 00:03:52,075
画像の左上に対し計算を行う 垂直エッジ検出器のようなものが

58
00:03:52,075 --> 00:03:55,476
同じ特徴が有効であるなら

59
00:03:55,476 --> 00:03:59,280
画像の右下隅でも有効である場合が多いだろう

60
00:03:59,280 --> 00:04:00,910
そして 画像の左上と右下隅に対する

61
00:04:00,910 --> 00:04:02,320
別の特徴検出器を

62
00:04:02,320 --> 00:04:05,140
学習させる必要はないだろう

63
00:04:05,140 --> 00:04:07,435
もしかすると

64
00:04:07,435 --> 00:04:12,087
左上隅と右下隅で 異なる分布を持つデータセットがあるかもしれない

65
00:04:12,087 --> 00:04:15,660
それらは 少し異なって見えるかもしれないしが 充分似ているだろう

66
00:04:15,660 --> 00:04:20,185
画像全体に渡り 特徴検出器を共有し ちゃんと上手く行く

67
00:04:20,185 --> 00:04:23,800
ConvNet が相対的に少ないパラメータでいる ２番目の理由は

68
00:04:23,800 --> 00:04:27,485
スパース(疎)な結合を持つことだ

69
00:04:27,485 --> 00:04:28,779
つまり どういうことかと言うと

70
00:04:28,779 --> 00:04:30,400
この０を見ると

71
00:04:30,400 --> 00:04:32,980
これは 3 x 3 畳み込みで計算されたもの

72
00:04:32,980 --> 00:04:38,350
そして それは この 3 x 3 格子 セルのみに依存している

73
00:04:38,350 --> 00:04:43,900
つまり この右の出力ユニットは

74
00:04:43,900 --> 00:04:50,155
この 6 x 6 36入力の内の９つのみと結合しているのと同じだ

75
00:04:50,155 --> 00:04:54,015
特に言えば ここの残りのピクセルは

76
00:04:54,015 --> 00:05:02,395
ここの全てのピクセル値 ここの全てのピクセル値は この出力に何の影響も無い

77
00:05:02,395 --> 00:05:04,945
これが 結合のスパース(疎)化が意味するものだ

78
00:05:04,945 --> 00:05:15,585
別の例を挙げると この出力は ここの９つの入力値のみに依存している

79
00:05:15,585 --> 00:05:20,293
これら９つの入力値が この出力と接続しているのと同じだ

80
00:05:20,293 --> 00:05:23,431
そして 他のピクセルは この出力に全く影響しない

81
00:05:23,431 --> 00:05:25,825
そして この２つのメカニズムによって

82
00:05:25,825 --> 00:05:30,310
非常に少ないパラメータを持つニューラルネットワークが

83
00:05:30,310 --> 00:05:35,380
少ない学習セットで学習し 過学習し難くくするのを可能にする

84
00:05:35,380 --> 00:05:37,445
時々 耳にすることがあるかもしれないが

85
00:05:37,445 --> 00:05:42,245
畳み込みニューラルネットワークは並進不変性を得るのに非常に良い

86
00:05:42,245 --> 00:05:44,725
これは こういうことだ

87
00:05:44,725 --> 00:05:48,170
猫の写真を右に数ピクセルずらしても

88
00:05:48,170 --> 00:05:50,735
明らかに 猫のままだ

89
00:05:50,735 --> 00:05:58,715
そして 畳み込み構造は ニューラルネットワークが 次の課題を処理するのを助けてくれる

90
00:05:58,715 --> 00:06:02,600
数ピクセル移動した画像は 殆ど同じ特徴量に落ち着くべきで

91
00:06:02,600 --> 00:06:07,515
同じ出力ラベルが付けられるべき という課題だ

92
00:06:07,515 --> 00:06:10,468
同じフィルターを適用するということが

93
00:06:10,468 --> 00:06:13,130
画像のあらゆる場所で

94
00:06:13,130 --> 00:06:16,255
また 初めの方の層でも 後の方の層でも

95
00:06:16,255 --> 00:06:20,060
ニューラルネットワークが自動的に学習し

96
00:06:20,060 --> 00:06:28,320
より堅牢で 並進不変のより良い望ましい性質を得るのを助けるのだ

97
00:06:28,320 --> 00:06:32,415
そう ２~３の理由がある

98
00:06:32,415 --> 00:06:37,320
なぜ 畳み込みや 畳み込みニューラルネットワークが コンピュータ ビジョンにおいて とても良く機能するか

99
00:06:37,320 --> 00:06:43,150
最後に 全てを纏めて このネットワークをどのように学習させるか 見てみよう

100
00:06:43,150 --> 00:06:45,980
猫検出器を作りたいものとする

101
00:06:45,980 --> 00:06:48,715
次のようなラベル付き学習セットがある

102
00:06:48,715 --> 00:06:52,180
Xを画像とし

103
00:06:52,180 --> 00:06:54,650
yを２値を取るラベルとする

104
00:06:54,650 --> 00:06:57,645
もしくは 複数値の内の１つ

105
00:06:57,645 --> 00:07:02,090
畳み込みニューラルネットワーク構造はできている

106
00:07:02,090 --> 00:07:06,468
画像があって それから 畳み込み層とプーリング層

107
00:07:06,468 --> 00:07:09,310
そして 全結合層

108
00:07:09,310 --> 00:07:13,880
続けて ソフトマックス出力で yハットを出力する

109
00:07:13,880 --> 00:07:20,165
畳み込み層と全結合層は 様々なパラメータを持つ

110
00:07:20,165 --> 00:07:23,213
w に バイアスの b

111
00:07:23,213 --> 00:07:26,780
いかなるパラメータの設定も

112
00:07:26,780 --> 00:07:32,540
前のコースで見たようなコスト関数を定義して処理する必要がある

113
00:07:32,540 --> 00:07:37,648
w と b をランダムに初期化しておけば

114
00:07:37,648 --> 00:07:40,237
コスト J を計算できる

115
00:07:40,237 --> 00:07:46,645
ニューラルネットワークの 全学習セットに対する予測の 誤差の合計

116
00:07:46,645 --> 00:07:50,880
それを m で割ったもの

117
00:07:50,880 --> 00:07:52,555
このニューラルネットワークを学習させるには

118
00:07:52,555 --> 00:07:56,210
必要なことは それから 勾配降下法や

119
00:07:56,210 --> 00:07:59,795
何らかのアルゴリズムを使うことだ

120
00:07:59,795 --> 00:08:03,447
モメンタム RMSProp Adam その他だ

121
00:08:03,447 --> 00:08:05,900
全てのパラメータを最適化するのに

122
00:08:05,900 --> 00:08:09,220
ニューラルネットワークは コスト関数 J を減らすようにする

123
00:08:09,220 --> 00:08:11,110
そして これを行えば

124
00:08:11,110 --> 00:08:18,759
とても良い 猫検出器や その他の検出器を 作ることができる

125
00:08:18,759 --> 00:08:21,700
おめでとう 今週のビデオを終えたね

126
00:08:21,700 --> 00:08:25,550
畳み込みニューラルネットワークの基本構成要素を全て見てきた

127
00:08:25,550 --> 00:08:30,415
そして どのように それらを組み立て きちんと動作する画像認識システムにするかを見てきた

128
00:08:30,415 --> 00:08:32,095
今週のプログラミング演習では

129
00:08:32,095 --> 00:08:34,310
これら全てのことが もっと具体的になるはずだ

130
00:08:34,310 --> 00:08:36,610
自分自身で これらを実装し

131
00:08:36,610 --> 00:08:39,805
自分自身で それが動くのを見る機会だ

132
00:08:39,805 --> 00:08:43,835
次週は 畳み込みニューラルネットワークにより深く入っていく

133
00:08:43,835 --> 00:08:45,730
前に言ったように

134
00:08:45,730 --> 00:08:48,115
畳み込みニューラルネットワークには 沢山のパラメータがある

135
00:08:48,115 --> 00:08:49,420
よって 次週したいことは

136
00:08:49,420 --> 00:08:52,000
いくつかの具体例を見せることだ

137
00:08:52,000 --> 00:08:54,680
最も効果的な畳み込みニューラルネットワークの例を

138
00:08:54,680 --> 00:08:57,010
そうしたら あなたは どんなタイプのネットワーク構造の

139
00:08:57,010 --> 00:09:00,055
パターンが効果があるのか理解し始めるだろう

140
00:09:00,055 --> 00:09:04,360
人々は よくこんなことを行う
他の誰かが

141
00:09:04,360 --> 00:09:05,885
見つけたり 研究論文に公開したりした構造を

142
00:09:05,885 --> 00:09:08,995
自身のアプリケーションにそのまま使う

143
00:09:08,995 --> 00:09:12,055
そこで 次週 いくつかのより具体的な例を見れば

144
00:09:12,055 --> 00:09:15,470
どうしたら もっとよくできるか 学べるだろう

145
00:09:15,470 --> 00:09:16,690
また 次週は それ以外にも

146
00:09:16,690 --> 00:09:21,520
何が ConvNet をつまく働かせるのか についても 洞察を得よう

147
00:09:21,520 --> 00:09:23,160
そして このコースの残りでは

148
00:09:23,160 --> 00:09:27,475
他の様々なコンピュータ ビジョン アプリケーションを見よう 例えば

149
00:09:27,475 --> 00:09:30,170
物体検出 それに ニューラル スタイル変換だ

150
00:09:30,170 --> 00:09:34,070
これらのアルゴリズムを使って どのように 新しい形の芸術作品を作るのだろうか

151
00:09:34,070 --> 00:09:35,564
じゃ 今週はここまで

152
00:09:35,564 --> 00:09:37,530
宿題 頑張って

153
00:09:37,530 --> 00:09:39,660
次週 会えるのを楽しみにしているよ