在這個禮拜最後一段影片中 我們來談一談為什麼 當您在您的神經網路中包含它們時
卷積是如此有用 最後，我們簡單談一下有關
如何將這些放在一起 當您有ㄧ個標籤的訓練集時
您可以如何訓練卷積神經網路 我想有兩種主要的優點 在於卷積層
而不只是用全連接層 優點是參數共享跟稀疏連接 我用一個例子來解釋 假設您有一個 32乘32乘3 維度的影像 這實際上是來自於前一段影片的例子 假設您用的是 5乘5 總共 6個過濾器 這給您一個 28乘28乘6 維度的輸出 所以  32乘32乘3 是 3,072 而 28乘28乘6 如果您把所有乘起來是 4,704 所以，如果您建立一個神經網路用 3,072 在一層 而 4,704 在下一層 而如果您要連接每一個神經元 那這個權重矩陣 權重矩陣中的參數數目會是 3,072 乘 4,704 大約是  1400 萬 所以這是相當多的參數訓練 在今天，您可以訓練一個神經網路甚至遠大於 1400 萬 但考慮到這只是一個相當小的影像 這已經是相當多的參數要訓練 當然，如果這是 1000乘1000 的影像 那您的矩陣會變為無法操作的大 但如果您看在這個卷積層的參數數目 每個過濾器是 5乘5 所以每個過濾器有 25 個參數 加上偏差參數，每個過濾器會有 26 個參數 您有 6 個過濾器 所以總共的參數是 會等於是 156  個參數 所以在這個卷積層的參數數目是相當小的 而 ConvNet 用相對少的參數的原因有兩種 其一是參數共用 而參數共用是起因於觀察 特徵偵測像是垂直邊緣偵測 在一部份的影像有用
或許在別的部分也有用 這個意思是 如果您找到一個 3乘3 的過濾器
對於偵測垂直邊緣有效 您可以應用同樣的 3乘3 過濾器在這裡 然後下一個位置 再下一個位置，等等 所以每一個這種特徵偵測 每一個輸出都可以用相同的參數在很多 您輸入影像中的不同的位置，為了 偵測，例如垂直邊緣或者其他特徵 而我想這在低階的特徵像是邊緣是真的 在高階的特徵也是，或許像是 偵測眼睛來判斷是不是臉部，
或者一隻貓，或者其他 但在這種情況下，共享 同樣這 9 個參數來計算這 16 個輸出 是一種減少參數數目的方式 而這或許也是一種直覺，一個特徵偵測 像是垂直邊緣偵測在左上方的影像上 同樣的特徵似乎也或許有用 很大的機會在右下角的影像偵測下很有用 所以或許您不需要 用不同的特徵偵測來學習 左上角跟右下角的影像 而或許您真的有這麼一種資料集 左上角跟右下角是不同的分佈 或者看起來有點不同
但也許已經夠相似 它們在整個影像裡共用特徵偵測也是可行的 第二種方式 ConvNet 使用較少的參數是使用稀疏連結 我們意思是 如果您看這個 0 這是從 3乘3 卷積而來 所以，它只依賴於這些 3乘3 個輸入格或者單元 就好像是右邊這個輸出單元只連結到 這 6乘6 36 個輸入中的 9 個特徵 特別是，其他這些像素值 所有其他這些像素並不會
對於這個輸出有任何影響 所以，這是我所謂的稀疏連結 另一個例子，這個輸出只依賴於這 9 個輸入特徵 所以，就好像這個 9 個輸入特徵連結於這個輸出 而其他的像素就是
一點都不會影響到這個輸出 所以，透過這兩種機制 一個神經網路有少很多的參數能夠 訓練在於一個較少的資料集上而不會過適 有時候您會聽到 卷積神經網路擅長於捕捉平移不變性 這種觀察在於 一張貓圖往右平移一些 還是很清楚的一隻貓 而卷積架構幫助神經網路解碼了一個影像 移動了幾個像素應該還是有類似的特徵 而或許應該對應到相同的輸出標籤 而當您使用了相同的過濾器 理解了影像的所有位置 同時在早期層和後期層 幫助神經網路自動學習得 更精實，更能捕捉到偏移不變的特性 所以這些是一些原因為什麼 卷積或者卷積神經網路在電腦視覺作用如此的棒 最後，讓我們將所有這些放一起，
看看您如何訓練這一個網路 假設您想建立一個貓的偵測器，您 有一些標籤過的訓練集如下 現在， X 是一個影像 然後 y 可以是一個二元標籤 或者 k 項之一 假設您選擇了使用卷積神經網路架構 或許從影像開始，然後有卷積層跟池層 然後一些全連結層 接著是 softmax 輸出最後輸出是 y hat  在 conv 層跟全連結層會有各種參數 W 跟偏差 b 所以，任何參數的設定 讓您定義一個成本函數
跟我們在之前的課程中見到的類似 我們隨機初始參數 w 跟 B 您就可以計算成本 J 也就是神經網路預測的所有損失的總和
在整個訓練集上 或許除上 m 要訓練神經網路 您要做的是使用梯度下降或者一些 演算法像是動量梯度下降法 或者 RMSProp 或者 Adam 或者其他 為了要最佳化所有的參數 在神經網路上試著減低成本函數 J 您發現如果您這樣做 您可以建立一個很有效的貓偵測器或者其他偵測器 恭喜您完成這個星期的課程 您已經見到了所有的卷積神經網路的建構基石 跟如何將它們放在一起成為一個很有效的影像辨識系統 在這個星期的練習中 我想所有這些東西都會變得更加具體 您會有機會自己來練習建置 這些，跟見到它們如何作用 下星期，我們將繼續深入卷積神經網路 我之前提過，有很多的 超參數在卷積神經網路上 我下周想做的事 要展示一些具體的例子對於一些 最有效的卷積神經網路 您可以開始理解一些模式 在哪些網路架構最有效率 人們常做的一件事是拿這些 其他人已經發現跟發佈在 研究論文的架構，直接用在您的應用上 所以，下星期看一些具體的例子 您也因此學到如何做得更好 除此，下個星期 我們也會得到一些直觀有關於
什麼樣的 ConvNet 會作用的好 然後在其餘課程 我們會看到一些不同的電腦視覺應用，像是 物件偵測跟神經風格轉換 它們如何用這些演算法來建立的藝術品風格 這個禮拜結束了 祝您這個禮拜的作業幸運 期待下禮拜見到你