Convolutional Networks (콘볼루션망)에 관한 이 강의에 오신 걸 환영합니다. 컴퓨터 비전은 빠르게 발전해오고 있는 분야 중 하나입니다. 딥러닝 덕분에 말이죠. 컴퓨터 비전 딥러닝은 자율주행 자동차들로 하여금 주변 어디에 다른 자동차나 보행자들이 있는지 찾아 그들을 피할 수 있도록 도와줍니다. 안면 인식이 예전보다도 훨씬 잘 작동하도록 만들어줍니다. 아마도 여러분 중 몇몇은 곧, 혹은 어쩌면 이미, 당신 얼굴만으로 잠긴 핸드폰을 열 수도 있고, 심지어 잠긴 문을 열 수도 있을 것입니다. 여러분의 핸드폰을 살펴보시면, 틀림없이 음식 사진이나 호텔 사진, 혹은 재미있는 풍경사진들을 보여주는 앱들을 많이 가지고 계실 겁니다. 그런 앱들을 만드는 몇몇 회사들은 딥러닝을 사용해서 가장 매력적이고, 가장 아름답거나, 혹은 가장 적절한 사진들을 당신에게 보여주도록 하고 있습니다. 그리고 제 생각엔 딥러닝은 심지어 새로운 유형의 예술을 탄생시키는 것도 가능하게 하고 있습니다. 그래서, 컴퓨터 비전에 대한 딥러닝에 대해서 여러분 또한 흥미로워 할 것이라고 생각하는 두 가지 이유가 있습니다. 첫 째로, 컴퓨터 비전 분야의 빠른 발전이 완전히 새로운 어플리케이션을 볼수 있게 해 줄 것이라는 겁니다. 비록 몇 년 전만해도 불가능했던 것들이지만 말이죠. 그리고 이러한 툴을 배움으로써, 아마 이러한 새로운 제품이나 어플리케이션을 고안해 낼 수 있도록 될 것입니다. 둘 째, 컴퓨터 비전 시스템 자체를 만드는 건 못한다 해도, 컴퓨터 비전을 연구하는 단체가 그 동안 아주 창의적이고 아주 독창적으로 새로운 신경망 구조와 알고리즘을 이용해 일 해왔기 때문에 실제로 다른 분야로도 교차 적용할 수 있도록 북돋워 준다는 것을 알게 되었습니다. 예를 들어, 제가 음성인식 작업중일 때, 때로는 컴퓨터 비전에서 나온 아이디어들로부터 영감을 받기도 하고 그것들을 음성 문헌으로 차용해 사용하기도 했습니다. 결국, 여러분이 컴퓨터 비전 작업을 하지 않는다 해도, 이 강의에서 여러분이 배운 아이디어들이 여러분의 알고리즘과 여러분의 구조들을 만드는데 도움이 되기를 바랍니다. 그럼, 이제 시작해봅시다. 여기 이 과정에서 우리가 공부할 컴퓨터 비전 문제점들의 몇 가지 예시가 있습니다. 여러분은 방금 이미지 분류를 보았죠. 때로는 영상 인식이라고도 불립니다. 64 x 64 사이즈의 이미지로 넣고 해결해봅시다 이건 고양이인가요? 컴퓨터 비전 문제점의 또 다른 예시는 물체 탐색입니다. 자율주행 자동차를 만들고 있다면, 아마도 이 이미지에 다른 자동차들이 있다는 걸 알아야 할 필요는 없습니다. 하지만 대신에, 이 사진에 있는 다른 자동차들의 위치는 알아야 할 필요가 있습니다. 여러분의 자동차가 그것들을 피해야 하니까요. 물체 탐색에서, 통상, 우리는 자동차 같은 이 다른 물체들이 있다는 것 발견하는 것뿐만 아니라 그것들 주변에 네모를 그려야 합니다. 사진 어디에 이런 물체들이 있는지를 알아내는 다른 방법들도 있습니다. 그리고 이 예시에서, 같은 사진 안에 여러 대의 자동차가 있을 수도 있다는 것을 인지해야 합니다. 혹은 이들 모두 여러분의 자동차로부터 일정 거리 안에 있을 수도 있다는 것도 말이죠. 또 하나의 예시가 있습니다. 아마 좀 더 재미있을 텐데요. 신경 스타일 이동입니다. 사진이 한 장 있습니다. 그리고 이 사진을 다른 스타일로 다시 그려지게 하려고 합니다. 그래서 신경 스타일 이동입니다. 컨텐츠 이미지가 있습니다. 그리고 스타일 이미지가 있습니다. 오른쪽 이미지는 사실 피카소의 작품입니다. 그리고 신경망으로 하여금 이미지들을 합치게 해서 왼쪽의 컨텐츠 이미지를 다시 그려지도록 할 수 있습니다. 오른쪽 스타일 이미지 안쪽에 말이죠. 그리고 마침내 아래와 같은 그림을 만들게 됩니다. 그래서, 이런 알고리즘이 새로운 작품 유형들이 탄생하는 것을 가능하게 하고 있죠. 그리고 이 과정에서, 여러분은 어떻게 이것을 직접 하는지도 배우게 될 것입니다. 컴퓨터 비전 문제 과제 중 하나는 입력 정말 큰 얻을 수 있습니다. 예를 들어, 이전 강의들에서, 64 x 64 크기의 이미지로 작업을 했는데요, 3가지 색상 채널이었기 때문에 64 x 64 x 3이라고 할 수 있습니다. 그리고 그것들을 곱셈해보면, 12288이죠. 따라서 입력feature는 12288 의 규모가 됩니다. 그리 나쁜 건 아닙니다. 하지만 64 x 64 는 사실 매우 작은 이미지죠. 만약 더 큰 이미지들로 작업을 하면, 아마 이것은 1000 x 1000 픽셀의 이미지 인 것 같은데요, 사실 백만 픽셀이죠. 하지만 입력feature의 규모는 1000 x 1000 x 3 이 될 겁니다. 왜냐하면 3개의 RGB 채널이 있기 때문이죠. 곧, 300만입니다. 만일 더 작은 화면으로 이것을 보고 있다면, 분명하게 보이진 않을지도 모릅니다. 하지만 이것은 사실 낮은 픽셀의 64 x 64 이미지입니다. 그리고 이것은 더 높은 픽셀의 1000 x 1000 이미지 입니다. 하지만, 300만의 입력feature를 가지고 있다면 이는 곧 300만 차원일 것이라는 것을 의미합니다. 결국, 첫 번째 은닉 층에서 아마도 1000 은닉 층이 있을 것이고 그럼 총 무게가 W1매트릭스라는 것입니다. 만일 여러분이 이 과정 1이나 2에서 다루었던 기본 혹은 연결된 네트워크를 사용한다면, 이 매트릭스는 1000 x 3000000 차원의 매트릭스가 될 것입니다. 왜냐하면 X는 300만을 곱한 R이 되기 때문이죠. 3m, 300만 표시하기 위해 m을 사용하고 있습니다. 이는 곧 이 매트릭스가 매우 매우 거대한 30억 파라미터에 이른다는 것이죠. 그리고 이 많은 파라미터로 신경망 네트워크가 과대 적합을 방지하도록 충분한 데이터를 얻는 것을 어렵습니다. 또한, 30억 파라미터를 가진 신경망을 단련하는 것에 대한 컴퓨터 요구사항과 메모리 요구사항은 실행불가능 합니다. 그러나 컴퓨터 비전 어플리케이션에 있어서는, 작은 이미지들만 한정해서 사용하는 것을 원치 않을 겁니다 큰 이미지들을 사용하고 싶죠. 그렇게 하려면, 더 나은 회선 작업을 구현 해야 컨볼루션 신경망의 근본적 구성 요소 중의 하나이기도 하니까요. 이게 뭘 의미하고 여러분이 어떻게 실행할 수 있을지를 다음 시간 영상에서 보시죠 edge detection의 예시를 통해 edge detection의 예시를 통해 컨볼루션을 설명하도록 하겠습니다.