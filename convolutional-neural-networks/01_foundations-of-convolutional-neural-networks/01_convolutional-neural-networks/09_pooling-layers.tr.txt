Konvolüsyon katmanlar dışında Evrişimsel sinir ağları da boyut küçültmek için kullanılır daha hızlı hesaplamak için bu özelliklerin yanı sıra özellikleri daha iyi belirleyen sağlam algoritmalar kullanılır. Hadi bir bakalım, sonra neden bunu yapmak istediğimiz hakkında konuşalım. Farz edelim ki 4x4 boyutunda bir girdimiz var, bunu filterelemek isterseniz max pooling i kullanabilirsiz. ve uygulamanın sonucu olarak çıktı boyut 2x2 ye düşer. Bunu yapmanın yolu çok kolay. 4x4 lük girdinizi alın ve bölün gördüğünüz üzere ben boyalı alanlara böldüm. Sonra, boyutu 2x2 olan çıktıdaki sayılar önceki alandaki en büyük sayılardır Bence sol üstte bu dört sayının en büyüğü 9. Sağ üstteki en büyük sayı 2 Sol aşağıda, en büyük sayı 6, sağ aşağıda en büyük sayı 3. Sağdaki sayıları hesaplamak için, 2x2 lik alandaki en büyük sayıyı aldık. Filtre boyutu iki olan bir filtre uygulamak isterseniz böyle yaparsınız Çünkü ikilik bir bölgeye alıyorsunuz ve iki adım ilerliyorsunuz. Yani, aslında bu filtreleme boyutundan başlayacağımız için maksimum havuzlamanın üst değişkenleridir(hyperparameters). Dokuza ikiye bölen iki bölgeye benziyor, ve sonra bu bölgeye bakmak için iki adımı atıyorsunuz. ve sonra sıradaki satır için Altı vermek için iki adım atıyorsun, ve sonra size üç vermek için sağa doğru iki adımla ilerleyin. Çünkü kareler ikiye iki olduğundan, f ikiye eşittir, ve ikiyle devam ettiğiniz için s ikiye eşittir. Yani, maksimum havuzlamanın yaptıklarının ardındaki sezgi. Bu dörtte dört bölge hakkında bir takım özellikler düşünürseniz, sinir ağının bazı katmanlarındaki aktivasyonlar, sonra çok sayıda, Bu, belirli bir özellik tespit edildiğini gösterir. Dolayısıyla, sol üst kadranın bu özelliği vardır. [Duyulmuyor] algılamaya çalışıyorsanız belki dikey bir kenar veya belki daha yüksek veya daha çirkin olabilir. Açıkça, bu özellik sol üst kadranda var. Oysa bu özellik, belki de kedi gözü dedektörü değil. Oysa bu özellik, sağ üst kadranda gerçekten mevcut değildir. Yani maksimum işlemin yaptığı, her yerde tespit edilen birçok özelliktir. ve bu çeyreklerden biri, daha sonra maksimum havuzlamanın çıktısında korunur. Yani, maks'in yaptığı şey gerçekten söylemek, Bu filtre bu filtrede herhangi bir yer tespit ederse, sonra yüksek bir sayı tutun. Ancak bu özellik tespit edilmezse, belki bu özellik sağ üst kadranda mevcut değildir. Sonra tüm bu sayıların maksimumu hala oldukça küçük. Yani belki de maksimum havuzlamanın arkasındaki sezgi budur. Ama itiraf etmeliyim, İnsanların maksimum havuzu kullanmasının ana sebebi olduğunu düşünüyorum. iyi çalışmak için çok fazla denemede bulunduğundan ve anlattığım sezgi, sık sık alıntı yapılmasına rağmen Bunun gerçek altta yatan neden olup olmadığını tam olarak bilen birini bilmiyorum. Eğer var mı bilmiyorum Max havuzlamanın ConvNets'te iyi çalışmasının altında yatan gerçek sebep. Max havuzlamanın ilginç bir özelliği de Bir grup hiperparametrede öğrenilecek parametreler yoktur. Öğrenmek için gradyan kökenli aslında hiçbir şey yok. F ve s düzeltdikten sonra, Bu sadece sabit bir hesaplama ve degrade iniş hiçbir şeyi değiştirmez. Biraz farklı hipermetrelerle bir örnek verelim. Burada kullanacağım, beşte beş girişiniz var ve en fazla üçte bir filtre boyutuyla maksimum havuzlamayı uygulayacağız. Yani f üçe eşittir ve bir adımı kullanalım. Yani bu durumda, çıktı boyutu üçte üç olacak. Ve geliştirdiğimiz formüller konv katman için çıktı boyutunu bulmak için önceki videolar, Bu formüller ayrıca maksimum havuzlama için çalışır. Yani, bu artı 2p eksi f artı artı 1. Bu formül aynı zamanda maksimum havuzlamanın çıkış boyutunu belirlemek için de çalışır. Fakat bu örnekte, bu üç öğenin öğelerinin her birini üç çıktı olarak hesaplayalım. Sol üstteki elemanlar, Bu bölgeye bakacağız. Yani üç bu üç bölge olduğunu dikkat edin çünkü filtre boyutu üç ve orada maks. Yani, bu dokuz olacak, ve sonra bir tanesini değiştirdik. Yani, mavi kutudaki maksimum dokuz. Bunu tekrar değiştirelim. Mavi kutunun maksimum beşi. Ve sonra bir sonraki sıraya geçelim, bir adım daha. Yani sadece bir adım aşağıya iniyoruz. Yani o bölgede en fazla dokuz, o bölgede en fazla dokuz, o bölgede max, Şimdi iki beşliyle, en fazla beşimiz var. Ve son olarak, max bu sekiz. Max bu altı, ve bunun içinde maksimum, bu değil.[duyulmuyor] Tamam, bu, bu hiperparametreler kümesinin f'ye eşit olduğunu, s eşittir bir çıktı çıktı verir [duyulmuyor]. Şimdiye kadar, bir 2D (2 Boyutlu) girişte maksimum havuzlamayı gösterdim. 3D(3 Boyutlu) girişiniz varsa, daha sonra çıktılar aynı boyuta sahip olacak. Örneğin, beşte beşe sahipseniz, daha sonra çıkış üçte üç olacak ve hesapladığınız yol maksimum havuzlamayı hesapladığınız yöntem, her bir kanalda tanımladığımız hesaplamayı bağımsız olarak gerçekleştirmektir. Bu yüzden, yukarıda gösterilen ilk kanal hala aynı, ve sonra ikinci kanal için sanırım, az önce çizdiğim bu, o dilim üzerinde aynı hesaplama yaparsınız ve bu size ikinci dilimi verir. Ve daha genel olarak, eğer bu sayı beşe kadar beş kanalsa, Çıkış aynı sayıda kanal tarafından üçte üç olur. Ve maksimum havuzlama hesaplaması, bu N_C kanallarının her birinde bağımsız olarak yapılır. Yani, bu maksimum havuz. Bu, çok sık kullanılmayan havuzlama türüdür. ama kısaca, ortalama bir havuz olan bahseteceğim. Yani, beklediğiniz şeyi hemen hemen yapar, her filtre içinde maksimumları almak yerine Ortalamayı sen al. Bu yüzden bu örnekte, Mor sayıların ortalaması 3,75, o zaman 1.25 ve dört ve iki. Ve böylece, bu hiperparametreler f ile ortalama ikiye eşittir, s ikiye eşittir, diğer hiperparametreleri de seçebiliriz. Yani bu günlerde, maksimum havuzlama çok daha fazla kullanılıyor Genellikle bir istisna ile ortalama havuzlamadan, bir sinir ağında bazen çok derindir. Temsilizi çökertmek için ortalama havuzlamayı kullanabilirsiniz. 7 x 7 1.000. Tüm [duyulmuyor] üzerinde bir ortalama, 1000'e kadar 1 alırsınız. Bunun bir örneğini daha sonra göreceğiz. Ama görüyorsunuz, maksimum havuzlama, nöral ağda ortalama havuzdan çok daha fazla şey kullandı. Yani özetlemek gerekirse, Havuzlama için hipermetreler f filtre boyutu ve s, adım, ve belki de ortak değişkenlerin (parameters) seçimleri f eşittir iki, s eşittir iki. Bu oldukça sık kullanılır ve bu etkisi vardır yükseklik ve genişliği yaklaşık ikiye katlayarak kabaca küçültmek, ve ortak seçilmiş üst değişkenler (hyperparameters) f eşittir iki, s eşittir iki, ve bu daralmanın etkisine sahiptir Temsilin yüksekliği ve genişliği, iki faktörle. Ayrıca eşittir üç eşittir, s eşittir iki kullanılır, ve sonra diğer üst değişken(hyperparameter), tıpkı ikili bir bit gibi, maksimum havuz kullanıyorsunuz veya ortalama havuz kullanıyorsunuz. İsterseniz ekstra bir üst değişken(hyperparameter) ekleyebilirsiniz Bu çok olmasına rağmen dolgulama(padding) için çok nadiren kullanılır. Maksimum havuzlama yaptığınızda, genellikle, herhangi bir dolgulama(padding) kullanmazsınız Sonraki hafta da göreceğimiz bir istisna olsa da. Ama maksimum havuzlamanın çoğu kısmı için genellikle, herhangi bir dolgulama(padding) kullanmazsınız. Dolayısıyla, p'nin en yaygın değeri p eşittir sıfırdır. Ve maksimum havuzlamanın girişi, size, N_H, N_W, N_C tarafından ve bunun tarafından verilen büyüklükte bir hacim çıkarırdı. Yani, N_W eksi f'ye göre bir dolgu olmadığı varsayılırsa, Bu bir N_C tarafından. Yani giriş kanalı sayısı, çıkış kanallarının sayısına eşittir Çünkü havuzlama, her bir kanalınıza bağımsız olarak uygulanır. Havuzlama hakkında dikkat edilmesi gereken bir şey, öğrenilecek parametreler olmamasıdır. Yani, bu ürünü uygularken, zeminin maksimum havuzlama yoluyla adapte olacağı hiçbir parametrenin olmadığını görüyorsunuz. Bunun yerine, sadece bir kez ayarladığınız hyperparameters(üst değişken) var, belki de bunları elle ayarlayabilir veya çapraz doğrulamayı kullanarak ayarlayabilirsiniz. Ve bunun ötesinde, işiniz biter. Sadece sinirsel ağın katmanlarından birinde hesapladığı sabit bir işlevdir. ve aslında öğrenecek bir şey yok. Bu sadece sabit bir işlev. Yani, bu havuz için. Artık, konvolüsyon katmanları ve havuz katmanları oluşturmayı biliyorsunuz. Bir sonraki videoda, ConvNet'in daha karmaşık bir örneğini görelim. Tamamen birbirine bağlı katmanları tanıtmamıza izin verecek bir tanesi.