1
00:00:00,000 --> 00:00:02,385
在這個禮拜最後一段影片中

2
00:00:02,385 --> 00:00:05,520
我們來談一談為什麼

3
00:00:05,520 --> 00:00:08,990
當您在您的神經網路中包含它們時
卷積是如此有用

4
00:00:08,990 --> 00:00:13,890
最後，我們簡單談一下有關
如何將這些放在一起

5
00:00:13,890 --> 00:00:20,160
當您有ㄧ個標籤的訓練集時
您可以如何訓練卷積神經網路

6
00:00:20,160 --> 00:00:23,610
我想有兩種主要的優點

7
00:00:23,610 --> 00:00:29,091
在於卷積層
而不只是用全連接層

8
00:00:29,091 --> 00:00:34,075
優點是參數共享跟稀疏連接

9
00:00:34,075 --> 00:00:36,097
我用一個例子來解釋

10
00:00:36,097 --> 00:00:42,915
假設您有一個 32乘32乘3 維度的影像

11
00:00:42,915 --> 00:00:49,040
這實際上是來自於前一段影片的例子

12
00:00:49,040 --> 00:00:54,945
假設您用的是 5乘5 總共 6個過濾器

13
00:00:54,945 --> 00:01:04,887
這給您一個 28乘28乘6 維度的輸出

14
00:01:04,887 --> 00:01:07,938
所以  32乘32乘3 是 3,072

15
00:01:07,938 --> 00:01:17,320
而 28乘28乘6 如果您把所有乘起來是 4,704

16
00:01:17,320 --> 00:01:24,049
所以，如果您建立一個神經網路用 3,072 在一層

17
00:01:24,049 --> 00:01:27,995
而 4,704 在下一層

18
00:01:27,995 --> 00:01:31,205
而如果您要連接每一個神經元

19
00:01:31,205 --> 00:01:32,650
那這個權重矩陣

20
00:01:32,650 --> 00:01:35,624
權重矩陣中的參數數目會是 3,072

21
00:01:35,624 --> 00:01:42,175
乘 4,704 大約是  1400 萬

22
00:01:42,175 --> 00:01:44,950
所以這是相當多的參數訓練

23
00:01:44,950 --> 00:01:49,455
在今天，您可以訓練一個神經網路甚至遠大於 1400 萬

24
00:01:49,455 --> 00:01:52,543
但考慮到這只是一個相當小的影像

25
00:01:52,543 --> 00:01:54,985
這已經是相當多的參數要訓練

26
00:01:54,985 --> 00:02:00,030
當然，如果這是 1000乘1000 的影像

27
00:02:00,030 --> 00:02:04,920
那您的矩陣會變為無法操作的大

28
00:02:04,920 --> 00:02:10,020
但如果您看在這個卷積層的參數數目

29
00:02:10,020 --> 00:02:12,710
每個過濾器是 5乘5

30
00:02:12,710 --> 00:02:15,385
所以每個過濾器有 25 個參數

31
00:02:15,385 --> 00:02:19,120
加上偏差參數，每個過濾器會有 26 個參數

32
00:02:19,120 --> 00:02:21,280
您有 6 個過濾器

33
00:02:21,280 --> 00:02:23,800
所以總共的參數是

34
00:02:23,800 --> 00:02:26,605
會等於是 156  個參數

35
00:02:26,605 --> 00:02:31,360
所以在這個卷積層的參數數目是相當小的

36
00:02:31,360 --> 00:02:37,965
而 ConvNet 用相對少的參數的原因有兩種

37
00:02:37,965 --> 00:02:40,110
其一是參數共用

38
00:02:40,110 --> 00:02:43,915
而參數共用是起因於觀察

39
00:02:43,915 --> 00:02:47,575
特徵偵測像是垂直邊緣偵測

40
00:02:47,575 --> 00:02:51,098
在一部份的影像有用
或許在別的部分也有用

41
00:02:51,098 --> 00:02:52,435
這個意思是

42
00:02:52,435 --> 00:02:56,635
如果您找到一個 3乘3 的過濾器
對於偵測垂直邊緣有效

43
00:02:56,635 --> 00:03:01,765
您可以應用同樣的 3乘3 過濾器在這裡

44
00:03:01,765 --> 00:03:03,755
然後下一個位置

45
00:03:03,755 --> 00:03:06,220
再下一個位置，等等

46
00:03:06,220 --> 00:03:09,040
所以每一個這種特徵偵測

47
00:03:09,040 --> 00:03:13,510
每一個輸出都可以用相同的參數在很多

48
00:03:13,510 --> 00:03:17,140
您輸入影像中的不同的位置，為了

49
00:03:17,140 --> 00:03:21,825
偵測，例如垂直邊緣或者其他特徵

50
00:03:21,825 --> 00:03:25,885
而我想這在低階的特徵像是邊緣是真的

51
00:03:25,885 --> 00:03:28,990
在高階的特徵也是，或許像是

52
00:03:28,990 --> 00:03:32,865
偵測眼睛來判斷是不是臉部，
或者一隻貓，或者其他

53
00:03:32,865 --> 00:03:34,640
但在這種情況下，共享

54
00:03:34,640 --> 00:03:39,455
同樣這 9 個參數來計算這 16 個輸出

55
00:03:39,455 --> 00:03:43,620
是一種減少參數數目的方式

56
00:03:43,620 --> 00:03:47,590
而這或許也是一種直覺，一個特徵偵測

57
00:03:47,590 --> 00:03:52,075
像是垂直邊緣偵測在左上方的影像上

58
00:03:52,075 --> 00:03:55,476
同樣的特徵似乎也或許有用

59
00:03:55,476 --> 00:03:59,280
很大的機會在右下角的影像偵測下很有用

60
00:03:59,280 --> 00:04:00,910
所以或許您不需要

61
00:04:00,910 --> 00:04:02,320
用不同的特徵偵測來學習

62
00:04:02,320 --> 00:04:05,140
左上角跟右下角的影像

63
00:04:05,140 --> 00:04:07,435
而或許您真的有這麼一種資料集

64
00:04:07,435 --> 00:04:12,087
左上角跟右下角是不同的分佈

65
00:04:12,087 --> 00:04:15,660
或者看起來有點不同
但也許已經夠相似

66
00:04:15,660 --> 00:04:20,185
它們在整個影像裡共用特徵偵測也是可行的

67
00:04:20,185 --> 00:04:23,800
第二種方式 ConvNet 

68
00:04:23,800 --> 00:04:27,485
使用較少的參數是使用稀疏連結

69
00:04:27,485 --> 00:04:28,779
我們意思是

70
00:04:28,779 --> 00:04:30,400
如果您看這個 0

71
00:04:30,400 --> 00:04:32,980
這是從 3乘3 卷積而來

72
00:04:32,980 --> 00:04:38,350
所以，它只依賴於這些 3乘3 個輸入格或者單元

73
00:04:38,350 --> 00:04:43,900
就好像是右邊這個輸出單元只連結到

74
00:04:43,900 --> 00:04:50,155
這 6乘6 36 個輸入中的 9 個特徵

75
00:04:50,155 --> 00:04:54,015
特別是，其他這些像素值

76
00:04:54,015 --> 00:05:02,395
所有其他這些像素並不會
對於這個輸出有任何影響

77
00:05:02,395 --> 00:05:04,945
所以，這是我所謂的稀疏連結

78
00:05:04,945 --> 00:05:15,585
另一個例子，這個輸出只依賴於這 9 個輸入特徵

79
00:05:15,585 --> 00:05:20,293
所以，就好像這個 9 個輸入特徵連結於這個輸出

80
00:05:20,293 --> 00:05:23,431
而其他的像素就是
一點都不會影響到這個輸出

81
00:05:23,431 --> 00:05:25,825
所以，透過這兩種機制

82
00:05:25,825 --> 00:05:30,310
一個神經網路有少很多的參數能夠

83
00:05:30,310 --> 00:05:35,380
訓練在於一個較少的資料集上而不會過適

84
00:05:35,380 --> 00:05:37,445
有時候您會聽到

85
00:05:37,445 --> 00:05:42,245
卷積神經網路擅長於捕捉平移不變性

86
00:05:42,245 --> 00:05:44,725
這種觀察在於

87
00:05:44,725 --> 00:05:48,170
一張貓圖往右平移一些

88
00:05:48,170 --> 00:05:50,735
還是很清楚的一隻貓

89
00:05:50,735 --> 00:05:58,715
而卷積架構幫助神經網路解碼了一個影像

90
00:05:58,715 --> 00:06:02,600
移動了幾個像素應該還是有類似的特徵

91
00:06:02,600 --> 00:06:07,515
而或許應該對應到相同的輸出標籤

92
00:06:07,515 --> 00:06:10,468
而當您使用了相同的過濾器

93
00:06:10,468 --> 00:06:13,130
理解了影像的所有位置

94
00:06:13,130 --> 00:06:16,255
同時在早期層和後期層

95
00:06:16,255 --> 00:06:20,060
幫助神經網路自動學習得

96
00:06:20,060 --> 00:06:28,320
更精實，更能捕捉到偏移不變的特性

97
00:06:28,320 --> 00:06:32,415
所以這些是一些原因為什麼

98
00:06:32,415 --> 00:06:37,320
卷積或者卷積神經網路在電腦視覺作用如此的棒

99
00:06:37,320 --> 00:06:43,150
最後，讓我們將所有這些放一起，
看看您如何訓練這一個網路

100
00:06:43,150 --> 00:06:45,980
假設您想建立一個貓的偵測器，您

101
00:06:45,980 --> 00:06:48,715
有一些標籤過的訓練集如下

102
00:06:48,715 --> 00:06:52,180
現在， X 是一個影像

103
00:06:52,180 --> 00:06:54,650
然後 y 可以是一個二元標籤

104
00:06:54,650 --> 00:06:57,645
或者 k 項之一

105
00:06:57,645 --> 00:07:02,090
假設您選擇了使用卷積神經網路架構

106
00:07:02,090 --> 00:07:06,468
或許從影像開始，然後有卷積層跟池層

107
00:07:06,468 --> 00:07:09,310
然後一些全連結層

108
00:07:09,310 --> 00:07:13,880
接著是 softmax 輸出最後輸出是 y hat 

109
00:07:13,880 --> 00:07:20,165
在 conv 層跟全連結層會有各種參數

110
00:07:20,165 --> 00:07:23,213
W 跟偏差 b

111
00:07:23,213 --> 00:07:26,780
所以，任何參數的設定

112
00:07:26,780 --> 00:07:32,540
讓您定義一個成本函數
跟我們在之前的課程中見到的類似

113
00:07:32,540 --> 00:07:37,648
我們隨機初始參數 w 跟 B

114
00:07:37,648 --> 00:07:40,237
您就可以計算成本 J

115
00:07:40,237 --> 00:07:46,645
也就是神經網路預測的所有損失的總和
在整個訓練集上

116
00:07:46,645 --> 00:07:50,880
或許除上 m

117
00:07:50,880 --> 00:07:52,555
要訓練神經網路

118
00:07:52,555 --> 00:07:56,210
您要做的是使用梯度下降或者一些

119
00:07:56,210 --> 00:07:59,795
演算法像是動量梯度下降法

120
00:07:59,795 --> 00:08:03,447
或者 RMSProp 或者 Adam 或者其他

121
00:08:03,447 --> 00:08:05,900
為了要最佳化所有的參數

122
00:08:05,900 --> 00:08:09,220
在神經網路上試著減低成本函數 J

123
00:08:09,220 --> 00:08:11,110
您發現如果您這樣做

124
00:08:11,110 --> 00:08:18,759
您可以建立一個很有效的貓偵測器或者其他偵測器

125
00:08:18,759 --> 00:08:21,700
恭喜您完成這個星期的課程

126
00:08:21,700 --> 00:08:25,550
您已經見到了所有的卷積神經網路的建構基石

127
00:08:25,550 --> 00:08:30,415
跟如何將它們放在一起成為一個很有效的影像辨識系統

128
00:08:30,415 --> 00:08:32,095
在這個星期的練習中

129
00:08:32,095 --> 00:08:34,310
我想所有這些東西都會變得更加具體

130
00:08:34,310 --> 00:08:36,610
您會有機會自己來練習建置

131
00:08:36,610 --> 00:08:39,805
這些，跟見到它們如何作用

132
00:08:39,805 --> 00:08:43,835
下星期，我們將繼續深入卷積神經網路

133
00:08:43,835 --> 00:08:45,730
我之前提過，有很多的

134
00:08:45,730 --> 00:08:48,115
超參數在卷積神經網路上

135
00:08:48,115 --> 00:08:49,420
我下周想做的事

136
00:08:49,420 --> 00:08:52,000
要展示一些具體的例子對於一些

137
00:08:52,000 --> 00:08:54,680
最有效的卷積神經網路

138
00:08:54,680 --> 00:08:57,010
您可以開始理解一些模式

139
00:08:57,010 --> 00:09:00,055
在哪些網路架構最有效率

140
00:09:00,055 --> 00:09:04,360
人們常做的一件事是拿這些

141
00:09:04,360 --> 00:09:05,885
其他人已經發現跟發佈在

142
00:09:05,885 --> 00:09:08,995
研究論文的架構，直接用在您的應用上

143
00:09:08,995 --> 00:09:12,055
所以，下星期看一些具體的例子

144
00:09:12,055 --> 00:09:15,470
您也因此學到如何做得更好

145
00:09:15,470 --> 00:09:16,690
除此，下個星期

146
00:09:16,690 --> 00:09:21,520
我們也會得到一些直觀有關於
什麼樣的 ConvNet 會作用的好

147
00:09:21,520 --> 00:09:23,160
然後在其餘課程

148
00:09:23,160 --> 00:09:27,475
我們會看到一些不同的電腦視覺應用，像是

149
00:09:27,475 --> 00:09:30,170
物件偵測跟神經風格轉換

150
00:09:30,170 --> 00:09:34,070
它們如何用這些演算法來建立的藝術品風格

151
00:09:34,070 --> 00:09:35,564
這個禮拜結束了

152
00:09:35,564 --> 00:09:37,530
祝您這個禮拜的作業幸運

153
00:09:37,530 --> 00:09:39,660
期待下禮拜見到你