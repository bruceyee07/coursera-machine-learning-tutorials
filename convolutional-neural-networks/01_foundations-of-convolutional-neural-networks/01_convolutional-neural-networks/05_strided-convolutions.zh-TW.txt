跨步卷積是另一個 卷積神經網路的基本建構基石之一 讓我展示您一個例子 假設您想要用這個 7乘7 影像
卷積這個 3乘3 過濾器 除了用平常的方式 我們用跨兩步來做這件事 意思是您照往常一樣拿這個左上角的 3乘3 區域逐元素乘積然後相加，得到 91 但與其將這個藍色框框往右跨一步 我們一次跨兩步 我們將它一次跨兩步像這樣 注意到這個左上角
如何從這裡到這裡 跳過一個位置 然後您做平常的逐元素乘積跟相加得到 100 然後照樣再做一次 讓這個藍色框框一次跳兩步 您最終在這裡得到 83 現在，當您到下一行 再一次跳兩步而不是 跳一步來移動這個藍色框框 請注意到我們跳過了一步，這給我們 69 現在再一次跳過兩步 這給您 91 等等 127 然後到最後一行，是 44, 72, 74 在這個例子，
我們卷積了一個 7乘7 的矩陣 跟這個 3乘3 矩陣，
我們得到這個 3乘3 輸出 輸出跟輸入維度實際上由下列公式控制 如果您有一個 n乘n 影像 跟一個 f乘f 過濾器卷積 而如果您使用填充 p 跟跨步 s, 在這個例子 s 等於 2, 您最終會得到一個輸出也就是 n+2p-f 因為現在您一次跨 s 步 而不是一次一步 您現在要除以 s +1 然後這邊一樣 在我們的例子，我們有 (7+0-3 除以 2) + 1 等於 (4 除以 2) + 1 等於 3 這是為什麼我們最終會有這個 3乘3 輸出 現在，最後一個細節，如果這個分數不是整數怎麼辦 這種情況下，我們用完全捨去法 這個記號記為某數的地板函數 這也稱為 Ｚ的地板值 意思是拿 Ｚ 捨去小數到最近的整數 實作的方式是您用 這樣的藍色框框作乘積，只有當藍色的框框完全 在影像或者影像加填充內， 如果這個藍色框框的一部份 在影像外面，您就不用做這樣的運算 傳統上您的 3乘3 過濾器 必須完全在您的影像內或者 影像加填充區域內， 在您產生輸出之前，
這是約定的做法 如此，正確計算輸出維度是 如果 (n+2p-f) / s  不是整數則捨去 總結一下，關於維度 如果您有一個  n乘n 矩陣 或者說 n乘n 影像，您跟 一個 f乘f 矩陣，或者說 f乘f 過濾器，
使用填充量 p 跟跨步 s 那輸出大小會是這個維度 我們可以自己選擇這些數字
讓它成為整數 雖然有時你不必這樣做, 
完全捨去也只是可以的 但請自己造一些例子使用不同的  n, f p 跟 s 值來說服自己 這個公式是正確地算出輸出大小 在繼續之前，我想做一個技術的註解有關於 交叉相關跟卷積的關係，這是為了 您必須這麼做來
建立卷積神經網路的事實 如果您讀了不同的數學教科書，
或者訊號處理教科書 有可能看到一個不一致的記號 如果您看一本典型的數學教科書 卷積運算的定義是
在做逐元素乘積跟相加之前 實際上會先採取另外一個步驟 也就是當這個 6乘6 矩陣跟這個  3乘3 過濾器卷積時 您首先拿這個 3乘3 過濾器，將其 垂直跟水平翻轉, 也就是這個 345, 102, -197 會變成 3 在這裡， 4 到這裡 5 到這裡，而第二行 會變成 102 跟 -197 實際上這是將這個 3乘3 過濾器 垂直跟水平鏡射 然後將這個翻轉過的矩陣
複製到這裡 要計算輸出 您會計算  2 乘 7 加上  3 乘  2 加上  7 乘  5 等等 您應該用這個翻轉過的矩陣來  計算這個  4乘4 輸出矩陣的左上角 然後用這 9 個數字 跨一步，然後跨一步等等 而在影片中，我們在定義卷積運算 時我們跳過了這個鏡射的運算 技術上而言，我們真正使用的 在前面幾個影片中使用的運算 有時稱為交叉相關而不是卷積 但是在深度學習的文獻中，傳統上 我們稱這個為卷積運算 總結一下，傳統上在機器學習中 我們通常不做這個翻轉的運算，技術上 這個運算或許稱為交叉相關比較好，但大部分 深度學習文獻稱之為卷積運算 我在影片中也會用這個約定稱呼 如果您讀過很多機器學習的文獻 您會發現大部分的人稱這個 為卷積運算而不使用這些翻轉 實際上在訊號處理或者特定的數學中 在卷積的定義中使用翻轉 會導致卷積運算的一種特性，也就是 A跟Ｂ卷積， 再跟Ｃ卷積，會等於Ａ跟 Ｂ卷積Ｃ的卷積 這個在數學上稱為結合率 這在訊號處理應用時很棒，但 對於深度網路學習，這真的不重要，所以 省略這個雙重鏡射的運算會簡化 程式，也讓神經網路照樣工作 傳統上，我們大部分人稱這個為卷積 即使數學家喜歡稱之為交叉相關 但這應該不會影響到您要做的 程式練習，也不該  影響您閱讀跟理解
深度學習文獻的能力 您見到了如何使用卷積 您也見到了如何使用填充跟跨步到卷積 但目前為止，我們都用卷積在矩陣上 像是 6乘6 矩陣 下一段影片，您將見到如何在容積上使用卷積 而這會讓您使用更強大的卷積運算 讓我們進入下一段影片