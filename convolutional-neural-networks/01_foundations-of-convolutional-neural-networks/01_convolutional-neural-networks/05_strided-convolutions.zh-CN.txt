Strided(带步长的)卷积是在卷积神经网络中 组成基础卷积模块的另一部分 请看这个例子 假设你想用3X3过滤器对这个7X7的图片进行卷积 除了使用平常的方式 我们这次用2为步长的方式进行卷积 这意味着，在左上角3X3的区域进行元素间相乘是不变的 之后把这些乘积相加得到91 但是，这次不把蓝色区域移动一个步长 而是将蓝色区域移动两个步长 这样，我们移动两步到了新的位置 注意到蓝色区域的左上角从这个位置到这个位置 跳过了一个元素 之后进行和平常一样，进行元素间相乘，并把结果相加得到100 现在我们要重复进行刚才的操作 确保蓝色区域跳过两个步长 移到这里，得到83 现在，我要将蓝色区域移到下一行 再一次移动两个步长 而不是移动一个步长。这样，蓝色区域被移到这里。 注意我们是跳过了一个步长的。这样，这部分卷积值为69 现在，再一次跳过两个步长 这个结果为91，下一个为127 最后一行的三个结果为44,72,74 这样，我们用3X3的过滤器对7X7的矩阵进行卷积 得到了一个3X3的输出 输入和输出的维度间的关系可以用以下的方程进行表示 如果你有一个NxN大小的图像 用一个FxF大小的过滤器对这个图像进行卷积 对图像使用p层填充，并假设步长为S。在这个例子中， S为2。此时，得到的结果的维度为N+2P-F 由于每次要移动S步长 而不是一步步进行 所以要除以S，再加上1后得到这个公式。现在可以应用这个公式 在我们的例子中，7+0-3 得4，再除以2，再加上1，等于 4除以2，得2，2+1等于3 这就是为什么我们得到这个3X3的输出矩阵 还有一个细节，如果这个分数中，分子不能被分母整除得到整数怎么办？ 这时，我们可以向下取整 用这个标志表示对于某个值向下取整 这又叫floor(z) 它表示最接近z的小于z的整数 之所以这样，是因为 蓝色区域被像素或补充的元素填满时，得到的是正数 如果蓝色区域 部分没有被图像或图像加填充部分覆盖 就这样落在外部的时候，我们不能进行计算 这说明，3X3的过滤器 必须全部落在原图像 或原图像加上填充的范围之内 就形成了这样的约定 之后，计算输出维度的正确做法是 如果(N+2P-F)/S不是整数的话，则将其向下取整。 总结一下维度的计算 如果你有一个NxN的图像或矩阵 将其填充P层元素后，用FxF大小的过滤器，以步长为S的方式 进行卷积。输出的矩阵大小为(N+2P-F)/S+1 我们可以选择这些数的数值，使结果为整数 尽管你不必考虑这些。使用向下取整也是很正常的。 但是如果你想的话，你尝试一些N，F，P，S的值 来说服自己 这个公式可以得到正确的维度 现在，在继续之前， 因为你们要自己实现卷积神经网络，所以 我要做点关于交叉相关与卷积的说明。 如果你读不同的数学课本或是信号处理的课本 在符号表示上，本课程可能与其有不一致的情况。 如果你看标准的数学课本， 对于卷积的定义，其实在做元素间相乘并求和的之前， 例如在用这个3x3的过滤器对6x6矩阵进行卷积之前 你其实需要做另外一个步奏， 你先将3x3过滤器沿水平轴进行翻转 同样对竖直轴进行翻转。这样3,4,5,1,0,2,-1,9,7会 变成,3到这,4到这 5到这。之后是第二行 变成这样。1,0,2,-1,9,7 这样就将3x3过滤器 对水平和竖直轴进行镜像映射 之后，将其放进矩阵中，放到这。 计算结果 2乘以7 加上3乘以2 加上7乘以5，,以此类推。 计算出这些值是为了 计算4x4输出矩阵中的左上角元素 之后将这九个值 右移一个步长，以此类推。 我们在本视频中定义的卷积操作 将翻转操作省略了。 技术层面来说，实际上 我们在之前的视频中进行的操作 应该是叫交叉相关，而不是卷积。 但是在深度学习文献中，由于约定 我们只不过将其称为卷积。 总结一下，在机器学习的约定中， 我们通常忽略掉翻转的操作。 技术上，我们进行的操作最好称之为交叉相关。 但是，大多数深度学习的文献都叫它卷积操作。 所以，在本课程的视频中，我将延续这一约定。 如果你读过许多机器学习的相关文献 你就会发现 大多数人叫这个卷积，并不需要做翻转 事实上，在信号处理或其他数学分支领域 对卷积核进行翻转 会使卷积核保持 （A卷积B）卷积C等于A卷积（B卷积C) 这一性质在数学上叫结合率（associativity） 这一性质在信号处理领域很有用 但对深度神经网络而言，它并不重要 所以元素间相乘并求和简化了代码 而且这一改变后，神经网络照常工作 为了方便，我们大部分人叫这个卷积 即使有时数学家更喜欢管它叫交叉相关 但是叫法对你在练习中写的代码没有影响 并且对你 阅读理解深度学习文献的能力没有影响 你现在已经看到了如何进行卷积 也看到了如何进行通过填充和跨步长进行卷积 但是现在，我们看到的都是对矩阵进行卷积 比如对6 x 6矩阵 在下个视频中，如果在3维体积中进行卷积 这会使卷积操作具有更加强大的魔力 我们下一节再见