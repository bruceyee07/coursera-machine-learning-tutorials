今週の最後のビデオでは なぜ 畳み込みが そんなに使えるのかについて話す ニューラルネットワークに組み込んだ場合にね そして最後に これらを全部まとめ上げる方法と ラベル付き学習データで どのようにして
畳み込みニューラルネットワークを学習させるかについて 簡単に話す 畳み込み層には 単に全結合層を使う場合に対し 主な利点が２つある その利点とは パラメータ共有と結合のスパース(疎)化だ 例を使って説明しよう ここに 32 x 32 x 3 次元の画像がある これは 実は 前のビデオの例から取ってきたものだ 5 x 5 フィルターを６個使おう そうすれば 28 x 28 x 6 次元の出力を得る 32 x 32 x 3 = 3,072 で 28 x 28 x 6 は 全部掛けると 4,704 だ もし １層に 3,072 ユニットあるニューラルネットワークを作成すると もし 次の層に 4,704 ユニットあるものだと そして これらのニューロン個々を全て結合すると 重み行列は 重み行列のパラメータ数は 3,072 x 4,704 これは約14百万だ これだと 大変な数のパラメータを学習させねばならない 今日では 14百万よりも多くのパラメータを持つニューラルネットワークを学習できるが これは かなり小さな画像に過ぎない これは 学習するには大量のパラメータだ 勿論 これが 1000 x 1000 画像だったら 表示した行列は 見えないくらい巨大になるだろう しかし もし この畳み込み層のパラメータ数を見てみれば 各フィルターは 5 x 5 で つまり 各フィルターには 25個のパラメータがあり バイアスパラメータを加えて フィルターあたり 26個のパラメータだ そして ６個のフィルターがあるから パラメータの合計数は 156 パラメータだ よって この畳み込み層のパラメータ数は 非常に小さい ConvNet が相対的に少ないパラメータしか持たない理由は ２つある １つがパラメータ共有だ パラメータ共有は 観測から 引き出された 垂直エッジ検出器のような特徴検出器は 画像の一部で有効なら 多分 画像の他の部分でも有効だ これが意味することは こうだ もし 例えば 垂直エッジ検出に 3 x 3 フィルターを見つけたら その 3 x 3 フィルターを ここに適用できて そして 次の位置にも その次の位置にも 次々に よって 各特徴検出器は ここの各出力に対して 同じパラメータを 入力画像の多くの異なる位置で 使うことができる 垂直エッジや 他の特徴を検出するのに 私は これは エッジのような低レベルの特徴に対しては正しいと思うし より高レベルの特徴 例えば 顔を示す目や 猫や その他 の検出についても正しいだろう 共有すること
この場合 この出力の１６個を計算するための同じ９つのパラメータ は パラメータ数を減らすための１つの方法だ これは 直観的でもある
特徴検出器が 画像の左上に対し計算を行う 垂直エッジ検出器のようなものが 同じ特徴が有効であるなら 画像の右下隅でも有効である場合が多いだろう そして 画像の左上と右下隅に対する 別の特徴検出器を 学習させる必要はないだろう もしかすると 左上隅と右下隅で 異なる分布を持つデータセットがあるかもしれない それらは 少し異なって見えるかもしれないしが 充分似ているだろう 画像全体に渡り 特徴検出器を共有し ちゃんと上手く行く ConvNet が相対的に少ないパラメータでいる ２番目の理由は スパース(疎)な結合を持つことだ つまり どういうことかと言うと この０を見ると これは 3 x 3 畳み込みで計算されたもの そして それは この 3 x 3 格子 セルのみに依存している つまり この右の出力ユニットは この 6 x 6 36入力の内の９つのみと結合しているのと同じだ 特に言えば ここの残りのピクセルは ここの全てのピクセル値 ここの全てのピクセル値は この出力に何の影響も無い これが 結合のスパース(疎)化が意味するものだ 別の例を挙げると この出力は ここの９つの入力値のみに依存している これら９つの入力値が この出力と接続しているのと同じだ そして 他のピクセルは この出力に全く影響しない そして この２つのメカニズムによって 非常に少ないパラメータを持つニューラルネットワークが 少ない学習セットで学習し 過学習し難くくするのを可能にする 時々 耳にすることがあるかもしれないが 畳み込みニューラルネットワークは並進不変性を得るのに非常に良い これは こういうことだ 猫の写真を右に数ピクセルずらしても 明らかに 猫のままだ そして 畳み込み構造は ニューラルネットワークが 次の課題を処理するのを助けてくれる 数ピクセル移動した画像は 殆ど同じ特徴量に落ち着くべきで 同じ出力ラベルが付けられるべき という課題だ 同じフィルターを適用するということが 画像のあらゆる場所で また 初めの方の層でも 後の方の層でも ニューラルネットワークが自動的に学習し より堅牢で 並進不変のより良い望ましい性質を得るのを助けるのだ そう ２~３の理由がある なぜ 畳み込みや 畳み込みニューラルネットワークが コンピュータ ビジョンにおいて とても良く機能するか 最後に 全てを纏めて このネットワークをどのように学習させるか 見てみよう 猫検出器を作りたいものとする 次のようなラベル付き学習セットがある Xを画像とし yを２値を取るラベルとする もしくは 複数値の内の１つ 畳み込みニューラルネットワーク構造はできている 画像があって それから 畳み込み層とプーリング層 そして 全結合層 続けて ソフトマックス出力で yハットを出力する 畳み込み層と全結合層は 様々なパラメータを持つ w に バイアスの b いかなるパラメータの設定も 前のコースで見たようなコスト関数を定義して処理する必要がある w と b をランダムに初期化しておけば コスト J を計算できる ニューラルネットワークの 全学習セットに対する予測の 誤差の合計 それを m で割ったもの このニューラルネットワークを学習させるには 必要なことは それから 勾配降下法や 何らかのアルゴリズムを使うことだ モメンタム RMSProp Adam その他だ 全てのパラメータを最適化するのに ニューラルネットワークは コスト関数 J を減らすようにする そして これを行えば とても良い 猫検出器や その他の検出器を 作ることができる おめでとう 今週のビデオを終えたね 畳み込みニューラルネットワークの基本構成要素を全て見てきた そして どのように それらを組み立て きちんと動作する画像認識システムにするかを見てきた 今週のプログラミング演習では これら全てのことが もっと具体的になるはずだ 自分自身で これらを実装し 自分自身で それが動くのを見る機会だ 次週は 畳み込みニューラルネットワークにより深く入っていく 前に言ったように 畳み込みニューラルネットワークには 沢山のパラメータがある よって 次週したいことは いくつかの具体例を見せることだ 最も効果的な畳み込みニューラルネットワークの例を そうしたら あなたは どんなタイプのネットワーク構造の パターンが効果があるのか理解し始めるだろう 人々は よくこんなことを行う
他の誰かが 見つけたり 研究論文に公開したりした構造を 自身のアプリケーションにそのまま使う そこで 次週 いくつかのより具体的な例を見れば どうしたら もっとよくできるか 学べるだろう また 次週は それ以外にも 何が ConvNet をつまく働かせるのか についても 洞察を得よう そして このコースの残りでは 他の様々なコンピュータ ビジョン アプリケーションを見よう 例えば 物体検出 それに ニューラル スタイル変換だ これらのアルゴリズムを使って どのように 新しい形の芸術作品を作るのだろうか じゃ 今週はここまで 宿題 頑張って 次週 会えるのを楽しみにしているよ