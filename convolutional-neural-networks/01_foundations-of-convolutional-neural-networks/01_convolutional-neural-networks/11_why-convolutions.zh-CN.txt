在这周的最后一个视频 咱们来谈谈为什么把卷积 放在神经网络中会如此有用 最后，我们简要说一下如何把卷积和神经网络合在一起，以及 如果你有一个标签的训练数据集，如何用它来训练这个卷积神经网络 我觉得卷积层和 只用完全连接的神经层比起来有两个优势 参数共享和连接的稀疏性 让我来进一步解释这一原理 比如说，你有一个32×32x3维的图片 事实上这来自于上一个视频的例子 但比如说你有6个5×5的滤网 然后这就给你一个28×28×6维的输出结果 所以32×32×3是3072 然后28×28×6，如果你把这些数字乘起来就是4704 所以，如果你是创建一个一层有3072个单元的神经网络 下一层是4704个单元 然后你会连接每一个这些神经元 接着是权重矩阵 在权重矩阵，这些参数的总数是3072 乘以4704，结果大约是1400万个 所以这样就有很多参数需要训练 当然如今你可以训练比1400万更多参数的神经网络 但是，考虑到这仅仅是很小的图像 却有如此多的参数需要训练 而且，如果说有一个1000×1000的图像 那么这个权重矩阵将会变得非常大 但是如果你看看这个卷积层的参数总数 每个滤网是5x5 因此每个滤网有25个参数 而且一个偏置参数对每个滤网会错过26个参数 你有6个滤网 所以总共的参数总数 就等于156个参数 所以这个卷积层的参数总数仍然很少 卷积神经网络参数很少的原因有两个 一个是参数共享 参数共享是源于 在特征检测器中，例如垂直边缘检测对于 图像的一部分是有用的，那么对于另一部分可能也是有用的 这意味着 如果你发现用一个3×3的滤网来检测垂直边缘 那么你就能够在这里用这个3×3滤网 然后到下一个位置 然后用再下一个位置，一直进行下去 所以对于所有这些特征检测器 所有这些输出结果可以在你的输入图像 许多不同的位置使用相同的参数 来检测比如说一个垂直的边缘或其他一些特征 我认为这对简单的特征 例如边缘 以及更高层次的特征 比如检测眼睛，脸，猫，或其他东西 都是可以的 但是共享参数在这个例子里面 用相同的9个参数来计算所有16个输出结果 是减少参数个数的方法之一 而且，直观的来看，像垂直的边缘探测器 这类功能探测器来计算它图片的左上角 相同的特征可能会在后面有用处 当用在右下角，这个特征有可能也会有用 所以，你可能不需要学习 分开的的特征探测器 在图片的左上角和右下角 如果你有一个数据集 在左上角和右下角有不同的分布 这两块也许看上去不同，但是它们可能已经足够相似 它们可以共用相同的特征探测器，效果是一样的 第二种卷积神经网络避免 只有相对少的参数方法是建立稀疏的联系 我的意思是 如果你看着这个0 这个是通过一个3×3的卷积算出来的 所以，它只是根据这个3×3格子的输入来决定的 所有这个右边输出单元 只和这个9分之36 （6×6=36）个特征所相连 以及所有剩下的像素（格子）值 这个像素值对其他输出值没有任何的影响 这就是我所说的稀疏式联系 另一个例子，这个输出值只和这9个特征输入值有关 所以，只有这个9个特征输入值和这个输出值相连 其他的像素（格子）更不会影响到这个输出值 所以，通过这两个机理 一个只有很少的参数神经网络 可以用少于30个单元的训练数据集来训练（大于30就不好了） 有时你也会听说 卷积神经网络会被用来捕捉平移不变 我们可以观察到 一张猫的图片，它的像素格从右边移动了几格 还是一个非常清晰的猫的图片 卷积结构帮助神经网络编译了 当一张图面移动了几个像素格，它同样还应该产生非常相似的特征 应该给它一个相同的标签 同时，因为你使用了相同的滤网 这张图片的各个部分 平移之前和平移之后的图层 帮助神经网络自然而然地学会更稳定 或者更佳的捕捉到平移不变所需要的特性 以上就是几个卷积，或者卷积神经网络 为什么在计算机视觉方面表现好的原因 最后，让我们把综上所述，看看我们如何来训练这样一个卷积神经网络 假设你想建立一个猫探测器, 你 有一个标记的训练集如下 现在, X 是一个图像 y 可以是二进制标签 或者其中之一的诱因 假设你选择了一个卷积神经网络结构 插入图像, 然后有神经卷积，拉层 和全连接层 接着是一个软件的输出, 控制y^ 卷积神经网络层和完全连通层将有各种参数 W和偏差B 所以任何参数的设置 让你定义一个类似我们以前课程中所看到的成本函数 我们随机初始化 W 和 B 的参数 你可以计算J的值 作为整个训练集的神经网络预测损失的总和 也可以除以 m 来训练这个神经网络 你所需要做的是使用梯度下降或一些类似的算法 比如梯度下降动量 或者 RMSProp，Adam，或者别的什么 为了优化所有的神经网络参数 来试图降低成本函数 J 这样做你会发现 你可以建立一个非常有效的猫探测器或其他检测器 到此 恭喜你完成了本周的视频 你现在已经看到了卷积神经网络的所有基本构件 以及如何将它们组合成一个有效的图像识别系统 在本周的节目练习中 我想所有这些事情都会变得更加具体 你会有机会练习实施 这些算法并看到这些算法的结果 下周, 我们将继续深入研究卷积神经网络 我刚才提到 卷积神经网络中有许多超参数 所以我下周 会展示一些具体的例子 和一些最有效的卷积神经网络 这样你可以开始从中识别到规律 知道哪些类型的网络体系结构是有效的 人们经常做的一件事就是 利用其他人已经发现并发表的 研究论文的框架 拿到自己的应用程序中使用 所以 我们下周再看一些具体的例子 你也可以学习如何做的更好 除此之外 我们还会学到卷积神经网络高效的背后机制 然后在余下的课程中 我们还将看到各种其他计算机视觉应用 比如对象检测和神经存储传输 他们如何使用这些算法来创建新的艺术品 所以 这就是这周的课程 希望你们能顺利做完课后练习 非常期待在下周见到大家