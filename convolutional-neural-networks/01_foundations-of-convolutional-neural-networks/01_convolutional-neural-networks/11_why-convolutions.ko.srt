1
00:00:00,000 --> 00:00:02,385
이번 주 마지막 강의에서는

2
00:00:02,385 --> 00:00:05,520
컨볼루션이 신경망에 포함될 때

3
00:00:05,520 --> 00:00:08,990
왜 커볼루션이 유용하게 사용되는지에 대해 설명하겠습니다

4
00:00:08,990 --> 00:00:13,890
그리고 나서 마지막으로, 이 모든 것을 결합하는 법과

5
00:00:13,890 --> 00:00:20,160
label training set이 있을 때에는 어떻게 컨볼루션 신경망을 학습시킬 수 있을지 간략하게 설명하겠습니다.

6
00:00:20,160 --> 00:00:23,610
저는 완전 연결 레이어를 사용하는 것 보다

7
00:00:23,610 --> 00:00:29,091
커볼루션 레이어에 두 가지 주요 장점이 있다고 생각합니다.

8
00:00:29,091 --> 00:00:34,075
그 장점들은 파라미터 공유와 연결의 희소성입니다.

9
00:00:34,075 --> 00:00:36,097
예시를 통해 설명해 보겠습니다.

10
00:00:36,097 --> 00:00:42,915
32 x 32 by 3 차원 이미지가 있다고 가정 해 봅시다.

11
00:00:42,915 --> 00:00:49,040
이는 사실 이전 강의의 예제에서 가져온 것인데요,

12
00:00:49,040 --> 00:00:54,945
5 x 5 필터를 의 6 필터를 사용한다고 가정 해 봅시다.

13
00:00:54,945 --> 00:01:04,887
그러면 28 x 28 x 6 차원 아웃풋이 나오죠.

14
00:01:04,887 --> 00:01:07,938
32 x 32 x 3는 3,072가되고,

15
00:01:07,938 --> 00:01:17,320
28 x 28 x 6 이 숫자를 모두 곱하면 4,704가 됩니다.

16
00:01:17,320 --> 00:01:24,049
그래서 만약 여러분이 하나의 레이어에 3,072 개의 유닛과

17
00:01:24,049 --> 00:01:27,995
다음 레이어에 4,704 개의 유닛을 가진 신경망을 생성한다면,

18
00:01:27,995 --> 00:01:31,205
그리고 이 뉴런 하나 하나를 연결한다면

19
00:01:31,205 --> 00:01:32,650
이는 가중치 매트릭스이고,

20
00:01:32,650 --> 00:01:35,624
가중치 매트릭스에서 파라미터 숫자들은 3,072 x 4,704 이므로

21
00:01:35,624 --> 00:01:42,175
이는 약 1 천 4 백만입니다.

22
00:01:42,175 --> 00:01:44,950
이는 그냥 훈련시킬 파라미터가 많이 있다는 것이죠.

23
00:01:44,950 --> 00:01:49,455
그리고 오늘날 1400 만 개 이상의 훨씬 많은 파라미터를 사용하여 신경망을 학습시킬 수 있습니다.

24
00:01:49,455 --> 00:01:52,543
하지만, 이게 매우 작은 이미지임을 감안할 때,

25
00:01:52,543 --> 00:01:54,985
훈련시킬 파라미터가 매우 많은 양입니다.

26
00:01:54,985 --> 00:02:00,030
물론, 이것이 1,000 x 1,000 이미지라면,

27
00:02:00,030 --> 00:02:04,920
디스플레이 매트릭스는 보이지 않을 만큼 커집니다

28
00:02:04,920 --> 00:02:10,020
그러나 이 컨볼루션 레이어 에서 파라미터의 개수를 살펴보면

29
00:02:10,020 --> 00:02:12,710
각 필터는 5 x 5 이므로,

30
00:02:12,710 --> 00:02:15,385
각 필터는 25파라미터가 있으며

31
00:02:15,385 --> 00:02:19,120
한 개의 바이어스 파라미터를 더해주면, 필터당 26 파라미터가 됩니다.

32
00:02:19,120 --> 00:02:21,280
그리고 6개의 필터가 있으므로,

33
00:02:21,280 --> 00:02:23,800
총 파라미터의 수는

34
00:02:23,800 --> 00:02:26,605
156 파라미터 입니다.

35
00:02:26,605 --> 00:02:31,360
따라서 이 conv 레이어 의 파라미터 개수는 매우 작습니다.

36
00:02:31,360 --> 00:02:37,965
그리고 자음이 작은 파라미터를 실행하는 이유는 실제로 두 가지 이유입니다.

37
00:02:37,965 --> 00:02:40,110
하나는 파라미터 공유입니다.

38
00:02:40,110 --> 00:02:43,915
그리고 파라미터 공유는

39
00:02:43,915 --> 00:02:47,575
수직 에지 감지기 같은 feature 감지기가

40
00:02:47,575 --> 00:02:51,098
이미지의 한 부분에서 유용하다면 이미지의 다른 부분에서도 유용 할 것이라는 견해에 따라 사용됩니다.

41
00:02:51,098 --> 00:02:52,435
그게 의미하는 바는

42
00:02:52,435 --> 00:02:56,635
즉, 수직 모서리를 감지하기 위해 3 x 3 필터를 사용했다면,

43
00:02:56,635 --> 00:03:01,765
여기에 같은 3 x 3 필터를 적용한 다음

44
00:03:01,765 --> 00:03:03,755
다음 위치에도,

45
00:03:03,755 --> 00:03:06,220
또 다음 위치에도, 계속 게속 사용해 갈 수 있다는 것입니다.

46
00:03:06,220 --> 00:03:09,040
이 각각의 특징 탐지기들,

47
00:03:09,040 --> 00:03:13,510
이 파란색 각각은 여러분의 인풋이미지의

48
00:03:13,510 --> 00:03:17,140
다른 위치에서 수직 모서리나 다른 feature를 감지하도록

49
00:03:17,140 --> 00:03:21,825
똑같은 파라미터를 사용할 수 있습니다.

50
00:03:21,825 --> 00:03:25,885
얼굴이나 고양이 등을 나타내는 눈을 감지하는 등의

51
00:03:25,885 --> 00:03:28,990
더 높은 수준의 feature는 물론, 가장자리 같은 저 수준 feature에 대해서는

52
00:03:28,990 --> 00:03:32,865
파라미터 공유가 적용이 될 것입니다.

53
00:03:32,865 --> 00:03:34,640
이 경우에 공유되는 것은

54
00:03:34,640 --> 00:03:39,455
이 아웃풋 모두 16 개를 계산하는 동일한 9 개의 파라미터가

55
00:03:39,455 --> 00:03:43,620
파라미터 개수를 줄이는 방법 중 하나라는 것입니다.

56
00:03:43,620 --> 00:03:47,590
그리고 또한 수직 모서리 감지기 같은 feature감지기가

57
00:03:47,590 --> 00:03:52,075
이미지의 왼쪽 상단 모서리를 계산하는 것이 직관적으로 보입니다.

58
00:03:52,075 --> 00:03:55,476
이처럼 동일한 feature가 유용 할 것이고

59
00:03:55,476 --> 00:03:59,280
이미지의 오른쪽 하단에도 유용할 것 같습니다.

60
00:03:59,280 --> 00:04:00,910
따라서 이미지의 왼쪽 상단과 오른쪽 하단에

61
00:04:00,910 --> 00:04:02,320
서로 다른 feature 감지기를

62
00:04:02,320 --> 00:04:05,140
배워야 할 필요가 없죠.

63
00:04:05,140 --> 00:04:07,435
어쩌면 왼쪽 상단 코너와 오른쪽 아래 코너부분에

64
00:04:07,435 --> 00:04:12,087
다른 분포를 가진 데이터 세트를 가지고 있을지도 모릅니다

65
00:04:12,087 --> 00:04:15,660
그래서 그들은 조금 다르게 보일지 모르지만, 충분히 유사 할 수 있습니다.

66
00:04:15,660 --> 00:04:20,185
그들은 모든 이미지에 걸쳐서 feature 감지기를 공유하고 있고, 잘 작동되고 있습니다.

67
00:04:20,185 --> 00:04:23,800
컨볼네트가 상대적으로 파라미터가 거의 없는 두 번째 방법은

68
00:04:23,800 --> 00:04:27,485
Sparsity of connections을 하는 것입니다.

69
00:04:27,485 --> 00:04:28,779
여기서 제가 의미하는 것은,

70
00:04:28,779 --> 00:04:30,400
여러분이 0을 본다면,

71
00:04:30,400 --> 00:04:32,980
이것은 3 x 3의 컨볼루션을 통해 계산됩니다.

72
00:04:32,980 --> 00:04:38,350
그리고 이것은 3 x 3 인풋 그리드 또는 셀에만 의존합니다

73
00:04:38,350 --> 00:04:43,900
따라서 오른쪽의 아웃풋 단위가

74
00:04:43,900 --> 00:04:50,155
마치 이 6 x 6, 36 인풋 feature 중의 9개에 대해서만 연결되어있는 것처럼 보입니다.

75
00:04:50,155 --> 00:04:54,015
특히 나머지 픽셀 값들,

76
00:04:54,015 --> 00:05:02,395
여기 있는 모든 픽셀 값은 이쪽 아웃풋에 영향을 미치지 않습니다.

77
00:05:02,395 --> 00:05:04,945
자, 이게 바로 Sparsity of connections입니다.

78
00:05:04,945 --> 00:05:15,585
또 다른 예시로, 이 아웃풋은 이 9 개의 인풋 feature에만 의존합니다.

79
00:05:15,585 --> 00:05:20,293
따라서 이쪽 9 개의 인풋 feature만이 아웃풋에 연결되어 있고,

80
00:05:20,293 --> 00:05:23,431
다른 픽셀은 이 아웃풋에 전혀 영향을 미치지 않는 것처럼 보입니다.

81
00:05:23,431 --> 00:05:25,825
이 두 가지 메카니즘을 통해,

82
00:05:25,825 --> 00:05:30,310
신경망은 파라미터를 거의 가지고 있지 않고,

83
00:05:30,310 --> 00:05:35,380
이는 더 작은 training cell로 훈련되고, 30 이상이 될 가능성의 더 적어지는 것이죠

84
00:05:35,380 --> 00:05:37,445
때로는 컨볼루션 신경망이

85
00:05:37,445 --> 00:05:42,245
변환불변성을 잘 캡쳐한다고 들었을 겁니다.

86
00:05:42,245 --> 00:05:44,725
즉, 고양이의 그림이

87
00:05:44,725 --> 00:05:48,170
오른쪽으로 픽셀 몇 개를 이동해도

88
00:05:48,170 --> 00:05:50,735
여전히 선명한 고양이 그림이라는 것입니다.

89
00:05:50,735 --> 00:05:58,715
컨볼루션 구조는

90
00:05:58,715 --> 00:06:02,600
몇 픽셀 이동 된 이미지도 결국 꽤 비슷한 feature를 유지하게 하고

91
00:06:02,600 --> 00:06:07,515
동일한 레이블 을 지정하도록 신경망를 도와줍니다.

92
00:06:07,515 --> 00:06:10,468
그리고 동일한 필터에 적용한다는 사실은

93
00:06:10,468 --> 00:06:13,130
이미지의 모든 위치를 알고 있다는 것인데요,

94
00:06:13,130 --> 00:06:16,255
이는 초기 레이어와 후기 레이어 둘 다에서

95
00:06:16,255 --> 00:06:20,060
신경망이 더 강력 해지거나

96
00:06:20,060 --> 00:06:28,320
변환불변성을 바람직한 특성을 더 잘 포착하는 데 도움이 됩니다.

97
00:06:28,320 --> 00:06:32,415
그래서, 이것들이 바로 커볼루션 이나 컨볼루션 신경망 이

98
00:06:32,415 --> 00:06:37,320
컴퓨터 비전에서 잘 작동하는 이유들 일 것입니다.

99
00:06:37,320 --> 00:06:43,150
마지막으로, 이 모든 것을 종합하여 이러한 네트워크 중 하나를 어떻게 훈련시킬 수 있는지 알아 보겠습니다.

100
00:06:43,150 --> 00:06:45,980
고양이 감지기를 만들어서

101
00:06:45,980 --> 00:06:48,715
다음과 같이 레이블된 training set가 있다고 가정 해 보겠습니다

102
00:06:48,715 --> 00:06:52,180
여기서 x는 이미지입니다.

103
00:06:52,180 --> 00:06:54,650
그리고 y는 이진수 레이블이거나,

104
00:06:54,650 --> 00:06:57,645
K 원인 중 하나 일 수 있습니다.

105
00:06:57,645 --> 00:07:02,090
그리고 여러분이 컨볼루션 신경망 구조를 선택했다고 가정 해 봅시다.

106
00:07:02,090 --> 00:07:06,468
이미지를 삽입 하고, 컨볼루션 신경망 레이어와 pooling 레이어를 만들고,

107
00:07:06,468 --> 00:07:09,310
완전 연결된 레이어를 만듭니다.

108
00:07:09,310 --> 00:07:13,880
이어서는 y hat 작동을 하는 softmax가 뒤따라옵니다.

109
00:07:13,880 --> 00:07:20,165
conv 레이어와 완전 연결 레이어는 다양한 파라미터

110
00:07:20,165 --> 00:07:23,213
W, 그리고 바이어스 의 B 가 있습니다.

111
00:07:23,213 --> 00:07:26,780
따라서 파라미터를 설정하면

112
00:07:26,780 --> 00:07:32,540
이전 과정에서 본 것과 비슷한 비용 함수를 정의 할 수 있습니다.

113
00:07:32,540 --> 00:07:37,648
여기에서 파라미터 W 및 B를 임의로 초기화했습니다

114
00:07:37,648 --> 00:07:40,237
여러분은 cost J를 계산할 수 있는데요,

115
00:07:40,237 --> 00:07:46,645
전체 training set 에서 신경망의 예측에서 생긴 손실 총액을

116
00:07:46,645 --> 00:07:50,880
M 으로 나누면 되겠죠. 따라서,

117
00:07:50,880 --> 00:07:52,555
신경망을 훈련시키기 위해서 해야 할 일은

118
00:07:52,555 --> 00:07:56,210
cost function J 값을 줄이는 노력으로 신경망의

119
00:07:56,210 --> 00:07:59,795
모든 파라미터를 최적화할 수 있도록 기울기 강하 momentum 이나,

120
00:07:59,795 --> 00:08:03,447
RMSProp 혹은 Adam같은

121
00:08:03,447 --> 00:08:05,900
알고리즘을

122
00:08:05,900 --> 00:08:09,220
사용하는 것입니다.

123
00:08:09,220 --> 00:08:11,110
이렇게 하시면,

124
00:08:11,110 --> 00:08:18,759
매우 효과적인 고양이 감지기나 또 다른 감지기도 만들 수 있습니다.

125
00:08:18,759 --> 00:08:21,700
자, 이번 주의 강의들을 모두 끝내신 것을 축하 드립니다.

126
00:08:21,700 --> 00:08:25,550
이제는 컨볼루션 신경망의 모든 기본 구성 요소를 보았고

127
00:08:25,550 --> 00:08:30,415
어떻게 그것들을 효과적인 이미지 인식 시스템으로 결합할 수 있을지 살펴보았습니다.

128
00:08:30,415 --> 00:08:32,095
이번 주 프로그램의 예제들은

129
00:08:32,095 --> 00:08:34,310
이런 모든 것들이 보다 구체적으로 이루어질 것이라고 생각합니다.

130
00:08:34,310 --> 00:08:36,610
이러한 일들을 스스로 실행해보고

131
00:08:36,610 --> 00:08:39,805
이것이 여러분을 위해 작동하는 것을 볼 수 있는 기회로 삼을 수 있을 것입니다.

132
00:08:39,805 --> 00:08:43,835
다음주에도, 계속해서 컨볼루션 신경망에 대해 자세히 다룰 것입니다.

133
00:08:43,835 --> 00:08:45,730
앞에서 언급했듯이, 컨볼루션 신경망에는

134
00:08:45,730 --> 00:08:48,115
많은 하이퍼 파라미터가 있습니다.

135
00:08:48,115 --> 00:08:49,420
그래서 다음 주에는

136
00:08:49,420 --> 00:08:52,000
가장 효과적인 컨볼루션 신경망의

137
00:08:52,000 --> 00:08:54,680
몇 가지 사례를 보여드리고,

138
00:08:54,680 --> 00:08:57,010
어떤 유형의 network architecture들이

139
00:08:57,010 --> 00:09:00,055
효과적인 패턴인지 알 수 있도록 도와드리겠습니다.

140
00:09:00,055 --> 00:09:04,360
사람들이 주로 하는 것은 누군가 찾아낸 설계도를 가져다가

141
00:09:04,360 --> 00:09:05,885
연구 보고서로 출간하고

142
00:09:05,885 --> 00:09:08,995
자신의 응용프로그램에 사용하는 것입니다.

143
00:09:08,995 --> 00:09:12,055
따라서, 다음주에는 더 많은 구체적인 예시를 통해

144
00:09:12,055 --> 00:09:15,470
그걸 어떻게 더 잘 배울 수 있고

145
00:09:15,470 --> 00:09:16,690
그 외에도, 다음주에는,

146
00:09:16,690 --> 00:09:21,520
컨볼네트가 잘 작동하게 만드는지에 대한 관점들도 알아보도록 하겠습니다.

147
00:09:21,520 --> 00:09:23,160
강의의 나머지 부분에서는

148
00:09:23,160 --> 00:09:27,475
object detection, 혹은 neural store transfer 와 같은

149
00:09:27,475 --> 00:09:30,170
다양한 컴퓨터 비전 응용 프로그램들이

150
00:09:30,170 --> 00:09:34,070
그것들이 어떻게 알고리즘을 이용해서 작품을 새로운 형태로 만들어 내는지 알아보도록 하겠습니다.

151
00:09:34,070 --> 00:09:35,564
이번 주 강의는 끝입니다.

152
00:09:35,564 --> 00:09:37,530
과제 열심히 하시고,

153
00:09:37,530 --> 00:09:39,660
다음주에 만나 뵙도록 하겠습니다.