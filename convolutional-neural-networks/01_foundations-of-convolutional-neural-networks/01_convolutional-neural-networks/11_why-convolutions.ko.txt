이번 주 마지막 강의에서는 컨볼루션이 신경망에 포함될 때 왜 커볼루션이 유용하게 사용되는지에 대해 설명하겠습니다 그리고 나서 마지막으로, 이 모든 것을 결합하는 법과 label training set이 있을 때에는 어떻게 컨볼루션 신경망을 학습시킬 수 있을지 간략하게 설명하겠습니다. 저는 완전 연결 레이어를 사용하는 것 보다 커볼루션 레이어에 두 가지 주요 장점이 있다고 생각합니다. 그 장점들은 파라미터 공유와 연결의 희소성입니다. 예시를 통해 설명해 보겠습니다. 32 x 32 by 3 차원 이미지가 있다고 가정 해 봅시다. 이는 사실 이전 강의의 예제에서 가져온 것인데요, 5 x 5 필터를 의 6 필터를 사용한다고 가정 해 봅시다. 그러면 28 x 28 x 6 차원 아웃풋이 나오죠. 32 x 32 x 3는 3,072가되고, 28 x 28 x 6 이 숫자를 모두 곱하면 4,704가 됩니다. 그래서 만약 여러분이 하나의 레이어에 3,072 개의 유닛과 다음 레이어에 4,704 개의 유닛을 가진 신경망을 생성한다면, 그리고 이 뉴런 하나 하나를 연결한다면 이는 가중치 매트릭스이고, 가중치 매트릭스에서 파라미터 숫자들은 3,072 x 4,704 이므로 이는 약 1 천 4 백만입니다. 이는 그냥 훈련시킬 파라미터가 많이 있다는 것이죠. 그리고 오늘날 1400 만 개 이상의 훨씬 많은 파라미터를 사용하여 신경망을 학습시킬 수 있습니다. 하지만, 이게 매우 작은 이미지임을 감안할 때, 훈련시킬 파라미터가 매우 많은 양입니다. 물론, 이것이 1,000 x 1,000 이미지라면, 디스플레이 매트릭스는 보이지 않을 만큼 커집니다 그러나 이 컨볼루션 레이어 에서 파라미터의 개수를 살펴보면 각 필터는 5 x 5 이므로, 각 필터는 25파라미터가 있으며 한 개의 바이어스 파라미터를 더해주면, 필터당 26 파라미터가 됩니다. 그리고 6개의 필터가 있으므로, 총 파라미터의 수는 156 파라미터 입니다. 따라서 이 conv 레이어 의 파라미터 개수는 매우 작습니다. 그리고 자음이 작은 파라미터를 실행하는 이유는 실제로 두 가지 이유입니다. 하나는 파라미터 공유입니다. 그리고 파라미터 공유는 수직 에지 감지기 같은 feature 감지기가 이미지의 한 부분에서 유용하다면 이미지의 다른 부분에서도 유용 할 것이라는 견해에 따라 사용됩니다. 그게 의미하는 바는 즉, 수직 모서리를 감지하기 위해 3 x 3 필터를 사용했다면, 여기에 같은 3 x 3 필터를 적용한 다음 다음 위치에도, 또 다음 위치에도, 계속 게속 사용해 갈 수 있다는 것입니다. 이 각각의 특징 탐지기들, 이 파란색 각각은 여러분의 인풋이미지의 다른 위치에서 수직 모서리나 다른 feature를 감지하도록 똑같은 파라미터를 사용할 수 있습니다. 얼굴이나 고양이 등을 나타내는 눈을 감지하는 등의 더 높은 수준의 feature는 물론, 가장자리 같은 저 수준 feature에 대해서는 파라미터 공유가 적용이 될 것입니다. 이 경우에 공유되는 것은 이 아웃풋 모두 16 개를 계산하는 동일한 9 개의 파라미터가 파라미터 개수를 줄이는 방법 중 하나라는 것입니다. 그리고 또한 수직 모서리 감지기 같은 feature감지기가 이미지의 왼쪽 상단 모서리를 계산하는 것이 직관적으로 보입니다. 이처럼 동일한 feature가 유용 할 것이고 이미지의 오른쪽 하단에도 유용할 것 같습니다. 따라서 이미지의 왼쪽 상단과 오른쪽 하단에 서로 다른 feature 감지기를 배워야 할 필요가 없죠. 어쩌면 왼쪽 상단 코너와 오른쪽 아래 코너부분에 다른 분포를 가진 데이터 세트를 가지고 있을지도 모릅니다 그래서 그들은 조금 다르게 보일지 모르지만, 충분히 유사 할 수 있습니다. 그들은 모든 이미지에 걸쳐서 feature 감지기를 공유하고 있고, 잘 작동되고 있습니다. 컨볼네트가 상대적으로 파라미터가 거의 없는 두 번째 방법은 Sparsity of connections을 하는 것입니다. 여기서 제가 의미하는 것은, 여러분이 0을 본다면, 이것은 3 x 3의 컨볼루션을 통해 계산됩니다. 그리고 이것은 3 x 3 인풋 그리드 또는 셀에만 의존합니다 따라서 오른쪽의 아웃풋 단위가 마치 이 6 x 6, 36 인풋 feature 중의 9개에 대해서만 연결되어있는 것처럼 보입니다. 특히 나머지 픽셀 값들, 여기 있는 모든 픽셀 값은 이쪽 아웃풋에 영향을 미치지 않습니다. 자, 이게 바로 Sparsity of connections입니다. 또 다른 예시로, 이 아웃풋은 이 9 개의 인풋 feature에만 의존합니다. 따라서 이쪽 9 개의 인풋 feature만이 아웃풋에 연결되어 있고, 다른 픽셀은 이 아웃풋에 전혀 영향을 미치지 않는 것처럼 보입니다. 이 두 가지 메카니즘을 통해, 신경망은 파라미터를 거의 가지고 있지 않고, 이는 더 작은 training cell로 훈련되고, 30 이상이 될 가능성의 더 적어지는 것이죠 때로는 컨볼루션 신경망이 변환불변성을 잘 캡쳐한다고 들었을 겁니다. 즉, 고양이의 그림이 오른쪽으로 픽셀 몇 개를 이동해도 여전히 선명한 고양이 그림이라는 것입니다. 컨볼루션 구조는 몇 픽셀 이동 된 이미지도 결국 꽤 비슷한 feature를 유지하게 하고 동일한 레이블 을 지정하도록 신경망를 도와줍니다. 그리고 동일한 필터에 적용한다는 사실은 이미지의 모든 위치를 알고 있다는 것인데요, 이는 초기 레이어와 후기 레이어 둘 다에서 신경망이 더 강력 해지거나 변환불변성을 바람직한 특성을 더 잘 포착하는 데 도움이 됩니다. 그래서, 이것들이 바로 커볼루션 이나 컨볼루션 신경망 이 컴퓨터 비전에서 잘 작동하는 이유들 일 것입니다. 마지막으로, 이 모든 것을 종합하여 이러한 네트워크 중 하나를 어떻게 훈련시킬 수 있는지 알아 보겠습니다. 고양이 감지기를 만들어서 다음과 같이 레이블된 training set가 있다고 가정 해 보겠습니다 여기서 x는 이미지입니다. 그리고 y는 이진수 레이블이거나, K 원인 중 하나 일 수 있습니다. 그리고 여러분이 컨볼루션 신경망 구조를 선택했다고 가정 해 봅시다. 이미지를 삽입 하고, 컨볼루션 신경망 레이어와 pooling 레이어를 만들고, 완전 연결된 레이어를 만듭니다. 이어서는 y hat 작동을 하는 softmax가 뒤따라옵니다. conv 레이어와 완전 연결 레이어는 다양한 파라미터 W, 그리고 바이어스 의 B 가 있습니다. 따라서 파라미터를 설정하면 이전 과정에서 본 것과 비슷한 비용 함수를 정의 할 수 있습니다. 여기에서 파라미터 W 및 B를 임의로 초기화했습니다 여러분은 cost J를 계산할 수 있는데요, 전체 training set 에서 신경망의 예측에서 생긴 손실 총액을 M 으로 나누면 되겠죠. 따라서, 신경망을 훈련시키기 위해서 해야 할 일은 cost function J 값을 줄이는 노력으로 신경망의 모든 파라미터를 최적화할 수 있도록 기울기 강하 momentum 이나, RMSProp 혹은 Adam같은 알고리즘을 사용하는 것입니다. 이렇게 하시면, 매우 효과적인 고양이 감지기나 또 다른 감지기도 만들 수 있습니다. 자, 이번 주의 강의들을 모두 끝내신 것을 축하 드립니다. 이제는 컨볼루션 신경망의 모든 기본 구성 요소를 보았고 어떻게 그것들을 효과적인 이미지 인식 시스템으로 결합할 수 있을지 살펴보았습니다. 이번 주 프로그램의 예제들은 이런 모든 것들이 보다 구체적으로 이루어질 것이라고 생각합니다. 이러한 일들을 스스로 실행해보고 이것이 여러분을 위해 작동하는 것을 볼 수 있는 기회로 삼을 수 있을 것입니다. 다음주에도, 계속해서 컨볼루션 신경망에 대해 자세히 다룰 것입니다. 앞에서 언급했듯이, 컨볼루션 신경망에는 많은 하이퍼 파라미터가 있습니다. 그래서 다음 주에는 가장 효과적인 컨볼루션 신경망의 몇 가지 사례를 보여드리고, 어떤 유형의 network architecture들이 효과적인 패턴인지 알 수 있도록 도와드리겠습니다. 사람들이 주로 하는 것은 누군가 찾아낸 설계도를 가져다가 연구 보고서로 출간하고 자신의 응용프로그램에 사용하는 것입니다. 따라서, 다음주에는 더 많은 구체적인 예시를 통해 그걸 어떻게 더 잘 배울 수 있고 그 외에도, 다음주에는, 컨볼네트가 잘 작동하게 만드는지에 대한 관점들도 알아보도록 하겠습니다. 강의의 나머지 부분에서는 object detection, 혹은 neural store transfer 와 같은 다양한 컴퓨터 비전 응용 프로그램들이 그것들이 어떻게 알고리즘을 이용해서 작품을 새로운 형태로 만들어 내는지 알아보도록 하겠습니다. 이번 주 강의는 끝입니다. 과제 열심히 하시고, 다음주에 만나 뵙도록 하겠습니다.