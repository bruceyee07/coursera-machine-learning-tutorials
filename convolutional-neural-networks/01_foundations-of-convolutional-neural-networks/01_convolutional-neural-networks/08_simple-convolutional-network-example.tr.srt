1
00:00:00,252 --> 00:00:04,029
Son videoda, tek bir katmanın yapı taşlarını gördünüz,

2
00:00:04,029 --> 00:00:06,721
evrişim ağındaki bir evrişim katmanına ait olan.

3
00:00:06,721 --> 00:00:12,339
Şimdi ise bir derin evrişimli sinir ağına ait somut örneğe gidelim.

4
00:00:12,339 --> 00:00:15,876
Ve bu, sunulan notasyonla size biraz pratik yaptıracaktır.

5
00:00:15,876 --> 00:00:17,373
son videonun sonuna doğru.

6
00:00:19,648 --> 00:00:22,203
Diyelim ki bir resminiz var ve

7
00:00:22,203 --> 00:00:26,959
görüntü sınıflandırması veya görüntü tanıma yapmak istiyorsunuz.

8
00:00:26,959 --> 00:00:31,745
Girdi olarak alınan x olarak ifade edilen bir resim almak istiyorsunuz ve bunun bir kedi olup olmadığına karar vermek istiyorsunuz, 0 veya

9
00:00:31,745 --> 00:00:34,254
1, dolayısıyla bu bir sınıflandırma problemidir.

10
00:00:34,254 --> 00:00:38,626
Bu görev için bir Evrişimli Ağ örneği oluşturalım.

11
00:00:38,626 --> 00:00:42,943
Bu örnek için, oldukça küçük bir resim kullanacağım.

12
00:00:42,943 --> 00:00:48,499
Diyelim ki resim 39 x 39 x 3.

13
00:00:48,499 --> 00:00:51,529
Bu seçim sadece bazı sayıların biraz daha iyi çalışmasını sağlar.

14
00:00:51,529 --> 00:00:57,470
Ve böylece, katman 0'daki nH nw'nin yüksekliğine eşit olacaktır ve

15
00:00:57,470 --> 00:01:00,581
genişliği 39'a eşit olacaktır ve

16
00:01:00,581 --> 00:01:06,532
kanalların sayısı ve katman 0 ise 3'e eşit olacaktır.

17
00:01:06,532 --> 00:01:11,906
İlk katmanın özellikleri tespit etmek için 3'e 3 filtreden oluşan bir dizi kullandığını varsayalım,

18
00:01:11,906 --> 00:01:16,924
yani f = 3 veya gerçekten f1 = 3,

19
00:01:16,924 --> 00:01:20,992
çünkü 3 x 3 işlemini kullanıyoruz.

20
00:01:20,992 --> 00:01:26,871
2 adım kullandığımızı ve dolgulama (padding) olmadığını varsayalım.

21
00:01:26,871 --> 00:01:32,641
Yani aynı evrişim kullanarak, 10 filtreniz olduğunu varsayalım.

22
00:01:34,632 --> 00:01:38,779
Sonra sinir ağının sonraki katmanındaki aktivasyonlar

23
00:01:38,779 --> 00:01:43,755
37 x 37 x 10 olacaktır ve

24
00:01:43,755 --> 00:01:49,335
bu 10 , 10 filtre kullanmanızdan gelmektedir.

25
00:01:49,335 --> 00:01:54,735
Ve 37 formülden gelmektedir.

26
00:01:54,735 --> 00:01:58,739
n + 2p-f üzerine s + 1.

27
00:01:58,739 --> 00:02:03,919
Doğru, 39'a sahip olduğunu tahmin ediyorum

28
00:02:03,919 --> 00:02:10,401
+0-3 üzerine 1-1 =37

29
00:02:10,401 --> 00:02:15,006
Bu yüzden çıktı 37'e 37'dir, bu geçerli bir evrişim ve

30
00:02:15,006 --> 00:02:17,590
çıktı boyutudur.

31
00:02:17,590 --> 00:02:25,029
Bizim notasyonumuzda, siz nh[1]=nw[1]=37 'e sahipsiniz ve

32
00:02:25,029 --> 00:02:30,126
nc[1] = 10, bu yüzden nc[1] aynı zamanda eşittir

33
00:02:30,126 --> 00:02:36,240
ilk katmandaki filtrelerin sayısına.

34
00:02:36,240 --> 00:02:42,040
Ve böylece bu ilk katmandaki aktivasyonun boyutu olur.

35
00:02:43,300 --> 00:02:45,980
Şimdi başka bir evrişimli katmana sahip olduğumuzu varsayalım ve

36
00:02:45,980 --> 00:02:48,900
bu sefer 5'e 5 filtreler kullandığımızı varsayalım.

37
00:02:48,900 --> 00:02:54,996
Dolayısıyla, bizim notasyonumuzda f[2] bir sonraki sinir ağında =5 'tir ve

38
00:02:54,996 --> 00:02:59,231
ve bu sefer 2 adım (stride) kullandığımızı varsayalım.

39
00:02:59,231 --> 00:03:03,922
Ve belki dolgulama (padding) olmadığını ve

40
00:03:03,922 --> 00:03:07,060
20 filtre olduğunu varsayalım

41
00:03:09,370 --> 00:03:15,933
Öyleyse bunun çıktısı başka bir hacim olacak,

42
00:03:15,933 --> 00:03:20,946
bu kez 17x17x20 olacaktır.

43
00:03:20,946 --> 00:03:23,866
Dikkat edin çünkü şimdi 2 'lik bir adım kullanıyoruz,

44
00:03:23,866 --> 00:03:25,926
boyut çok daha hızlı küçüldü.

45
00:03:25,926 --> 00:03:32,800
37 x 37, 2 kattan biraz daha küçülmüştür 17 x 17'ye kadar

46
00:03:32,800 --> 00:03:37,554
20 filter kullandığınızdan dolayı, kanal sayısı şimdi 20'dir.

47
00:03:37,554 --> 00:03:42,167
Yani bu a2 aktivasyonu

48
00:03:42,167 --> 00:03:46,971
bu boyutta olacak ve böylece

49
00:03:46,971 --> 00:03:52,160
nh[2] = nw[2] = 17 ve

50
00:03:52,160 --> 00:03:55,247
nc[2] = 20.

51
00:03:55,247 --> 00:03:58,180
Pekala, son bir evrişim katmanı uygulayalım.

52
00:03:58,180 --> 00:04:04,071
Tekrar 5'e 5 filtre kullandığımızı varsayalım,

53
00:04:04,071 --> 00:04:07,390
ve tekrar 2 adım (stride) olduğunu.

54
00:04:07,390 --> 00:04:13,681
Yani bunu yaparsan, matematiği geçeceğim, ama 7 x 7 ile sonuçlanır ve

55
00:04:13,681 --> 00:04:19,251
40 filtre kullandığımızı, dolgulama (padding) ve 40 filtre olduğunu varsayalım.

56
00:04:19,251 --> 00:04:22,760
Sonuç olarak 7x7x40.

57
00:04:22,760 --> 00:04:27,860
Şimdi yaptığınız şey, 39 x 39 x 3 giriş görüntüsünüzü aldı 

58
00:04:29,380 --> 00:04:34,810
ve bu görüntü için 7 x 7 x 40 özelliklerini hesapladı.

59
00:04:34,810 --> 00:04:41,075
Ve sonuç olarak, genellikle 7 x 7 x 40 değerini alırsanız

60
00:04:41,075 --> 00:04:45,137
7 kere 7 kere 40 1960 elde edilir.

61
00:04:45,137 --> 00:04:50,888
Ve böylece yapabildiğimiz şey bu hacmi (volume) almak ve onu düzleştirmek (flatten) ya da

62
00:04:50,888 --> 00:04:55,901
sadece 1.960 birim halinde açmak değil mi?

63
00:04:55,901 --> 00:04:59,347
Sadece bir vektör içine düzleştirin ve

64
00:04:59,347 --> 00:05:05,283
ardından bununla bir lojistik regresyon birimine veya bir softmax birimini besleyin.

65
00:05:07,917 --> 00:05:11,682
Tanımaya çalışmanıza bağlı olarak veya

66
00:05:11,682 --> 00:05:15,150
farklı objelerden birini tanımaya çalışmanıza bağlı olarak ve

67
00:05:15,150 --> 00:05:19,900
daha sonra sadece bu sinir ağ için son tahmini çıktı vermek.

68
00:05:20,925 --> 00:05:26,520
Öyleyse, açık olarak, bu son adım tüm bu sayıları,

69
00:05:26,520 --> 00:05:32,222
tüm bu 1.960 sayıyı alıyor ve onları çok uzun bir vektöre dönüştürüyor.

70
00:05:32,222 --> 00:05:36,483
Sonrasında softmax katmanını besleyeceğiniz sadece tek bir uzun vektörünüz oluyor 

71
00:05:36,483 --> 00:05:39,770
son çıktı için tahmin yapmak için sadece bir gerileme (regression) olana kadar.

72
00:05:41,600 --> 00:05:46,125
Yani bu bir evrişimli ağın (ConvNet) oldukça tipik bir örneği olabilir.

73
00:05:47,380 --> 00:05:51,187
Evrişimli sinir ağı tasarlamadaki çalışmanın çoğu ,

74
00:05:51,187 --> 00:05:54,880
toplam boyutun ne olduğuna karar vermek gibi, hipermetreler seçmektir.

75
00:05:54,880 --> 00:05:55,840
Adım (stride) nedir?

76
00:05:55,840 --> 00:05:58,860
Dolgulama (padding) nedir ve kaç filtre kullanılacak?

77
00:06:00,190 --> 00:06:03,980
Ve hem bu hafta hem de önümüzdeki haftalarda,bazı öneriler

78
00:06:03,980 --> 00:06:07,440
ve bazı kurallar vereceğiz,bu seçimlerin nasıl yapılacağına dair.

79
00:06:07,440 --> 00:06:12,510
Ama şimdilik, bundan kurtulmak için belki de

80
00:06:12,510 --> 00:06:17,950
Bir sinir ağında derine gittiğinizde, genellikle büyük resimlerle başlarsınız, 39'a 39.

81
00:06:17,950 --> 00:06:21,202
Ve sonra yükseklik ve genişlik bir süre aynı kalacaktır

82
00:06:21,202 --> 00:06:25,859
ve sinir ağında daha derine gittikçe yavaş yavaş azalacaktır.

83
00:06:25,859 --> 00:06:29,663
39 ila 37 ila 17 ila 14 arasında gitti.

84
00:06:29,663 --> 00:06:33,961
Afedersiniz, 39'dan 37'ye 17'den 7'ye gitti.

85
00:06:33,961 --> 00:06:36,753
Oysa ki, kanal sayısı genellikle artar.

86
00:06:36,753 --> 00:06:41,412
3, 10, 20, 40 arasında gitti ve bu genel eğilimi

87
00:06:41,412 --> 00:06:45,930
diğer pek çok diğer yapay sinir ağında da görüyorsunuz.

88
00:06:47,060 --> 00:06:52,576
Bu nedenle, bu parametreleri sonraki videolarda nasıl tasarlayacağımız konusunda daha fazla kılavuz bulacağız.

89
00:06:52,576 --> 00:06:57,196
Fakat şimdi ilk olarak bir evrişimli sinir ağına örneğini gördünüz, veya

90
00:06:57,196 --> 00:06:59,210
kısaca ConvNet.

91
00:06:59,210 --> 00:07:00,770
Bu konuda tebrikler.

92
00:07:02,050 --> 00:07:05,500
Ve bu tipik bir evrişimli ağda ortaya çıkıyor,

93
00:07:05,500 --> 00:07:07,870
burada genellikle 3 tip katman vardır.

94
00:07:07,870 --> 00:07:13,615
Biri evrişim katmanıdır ve bizler sıklıkla Conv katman olarak belirtiriz.

95
00:07:13,615 --> 00:07:17,025
Ve bu, önceki ağda kullandığımız şeydir.

96
00:07:17,025 --> 00:07:20,893
Henüz görmediğiniz iki ortak katman türü daha var,

97
00:07:20,893 --> 00:07:23,945
ancak önümüzdeki birkaç videoda konuşacağız.

98
00:07:23,945 --> 00:07:28,272
Biri ortaklama katmanı (pooling layer) olarak adlandırılır, genellikle bu havuz (pool) olarak adlandırılır.

99
00:07:28,272 --> 00:07:32,241
Ve daha sonra son katman tam bağlı katman (fully connected layer-FC) olarak adlandırılır.

100
00:07:32,241 --> 00:07:36,466
Ve sadece evrişim katmanları kullanarak oldukça iyi bir sinir ağı tasarlamak mümkün olsa da,

101
00:07:36,466 --> 00:07:41,278
Çoğu sinir ağı mimarisinde ayrıca birkaç ortaklama katmanı (pooling layer) 

102
00:07:41,278 --> 00:07:43,569
ve birkaç tane tam bağlı katman (fully connected layer) bulunur.

103
00:07:46,398 --> 00:07:48,103
Neyse ki ortaklama katmanının (pooling layer) ve

104
00:07:48,103 --> 00:07:52,340
tam bağlantılı katmanlarının (fully connected layers) tanımlanması evrişimli katmanların tanımlanmasından biraz daha basit.

105
00:07:54,150 --> 00:07:58,472
Bu yüzden önümüzdeki iki videoda bunu çabucak yapacağız ve daha sonra bir fikriniz olacak

106
00:07:58,472 --> 00:08:03,173
bir evrişimli sinir ağının en çok kullanılan tüm katmanları hakkında.

107
00:08:03,173 --> 00:08:06,725
Ve siz daha güçlü ağları bir araya getireceksiniz

108
00:08:06,725 --> 00:08:07,290
az önce gördüğümüzden.

109
00:08:08,990 --> 00:08:14,110
İlk tam evrişimli sinir ağını gördüğünüz için tekrar tebrik ediyorum.

110
00:08:14,110 --> 00:08:18,450
Bu hafta daha sonra ki zamanda, bu ağların nasıl eğitildiğini konuşacağız, fakat

111
00:08:18,450 --> 00:08:22,180
Öncelikle kısaca ortaklama (pooling) ve tam bağlı katmanlar (fully connected layers)hakkında konuşalım.

112
00:08:22,180 --> 00:08:24,659
Ve daha sonra bunları eğitirken, geri yayılım (back propagation) kullanılacak

113
00:08:24,659 --> 00:08:26,241
zaten aşina olduğunuz.

114
00:08:26,241 --> 00:08:30,421
Fakat gelecek videoda, ortaklama katmanını (pooling layer) nasıl uygulayacağımıza hızlıca bakalım

115
00:08:30,421 --> 00:08:31,230
Evrişimli ağımız için.