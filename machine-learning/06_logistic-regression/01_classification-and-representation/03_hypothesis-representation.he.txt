בואו נתחיל לדבר על רגרסיה לוגיסטית. בסרטון הזה, אני רוצה להראות לכם איך מייצגים את ההשערה. כלומר, מה סוג הפונקציה בה נשתמש כדי לייצג את ההשערה שלנו כאשר יש לנו בעיית סיווג. מקודם אמרנו שאנחנו רוצים שפונקצית ההשערה שלנו תוציא ערכי פלט בין 0 ל-1. אז אנחנו רוצים לייצר פונקציית השערה שעונה לקריטריון הזה, כלומר שפולטת תחזיות בין 0 ל-1. כשהשתמשנו ברגרסיה ליניארית, זו היתה צורת ההשערה שלנו, כאשר (h(x היא תטא משוחלפת כפול x. ברגרסיה לוגיסטית אני אשנה את זה קצת ואגדיר את ההשערה להיות g של תטא משוחלפת כפול x. כשהפונקציה g תוגדר כדלקמן. (g(z, כש-z הוא מספר ממשי, שווה לאחת חלקי אחת פלוס e בחזקת מינוס z. הדבר הזה נקרא פונקצית סיגמואיד או הפונקציה הלוגיסטית, והמונח פונקציה לוגיסטית הוא מה שחולל את השם רגרסיה לוגיסטית. ודרך אגב, המונחים פונקצית סיגמואיד ופונקציה לוגיסטית הם בעצם מילים נרדפות שאומרות אותו דבר. שני המושגים הם מושגים חליפיים, וכל אחד מהם יכול לשמש כשמתייחסים לפונקציה g הזו. ואם ניקח את שתי המשוואות הללו ונחבר ביניהם, זו היא פשוט דרך חלופית לרשום את פונקציית ההשערה. זה אומר ש (h(x שווה ל-1 חלקי 1 ועוד e בחזקת מינוס תטא משוחלפת כפול x. וכל מה שעשיתי הוא לקחת את המשתנה z הזה, z הזה שהוא מספר ממשי, והצבתי בו את תטא משוחלפת כפול x. אז קיבלנו תטא משוחלפת כפול x במקום ה-z כאן. ועכשיו הרשו לי להראות לכם איך נראית פונקצית הסיגמואיד. אנחנו נשרטט אותה בתרשים כאן. פונקצית הסיגמואיד, (g(z, המכונה גם פונקציה לוגיסטית, נראית כך. היא מתחילה ליד ה-0 ואז היא עולה עד שהיא חוצה את 0.5 כשהיא עוברת את ציר ה-y, ואז היא מתיישרת ומשתטחת כך. אז כך נראית פונקצית סיגמואיד. ואתם יכולים לראות שפונקצית הסיגמואיד, שמקבלת אסימפטוטות באחת ובאפס, כאשר ציר z, הציר האופקי שהוא z, כאשר z מתקרב למינוס אינסוף, (g(z שואף לאפס. וכאשר z מתקרב לאינסוף, (g(z שואף לאחת. וכך מאחר והערכים של (g(z הם בין אפס ואחת, לכן גם (h(x חייב להיות בין אפס ואחת. ובסוף, אחרי שבנינו ייצוג להשערה הזו, מה שאנחנו צריכים לעשות, כמו קודם, הוא להתאים או לכוון את הפרמטרים תטא לנתונים. כך שבהינתן סדרת אימון אנחנו צריכים לבחור ערך עבור סט הפרמטרים תטא ואז תאפשר לנו ההשערה לעשות תחזיות. נדבר מאוחר יותר על אלגוריתם למידה לבחירת הפרמטרים, אבל קודם בואו נדבר קצת על פירושו של המודל הזה. כך אני מפרש את הפלט של פונקצית ההשערה (h(x. כאשר ההשערה שלי פולטת איזה מספר, אני מתייחס למספר כהסתברות ש-y = 1 על דוגמת קלט חדשה, x. להבהרת כוונתי, הנה דוגמא. נניח שאנחנו משתמשים בדוגמא של סיווג גידולים, אז ייתכן שיהיה לנו וקטור תכונות x, שבו x0 שווה לאחת כרגיל. ותכונה מספר אחת היא הגודל של הגידול. נניח שמגיע מטופל עם גודל מסוים של גידול ואני שולח את וקטור התכונות x שלו לתוך פונקציית ההשערה שלי. ונניח שההשערה הוציאה כפלט את המספר 0.7. אז אני מפרש את ההשערה שלי כדלקמן. מה שאני אומר הוא שההשערה הזו אומרת שלחולה עם תכונות x, ההסתברות ש-y שווה 1 היא 0.7. במילים אחרות, אני עומד לספר לפציינט שלצערי לגידול יש סיכוי של 70 אחוז, או סיכוי של 0.7 להיות ממאיר. נכתוב את זה בצורה קצת יותר רשמית, או בצורה מתמטית, אני מפרש את הפלט של ההשערה כך. P של y = 1 בהינתן x שהפרמטרים שלו הם תטא. אז לאלה מכם שמכירים הסתברות, המשוואה הזו עשויה להראות הגיונית. אם אתם קצת פחות מבינים בהסתברות, אז הנה איך אני קורא את הביטוי הזה. זוהי ההסתברות ש-y שווה לאחת. בהינתן x, בהינתן פציינט שהתכונות שלו הם x, או במלים אחרות אם למטופל שלי יש גודל של גידול המיוצג על ידי וקטור תכונות x. והפרמטרים של ההסתברות הזו הם תטא. אז בעצם אנחנו סומכים על כך שההשערה שלנו תיתן לנו אומדן של ההסתברות ש-y שווה ל-1. עכשיו, מכיוון שמדובר בבעיית סיווג, אנו יודעים ש-y חייב להיות או 0 או 1, נכון? אלה הם שני הערכים היחידים ש-y יכול לקבל, הן בסדרת האימון והן עבור חולים חדשים המגיעים למעבדה שלי, או בעתיד למרפאתו של הרופא. כך שבהינתן (h(x, אנחנו יכולים לחשב את ההסתברות ש-y=0 בדיוק, כי y חייב להיות 0 או 1. ומכיוון שאנו יודעים שההסתברות של y = 0 ועוד ההסתברות של y = 1 חייבות להסתכם ב-1. המשוואה הראשונה נראית קצת יותר מסובכת. היא בעצם אומרת שההסתברות ש-y = 0 למטופל מסוים עם וקטור תכונות x, ובהנתן סט הפרמטרים תטא שלנו, פלוס ההסתברות ש-y = 1 לאותו חולה עם וקטור תכונות x, ואותו סט פרמטרים תטא, חייבות להסתכם באחת. אם המשוואה הזו נראית קצת מסובכת, פשוט תדמיינו את זה בלי התטא וה-x. זה פשוט אומר שההסתברות ש-y שווה לאפס ועוד ההסתברות ש-y שווה לאחת, חייב להיות שווה לאחת. וברור לנו שזה נכון כי y חייב להיות או אפס או אחת, ולכן הסיכוי ש-y שווה לאפס ועוד הסיכוי ש-y הוא אחת, שתי ההסתברויות האלה חייבות להסתכם באחת. אז אם פשוט תקחו את הביטוי הזה ותעבירו אותו לצד ימין, אז תגיעו למשוואה הזו. זה אומר שההסתברות ש-y שווה לאפס היא 1 פחות ההסתברות ש-y שווה 1, אז אם התכונה x ביחד עם ההשערה שלנו נותנת לנו את הביטוי הזה, ניתן לחשב בפשטות גם את ההסתברות או האומדן של ההסתברות ש-y שווה 0. אז עכשיו אתם יודעים איך מייצגים את ההשערה של הרגרסיה הלוגיסטית ואנו רואים מהי הנוסחה המתמטית שמגדירה את ההשערה של רגרסיה לוגיסטית. בסרטון הבא, אני רוצה לנסות לתת לכם אינטואיציה קצת טובה יותר על איך נראית פונקצית ההשערה. ואני רוצה לספר לכם על משהו שנקרא סף החלטה. ואנחנו נסתכל על כמה איורים כדי לנסות לקבל תחושה טובה יותר לגבי איך למעשה נראית פונקצית השערה של רגרסיה לוגיסטית.