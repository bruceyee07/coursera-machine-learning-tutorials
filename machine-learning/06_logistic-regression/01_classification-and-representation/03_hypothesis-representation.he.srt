1
00:00:00,230 --> 00:00:03,000
בואו נתחיל לדבר על רגרסיה לוגיסטית.

2
00:00:03,000 --> 00:00:07,010
בסרטון הזה, אני רוצה להראות לכם איך מייצגים את ההשערה.

3
00:00:07,010 --> 00:00:11,650
כלומר, מה סוג הפונקציה בה נשתמש כדי לייצג את ההשערה שלנו

4
00:00:11,650 --> 00:00:13,480
כאשר יש לנו בעיית סיווג.

5
00:00:15,460 --> 00:00:19,980
מקודם אמרנו שאנחנו רוצים שפונקצית ההשערה שלנו

6
00:00:19,980 --> 00:00:22,940
תוציא ערכי פלט בין 0 ל-1.

7
00:00:22,940 --> 00:00:27,310
אז אנחנו רוצים לייצר פונקציית השערה שעונה לקריטריון הזה, כלומר

8
00:00:27,310 --> 00:00:29,840
שפולטת תחזיות בין 0 ל-1.

9
00:00:29,840 --> 00:00:34,780
כשהשתמשנו ברגרסיה ליניארית, זו היתה צורת ההשערה שלנו,

10
00:00:34,780 --> 00:00:38,200
כאשר (h(x היא תטא משוחלפת כפול x.

11
00:00:38,200 --> 00:00:42,965
ברגרסיה לוגיסטית אני אשנה את זה קצת

12
00:00:42,965 --> 00:00:46,065
ואגדיר את ההשערה להיות g של תטא משוחלפת כפול x.

13
00:00:46,065 --> 00:00:50,585
כשהפונקציה g תוגדר כדלקמן.

14
00:00:50,585 --> 00:00:56,830
(g(z, כש-z הוא מספר ממשי, שווה לאחת חלקי אחת פלוס e בחזקת מינוס z.

15
00:00:58,100 --> 00:01:03,093
הדבר הזה נקרא פונקצית סיגמואיד או הפונקציה הלוגיסטית,

16
00:01:03,093 --> 00:01:05,635
והמונח פונקציה לוגיסטית

17
00:01:05,635 --> 00:01:11,090
הוא מה שחולל את השם רגרסיה לוגיסטית.

18
00:01:11,090 --> 00:01:14,130
ודרך אגב, המונחים פונקצית סיגמואיד ופונקציה לוגיסטית

19
00:01:14,130 --> 00:01:18,680
הם בעצם מילים נרדפות שאומרות אותו דבר.

20
00:01:18,680 --> 00:01:21,640
שני המושגים הם מושגים חליפיים,

21
00:01:21,640 --> 00:01:25,620
וכל אחד מהם יכול לשמש כשמתייחסים לפונקציה g הזו.

22
00:01:25,620 --> 00:01:29,460
ואם ניקח את שתי המשוואות הללו ונחבר ביניהם,

23
00:01:29,460 --> 00:01:34,840
זו היא פשוט דרך חלופית לרשום את פונקציית ההשערה.

24
00:01:34,840 --> 00:01:41,890
זה אומר ש (h(x שווה ל-1 חלקי 1 ועוד e בחזקת מינוס תטא משוחלפת כפול x.

25
00:01:41,890 --> 00:01:45,290
וכל מה שעשיתי הוא לקחת את המשתנה z הזה,

26
00:01:45,290 --> 00:01:49,970
z הזה שהוא מספר ממשי, והצבתי בו את תטא משוחלפת כפול x.

27
00:01:49,970 --> 00:01:55,000
אז קיבלנו תטא משוחלפת כפול x במקום ה-z כאן.

28
00:01:55,000 --> 00:01:57,960
ועכשיו הרשו לי להראות לכם איך נראית פונקצית הסיגמואיד.

29
00:01:57,960 --> 00:02:00,300
אנחנו נשרטט אותה בתרשים כאן.

30
00:02:00,300 --> 00:02:04,700
פונקצית הסיגמואיד, (g(z, המכונה גם פונקציה לוגיסטית, נראית כך.

31
00:02:04,700 --> 00:02:09,580
היא מתחילה ליד ה-0 ואז היא עולה עד שהיא חוצה את 0.5

32
00:02:09,580 --> 00:02:13,540
כשהיא עוברת את ציר ה-y, ואז היא מתיישרת ומשתטחת כך.

33
00:02:13,540 --> 00:02:16,020
אז כך נראית פונקצית סיגמואיד.

34
00:02:16,020 --> 00:02:21,427
ואתם יכולים לראות שפונקצית הסיגמואיד, שמקבלת אסימפטוטות באחת

35
00:02:21,427 --> 00:02:26,980
ובאפס, כאשר ציר z, הציר האופקי שהוא z,

36
00:02:26,980 --> 00:02:30,940
כאשר z מתקרב למינוס אינסוף, (g(z שואף לאפס.

37
00:02:30,940 --> 00:02:35,670
וכאשר z מתקרב לאינסוף, (g(z שואף לאחת.

38
00:02:35,670 --> 00:02:40,830
וכך מאחר והערכים של (g(z הם בין אפס

39
00:02:40,830 --> 00:02:47,170
ואחת, לכן גם (h(x חייב להיות בין אפס ואחת.

40
00:02:47,170 --> 00:02:52,930
ובסוף, אחרי שבנינו ייצוג להשערה הזו, מה שאנחנו צריכים לעשות,

41
00:02:52,930 --> 00:02:59,160
כמו קודם, הוא להתאים או לכוון את הפרמטרים תטא לנתונים.

42
00:02:59,160 --> 00:03:01,760
כך שבהינתן סדרת אימון אנחנו צריכים לבחור ערך עבור

43
00:03:01,760 --> 00:03:07,030
סט הפרמטרים תטא ואז תאפשר לנו ההשערה לעשות תחזיות.

44
00:03:07,030 --> 00:03:11,830
נדבר מאוחר יותר על אלגוריתם למידה לבחירת הפרמטרים,

45
00:03:11,830 --> 00:03:16,100
אבל קודם בואו נדבר קצת על פירושו של המודל הזה.

46
00:03:18,630 --> 00:03:23,905
כך אני מפרש את הפלט של פונקצית ההשערה (h(x.

47
00:03:25,060 --> 00:03:30,060
כאשר ההשערה שלי פולטת איזה מספר, אני מתייחס למספר

48
00:03:30,060 --> 00:03:38,050
כהסתברות ש-y = 1 על דוגמת קלט חדשה, x.

49
00:03:38,050 --> 00:03:40,360
להבהרת כוונתי, הנה דוגמא.

50
00:03:40,360 --> 00:03:44,190
נניח שאנחנו משתמשים בדוגמא של סיווג גידולים, אז

51
00:03:44,190 --> 00:03:48,920
ייתכן שיהיה לנו וקטור תכונות x, שבו x0 שווה לאחת כרגיל.

52
00:03:48,920 --> 00:03:51,860
ותכונה מספר אחת היא הגודל של הגידול.

53
00:03:52,890 --> 00:03:57,063
נניח שמגיע מטופל עם גודל מסוים של גידול

54
00:03:57,063 --> 00:04:00,394
ואני שולח את וקטור התכונות x שלו לתוך פונקציית ההשערה שלי.

55
00:04:00,394 --> 00:04:03,920
ונניח שההשערה הוציאה כפלט את המספר 0.7.

56
00:04:03,920 --> 00:04:07,340
אז אני מפרש את ההשערה שלי כדלקמן.

57
00:04:07,340 --> 00:04:11,150
מה שאני אומר הוא שההשערה הזו אומרת

58
00:04:11,150 --> 00:04:17,820
שלחולה עם תכונות x, ההסתברות ש-y שווה 1 היא 0.7.

59
00:04:17,820 --> 00:04:21,800
במילים אחרות, אני עומד לספר לפציינט שלצערי

60
00:04:21,800 --> 00:04:26,710
לגידול יש סיכוי של 70 אחוז, או סיכוי של 0.7 להיות ממאיר.

61
00:04:26,710 --> 00:04:32,246
נכתוב את זה בצורה קצת יותר רשמית, או בצורה מתמטית,

62
00:04:32,246 --> 00:04:36,140
אני מפרש את הפלט של ההשערה כך.

63
00:04:36,140 --> 00:04:41,860
P של y = 1 בהינתן x שהפרמטרים שלו הם תטא.

64
00:04:41,860 --> 00:04:46,310
אז לאלה מכם שמכירים הסתברות, המשוואה הזו עשויה להראות הגיונית.

65
00:04:46,310 --> 00:04:49,040
אם אתם קצת פחות מבינים בהסתברות,

66
00:04:49,040 --> 00:04:51,390
אז הנה איך אני קורא את הביטוי הזה.

67
00:04:51,390 --> 00:04:54,069
זוהי ההסתברות ש-y שווה לאחת.

68
00:04:54,069 --> 00:04:57,515
בהינתן x, בהינתן פציינט שהתכונות שלו הם x,

69
00:04:57,515 --> 00:05:02,698
או במלים אחרות אם למטופל שלי יש גודל של גידול המיוצג על ידי וקטור תכונות x.

70
00:05:02,698 --> 00:05:07,180
והפרמטרים של ההסתברות הזו הם תטא.

71
00:05:07,180 --> 00:05:11,250
אז בעצם אנחנו סומכים על כך שההשערה שלנו תיתן לנו

72
00:05:11,250 --> 00:05:15,070
אומדן של ההסתברות ש-y שווה ל-1.

73
00:05:15,070 --> 00:05:18,130
עכשיו, מכיוון שמדובר בבעיית סיווג,

74
00:05:18,130 --> 00:05:21,790
אנו יודעים ש-y חייב להיות או 0 או 1, נכון?

75
00:05:21,790 --> 00:05:25,350
אלה הם שני הערכים היחידים ש-y יכול לקבל,

76
00:05:25,350 --> 00:05:29,490
הן בסדרת האימון והן עבור חולים חדשים המגיעים למעבדה שלי,

77
00:05:29,490 --> 00:05:31,078
או בעתיד למרפאתו של הרופא.

78
00:05:31,078 --> 00:05:36,440
כך שבהינתן (h(x, אנחנו יכולים לחשב את ההסתברות

79
00:05:36,440 --> 00:05:42,300
ש-y=0 בדיוק, כי y חייב להיות 0 או 1.

80
00:05:42,300 --> 00:05:50,280
ומכיוון שאנו יודעים שההסתברות של y = 0 ועוד ההסתברות של y = 1 חייבות להסתכם ב-1.

81
00:05:50,280 --> 00:05:52,680
המשוואה הראשונה נראית קצת יותר מסובכת.

82
00:05:52,680 --> 00:05:55,740
היא בעצם אומרת שההסתברות ש-y = 0

83
00:05:55,740 --> 00:05:59,700
למטופל מסוים עם וקטור תכונות x, ובהנתן סט הפרמטרים תטא שלנו,

84
00:06:00,750 --> 00:06:04,190
פלוס ההסתברות ש-y = 1 לאותו חולה עם וקטור תכונות x,

85
00:06:04,190 --> 00:06:07,510
ואותו סט פרמטרים תטא, חייבות להסתכם באחת.

86
00:06:07,510 --> 00:06:09,800
אם המשוואה הזו נראית קצת מסובכת,

87
00:06:09,800 --> 00:06:14,300
פשוט תדמיינו את זה בלי התטא וה-x.

88
00:06:14,300 --> 00:06:17,460
זה פשוט אומר שההסתברות ש-y שווה לאפס ועוד ההסתברות ש-y

89
00:06:17,460 --> 00:06:19,560
שווה לאחת, חייב להיות שווה לאחת.

90
00:06:19,560 --> 00:06:23,480
וברור לנו שזה נכון כי y חייב להיות או אפס או אחת, ולכן

91
00:06:23,480 --> 00:06:27,260
הסיכוי ש-y שווה לאפס ועוד הסיכוי ש-y הוא אחת,

92
00:06:27,260 --> 00:06:29,560
שתי ההסתברויות האלה חייבות להסתכם באחת.

93
00:06:29,560 --> 00:06:33,670
אז אם פשוט תקחו את הביטוי הזה

94
00:06:33,670 --> 00:06:37,340
ותעבירו אותו לצד ימין, אז תגיעו למשוואה הזו.

95
00:06:37,340 --> 00:06:41,730
זה אומר שההסתברות ש-y שווה לאפס היא 1 פחות ההסתברות ש-y שווה 1,

96
00:06:41,730 --> 00:06:47,480
אז אם התכונה x ביחד עם ההשערה שלנו נותנת לנו את הביטוי הזה,

97
00:06:47,480 --> 00:06:50,950
ניתן לחשב בפשטות גם את ההסתברות או

98
00:06:50,950 --> 00:06:55,370
האומדן של ההסתברות ש-y שווה 0.

99
00:06:55,370 --> 00:06:59,262
אז עכשיו אתם יודעים איך מייצגים את ההשערה של

100
00:06:59,262 --> 00:07:03,570
הרגרסיה הלוגיסטית ואנו רואים מהי הנוסחה המתמטית

101
00:07:03,570 --> 00:07:06,670
שמגדירה את ההשערה של רגרסיה לוגיסטית.

102
00:07:06,670 --> 00:07:10,150
בסרטון הבא, אני רוצה לנסות לתת לכם אינטואיציה קצת טובה יותר

103
00:07:10,150 --> 00:07:12,840
על איך נראית פונקצית ההשערה.

104
00:07:12,840 --> 00:07:16,220
ואני רוצה לספר לכם על משהו שנקרא סף החלטה.

105
00:07:16,220 --> 00:07:20,340
ואנחנו נסתכל על כמה איורים כדי לנסות לקבל תחושה טובה יותר

106
00:07:20,340 --> 00:07:23,900
לגבי איך למעשה נראית פונקצית השערה של רגרסיה לוגיסטית.