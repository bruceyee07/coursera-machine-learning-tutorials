בסרטון הקודם, דיברנו על איך מייצגים את פונקצית ההשערה עבור רגרסיה לוגיסטית. מה שהייתי רוצה לעשות עכשיו הוא לספר לכם על משהו שנקרא סף ההחלטה, מה שיגביר את האינטואיציה שלנו לגבי מה בעצם מחשבת פונקצית ההשערה ברגרסיה לוגיסטית. לתזכורת, זה מה שכתבנו בפעם שעברה, שם אמרנו שההשערה מיוצגת כ-h של x שווה g של תטא משוחלפת כפול x, כאשר g היא הפונקציה הזו שנקראת פונקצית סיגמואיד ושנראית כך. היא עולה לאט מאפס עד אחת, ויש לה אסימפטוטה באחת. מה שאני רוצה לעשות עכשיו הוא לנסות להבין טוב יותר מתי השערה כזו תפלוט תחזית ש-y שווה ל-1 לעומת מתי היא תפלוט תחזית ש-y שווה ל-0. ולהבין יותר טוב איך נראית פונקצית ההשערה, במיוחד כאשר יש לנו יותר ממאפיין אחד. קונקרטית, ההשערה מוציאה הערכה של ההסתברות ש-y שווה לאחד, בהינתן x מסויים ווקטור תטא של פרמטרים. אז אם אנחנו רוצים לחזות האם y שווה לאחת או y שווה לאפס, הנה דוגמא של משהו שאנחנו יכולים לעשות. בכל פעם שההשערה מוציאה פלט שההסתברות של y = 1 גדולה או שווה ל-0.5, זאת אומרת שיש סיכוי יותר גבוה ש-y שווה 1 מאשר ש-y שווה 0, אז אנחנו ניתן תחזית ש-y שווה 1. ואחרת, אם ההסתברות, ההסתברות המוערכת של y = 1 קטנה מ-0.5, אז נחזה ש-y שווה 0. ובחרתי גדול שווה כאן, וקטן ממש כאן, אם h של x שווה 0.5 בדיוק, אז אתם יכולים להחליט לחזות אחת או אפס, אבל יש כאן איזו פרצה, ולכן כדאי להגדיר משהו, לדוגמא שניתן ניבוי חיובי אם h של x שווה בדיוק ל-0.5, אבל זה פרט שולי למדי. מה שאני רוצה לעשות הוא להבין טוב יותר מתי בדיוק h של x גדול או שווה ל-0.5, המצב שבו בסופו של דבר אנחנו ננבא ש-y שווה ל-1. אם נסתכל על הגרף הזה של פונקצית הסיגמואיד, אנו נבחין כי פונקצית הסיגמואיד, g של z גדול או שווה ל-0.5 כאשר z גדול או שווה לאפס. המחצית הזו של הגרף שבה g מקבל ערכים מ-0.5 ומעלה. הסימון הזה כאן, זה 0.5, ולכן כאשר z הוא חיובי, g של z, פונקצית הסיגמואיד גדולה או שווה ל-0.5. מאחר וההשערה עבור רגרסיה לוגיסטית היא h של x שווה g של תטא משוחלפת כפול x, הערך שלה יהיה גדול או שווה ל-0.5 בדיוק כאשר תטא משוחלפת כפול x גדול או שווה ל-0. זה מה שראינו כרגע, נכון, כי כאן תטא משוחלפת כפול x משחקת בתפקיד z. אז מה שאנחנו רואים הוא שההשערה תצפה ש-y שווה 1 אם תטא משוחלפת כפול x גדול או שווה ל-0. בואו עכשיו נסתכל על המקרה השני כאשר ההשערה צופה ש-y שווה ל-0. ובכן, בטענה מקבילה לזו למעלה, (h(x יהיה קטן מ-0.5 אם ורק אם (g(z קטן מ-0.5 כי טווח הערכים של z שבהם (g(z מקבל ערכים קטנים מ-0.5 הוא כאשר z שלילי. זאת אומרת שכאשר (g(z קטן מ-0.5, ההשערה חוזה ש-y שווה ל -0. ועל ידי טענה דומה לקודמת, (h(x שווה ל-g של תטא משוחלפת כפול x ולכן נחזה ש-y שווה 0 כל אימת שתטא משוחלפת כפול x קטנה מ-0. כדי לסכם את מה שעשינו עכשיו, ראינו שאם נחליט לחזות אם y = 1 או y = 0 לפי אם האומדן של ההסתברות גדול או שווה ל-0.5 או קטן מ-0.5, זה שקול לכך שאנו צופים ש-y = 1 כאשר תטא משוחלפת כפול x גדול או שווה ל-0. ואנו צופים ש-y שווה ל-0 בכל פעם שתטא משוחלפת כפול x קטן מ-0. בואו נשתמש בזה בכדי להבין יותר טוב כיצד מייצרת פונקצית ההשערה של רגרסיה לוגיסטית את הניבויים האלה. נניח שיש לנו סדרת אימון כמו זו המוצגת בשקופית. ונניח שההשערה היא ש-h של x שווה g של תטא אפס פלוס תטא אחת כפול x1 פלוס תטא שתיים כפול x2. לא דיברנו עדיין על איך מחשבים את הפרמטרים של המודל הזה. נדבר על זה בסרטון הבא. אבל נניח שבאמצעות איזה שהוא תהליך אנחנו בחרנו את הערכים הבאים עבור הפרמטרים. נניח שאנו בוחרים תטא-0 שווה 3, תטא-1 שווה 1, תטא-2 שווה 1. אז זה אומר שוקטור הפרמטרים שלנו הוא תטא שווה 3-, 1, 1. אז בהינתן הבחירה הזאת של פרמטרי ההשערה, בואו ננסה להבין איפה ההשערה בסופו של דבר מנבאת ש-y שווה לאחת ומתי היא מנבאת ש-y שווה לאפס. תוך שימוש בנוסחאות שסקרנו בשקופית הקודמת, אנו יודעים שההסתברות ש-y שווה לאחת גדולה או שווה ל-0.5 אם תטא משוחלפת כפול x גדול מאפס. והנוסחא הזאת שכרגע הדגשתי, x1 + x2 - 3, היא, כמובן, תטא משוחלפת כפול x כאשר תטא שווה לווקטור הפרמטרים שאנחנו בדיוק בחרנו. אז עבור כל דוגמא, עבור כל דוגמא שיש לה תכונות x1 ו-x2 כך שמתקיימת המשוואה הזאת, ש 3- ועוד x1 ועוד x2 גדול או שווה ל-0, ההשערה שלנו תנבא ש-y שווה 1 יותר סביר, או היא תנבא ש-y שווה 1. אנחנו יכולים גם להעביר את ה-3- ימינה ולשכתב את הנוסחה כ-x1 + x2 גדול או שווה 3, שזה שקול לקודם, ומצאנו שההשערה הזו תנבא y = 1 אם x1 + x2 גדול או שווה 3. בואו נראה מה זה אומר על הגרף, אם אני רושם את המשוואה X1 + X2 = 3, אז זוהי משוואה של קו ישר ואם אני מצייר איך הוא נראה, זה נותן קו שעובר ב-3 על ציר x1 ו-3 על ציר x2. ולכן האזור החיצוני כאן, החלק של המישור X1 X2 שמתאים לאזור בו X1 ועוד X2 גדול או שווה ל-3, זה החלק הזה מימין, כל מה שמימין ומלמעלה לקו הסגול הזה שציירתי כאן. האזור שבו ההשערה שלנו צופה ש-y = 1, הוא האזור הזה, האזור הבאמת ענק הזה, חצי המרחב הזה בצד ימין למעלה. תנו לי רק לרשום את זה, אני אקרא לזה "אזור ה-y = 1". ולעומת זאת, באזור שבו x1 + x2 קטן מ-3, אנחנו צופים ש-y שווה ל-0. וזה מתאים לאזור הזה. ויש באמת חצי מישור, האזור הזה משמאל הוא האזור שבו ההשערה שלנו תהיה ש-y = 0. אני רוצה לתת שם לקו הזה, הקו הסגול הזה שציירתי. הקו הזה, כאן, נקרא סף ההחלטה. וקונקרטית, זה הקו הישר הזה, X1 + X2 שווה 3. זה מתאים לקבוצה הזו של נקודות, כך שזה תואם את האזור שבו h של x שווה בדיוק 0.5 וסף ההחלטה שהוא הקו הישר הזה, זה הקו שמפריד בין האזור בו נמצאת ההשערה שצופה ש-y שווה 1 ובין האזור שבו ההשערה צופה ש-y שווה לאפס. וכדי שיהיה ברור, סף ההחלטה הוא תכונה של פונקציית ההשערה כולל הפרמטרים תטא-0, תטא-1 ותטא-2. וסימנתי בתוך הציור סדרת אימון, סדרת נתונים, לסייע להבנתנו. אבל גם בלי סדרת הנתונים, סף ההחלטה והאזור שבו אנו מנבאים ש-y = 1 מול האזור שבו y = 0, הם מאפיינים של ההשערה ושל הפרמטרים של ההשערה ולא תכונה של סדרת הנתונים. בהמשך, כמובן, נדבר על איך להתאים את וקטור הפרמטרים ואז נשתמש בסדרת האימון, נשתמש בנתונים שלנו כדי לקבוע את הערך של הפרמטרים. אבל ברגע שהחלטנו על ערכים מסוימים עבור הפרמטרים תטא-0, תטא-1 ותטא-2 אז זה לחלוטין מגדיר את סף ההחלטה ואנחנו לא באמת צריכים לצייר סדרת אימון בכדי להתוות את סף ההחלטה. עכשיו בואו נסתכל על דוגמה מורכבת יותר, בה כהרגלנו צלבים מציינים דוגמאות חיוביות ומעגלים מציינים דוגמאות שליליות. בהינתן סדרת אימון כזו, איך אני יכול לגרום לרגרסיה לוגיסטית להתאים לנתונים האלה? מוקדם יותר כשדיברנו על רגרסיה פולינומית או על רגרסיה ליניארית, דיברנו על כך שאפשר להוסיף אברים של פולינומים מסדר גבוה יותר לתכונות. ואנחנו יכולים לעשות אותו הדבר עבור רגרסיה לוגיסטית. באופן קונקרטי, נניח שההשערה שלי נראית כמו זה, כאן הוספתי שתי כאילו-תכונות נוספות, x1 בריבוע ו-x2 בריבוע, לרשימת התכונות. אז עכשיו יש לנו חמישה פרמטרים, תטא-0 עד תטא-4. כמו שאמרתי קודם, אנחנו נדחה לסרטון הבא את הדיון על האופן בו ניתן לבחור באופן אוטומטי ערכים עבור הפרמטרים תטא-0 עד תטא-4. אבל נניח שבאמצעות התהליך שיפורט, בחרנו תטא-0 שווה 1-, תטא-1 שווה 0, תטא-2 שווה 0, תטא-3 שווה 1 ותטא-4 שווה 1. פירוש הדבר הוא שעם סט הפרמטרים המסוים הזה, סט הפרמטרים תטא נראה כך, 1-, 0, 0, 1, 1. אז כמו שהיסקנו בדיון הקודם שלנו, משמעות סט הפרמטרים הזה הוא שההשערה תחזה ש-y = 1 כאשר 1- + x1 בריבוע + x2 בריבוע גדול או שווה ל-0. זאת אומרת כאשר תטא משוחלפת כפול ערכי התכונות שלנו גדול או שווה לאפס. ואם אני לוקח את 1- ומעביר אותו לצד ימין, אנחנו מקבלים שההשערה שלנו צופה ש-y שווה ל-1 כאשר x1 בריבוע פלוס x2 בריבוע גדול או שווה ל-1. אז איך נראה כאן סף ההחלטה? אז לו שרטטנו את העקומה עבור x1 בריבוע פלוס x2 בריבוע שווה 1, חלק מכם ודאי יזהו שזו המשוואה עבור מעגל עם רדיוס אחת סביב ראשית הצירים. אז זהו סף ההחלטה. כל מה שמחוץ למעגל, אנחנו נצפה ש-y = 1. אז זה האזור בו y שווה 1, ואנו צופים ש-y שווה 1, ואילו כאן בתוך המעגל זה האזור שבו אני צופים ש-y שווה ל -0. אז על ידי כך שהוספנו את הביטויים היותר מורכבים האלה, או הביטויים הפולינומיאליים האלה לסט התכונות שלנו, אנחנו יכולים לקבל ספי החלטה מורכבים יותר שלא רק מנסים להפריד בין הדוגמאות החיוביות והשליליות על ידי קו ישר, אלא הצלחנו לעשות סף החלטה מעגלי. שוב, סף ההחלטה הוא תכונה לא של סדרת האימון, אלא של פונקציית ההשערה עם הפרמטרים הספציפיים. אז כל עוד יש לנו וקטור הפרמטרים תטא, זה מגדיר את סף ההחלטה, שהוא המעגל. אבל סדרת האימון איננה מה שאנו משתמשים בו כדי להגדיר את סף ההחלטה. ניתן להשתמש בסדרת האימון כדי להתאים את וקטור הפרמטרים תטא. נדבר מאוחר יותר על איך עושים את זה. אבל ברגע שיש לך את הפרמטרים תטא, זה מה שמגדיר את סף ההחלטה. הרשו לי להחזיר את סדרת האימון רק לשם ויזואליזציה. ולבסוף הבה נסתכל על דוגמא יותר מורכבת. האם אנחנו יכולים גם להגדיר ספי החלטה עוד יותר מורכבים מזה? אם נוסיף ביטויים פולינומיים אפילו גבוהים יותר, דברים כמו X1 בריבוע, X1 בריבוע כפול X2, ו-X1 בריבוע כפול X2 בריבוע וכיוצא באלה. וביטויים כאלה מסדר גבוה, אז אפשר להראות שאפשר לקבל ספי החלטה מורכבים עוד יותר והרגרסיה יכולה לתת ספי החלטה שיכולים למשל להיות אליפסה כזו, או אולי עם הגדרה קצת שונה של פרמטרים אפשר לקבל סף החלטה שונה שעשוי אפילו להיראות כמו הצורה המוזרה כאן. ובדוגמאות עוד יותר מורכבות אפשר אולי גם לקבל ספי החלטה שייראו בצורות יותר מורכבות כמו זו שלכל מה בתוכה אנחנו צופים ש-y = 1 וכל מה שמחוץ לה אנחנו מנבאים ש-y = 0. אז עם תכונות פולינומיאליות מסדר גבוה אפשר לייצר ספי החלטה מאוד מורכבים. אז בעזרת ההדגמות האלה, אני מקווה שקיבלתם תחושה של אילו סוגים של פונקציות השערה נוכל לייצג באמצעות הייצוג שלנו עבור רגרסיה לוגיסטית. עכשיו כשאנחנו יודעים איך יכול (h(x להיראות, מה שאני רוצה לעשות בסרטון הבא זה לדבר על איך לבחור את סט הפרמטרים תטא באופן אוטומטי, כך שבהינתן סדרת אימון נוכל להתאים את הפרמטרים באופן אוטומטי לנתונים שלנו.