1
00:00:01,020 --> 00:00:05,100
בסרטון הקודם, דיברנו על איך מייצגים את פונקצית ההשערה

2
00:00:05,100 --> 00:00:06,200
עבור רגרסיה לוגיסטית.

3
00:00:06,200 --> 00:00:10,840
מה שהייתי רוצה לעשות עכשיו הוא לספר לכם על משהו שנקרא סף ההחלטה,

4
00:00:10,840 --> 00:00:15,070
מה שיגביר את האינטואיציה שלנו לגבי מה בעצם

5
00:00:15,070 --> 00:00:16,740
מחשבת פונקצית ההשערה ברגרסיה לוגיסטית.

6
00:00:17,740 --> 00:00:22,510
לתזכורת, זה מה שכתבנו בפעם שעברה, שם אמרנו

7
00:00:22,510 --> 00:00:27,780
שההשערה מיוצגת כ-h של x שווה g של תטא משוחלפת כפול x,

8
00:00:27,780 --> 00:00:32,810
כאשר g היא הפונקציה הזו שנקראת פונקצית סיגמואיד ושנראית כך.

9
00:00:32,810 --> 00:00:37,400
היא עולה לאט מאפס עד אחת, ויש לה אסימפטוטה באחת.

10
00:00:38,930 --> 00:00:42,160
מה שאני רוצה לעשות עכשיו הוא לנסות להבין טוב יותר

11
00:00:42,160 --> 00:00:45,080
מתי השערה כזו תפלוט תחזית ש-y

12
00:00:45,080 --> 00:00:49,670
שווה ל-1 לעומת מתי היא תפלוט תחזית ש-y שווה ל-0.

13
00:00:49,670 --> 00:00:53,260
ולהבין יותר טוב איך נראית פונקצית ההשערה,

14
00:00:53,260 --> 00:00:56,470
במיוחד כאשר יש לנו יותר ממאפיין אחד.

15
00:00:56,470 --> 00:01:00,610
קונקרטית, ההשערה מוציאה הערכה

16
00:01:00,610 --> 00:01:05,560
של ההסתברות ש-y שווה לאחד, בהינתן x מסויים ווקטור תטא של פרמטרים.

17
00:01:05,560 --> 00:01:08,750
אז אם אנחנו רוצים לחזות האם y שווה לאחת או

18
00:01:08,750 --> 00:01:12,230
y שווה לאפס, הנה דוגמא של משהו שאנחנו יכולים לעשות.

19
00:01:12,230 --> 00:01:16,360
בכל פעם שההשערה מוציאה פלט שההסתברות של y = 1

20
00:01:16,360 --> 00:01:21,170
גדולה או שווה ל-0.5, זאת אומרת שיש סיכוי יותר גבוה

21
00:01:21,170 --> 00:01:25,740
ש-y שווה 1 מאשר ש-y שווה 0, אז אנחנו ניתן תחזית ש-y שווה 1.

22
00:01:25,740 --> 00:01:30,870
ואחרת, אם ההסתברות, ההסתברות המוערכת של y = 1

23
00:01:30,870 --> 00:01:34,820
קטנה מ-0.5, אז נחזה ש-y שווה 0.

24
00:01:34,820 --> 00:01:40,080
ובחרתי גדול שווה כאן, וקטן ממש כאן,

25
00:01:40,080 --> 00:01:45,080
אם h של x שווה 0.5 בדיוק, אז אתם יכולים להחליט לחזות אחת או אפס,

26
00:01:45,080 --> 00:01:50,960
אבל יש כאן איזו פרצה, ולכן כדאי להגדיר משהו, לדוגמא שניתן ניבוי חיובי

27
00:01:50,960 --> 00:01:54,830
אם h של x שווה בדיוק ל-0.5, אבל זה פרט שולי למדי.

28
00:01:56,690 --> 00:02:01,750
מה שאני רוצה לעשות הוא להבין טוב יותר מתי בדיוק h של x

29
00:02:01,750 --> 00:02:08,420
גדול או שווה ל-0.5, המצב שבו בסופו של דבר אנחנו ננבא ש-y שווה ל-1.

30
00:02:08,420 --> 00:02:13,350
אם נסתכל על הגרף הזה של פונקצית הסיגמואיד,

31
00:02:13,350 --> 00:02:19,040
אנו נבחין כי פונקצית הסיגמואיד, g של z גדול או

32
00:02:19,040 --> 00:02:26,050
שווה ל-0.5 כאשר z גדול או שווה לאפס.

33
00:02:26,050 --> 00:02:32,580
המחצית הזו של הגרף שבה g מקבל ערכים מ-0.5 ומעלה.

34
00:02:32,580 --> 00:02:37,980
הסימון הזה כאן, זה 0.5, ולכן כאשר z הוא חיובי, g של z,

35
00:02:37,980 --> 00:02:41,534
פונקצית הסיגמואיד גדולה או שווה ל-0.5.

36
00:02:42,550 --> 00:02:48,168
מאחר וההשערה עבור רגרסיה לוגיסטית היא h של x שווה g של תטא

37
00:02:48,168 --> 00:02:53,966
משוחלפת כפול x, הערך שלה יהיה גדול או שווה ל-0.5

38
00:02:53,966 --> 00:03:00,240
בדיוק כאשר תטא משוחלפת כפול x גדול או שווה ל-0.

39
00:03:00,240 --> 00:03:06,670
זה מה שראינו כרגע, נכון, כי כאן תטא משוחלפת כפול x משחקת בתפקיד z.

40
00:03:08,230 --> 00:03:13,150
אז מה שאנחנו רואים הוא שההשערה תצפה ש-y שווה 1

41
00:03:13,150 --> 00:03:17,920
אם תטא משוחלפת כפול x גדול או שווה ל-0.

42
00:03:17,920 --> 00:03:24,700
בואו עכשיו נסתכל על המקרה השני כאשר ההשערה צופה ש-y שווה ל-0.

43
00:03:24,700 --> 00:03:29,946
ובכן, בטענה מקבילה לזו למעלה, (h(x יהיה קטן מ-0.5

44
00:03:29,946 --> 00:03:35,598
אם ורק אם (g(z קטן מ-0.5 כי טווח הערכים של z

45
00:03:35,598 --> 00:03:41,568
שבהם (g(z מקבל ערכים קטנים מ-0.5 הוא כאשר z שלילי.

46
00:03:41,568 --> 00:03:44,940
זאת אומרת שכאשר (g(z קטן מ-0.5,

47
00:03:44,940 --> 00:03:48,370
ההשערה חוזה ש-y שווה ל -0.

48
00:03:48,370 --> 00:03:51,345
ועל ידי טענה דומה לקודמת,

49
00:03:51,345 --> 00:03:56,880
(h(x שווה ל-g של תטא משוחלפת כפול x

50
00:03:56,880 --> 00:04:03,864
ולכן נחזה ש-y שווה 0 כל אימת שתטא משוחלפת כפול x קטנה מ-0.

51
00:04:04,980 --> 00:04:10,237
כדי לסכם את מה שעשינו עכשיו, ראינו שאם נחליט לחזות אם

52
00:04:10,237 --> 00:04:15,571
y = 1 או y = 0 לפי אם האומדן של ההסתברות גדול או

53
00:04:15,571 --> 00:04:21,064
שווה ל-0.5 או קטן מ-0.5, זה שקול לכך

54
00:04:21,064 --> 00:04:26,720
שאנו צופים ש-y = 1 כאשר תטא משוחלפת כפול x גדול או שווה ל-0.

55
00:04:26,720 --> 00:04:31,050
ואנו צופים ש-y שווה ל-0 בכל פעם שתטא משוחלפת כפול x קטן מ-0.

56
00:04:31,050 --> 00:04:35,320
בואו נשתמש בזה בכדי להבין יותר טוב

57
00:04:35,320 --> 00:04:40,090
כיצד מייצרת פונקצית ההשערה של רגרסיה לוגיסטית את הניבויים האלה.

58
00:04:40,090 --> 00:04:44,510
נניח שיש לנו סדרת אימון כמו זו המוצגת בשקופית.

59
00:04:44,510 --> 00:04:47,100
ונניח שההשערה היא

60
00:04:47,100 --> 00:04:51,860
ש-h של x שווה g של תטא אפס פלוס תטא אחת כפול x1 פלוס תטא שתיים כפול x2.

61
00:04:52,860 --> 00:04:56,740
לא דיברנו עדיין על איך מחשבים את הפרמטרים של המודל הזה.

62
00:04:56,740 --> 00:04:59,340
נדבר על זה בסרטון הבא.

63
00:04:59,340 --> 00:05:03,230
אבל נניח שבאמצעות איזה שהוא תהליך

64
00:05:03,230 --> 00:05:06,200
אנחנו בחרנו את הערכים הבאים עבור הפרמטרים.

65
00:05:06,200 --> 00:05:12,930
נניח שאנו בוחרים תטא-0 שווה 3, תטא-1 שווה 1, תטא-2 שווה 1.

66
00:05:12,930 --> 00:05:18,106
אז זה אומר שוקטור הפרמטרים שלנו הוא תטא

67
00:05:18,106 --> 00:05:23,011
שווה 3-, 1, 1.

68
00:05:24,110 --> 00:05:30,130
אז בהינתן הבחירה הזאת של פרמטרי ההשערה,

69
00:05:30,130 --> 00:05:35,550
בואו ננסה להבין איפה ההשערה בסופו של דבר מנבאת ש-y שווה לאחת

70
00:05:35,550 --> 00:05:37,980
ומתי היא מנבאת ש-y שווה לאפס.

71
00:05:39,170 --> 00:05:42,340
תוך שימוש בנוסחאות שסקרנו בשקופית

72
00:05:42,340 --> 00:05:46,960
הקודמת, אנו יודעים שההסתברות ש-y

73
00:05:46,960 --> 00:05:51,806
שווה לאחת גדולה או שווה ל-0.5

74
00:05:51,806 --> 00:05:57,230
אם תטא משוחלפת כפול x גדול מאפס.

75
00:05:57,230 --> 00:06:01,710
והנוסחא הזאת שכרגע הדגשתי, x1 + x2 - 3,

76
00:06:01,710 --> 00:06:06,560
היא, כמובן, תטא משוחלפת כפול x כאשר תטא

77
00:06:06,560 --> 00:06:11,160
שווה לווקטור הפרמטרים שאנחנו בדיוק בחרנו.

78
00:06:12,420 --> 00:06:16,900
אז עבור כל דוגמא, עבור כל דוגמא שיש לה תכונות x1

79
00:06:16,900 --> 00:06:20,100
ו-x2 כך שמתקיימת המשוואה הזאת,

80
00:06:20,100 --> 00:06:25,290
ש 3- ועוד x1 ועוד x2 גדול או שווה ל-0, ההשערה

81
00:06:25,290 --> 00:06:30,994
שלנו תנבא ש-y שווה 1 יותר סביר, או היא תנבא ש-y שווה 1.

82
00:06:32,460 --> 00:06:36,426
אנחנו יכולים גם להעביר את ה-3- ימינה

83
00:06:36,426 --> 00:06:41,055
ולשכתב את הנוסחה כ-x1 + x2 גדול או שווה 3,

84
00:06:41,055 --> 00:06:45,873
שזה שקול לקודם, ומצאנו שההשערה הזו תנבא

85
00:06:45,873 --> 00:06:50,329
y = 1 אם x1 + x2 גדול או שווה 3.

86
00:06:51,930 --> 00:06:56,816
בואו נראה מה זה אומר על הגרף, אם אני רושם את המשוואה

87
00:06:56,816 --> 00:07:03,510
X1 + X2 = 3, אז זוהי משוואה של קו ישר

88
00:07:03,510 --> 00:07:08,680
ואם אני מצייר איך הוא נראה, זה נותן קו

89
00:07:08,680 --> 00:07:13,699
שעובר ב-3 על ציר x1 ו-3 על ציר x2.

90
00:07:16,250 --> 00:07:19,930
ולכן האזור החיצוני כאן, החלק של המישור X1 X2

91
00:07:19,930 --> 00:07:24,650
שמתאים לאזור בו X1 ועוד X2 גדול או שווה ל-3,

92
00:07:24,650 --> 00:07:29,680
זה החלק הזה מימין, כל מה שמימין

93
00:07:29,680 --> 00:07:34,080
ומלמעלה לקו הסגול הזה שציירתי כאן.

94
00:07:34,080 --> 00:07:39,670
האזור שבו ההשערה שלנו צופה ש-y = 1, הוא האזור הזה,

95
00:07:39,670 --> 00:07:44,410
האזור הבאמת ענק הזה, חצי המרחב הזה בצד ימין למעלה.

96
00:07:44,410 --> 00:07:49,710
תנו לי רק לרשום את זה, אני אקרא לזה "אזור ה-y = 1".

97
00:07:49,710 --> 00:07:56,530
ולעומת זאת, באזור שבו x1 + x2 קטן מ-3,

98
00:07:56,530 --> 00:08:01,200
אנחנו צופים ש-y שווה ל-0.

99
00:08:01,200 --> 00:08:03,830
וזה מתאים לאזור הזה.

100
00:08:03,830 --> 00:08:06,638
ויש באמת חצי מישור,

101
00:08:06,638 --> 00:08:12,480
האזור הזה משמאל הוא האזור שבו ההשערה שלנו תהיה ש-y = 0.

102
00:08:12,480 --> 00:08:16,475
אני רוצה לתת שם לקו הזה, הקו הסגול הזה שציירתי.

103
00:08:16,475 --> 00:08:22,335
הקו הזה, כאן, נקרא סף ההחלטה.

104
00:08:24,570 --> 00:08:28,760
וקונקרטית, זה הקו הישר הזה, X1 + X2 שווה 3.

105
00:08:28,760 --> 00:08:33,830
זה מתאים לקבוצה הזו של נקודות, כך שזה תואם את האזור שבו h של

106
00:08:33,830 --> 00:08:40,350
x שווה בדיוק 0.5 וסף ההחלטה שהוא הקו הישר הזה,

107
00:08:40,350 --> 00:08:45,370
זה הקו שמפריד בין האזור בו נמצאת ההשערה שצופה ש-y שווה 1

108
00:08:45,370 --> 00:08:50,210
ובין האזור שבו ההשערה צופה ש-y שווה לאפס.

109
00:08:50,210 --> 00:08:55,940
וכדי שיהיה ברור, סף ההחלטה הוא תכונה של פונקציית ההשערה

110
00:08:57,470 --> 00:09:00,870
כולל הפרמטרים תטא-0, תטא-1 ותטא-2.

111
00:09:00,870 --> 00:09:03,280
וסימנתי בתוך הציור סדרת אימון,

112
00:09:03,280 --> 00:09:06,520
סדרת נתונים, לסייע להבנתנו.

113
00:09:06,520 --> 00:09:11,590
אבל גם בלי סדרת הנתונים, סף ההחלטה והאזור

114
00:09:11,590 --> 00:09:16,650
שבו אנו מנבאים ש-y = 1 מול האזור שבו y = 0, הם מאפיינים של ההשערה

115
00:09:16,650 --> 00:09:20,710
ושל הפרמטרים של ההשערה ולא תכונה של סדרת הנתונים.

116
00:09:22,190 --> 00:09:25,800
בהמשך, כמובן, נדבר על איך להתאים את וקטור הפרמטרים

117
00:09:25,800 --> 00:09:29,670
ואז נשתמש בסדרת האימון, נשתמש בנתונים שלנו

118
00:09:29,670 --> 00:09:32,510
כדי לקבוע את הערך של הפרמטרים.

119
00:09:32,510 --> 00:09:36,620
אבל ברגע שהחלטנו על ערכים מסוימים עבור הפרמטרים תטא-0, תטא-1

120
00:09:36,620 --> 00:09:41,700
ותטא-2 אז זה לחלוטין מגדיר את סף ההחלטה ואנחנו

121
00:09:41,700 --> 00:09:46,610
לא באמת צריכים לצייר סדרת אימון בכדי להתוות את סף ההחלטה.

122
00:09:49,500 --> 00:09:53,450
עכשיו בואו נסתכל על דוגמה מורכבת יותר, בה כהרגלנו

123
00:09:53,450 --> 00:09:58,920
צלבים מציינים דוגמאות חיוביות ומעגלים מציינים דוגמאות שליליות.

124
00:09:58,920 --> 00:10:00,760
בהינתן סדרת אימון כזו,

125
00:10:00,760 --> 00:10:04,441
איך אני יכול לגרום לרגרסיה לוגיסטית להתאים לנתונים האלה?

126
00:10:05,560 --> 00:10:08,540
מוקדם יותר כשדיברנו על רגרסיה פולינומית או

127
00:10:08,540 --> 00:10:11,920
על רגרסיה ליניארית, דיברנו על כך שאפשר

128
00:10:11,920 --> 00:10:15,650
להוסיף אברים של פולינומים מסדר גבוה יותר לתכונות.

129
00:10:15,650 --> 00:10:18,960
ואנחנו יכולים לעשות אותו הדבר עבור רגרסיה לוגיסטית.

130
00:10:18,960 --> 00:10:22,810
באופן קונקרטי, נניח שההשערה שלי נראית כמו זה, כאן

131
00:10:22,810 --> 00:10:27,760
הוספתי שתי כאילו-תכונות נוספות, x1 בריבוע ו-x2 בריבוע, לרשימת התכונות.

132
00:10:27,760 --> 00:10:31,550
אז עכשיו יש לנו חמישה פרמטרים, תטא-0 עד תטא-4.

133
00:10:32,810 --> 00:10:37,610
כמו שאמרתי קודם, אנחנו נדחה לסרטון הבא את הדיון על

134
00:10:37,610 --> 00:10:43,010
האופן בו ניתן לבחור באופן אוטומטי ערכים עבור הפרמטרים תטא-0 עד תטא-4.

135
00:10:43,010 --> 00:10:46,760
אבל נניח שבאמצעות התהליך שיפורט,

136
00:10:46,760 --> 00:10:51,890
בחרנו תטא-0 שווה 1-, תטא-1 שווה 0,

137
00:10:51,890 --> 00:10:58,090
תטא-2 שווה 0, תטא-3 שווה 1 ותטא-4 שווה 1.

138
00:10:59,470 --> 00:11:03,570
פירוש הדבר הוא שעם סט הפרמטרים המסוים הזה,

139
00:11:03,570 --> 00:11:08,100
סט הפרמטרים תטא נראה כך, 1-, 0, 0, 1, 1.

140
00:11:10,590 --> 00:11:14,543
אז כמו שהיסקנו בדיון הקודם שלנו, משמעות סט הפרמטרים הזה הוא שההשערה תחזה

141
00:11:14,543 --> 00:11:20,940
ש-y = 1 כאשר 1- + x1 בריבוע + x2 בריבוע גדול או שווה ל-0.

142
00:11:20,940 --> 00:11:26,380
זאת אומרת כאשר תטא משוחלפת כפול

143
00:11:26,380 --> 00:11:29,780
ערכי התכונות שלנו גדול או שווה לאפס.

144
00:11:29,780 --> 00:11:33,830
ואם אני לוקח את 1- ומעביר אותו לצד ימין,

145
00:11:33,830 --> 00:11:39,460
אנחנו מקבלים שההשערה שלנו צופה ש-y שווה ל-1

146
00:11:39,460 --> 00:11:44,480
כאשר x1 בריבוע פלוס x2 בריבוע גדול או שווה ל-1.

147
00:11:44,480 --> 00:11:47,310
אז איך נראה כאן סף ההחלטה?

148
00:11:47,310 --> 00:11:53,140
אז לו שרטטנו את העקומה עבור x1 בריבוע פלוס x2 בריבוע

149
00:11:53,140 --> 00:11:58,360
שווה 1, חלק מכם ודאי יזהו שזו המשוואה עבור

150
00:11:58,360 --> 00:12:04,140
מעגל עם רדיוס אחת סביב ראשית הצירים.

151
00:12:04,140 --> 00:12:06,790
אז זהו סף ההחלטה.

152
00:12:10,490 --> 00:12:14,900
כל מה שמחוץ למעגל, אנחנו נצפה ש-y = 1.

153
00:12:14,900 --> 00:12:19,300
אז זה האזור בו y שווה 1,

154
00:12:19,300 --> 00:12:22,810
ואנו צופים ש-y שווה 1,

155
00:12:22,810 --> 00:12:27,150
ואילו כאן בתוך המעגל זה האזור שבו אני צופים ש-y שווה ל -0.

156
00:12:27,150 --> 00:12:33,240
אז על ידי כך שהוספנו את הביטויים היותר מורכבים האלה, או הביטויים הפולינומיאליים האלה

157
00:12:33,240 --> 00:12:36,520
לסט התכונות שלנו, אנחנו יכולים לקבל ספי החלטה מורכבים יותר שלא רק

158
00:12:36,520 --> 00:12:39,540
מנסים להפריד בין הדוגמאות החיוביות והשליליות על ידי קו ישר,

159
00:12:39,540 --> 00:12:43,220
אלא הצלחנו לעשות סף החלטה מעגלי.

160
00:12:44,280 --> 00:12:49,230
שוב, סף ההחלטה הוא תכונה לא של סדרת האימון, אלא

161
00:12:49,230 --> 00:12:51,690
של פונקציית ההשערה עם הפרמטרים הספציפיים.

162
00:12:51,690 --> 00:12:55,400
אז כל עוד יש לנו וקטור הפרמטרים תטא,

163
00:12:55,400 --> 00:12:58,614
זה מגדיר את סף ההחלטה, שהוא המעגל.

164
00:12:58,614 --> 00:13:03,070
אבל סדרת האימון איננה מה שאנו משתמשים בו כדי להגדיר את סף ההחלטה.

165
00:13:03,070 --> 00:13:06,560
ניתן להשתמש בסדרת האימון כדי להתאים את וקטור הפרמטרים תטא.

166
00:13:06,560 --> 00:13:08,650
נדבר מאוחר יותר על איך עושים את זה.

167
00:13:08,650 --> 00:13:11,110
אבל ברגע שיש לך את הפרמטרים תטא,

168
00:13:11,110 --> 00:13:13,540
זה מה שמגדיר את סף ההחלטה.

169
00:13:14,650 --> 00:13:17,450
הרשו לי להחזיר את סדרת האימון רק לשם ויזואליזציה.

170
00:13:18,540 --> 00:13:21,260
ולבסוף הבה נסתכל על דוגמא יותר מורכבת.

171
00:13:22,350 --> 00:13:26,580
האם אנחנו יכולים גם להגדיר ספי החלטה עוד יותר מורכבים מזה?

172
00:13:26,580 --> 00:13:31,480
אם נוסיף ביטויים פולינומיים אפילו גבוהים יותר, דברים כמו

173
00:13:32,990 --> 00:13:37,810
X1 בריבוע, X1 בריבוע כפול X2, ו-X1 בריבוע כפול X2 בריבוע וכיוצא באלה.

174
00:13:37,810 --> 00:13:42,620
וביטויים כאלה מסדר גבוה, אז אפשר להראות שאפשר

175
00:13:42,620 --> 00:13:47,010
לקבל ספי החלטה מורכבים עוד יותר והרגרסיה יכולה לתת

176
00:13:47,010 --> 00:13:51,960
ספי החלטה שיכולים למשל להיות אליפסה כזו, או

177
00:13:51,960 --> 00:13:56,150
אולי עם הגדרה קצת שונה של פרמטרים אפשר לקבל

178
00:13:56,150 --> 00:14:00,720
סף החלטה שונה שעשוי אפילו להיראות כמו הצורה המוזרה כאן.

179
00:14:03,990 --> 00:14:08,391
ובדוגמאות עוד יותר מורכבות אפשר אולי גם לקבל ספי

180
00:14:08,391 --> 00:14:13,387
החלטה שייראו בצורות יותר מורכבות כמו זו שלכל מה בתוכה

181
00:14:13,387 --> 00:14:17,730
אנחנו צופים ש-y = 1 וכל מה שמחוץ לה אנחנו מנבאים ש-y = 0.

182
00:14:17,730 --> 00:14:23,100
אז עם תכונות פולינומיאליות מסדר גבוה אפשר לייצר ספי החלטה מאוד מורכבים.

183
00:14:23,100 --> 00:14:27,960
אז בעזרת ההדגמות האלה, אני מקווה שקיבלתם תחושה של אילו סוגים

184
00:14:27,960 --> 00:14:32,640
של פונקציות השערה נוכל לייצג באמצעות הייצוג שלנו

185
00:14:32,640 --> 00:14:33,570
עבור רגרסיה לוגיסטית.

186
00:14:34,930 --> 00:14:39,680
עכשיו כשאנחנו יודעים איך יכול (h(x להיראות, מה שאני רוצה לעשות בסרטון

187
00:14:39,680 --> 00:14:44,650
הבא זה לדבר על איך לבחור את סט הפרמטרים תטא באופן אוטומטי, כך

188
00:14:44,650 --> 00:14:48,690
שבהינתן סדרת אימון נוכל להתאים את הפרמטרים באופן אוטומטי לנתונים שלנו.