1
00:00:00,230 --> 00:00:04,080
이 비디오에서는 멀티클래스 분류 문제에 대해

2
00:00:04,080 --> 00:00:06,180
로지스틱 회귀를 어떻게 적용하는지에 대해 설명하겠습니다.

3
00:00:06,180 --> 00:00:10,134
특히 'one-vs-all'분류라고 불리는 알고리즘에 대해

4
00:00:10,134 --> 00:00:10,957
말씀드리고 싶습니다.

5
00:00:12,140 --> 00:00:13,980
멀티클래스, 결과값이 여러 개로 
분류되는 문제란 무엇일까요?

6
00:00:13,980 --> 00:00:15,970
몇 가지 예시입니다.

7
00:00:15,970 --> 00:00:20,111
학습 알고리즘이 여러분의 이메일을 
자동으로 여러 개의 폴더에 분리하는 경우 

8
00:00:20,111 --> 00:00:23,265
혹은 각 이메일에 태그를 
지정하는 경우를 가정해 봅시다.

9
00:00:23,265 --> 00:00:27,012
업무용 이메일, 친구 이메일, 
가족 이메일 및 취미 이메일에 대해

10
00:00:27,012 --> 00:00:31,504
각각 다른 폴더 또는 
다른 태그를 가지게 될 겁니다.

11
00:00:31,504 --> 00:00:38,260
그래서 우리는 이 상황을 
네 개의 클래스로 분류해

12
00:00:38,260 --> 00:00:43,771
각각 y = 1, 2, 3, 4라고 
할당할 수 있게 됩니다.

13
00:00:43,771 --> 00:00:46,920
또 다른 예를 들어 보죠. 
의학적 진단의 경우, 즉

14
00:00:46,920 --> 00:00:50,910
어떤 환자가 코가 아파서 병원에 왔을 때

15
00:00:50,910 --> 00:00:53,790
진단할 수 있는 선택지로는 우선 
병에 걸린 것이 아니라는 게 있죠.

16
00:00:53,790 --> 00:00:55,200
그걸 y = 1 이라 하겠습니다.

17
00:00:55,200 --> 00:00:56,801
아니면 감기에 걸렸을 수도 있겠죠. 
y = 2라 합시다.

18
00:00:56,801 --> 00:00:57,830
혹은 독감에 걸렸을 수도 
있습니다. (y = 3)

19
00:00:59,030 --> 00:01:02,700
마지막으로 세 번째 예를 들어 보겠습니다. 
기계 학습을 사용하여

20
00:01:02,700 --> 00:01:07,280
날씨를 분류하는 경우, 
날씨가 맑거나 흐리거나

21
00:01:07,280 --> 00:01:12,240
비가 오거나 눈이 내릴 지를 
결정할 수 있습니다. 즉 이러한 예시 안에서

22
00:01:12,240 --> 00:01:17,100
y = 1~3 이나 y = 1~4 와 같이 
y를 어떠한 작은 숫자로 취할 수 있으며

23
00:01:17,100 --> 00:01:20,640
이것이 바로 멀티클래스 분류 문제입니다.

24
00:01:20,640 --> 00:01:25,510
여기에서 y의 인덱스가 0, 1, 2, 3인지

25
00:01:25,510 --> 00:01:26,690
1, 2, 3, 4인지는 중요하지 않습니다.

26
00:01:26,690 --> 00:01:30,840
제 개인적으로는 0이 아니라 1부터 시작하여 
클래스를 인덱싱하는 경향이 있습니다만

27
00:01:30,840 --> 00:01:33,750
어느 쪽이든 우리는 결정만 하면 되고 
그것은 정말로 중요하지 않습니다.

28
00:01:33,750 --> 00:01:35,080
저번에 우리가 했던

29
00:01:35,080 --> 00:01:38,807
바이너리 분류 문제에서 
데이터의 집합은 이런 모양이었습니다.

30
00:01:38,807 --> 00:01:42,780
반면에 멀티클래스 분류 문제의 경우, 
데이터 집합은 다음과 같이

31
00:01:42,780 --> 00:01:48,400
세 개의 다른 기호를 사용하여 
서로 다른 세 개의 클래스로 표현됩니다.

32
00:01:48,400 --> 00:01:52,270
그래서 문제는, 주어진 데이터 집합이 
세 개의 클래스로 구성되어

33
00:01:52,270 --> 00:01:55,920
이게 한 클래스, 이게 두 번째 클래스,

34
00:01:55,920 --> 00:01:58,430
이게 세 번째 클래스라고 할 수 있겠죠.

35
00:01:58,430 --> 00:02:01,610
이 주어진 데이터에 학습 알고리즘을 
어떻게 적용 할 수 있을까요?

36
00:02:01,610 --> 00:02:05,630
우리는 이미 회귀를 사용하여 
두 개의 데이터로 분류하는 방법을 알고 있습니다.

37
00:02:05,630 --> 00:02:08,920
이 데이터 그룹 사이에 직선을 그어

38
00:02:08,920 --> 00:02:10,640
양의 클래스와 음의 클래스를 
구분할 수 있었죠.

39
00:02:10,640 --> 00:02:14,150
여기에서 이제 one-vs-all 분류라 불리는 
아이디어를 보여드릴 건데요

40
00:02:14,150 --> 00:02:18,650
그것을 사용해 같은 방식을 
멀티클래스 분류에도 적용 할 수 있습니다.

41
00:02:18,650 --> 00:02:21,570
one-vs-all 분류가 작동하는 
방법은 다음과 같습니다.

42
00:02:21,570 --> 00:02:25,810
이 분류는 one-vs-rest
라고 부를 때도 있어요.

43
00:02:25,810 --> 00:02:28,600
왼쪽에 보이는 것과 같은 
훈련 집합이 있다고 가정해 봅시다.

44
00:02:28,600 --> 00:02:33,120
여기에 세 개의 클래스가 있는데, 
△을 y = 1

45
00:02:33,120 --> 00:02:38,300
□을 y = 2, 
×를 y = 3이라 놓겠습니다.

46
00:02:38,300 --> 00:02:40,980
우리가 해야 할 일은 이 훈련 집합을

47
00:02:40,980 --> 00:02:44,850
세 가지로 나누어진 바이너리 
분류 문제로 바꾸는 것입니다.

48
00:02:44,850 --> 00:02:49,120
이것을 세 가지의 2종류 
분류 문제로 바꿀 것입니다.

49
00:02:49,120 --> 00:02:51,670
△ 클래스 1부터 시작합시다.

50
00:02:51,670 --> 00:02:56,530
여기에서 새롭게 가짜 훈련 집합 
○을 만들어

51
00:02:56,530 --> 00:02:59,080
클래스 2와 클래스 3을 배정해야 합니다.

52
00:02:59,080 --> 00:03:01,340
그리고 클래스 1을 양의 클래스로 배정합니다.

53
00:03:01,340 --> 00:03:05,090
오른쪽에 보이는 것과 같은 
새로운 훈련 집합을 만들고 싶기 때문에

54
00:03:05,090 --> 00:03:10,220
fitting을 위한 분류를 다음과 같이

55
00:03:10,220 --> 00:03:14,560
h _Θ ^(1) (x) 라고 하겠습니다.

56
00:03:14,560 --> 00:03:19,030
여기에서 △은 양의 예이고 
○은 음의 예이므로

57
00:03:19,030 --> 00:03:22,220
△에는 값 1이 할당되고

58
00:03:22,220 --> 00:03:25,280
○에는 0이 할당됩니다.

59
00:03:25,280 --> 00:03:29,920
그리고 이제 표준 로지스틱 
회귀 분류를 훈련시킬 것입니다.

60
00:03:29,920 --> 00:03:33,310
그러면 바이너리 분류에서 했던 것과 같이 
경계선이 그어지겠죠.

61
00:03:33,310 --> 00:03:33,810
알겠죠?

62
00:03:34,910 --> 00:03:38,570
이 위첨자는 클래스 1을 의미하므로

63
00:03:38,570 --> 00:03:40,960
클래스 1의 △에 대한 훈련을 하고 있습니다.

64
00:03:40,960 --> 00:03:42,530
다음으로 클래스 2에 대해서도 
똑같은 일을 할 겁니다.

65
00:03:42,530 --> 00:03:46,580
□을 가져 와서 양의 값을 할당하고

66
00:03:46,580 --> 00:03:50,470
나머지 모든 것들, 즉 △와 ×에 
음의 값을 할당하겠습니다.

67
00:03:50,470 --> 00:03:55,970
그리고 나서 우리는 두 번째 
로지스틱 회귀 분류를 fitting하고

68
00:03:55,970 --> 00:04:01,250
이것을 h _Θ ^(2) (x) 라고 
부르겠습니다. 여기서 위 첨자 2는 이 식이

69
00:04:01,250 --> 00:04:04,620
클래스 2에 대한 훈련을 하고 있음을 
나타내며, □을 양의 클래스로 취급합니다.

70
00:04:04,620 --> 00:04:07,840
그 결과 이런 경계선을 얻을 수 있겠죠.

71
00:04:07,840 --> 00:04:10,780
그리고 마지막으로, 세 번째 
클래스에서 똑같은 작업을 수행하고

72
00:04:10,780 --> 00:04:15,870
세 번째 분류 h(3)(x)을 fitting합니다.

73
00:04:15,870 --> 00:04:19,230
그 결과 ×에서도 경계선을 
결정할 수 있을 겁니다.

74
00:04:19,230 --> 00:04:21,280
이 경계선이 양의 값과 
음의 값을 나누게 됩니다.

75
00:04:22,870 --> 00:04:27,890
요약하자면, 우리가 한 것은 
세 가지의 분류를 fitting한 것입니다.

76
00:04:27,890 --> 00:04:29,446
즉 i = 1, 2, 3에 대해

77
00:04:29,446 --> 00:04:34,685
x^(i) 를 x_Θ에 fitting했습니다.

78
00:04:34,685 --> 00:04:39,600
그래서 y = i 이고 x가 매개 변수 Θ로 주어질

79
00:04:39,600 --> 00:04:41,630
확률이 얼마인지 추정하려고 합니다.

80
00:04:41,630 --> 00:04:44,050
맞지요? 여기 첫번째 예에서

81
00:04:44,050 --> 00:04:49,410
이 h는 삼각형을 인식하는 방법을 배웠습니다.

82
00:04:49,410 --> 00:04:52,460
그래서 △을 양의 클래스로 생각하고 있으므로

83
00:04:52,460 --> 00:04:56,530
x^(1)은 매개 변수 Θ에 대한 x가 주어졌을 때

84
00:04:56,530 --> 00:05:02,100
y=1일 확률을 추정하려고 합니다.

85
00:05:02,100 --> 00:05:07,020
여기에서도 비슷하게 이 h는 
□을 양의 클래스로 생각하므로

86
00:05:07,020 --> 00:05:10,780
y=2일 확률을 추정합니다. 
3의 경우도 같고요.

87
00:05:10,780 --> 00:05:13,170
그래서 여기 우리가 가진 세 개의 h는

88
00:05:13,170 --> 00:05:16,680
각각 세 클래스 중 하나를 인식해 
훈련하도록 되어 있습니다.

89
00:05:16,680 --> 00:05:19,890
요약하자면 우리가 한 것은

90
00:05:19,890 --> 00:05:24,260
세 개의 로지스틱 회귀 h(i)(x)를 훈련시켜서

91
00:05:24,260 --> 00:05:27,420
각각이 클래스 i에 대해 
y=i일 확률을 예측하도록 했습니다.

92
00:05:27,420 --> 00:05:31,540
마지막으로, 새로운 입력값 x가 주어진다면

93
00:05:31,540 --> 00:05:33,470
예측을 하기 위해서

94
00:05:33,470 --> 00:05:38,570
우리가 해야 할 작업은 그냥 세 개의 h를

95
00:05:38,570 --> 00:05:44,080
새로운 x에 대해 전부 돌려 보고 
최대값이 나온 클래스 i를 고르면 됩니다.

96
00:05:44,080 --> 00:05:46,470
기본적으로는 그냥 h를 고르면 되는데요

97
00:05:46,470 --> 00:05:50,520
세 개의 h 중 가장 신뢰도가 높고

98
00:05:50,520 --> 00:05:54,250
가장 열정적으로 "이것이 올바른 클래스다"
라고 말하는 것을 선택합니다ㅎㅎ

99
00:05:54,250 --> 00:05:57,930
가장 높은 확률을 주는 i 값이라면

100
00:05:57,930 --> 00:05:59,850
y가 그 값이라고 예측할 수 있겠죠.

101
00:06:02,690 --> 00:06:07,730
여기까지가 one-vs-all을 사용한 멀티 클래스 분류였고요,

102
00:06:07,730 --> 00:06:10,890
이 간단한 방법을 사용하면 이제 로지스틱 회귀를 사용하여

103
00:06:10,890 --> 00:06:14,620
다중 클래스 분류 문제도 해결할 수 있습니다.