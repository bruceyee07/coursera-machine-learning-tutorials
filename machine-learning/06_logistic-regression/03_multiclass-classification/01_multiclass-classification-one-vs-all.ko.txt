이 비디오에서는 멀티클래스 분류 문제에 대해 로지스틱 회귀를 어떻게 적용하는지에 대해 설명하겠습니다. 특히 'one-vs-all'분류라고 불리는 알고리즘에 대해 말씀드리고 싶습니다. 멀티클래스, 결과값이 여러 개로 
분류되는 문제란 무엇일까요? 몇 가지 예시입니다. 학습 알고리즘이 여러분의 이메일을 
자동으로 여러 개의 폴더에 분리하는 경우 혹은 각 이메일에 태그를 
지정하는 경우를 가정해 봅시다. 업무용 이메일, 친구 이메일, 
가족 이메일 및 취미 이메일에 대해 각각 다른 폴더 또는 
다른 태그를 가지게 될 겁니다. 그래서 우리는 이 상황을 
네 개의 클래스로 분류해 각각 y = 1, 2, 3, 4라고 
할당할 수 있게 됩니다. 또 다른 예를 들어 보죠. 
의학적 진단의 경우, 즉 어떤 환자가 코가 아파서 병원에 왔을 때 진단할 수 있는 선택지로는 우선 
병에 걸린 것이 아니라는 게 있죠. 그걸 y = 1 이라 하겠습니다. 아니면 감기에 걸렸을 수도 있겠죠. 
y = 2라 합시다. 혹은 독감에 걸렸을 수도 
있습니다. (y = 3) 마지막으로 세 번째 예를 들어 보겠습니다. 
기계 학습을 사용하여 날씨를 분류하는 경우, 
날씨가 맑거나 흐리거나 비가 오거나 눈이 내릴 지를 
결정할 수 있습니다. 즉 이러한 예시 안에서 y = 1~3 이나 y = 1~4 와 같이 
y를 어떠한 작은 숫자로 취할 수 있으며 이것이 바로 멀티클래스 분류 문제입니다. 여기에서 y의 인덱스가 0, 1, 2, 3인지 1, 2, 3, 4인지는 중요하지 않습니다. 제 개인적으로는 0이 아니라 1부터 시작하여 
클래스를 인덱싱하는 경향이 있습니다만 어느 쪽이든 우리는 결정만 하면 되고 
그것은 정말로 중요하지 않습니다. 저번에 우리가 했던 바이너리 분류 문제에서 
데이터의 집합은 이런 모양이었습니다. 반면에 멀티클래스 분류 문제의 경우, 
데이터 집합은 다음과 같이 세 개의 다른 기호를 사용하여 
서로 다른 세 개의 클래스로 표현됩니다. 그래서 문제는, 주어진 데이터 집합이 
세 개의 클래스로 구성되어 이게 한 클래스, 이게 두 번째 클래스, 이게 세 번째 클래스라고 할 수 있겠죠. 이 주어진 데이터에 학습 알고리즘을 
어떻게 적용 할 수 있을까요? 우리는 이미 회귀를 사용하여 
두 개의 데이터로 분류하는 방법을 알고 있습니다. 이 데이터 그룹 사이에 직선을 그어 양의 클래스와 음의 클래스를 
구분할 수 있었죠. 여기에서 이제 one-vs-all 분류라 불리는 
아이디어를 보여드릴 건데요 그것을 사용해 같은 방식을 
멀티클래스 분류에도 적용 할 수 있습니다. one-vs-all 분류가 작동하는 
방법은 다음과 같습니다. 이 분류는 one-vs-rest
라고 부를 때도 있어요. 왼쪽에 보이는 것과 같은 
훈련 집합이 있다고 가정해 봅시다. 여기에 세 개의 클래스가 있는데, 
△을 y = 1 □을 y = 2, 
×를 y = 3이라 놓겠습니다. 우리가 해야 할 일은 이 훈련 집합을 세 가지로 나누어진 바이너리 
분류 문제로 바꾸는 것입니다. 이것을 세 가지의 2종류 
분류 문제로 바꿀 것입니다. △ 클래스 1부터 시작합시다. 여기에서 새롭게 가짜 훈련 집합 
○을 만들어 클래스 2와 클래스 3을 배정해야 합니다. 그리고 클래스 1을 양의 클래스로 배정합니다. 오른쪽에 보이는 것과 같은 
새로운 훈련 집합을 만들고 싶기 때문에 fitting을 위한 분류를 다음과 같이 h _Θ ^(1) (x) 라고 하겠습니다. 여기에서 △은 양의 예이고 
○은 음의 예이므로 △에는 값 1이 할당되고 ○에는 0이 할당됩니다. 그리고 이제 표준 로지스틱 
회귀 분류를 훈련시킬 것입니다. 그러면 바이너리 분류에서 했던 것과 같이 
경계선이 그어지겠죠. 알겠죠? 이 위첨자는 클래스 1을 의미하므로 클래스 1의 △에 대한 훈련을 하고 있습니다. 다음으로 클래스 2에 대해서도 
똑같은 일을 할 겁니다. □을 가져 와서 양의 값을 할당하고 나머지 모든 것들, 즉 △와 ×에 
음의 값을 할당하겠습니다. 그리고 나서 우리는 두 번째 
로지스틱 회귀 분류를 fitting하고 이것을 h _Θ ^(2) (x) 라고 
부르겠습니다. 여기서 위 첨자 2는 이 식이 클래스 2에 대한 훈련을 하고 있음을 
나타내며, □을 양의 클래스로 취급합니다. 그 결과 이런 경계선을 얻을 수 있겠죠. 그리고 마지막으로, 세 번째 
클래스에서 똑같은 작업을 수행하고 세 번째 분류 h(3)(x)을 fitting합니다. 그 결과 ×에서도 경계선을 
결정할 수 있을 겁니다. 이 경계선이 양의 값과 
음의 값을 나누게 됩니다. 요약하자면, 우리가 한 것은 
세 가지의 분류를 fitting한 것입니다. 즉 i = 1, 2, 3에 대해 x^(i) 를 x_Θ에 fitting했습니다. 그래서 y = i 이고 x가 매개 변수 Θ로 주어질 확률이 얼마인지 추정하려고 합니다. 맞지요? 여기 첫번째 예에서 이 h는 삼각형을 인식하는 방법을 배웠습니다. 그래서 △을 양의 클래스로 생각하고 있으므로 x^(1)은 매개 변수 Θ에 대한 x가 주어졌을 때 y=1일 확률을 추정하려고 합니다. 여기에서도 비슷하게 이 h는 
□을 양의 클래스로 생각하므로 y=2일 확률을 추정합니다. 
3의 경우도 같고요. 그래서 여기 우리가 가진 세 개의 h는 각각 세 클래스 중 하나를 인식해 
훈련하도록 되어 있습니다. 요약하자면 우리가 한 것은 세 개의 로지스틱 회귀 h(i)(x)를 훈련시켜서 각각이 클래스 i에 대해 
y=i일 확률을 예측하도록 했습니다. 마지막으로, 새로운 입력값 x가 주어진다면 예측을 하기 위해서 우리가 해야 할 작업은 그냥 세 개의 h를 새로운 x에 대해 전부 돌려 보고 
최대값이 나온 클래스 i를 고르면 됩니다. 기본적으로는 그냥 h를 고르면 되는데요 세 개의 h 중 가장 신뢰도가 높고 가장 열정적으로 "이것이 올바른 클래스다"
라고 말하는 것을 선택합니다ㅎㅎ 가장 높은 확률을 주는 i 값이라면 y가 그 값이라고 예측할 수 있겠죠. 여기까지가 one-vs-all을 사용한 멀티 클래스 분류였고요, 이 간단한 방법을 사용하면 이제 로지스틱 회귀를 사용하여 다중 클래스 분류 문제도 해결할 수 있습니다.