1
00:00:00,300 --> 00:00:01,680
בהרצאה הקודמת דיברנו

2
00:00:01,990 --> 00:00:03,920
על ירידה במדרון למזעור

3
00:00:04,440 --> 00:00:06,700
פונקציית העלות J של תטא עבור רגרסיה לוגיסטית.

4
00:00:07,800 --> 00:00:08,930
בהרצאה הזו, אני רוצה

5
00:00:09,020 --> 00:00:10,250
לספר לכם על כמה אלגוריתמים

6
00:00:10,850 --> 00:00:12,340
מתקדמים לאופטימיזציה ועל כמה

7
00:00:12,670 --> 00:00:14,060
מושגים מתקדמים לאופטימיזציה.

8
00:00:15,180 --> 00:00:16,480
באמצעות כמה מהרעיונות האלה,

9
00:00:16,630 --> 00:00:17,930
נוכל לגרום לרגרסיה לוגיסטית

10
00:00:19,010 --> 00:00:20,220
לרוץ הרבה יותר מהר ממה

11
00:00:20,350 --> 00:00:21,970
שזה אפשרי עם ירידה במדרון.

12
00:00:22,880 --> 00:00:24,190
וזה גם יאפשר לאלגוריתם

13
00:00:24,320 --> 00:00:26,060
לעבוד בקנה מידה גדול הרבה יותר

14
00:00:26,670 --> 00:00:28,030
ולטפל בבעיות למידה חישובית גדולות,

15
00:00:28,660 --> 00:00:30,950
לדוגמא עם מספר גדול מאוד של תכונות או מאפיינים.

16
00:00:31,850 --> 00:00:33,360
הנה תצוגה אלטרנטיבית של

17
00:00:33,750 --> 00:00:34,910
פעולת הירידה במדרון.

18
00:00:35,590 --> 00:00:38,030
יש לנו איזו פונקצית עלות J ואנחנו רוצים למזער אותה.

19
00:00:38,950 --> 00:00:39,980
אז מה שאנחנו צריכים

20
00:00:40,340 --> 00:00:41,080
הוא, אנחנו צריכים לכתוב

21
00:00:41,330 --> 00:00:42,640
קוד שמקבל

22
00:00:42,850 --> 00:00:44,980
כקלט את הפרמטרים תטא

23
00:00:45,200 --> 00:00:46,470
ומחשב שני דברים: J

24
00:00:46,700 --> 00:00:48,190
של תטא ואת הנגזרות

25
00:00:48,620 --> 00:00:50,280
החלקיות, אתה יודע,

26
00:00:50,530 --> 00:00:51,820
של J שווה 0, 1

27
00:00:51,890 --> 00:00:53,700
עד n. בהינתן קוד

28
00:00:53,830 --> 00:00:54,980
שיכול לעשות את שני אלה, מה

29
00:00:55,160 --> 00:00:56,710
שעושה הירידה במדרון הוא שהיא

30
00:00:56,790 --> 00:00:58,620
מריצה את זה שוב ושוב ומבצעת את השלב הבא.

31
00:00:59,100 --> 00:00:59,100
נכון?

32
00:00:59,280 --> 00:01:00,500
אז בהינתן הקוד

33
00:01:00,670 --> 00:01:01,750
שכתבנו כדי לחשב את הנגזרות

34
00:01:02,090 --> 00:01:03,800
החלקיות האלה, הירידה במדרון מציבה

35
00:01:04,480 --> 00:01:07,330
כאן את הקוד ומשתמשת בזה כדי לעדכן את סט הפרמטרים שלנו תטא.

36
00:01:08,650 --> 00:01:09,590
אז דרך נוספת לחשוב

37
00:01:09,910 --> 00:01:11,070
על ירידה במדרון היא

38
00:01:11,350 --> 00:01:12,670
שאנחנו צריכים לספק קוד כדי

39
00:01:12,810 --> 00:01:14,050
לחשב את J של תטא

40
00:01:14,230 --> 00:01:15,700
ואת הנגזרות האלה, ואז

41
00:01:15,900 --> 00:01:16,930
מציבים אותם בירידה

42
00:01:17,370 --> 00:01:20,110
במדרון, שיכולה אז לנסות למזער את הפונקציה עבורנו.

43
00:01:20,970 --> 00:01:21,970
עבור ירידה במדרון, אני מניח

44
00:01:22,480 --> 00:01:23,790
שמבחינה טכנית לא באמת צריך קוד

45
00:01:24,170 --> 00:01:26,520
כדי לחשב את פונקציית העלות J של תטא.

46
00:01:26,940 --> 00:01:28,980
צריכים רק קוד לחשב את הנגזרות החלקיות.

47
00:01:29,740 --> 00:01:30,480
אבל אם תחשבו על

48
00:01:30,590 --> 00:01:32,300
הקוד כקוד שצריך גם לנטר את ההתכנסות

49
00:01:33,000 --> 00:01:34,060
של האלגוריתם,

50
00:01:34,190 --> 00:01:35,440
אז פשוט נחשוב

51
00:01:35,530 --> 00:01:37,380
שבעצם אנחנו אמורים לספק קוד

52
00:01:37,510 --> 00:01:38,530
לחשב הן את פונקציית

53
00:01:38,890 --> 00:01:40,250
העלות והן את הנגזרות.

54
00:01:42,700 --> 00:01:44,130
אז לאחר כתיבת קוד

55
00:01:44,280 --> 00:01:45,860
לחשב את שני הדברים האלה,

56
00:01:46,090 --> 00:01:47,820
אלגוריתם אחד בו אפשר להשתמש הוא ירידה במדרון.

57
00:01:48,910 --> 00:01:51,590
אבל ירידה במדרון אינה האלגוריתם היחיד שאנו יכולים להשתמש בו.

58
00:01:52,280 --> 00:01:53,690
ויש אלגוריתמים אחרים,

59
00:01:54,330 --> 00:01:55,930
מתקדמים יותר, מתוחכמים יותר,

60
00:01:56,720 --> 00:01:57,880
שאם רק נותנים

61
00:01:58,400 --> 00:01:59,520
להם דרך לחשב

62
00:01:59,960 --> 00:02:01,550
את שני הדברים האלה, אז אלה

63
00:02:01,760 --> 00:02:03,040
הן גישות שונות כדי למצוא את

64
00:02:03,490 --> 00:02:04,790
פונקציית העלות האופטימלית עבורנו.

65
00:02:05,110 --> 00:02:07,910
"מדרון מוטה" או "מדרון מכוון" (בו הנגזרת שבה מטפלים גורמת להטית שאר האלמנטים), BFGS

66
00:02:08,110 --> 00:02:09,240
וגם L-BFGS, הם דוגמאות של אלגוריתמים

67
00:02:09,460 --> 00:02:11,490
יותר מתוחכמים לאופטימיזציה

68
00:02:11,640 --> 00:02:12,610
שצריכים דרך לחשב את J

69
00:02:12,810 --> 00:02:13,670
של תטא

70
00:02:13,750 --> 00:02:15,430
ואת הנגזרות, ויכולים

71
00:02:15,670 --> 00:02:16,940
להשתמש באסטרטגיות מתוחכמות

72
00:02:17,620 --> 00:02:19,880
יותר מאשר ירידה במדרון כדי למזער את פונקצית העלות.

73
00:02:21,260 --> 00:02:22,560
הפרטים המדויקים

74
00:02:22,780 --> 00:02:25,920
של שלושת האלגוריתמים האלה הם הרבה מעבר להיקף של קורס זה.

75
00:02:26,490 --> 00:02:28,200
ולמעשה אנשים

76
00:02:28,650 --> 00:02:30,570
מבלים ימים רבים,

77
00:02:31,060 --> 00:02:32,670
או מספר שבועות בלימוד האלגוריתמים האלה

78
00:02:33,240 --> 00:02:35,840
כאשר לוקחים קורס באנליזה נומרית מתקדמת.

79
00:02:36,920 --> 00:02:38,200
אבל הרשו לי לספר לך קצת על כמה מהתכונות שלהם.

80
00:02:40,080 --> 00:02:42,150
לשלושת האלגוריתמים האלה יש מספר יתרונות.

81
00:02:42,900 --> 00:02:44,070
אחד היתרונות הוא

82
00:02:44,290 --> 00:02:45,850
שבכל אחד מהם אין צורך

83
00:02:46,000 --> 00:02:48,970
לבחור ידנית את שיעור הלמידה אלפא.

84
00:02:50,670 --> 00:02:51,450
אז אחת הדרכים לחשוב

85
00:02:51,650 --> 00:02:53,630
על האלגוריתמים האלה היא שבהינתן

86
00:02:54,230 --> 00:02:56,900
דרך לחשב את הנגזרת ואת פונקציה העלות

87
00:02:57,320 --> 00:02:59,740
אתה יכול לחשוב על האלגוריתמים כאילו יש להם לולאה פנימית חכמה.

88
00:03:00,060 --> 00:03:00,680
ולמעשה, יש להם לולאה

89
00:03:01,810 --> 00:03:03,780
פנימית חכמה הנקראת אלגוריתם

90
00:03:04,200 --> 00:03:05,840
חיפוש קו שמנסה באופן אוטומטי

91
00:03:06,520 --> 00:03:08,010
ערכים שונים עבור

92
00:03:08,080 --> 00:03:09,360
שיעור הלימוד אלפא ובוחרת

93
00:03:10,010 --> 00:03:11,090
באופן אוטומטי שיעור למידה אלפא טוב,

94
00:03:12,030 --> 00:03:12,900
והם אפילו יכולים לבחור

95
00:03:13,130 --> 00:03:14,570
שיעור למידה שונה עבור כל איטרציה.

96
00:03:15,490 --> 00:03:18,230
אז אתה לא צריך לבחור את זה בעצמך.

97
00:03:21,430 --> 00:03:22,770
האלגוריתמים האלה למעשה עושים

98
00:03:22,910 --> 00:03:24,260
דברים מתוחכמים יותר מאשר פשוט

99
00:03:24,470 --> 00:03:25,640
לבחור שיעור למידה טוב,

100
00:03:25,800 --> 00:03:27,300
ולכן הם מצליחים

101
00:03:27,490 --> 00:03:30,320
להתכנס הרבה יותר מהר מאשר ירידה במדרון.

102
00:03:32,470 --> 00:03:33,740
האלגוריתמים האלה למעשה עושים עוד

103
00:03:33,980 --> 00:03:35,160
דברים מתוחכמים חוץ מאשר רק

104
00:03:35,360 --> 00:03:36,740
לבחור שיעור למידה טוב,

105
00:03:36,880 --> 00:03:38,770
ולכן הם בסופו של דבר מתכנסים הרבה

106
00:03:39,020 --> 00:03:40,840
יותר מהר מהירידה במדרון, אבל

107
00:03:41,040 --> 00:03:42,230
דיון מפורט על כל

108
00:03:42,710 --> 00:03:44,420
מה שהם בדיוק עושים הוא מעבר להיקף של הקורס הזה.

109
00:03:45,580 --> 00:03:47,060
למעשה, אני השתמשתי

110
00:03:47,570 --> 00:03:49,020
באלגוריתמים האלה

111
00:03:49,170 --> 00:03:50,170
במשך זמן רב, אולי

112
00:03:50,470 --> 00:03:53,070
עשר שנים, לעתים קרובות למדי, וזה

113
00:03:53,290 --> 00:03:54,410
היה רק לפני

114
00:03:54,510 --> 00:03:55,460
כמה שנים, שאני באמת

115
00:03:56,150 --> 00:03:57,200
הבנתי בעצמי את הפרטים של

116
00:03:57,780 --> 00:04:00,220
מה עושים האלגוריתמים האלה, המדרון המוטה, BFGS ו- L-BFGS.

117
00:04:00,980 --> 00:04:02,740
אז זה אפשרי לחלוטין

118
00:04:03,560 --> 00:04:05,380
להשתמש באלגוריתמים האלה בהצלחה

119
00:04:05,480 --> 00:04:06,530
וליישם אותם על הרבה בעיות למידה

120
00:04:06,780 --> 00:04:08,490
שונות מבלי להבין למעשה

121
00:04:09,460 --> 00:04:11,140
את הלולאה הפנימית שהאלגוריתמים האלה מבצעים.

122
00:04:12,270 --> 00:04:13,630
אם יש לאלגוריתמים האלה חסרון,

123
00:04:14,200 --> 00:04:15,350
הייתי אומר שהחיסרון

124
00:04:15,610 --> 00:04:16,970
העיקרי הוא שהם

125
00:04:17,110 --> 00:04:19,390
הרבה יותר מסובכים מאשר ירידה במדרון.

126
00:04:20,180 --> 00:04:21,700
ולמעשה, כנראה לא כדאי

127
00:04:21,970 --> 00:04:23,290
לך ליישם את האלגוריתמים האלה -

128
00:04:23,850 --> 00:04:26,060
המדרון המוטה, BGFS ו- L-BFGS -

129
00:04:26,360 --> 00:04:29,520
בעצמך, אלא אם כן אתה מומחה בתחום החישוב הנומרי.

130
00:04:30,720 --> 00:04:32,320
במקום זאת, בדיוק כפי

131
00:04:32,420 --> 00:04:33,640
שלא הייתי ממליץ לכם לכתוב

132
00:04:33,850 --> 00:04:35,240
בעצמכם קוד לחשב שורשים

133
00:04:35,590 --> 00:04:36,660
ריבועיים של מספרים או

134
00:04:36,770 --> 00:04:39,010
לחשב את ההופכי של מטריצות,

135
00:04:39,140 --> 00:04:40,600
גם לגבי האלגוריתמים האלה מה שהייתי

136
00:04:40,710 --> 00:04:42,530
ממליץ לכם לעשות הוא פשוט להשתמש בספריית תוכנה.

137
00:04:43,030 --> 00:04:43,770
כמו שכדי להוציא שורש

138
00:04:44,120 --> 00:04:44,940
מרובע מה שכולנו

139
00:04:45,150 --> 00:04:46,440
עושים הוא להשתמש בפונקציה

140
00:04:47,080 --> 00:04:48,310
שמישהו אחר

141
00:04:48,530 --> 00:04:50,200
כתב כדי לחשב שורשים ריבועיים של מספרים.

142
00:04:51,330 --> 00:04:53,530
ולמרבה המזל, באוקטבה

143
00:04:53,760 --> 00:04:55,070
ובשפה הקשורה קשר הדוק MATLAB -

144
00:04:55,430 --> 00:04:57,110
ונשתמש גם בה -

145
00:04:57,140 --> 00:04:58,370
באוקטבה יש ספריה טובה מאד,

146
00:04:58,530 --> 00:05:02,410
ספרייה סבירה למדי ליישום של האלגוריתמים המתקדמים האלה לאופטימיזציה.

147
00:05:03,380 --> 00:05:04,350
אז אם פשוט תשתמשו

148
00:05:04,600 --> 00:05:06,800
בספרייה הקיימת, תקבלו תוצאות די טובות.

149
00:05:08,010 --> 00:05:08,880
אני חייב לומר שיש

150
00:05:09,370 --> 00:05:10,880
הבדל בין יישומים

151
00:05:11,230 --> 00:05:12,740
טובים ופחות טובים של האלגוריתמים האלה.

152
00:05:13,690 --> 00:05:15,010
אז אם אתם משתמשים

153
00:05:15,120 --> 00:05:16,270
בשפה אחרת עבור יישום

154
00:05:16,470 --> 00:05:17,560
הלמידה החישובית שלכם, אם אתם משתמשים

155
00:05:18,190 --> 00:05:20,090
ב- C, C++, Java,

156
00:05:20,250 --> 00:05:24,060
וכן הלאה,

157
00:05:24,210 --> 00:05:24,710
מומלץ לנסות כמה

158
00:05:24,730 --> 00:05:25,660
ספריות שונות כדי לוודא שאתם מוצאים

159
00:05:25,740 --> 00:05:27,790
ספריה טובה ליישום האלגוריתמים הללו.

160
00:05:28,250 --> 00:05:29,410
כי יש הבדל

161
00:05:29,480 --> 00:05:30,740
בביצועים בין יישום טוב

162
00:05:31,680 --> 00:05:33,150
של, לדוגמא, מדרון מוטה או

163
00:05:33,530 --> 00:05:35,150
L-PFGS לעומת יישום טוב

164
00:05:35,350 --> 00:05:37,680
פחות של מדרון מוטה או L-PFGS.

165
00:05:43,060 --> 00:05:44,310
אז עכשיו בואו נבין איך

166
00:05:44,580 --> 00:05:47,080
להשתמש באלגוריתמים האלה, ואני הולך לעשות זאת עם דוגמה.

167
00:05:48,970 --> 00:05:50,220
נניח שיש לך

168
00:05:50,370 --> 00:05:51,620
בעיה עם שני פרמטרים,

169
00:05:53,380 --> 00:05:55,580
תטא-1 ותטא-2.

170
00:05:56,410 --> 00:05:57,450
ונניח שפונקצית העלות שלך

171
00:05:57,970 --> 00:05:59,210
היא J של תטא שווה

172
00:05:59,430 --> 00:06:01,540
תטא-1 מינוס 5 בריבוע ועוד תטא-2 מינוס 5 בריבוע.

173
00:06:02,630 --> 00:06:04,080
אז עם פונקצית העלות הזו,

174
00:06:04,590 --> 00:06:06,960
הערך עבור תטא-1 ותטא-2,

175
00:06:07,080 --> 00:06:09,590
אם אתה רוצה למזער את J של תטא כפונקציה של תטא.

176
00:06:09,940 --> 00:06:10,910
הערך שממזער את זה

177
00:06:11,030 --> 00:06:12,040
יהיה תטא-1 שווה 5,

178
00:06:12,420 --> 00:06:14,220
תטא-2 שווה 5.

179
00:06:15,230 --> 00:06:16,620
עכשיו, שוב, אני יודע שחלק

180
00:06:16,950 --> 00:06:18,320
מכם יודעים יותר חשבון דיפרנציאלי מאחרים,

181
00:06:19,010 --> 00:06:20,770
אבל הנגזרות של

182
00:06:20,850 --> 00:06:23,420
פונקציית העלות J מתברר שהם שני הביטויים האלה.

183
00:06:24,270 --> 00:06:25,060
עשיתי את החישוב.

184
00:06:26,260 --> 00:06:27,250
אז אם אתה רוצה ליישם

185
00:06:27,480 --> 00:06:29,220
את אחד האלגוריתמים המתקדמים לאופטימיזציה

186
00:06:29,810 --> 00:06:31,380
כדי למזער את פונקצית העלות J.

187
00:06:31,660 --> 00:06:32,630
אז לולא

188
00:06:32,880 --> 00:06:34,680
ידענו שהמינימום הוא

189
00:06:34,780 --> 00:06:36,140
ב-5,5, אבל אם אתה רוצה

190
00:06:36,240 --> 00:06:37,550
שפונקציה העלות תמצא את המינימום

191
00:06:37,970 --> 00:06:39,840
בצורה נומרית באמצעות משהו כמו

192
00:06:40,040 --> 00:06:41,560
ירידה במדרון אבל עדיף משהו

193
00:06:41,730 --> 00:06:43,430
יותר מתקדם מאשר ירידה במדרון, מה

194
00:06:43,550 --> 00:06:45,010
שהיית עושה הוא ליישם פונקציה

195
00:06:45,570 --> 00:06:46,690
כזו באוקטבה, אז

196
00:06:46,860 --> 00:06:48,190
ניישם פונקציית עלות,

197
00:06:49,210 --> 00:06:51,180
פונקציית עלות שהיא פונקציה של תטא כמו זו,

198
00:06:52,180 --> 00:06:53,250
ומה שזה עושה

199
00:06:53,380 --> 00:06:55,660
הוא מחזיר שני איברים,

200
00:06:55,760 --> 00:06:57,780
הראשון, jVal,

201
00:06:58,910 --> 00:07:00,020
מגדיר איך אנחנו מחשבים את פונקציית העלות

202
00:07:00,680 --> 00:07:01,780
J. אז זה פשוט נותן כאן את הפונקציה

203
00:07:02,080 --> 00:07:03,210
jVal שהיא כמו שאמרנו

204
00:07:03,440 --> 00:07:04,630
תטא-1 מינוס 5 בריבוע ועוד

205
00:07:05,330 --> 00:07:06,230
תטא-2 מינוס 5 בריבוע.

206
00:07:06,540 --> 00:07:09,140
אז זו פשוט ההגדרה של פונקצית המחיר שלנו.

207
00:07:10,540 --> 00:07:12,040
והארגומנט השני

208
00:07:12,260 --> 00:07:14,190
שהפונקציה מחזירה הוא הגרדיינט.

209
00:07:14,840 --> 00:07:16,030
והגרדיינט הוא

210
00:07:16,160 --> 00:07:17,320
וקטור של 2 על 1,

211
00:07:18,870 --> 00:07:20,050
ושני האיברים

212
00:07:20,120 --> 00:07:22,100
בוקטור הגרדיינט מתאימים

213
00:07:22,800 --> 00:07:24,670
לשתי הנגזרות החלקיות כאן.

214
00:07:27,150 --> 00:07:28,570
אחרי שמממשים את פונקצית העלות הזו,

215
00:07:29,580 --> 00:07:30,390
אפשר אז

216
00:07:31,510 --> 00:07:33,010
לקרוא לפונקצית האופטימיזציה

217
00:07:34,270 --> 00:07:35,720
המתקדמת שנקראת fminunc -

218
00:07:35,950 --> 00:07:36,900
שפרושו פונקצית (f)

219
00:07:37,610 --> 00:07:39,360
מינימום (min) בלתי מאולצת (unc) באוקטבה,

220
00:07:40,300 --> 00:07:41,520
והדרך לקרוא לפונקציה היא זו.

221
00:07:41,790 --> 00:07:42,350
אתה קובע כמה אופציות.

222
00:07:43,230 --> 00:07:43,580
הפרמטר הזה, אופציות,

223
00:07:44,330 --> 00:07:46,680
הוא מבנה נתונים בו מאחסנים את האופציות הרצויות.

224
00:07:47,320 --> 00:07:48,960
הפרמטר הראשון, GradObj, עם ערך "on"

225
00:07:49,160 --> 00:07:52,100
מדליק את האופציה שנקראת "מטרת הגרדיינט" למצב "דלוק".

226
00:07:52,270 --> 00:07:55,180
משמעו של הפרמטר הוא שאנו נספק וקטור גרדיינט לפונקציה.

227
00:07:56,150 --> 00:07:57,550
הפרמטר השני מחליט לעצור את הריצה

228
00:07:57,840 --> 00:07:59,280
אחרי לכל היותר 100 איטרציות.

229
00:07:59,580 --> 00:08:02,230
הפונקציה גם מקבלת ערך או ניחוש ראשוני עבור תטא,

230
00:08:02,720 --> 00:08:03,680
שהוא וקטור של 2 על 1

231
00:08:04,440 --> 00:08:06,860
והפקודה הזו קוראת לפונקצית ה-fminunc.

232
00:08:07,530 --> 00:08:10,290
הסימן @ מסמן

233
00:08:10,420 --> 00:08:11,810
מצביע לפונקצית המחיר

234
00:08:13,010 --> 00:08:14,320
שהגדרנו למעלה.

235
00:08:15,060 --> 00:08:16,020
וכשקוראים לפונקציה הזו

236
00:08:16,270 --> 00:08:18,290
היא תחשב, תשתמש

237
00:08:18,620 --> 00:08:20,490
באחד מאלגוריתמימי האופטימיזציה המתקדמים יותר.

238
00:08:21,110 --> 00:08:23,350
ואם אתם רוצים, חשבו על זה בדיוק כמו ירידה במדרון.

239
00:08:23,690 --> 00:08:25,170
אבל כזו שבוחרת באופן אוטומטי את קצב

240
00:08:25,500 --> 00:08:27,290
הלמידה אלפא כך שלא תצטרכו לעשות זאת בעצמכם.

241
00:08:28,210 --> 00:08:29,880
אלא היא תנסה

242
00:08:30,160 --> 00:08:32,000
להשתמש בסוג של אלגוריתמי אופטימיזציה מתקדמים.

243
00:08:32,640 --> 00:08:33,770
זה ירוץ כמו ירידה במדרון על סטרואידים,

244
00:08:34,400 --> 00:08:36,490
כדי לנסות למצוא את הערך האופטימלי של תטא.

245
00:08:37,180 --> 00:08:39,040
הרשו לי להראות לכם איך זה נראה באוקטבה.

246
00:08:40,690 --> 00:08:42,460
אז כתבתי את פונקציית העלות

247
00:08:42,900 --> 00:08:46,440
של תטא בדיוק כמו שראינו מקודם.

248
00:08:46,650 --> 00:08:49,070
היא מחשבת את jVal שהיא פונקציית העלות.

249
00:08:49,920 --> 00:08:51,810
והיא מחשבת את הגרדיינט

250
00:08:52,040 --> 00:08:53,050
עם שני האיברים שהם הנגזרות

251
00:08:53,450 --> 00:08:54,430
החלקיות של פונקציית העלות

252
00:08:55,220 --> 00:08:56,200
ביחס

253
00:08:56,360 --> 00:08:57,910
לשני הפרמטרים, תטא-1 ותטא-2.

254
00:08:59,040 --> 00:09:00,360
עכשיו בואו נעבור לחלון אוקטבה שלי.

255
00:09:00,710 --> 00:09:02,900
אני הולך להקליד את הפקודות שבדיוק דיברנו עליהן.

256
00:09:03,470 --> 00:09:05,850
options = optimset....

257
00:09:06,630 --> 00:09:08,510
זו הגדרת האופציות

258
00:09:09,670 --> 00:09:11,190
עם אותם ערכים כמו שדיברנו

259
00:09:11,710 --> 00:09:13,850
לאלגוריתם. GradObj הוא on, ונגביל את maxIter ל-100

260
00:09:14,130 --> 00:09:17,600
דהיינו עד 100

261
00:09:18,310 --> 00:09:19,610
איטרציות, ואני

262
00:09:19,730 --> 00:09:22,090
מספק את הגרדיינט לאלגוריתם.

263
00:09:23,490 --> 00:09:27,190
בואו נציב בתטא הראשוני שלנו 0 בתטא-1 ובתטא-2.

264
00:09:27,980 --> 00:09:29,280
זה ה"ניחוש" הראשוני שלנו עבור תטא.

265
00:09:30,500 --> 00:09:31,390
ועכשיו אני קורא לפונקציה שמחזירה וקטור של תטא אופטימלי,

266
00:09:32,620 --> 00:09:35,100
ערך הפונקציה, קוד יציאה

267
00:09:37,610 --> 00:09:39,430
קורא לפונקציה fminunc עם

268
00:09:40,570 --> 00:09:41,600
מצביע לפונקצית המחיר,

269
00:09:43,010 --> 00:09:44,700
שולח את הניחוש הראשוני

270
00:09:46,090 --> 00:09:49,060
ואת האופציות.

271
00:09:49,820 --> 00:09:52,760
וכשאני מקיש <Enter> זה מריץ את הפונקציה.

272
00:09:53,940 --> 00:09:54,810
והיא חוזרת די מהר.

273
00:09:55,790 --> 00:09:57,040
הקשקוש על הפרומפט שלי

274
00:09:57,430 --> 00:09:58,430
הוא בגלל איזו

275
00:09:59,700 --> 00:10:00,290
גלישה של הפקודה שהיקשתי,

276
00:10:00,680 --> 00:10:02,540
פשוט היתה גלישה

277
00:10:02,760 --> 00:10:04,890
ושורת הפקודה התחרבשה קצת.

278
00:10:05,490 --> 00:10:06,290
אבל מה שזה אומר הוא

279
00:10:06,550 --> 00:10:08,500
שהריצה של הפונקציה, תחשבו

280
00:10:08,670 --> 00:10:10,400
עליה כעל ירידה במדרון

281
00:10:10,440 --> 00:10:11,620
על סטרואידים, מצאה את הערך האופטימלי של

282
00:10:11,760 --> 00:10:13,150
תטא והוא תטא-1

283
00:10:13,400 --> 00:10:15,670
שווה 5, תטה-2 שווה 5, בדיוק כפי שקיוינו שתמצא.

284
00:10:16,520 --> 00:10:18,760
ערך הפונקציה

285
00:10:18,840 --> 00:10:21,430
באופטימום חושב כ-10 בחזקת מינוס 30.

286
00:10:21,670 --> 00:10:23,160
שזה בעצם אפס, וזה

287
00:10:23,370 --> 00:10:24,760
גם מה שקיוינו.

288
00:10:24,840 --> 00:10:27,060
וקוד היציאה הוא

289
00:10:27,240 --> 00:10:29,080
1, והוא מסמן

290
00:10:29,730 --> 00:10:31,400
מה מצב ההתכנסות של הפונקציה.

291
00:10:31,800 --> 00:10:33,010
ואם אתם רוצים תריצו את הפקודה

292
00:10:33,150 --> 00:10:35,020
help fminunc

293
00:10:35,130 --> 00:10:36,480
ותקראו את התיעוד של כיצד

294
00:10:36,680 --> 00:10:38,650
לפרש את קוד היציאה.

295
00:10:38,760 --> 00:10:41,600
אבל קוד היציאה מאפשר לך לברר האם האלגוריתם התכנס או לא.

296
00:10:43,960 --> 00:10:46,450
אז ככה מפעילים את האלגוריתמים האלה באוקטבה.

297
00:10:47,480 --> 00:10:48,920
אני צריך לציין, דרך אגב,

298
00:10:48,940 --> 00:10:51,020
כי עבור היישום באוקטבה, הערך הזה

299
00:10:51,640 --> 00:10:53,010
של תטה, הפרמטר שהוא הוקטור

300
00:10:53,370 --> 00:10:54,940
תטא, חייב להיות

301
00:10:55,280 --> 00:10:58,210
במרחב R עם ממד גדול או שווה 2.

302
00:10:58,450 --> 00:11:00,330
אז אם תטא הוא פשוט מספר ממשי.

303
00:11:00,770 --> 00:11:02,040
אם הוא לא לפחות

304
00:11:02,160 --> 00:11:03,160
וקטור דו מימדי

305
00:11:03,800 --> 00:11:04,860
או בעל ממד גבוה יותר מ-2,

306
00:11:05,160 --> 00:11:06,840
פונקצית fminunc

307
00:11:07,560 --> 00:11:08,760
לא תוכל לעבוד, אז אם

308
00:11:09,140 --> 00:11:10,310
במקרה יש לך

309
00:11:10,590 --> 00:11:11,590
פונקציה חד מימדית שאתה צריך

310
00:11:11,830 --> 00:11:12,930
לייעל - לעשות לה אופטימיזציה, תראה

311
00:11:13,100 --> 00:11:14,680
את התיעוד באוקטבה של הפונקציה fminunc

312
00:11:14,950 --> 00:11:16,230
לפרטים נוספים.

313
00:11:18,230 --> 00:11:19,360
אז כך אנחנו מייעלים

314
00:11:19,620 --> 00:11:21,640
את הדוגמה הקטנה

315
00:11:22,190 --> 00:11:23,810
של פונקצית העלות הריבועית הפשוטה שלנו.

316
00:11:24,440 --> 00:11:26,520
איך אנחנו יכולים ליישם את זה לרגרסיה לוגיסטית?

317
00:11:27,720 --> 00:11:29,270
ברגרסיה לוגיסטית יש לנו

318
00:11:29,520 --> 00:11:31,290
וקטור פרמטרים תטא,

319
00:11:31,430 --> 00:11:32,210
ואני עומד להשתמש בתערובת

320
00:11:32,620 --> 00:11:34,880
של סימונים מאוקטבה וממתמטיקה.

321
00:11:35,300 --> 00:11:36,400
אבל אני מקווה שההסבר הזה

322
00:11:36,870 --> 00:11:38,050
יהיה ברור, אבל וקטור

323
00:11:38,520 --> 00:11:40,360
הפרמטרים תטא כולל

324
00:11:40,540 --> 00:11:41,780
את הפרמטרים תטא-0 עד

325
00:11:42,210 --> 00:11:44,230
תטא-n, ובגלל האינדקסים של אוקטבה,

326
00:11:46,090 --> 00:11:48,040
בה וקטורים מתחילים באינדקס

327
00:11:48,460 --> 00:11:49,640
1, תטא-0 למעשה

328
00:11:49,710 --> 00:11:51,190
נכתב תטא-1

329
00:11:51,330 --> 00:11:53,290
באוקטבה, תטא-1 נכתב

330
00:11:53,930 --> 00:11:54,690
כתטא-2 ותטא-n

331
00:11:55,280 --> 00:11:56,180
באוקטבה נכתב

332
00:11:56,780 --> 00:11:58,430
כתטא-n+1, נכון?

333
00:11:58,610 --> 00:12:00,650
וזאת מאחר שהאינדקסים באוקטבה

334
00:12:01,320 --> 00:12:03,070
בוקטורים מתחילים מאינדקס

335
00:12:03,430 --> 00:12:05,200
1 ולא מאינדקס 0.

336
00:12:06,920 --> 00:12:07,950
אז מה שאנחנו צריכים

337
00:12:08,160 --> 00:12:09,670
לעשות הוא לכתוב

338
00:12:09,880 --> 00:12:12,070
פונקצית עלות שמממשת

339
00:12:12,710 --> 00:12:14,210
את פונקצית העלות עבור רגרסיה לוגיסטית.

340
00:12:15,170 --> 00:12:16,450
באופן קונקרטי, פונקציית העלות

341
00:12:16,880 --> 00:12:18,310
צריכה להחזיר jVal, שהוא, כידוע, jVal

342
00:12:18,940 --> 00:12:20,430
כפי שצריך לקודד אותו כדי

343
00:12:20,640 --> 00:12:22,440
לחשב את J של תטא

344
00:12:22,710 --> 00:12:24,010
ואנחנו גם צריכים לתת לה את הגרדיינט.

345
00:12:24,540 --> 00:12:25,460
אז, גרדיינט 1 יהיה

346
00:12:25,920 --> 00:12:27,080
קוד לחישוב

347
00:12:27,280 --> 00:12:29,100
הנגזרת החלקית ביחס

348
00:12:29,390 --> 00:12:31,250
לתטא-0, הנגזרת החלקית

349
00:12:31,600 --> 00:12:34,300
הבאה עבור תטא-1 וכן הלאה.

350
00:12:34,770 --> 00:12:36,260
שוב, זה גרדיינט 0, גרדיינט

351
00:12:37,500 --> 00:12:38,390
1 ,גרדיינט 2 וכן הלאה,

352
00:12:39,030 --> 00:12:40,330
ולא גרדיינט 0, גרדיינט 1

353
00:12:40,500 --> 00:12:42,730
כי באוקטבה האינדקסים

354
00:12:43,460 --> 00:12:46,200
של וקטורים מתחילים מ-1 ולא מ-0.

355
00:12:47,440 --> 00:12:48,460
אבל הרעיון המרכזי שאני מקווה

356
00:12:48,690 --> 00:12:49,540
שאתם מבינים מהשקופית הזו

357
00:12:49,900 --> 00:12:50,870
הוא, כי מה שעליכם לעשות,

358
00:12:51,070 --> 00:12:54,370
הוא לכתוב פונקציה המחזירה

359
00:12:55,500 --> 00:12:56,930
את העלות ואת הגרדיינט.

360
00:12:58,410 --> 00:12:59,750
אז כדי

361
00:12:59,960 --> 00:13:01,410
ליישם את זה ברגרסיה לוגיסטית

362
00:13:02,100 --> 00:13:03,430
או אפילו ברגרסיה ליניארית, אם

363
00:13:03,560 --> 00:13:06,230
תרצו להשתמש באלגוריתמי האופטימיזציה האלה עבור רגרסיה ליניארית.

364
00:13:07,340 --> 00:13:08,350
מה שצריך לעשות הוא לתקוע כאן

365
00:13:08,500 --> 00:13:09,960
את הקוד המתאים כדי לחשב

366
00:13:10,820 --> 00:13:12,280
את הדברים האלה שכאן.

367
00:13:15,100 --> 00:13:17,910
אז עכשיו אתם יודעים איך להשתמש באלגוריתמי האופטימיזציה המתקדמים האלה.

368
00:13:19,030 --> 00:13:21,170
מאחר ובאלגוריתמים

369
00:13:21,320 --> 00:13:22,660
האלה משתמשים

370
00:13:22,870 --> 00:13:25,190
בספריית אופטימיזציה מתוחכמת, זה עושה

371
00:13:25,690 --> 00:13:26,710
את הקוד קצת

372
00:13:26,940 --> 00:13:28,510
פחות שקוף ולכן

373
00:13:28,740 --> 00:13:30,390
קצת יותר קשה לנפות (לדבג) אותו.

374
00:13:31,290 --> 00:13:32,660
אבל בגלל שהאלגוריתמים האלה לעתים קרובות

375
00:13:33,010 --> 00:13:34,370
רצים הרבה יותר מהר מאשר הירידה במדרון,

376
00:13:35,010 --> 00:13:36,760
לעתים קרובות למדי, או בכל פעם

377
00:13:37,060 --> 00:13:38,180
שיש לי בעיה גדולה של למידה

378
00:13:38,410 --> 00:13:39,500
חישובית, אני אשתמש

379
00:13:39,760 --> 00:13:42,110
באלגוריתמים האלה במקום להשתמש בירידה במדרון.

380
00:13:43,900 --> 00:13:45,070
ועם הרעיונות האלה, אני מקווה,

381
00:13:45,450 --> 00:13:46,710
תוכל לגרום לרגרסיה לוגיסטית

382
00:13:47,350 --> 00:13:48,780
וגם לרגרסיה ליניארית להצליח לפעול

383
00:13:49,100 --> 00:13:51,410
בבעיות הרבה יותר גדולות.

384
00:13:51,830 --> 00:13:53,820
אז, זהו זה בקשר למושגים של אופטימיזציה מתקדמת.

385
00:13:55,120 --> 00:13:56,170
בסרטון הבא

386
00:13:56,320 --> 00:13:57,720
והאחרון על רגרסיה לוגיסטית,

387
00:13:58,550 --> 00:13:59,470
אני רוצה לתאר איך

388
00:13:59,600 --> 00:14:00,990
לוקחים את אלגוריתם הרגרסיה הלוגיסטית

389
00:14:01,520 --> 00:14:02,790
שאתם כבר מכירים, ולגרום לו

390
00:14:02,990 --> 00:14:05,420
לעבוד גם על בעיות סיווג רבות מחלקות.