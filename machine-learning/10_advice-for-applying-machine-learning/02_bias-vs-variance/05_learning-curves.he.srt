1
00:00:00,090 --> 00:00:02,040
בסרטון זה, אני רוצה לספר לכם על עקומות למידה.

2
00:00:03,310 --> 00:00:05,850
עקומות למידה הם דבר שלעתים קרובות מאוד שימושי לשרטט אותן.

3
00:00:06,710 --> 00:00:08,170
אם אתה רוצה בדיקה מהירה

4
00:00:08,430 --> 00:00:09,590
שהאלגוריתם שלך עובד כראוי,

5
00:00:10,400 --> 00:00:12,730
או אם אתה רוצה לשפר את הביצועים של האלגוריתם.

6
00:00:13,950 --> 00:00:15,200
עקומות למידה הוא

7
00:00:15,310 --> 00:00:16,410
כלי שאני באמת משתמש בו

8
00:00:16,820 --> 00:00:17,920
לעתים קרובות מאוד כדי לנסות

9
00:00:18,290 --> 00:00:20,030
לאבחן אם אלגוריתם הלמידה שלי אכן

10
00:00:20,180 --> 00:00:23,220
סובל מבעיית הטייה, שונות או גם מזה וגם מזה.

11
00:00:27,170 --> 00:00:28,070
אז מהי עקומת למידה.

12
00:00:28,830 --> 00:00:30,550
כדי לשרטט עקומת למידה, מה

13
00:00:30,700 --> 00:00:31,760
שאני בדרך כלל עושה הוא לשרטט

14
00:00:32,210 --> 00:00:33,950
את J-אימון שהוא, למשל,

15
00:00:35,030 --> 00:00:36,050
הממוצע של ריבוע השגיאה על סט

16
00:00:36,440 --> 00:00:39,090
האימון שלי או J-cv שהוא

17
00:00:39,340 --> 00:00:41,130
הממוצע של ריבוע השגיאה על סט האימות הצולב שלי.

18
00:00:41,590 --> 00:00:42,900
ואני משרטט

19
00:00:43,140 --> 00:00:44,160
את זה כפונקציה

20
00:00:44,500 --> 00:00:46,380
של m, כפונקציה

21
00:00:47,230 --> 00:00:51,260
של מספר דוגמאות ההכשרה שיש לי.

22
00:00:51,950 --> 00:00:53,420
אז m הוא בדרך כלל קבוע כמו לדוגמא אולי יש לי 100

23
00:00:53,650 --> 00:00:55,220
דוגמאות אימון, אבל מה שאני

24
00:00:55,330 --> 00:00:57,670
עושה הוא שאני מקטין

25
00:00:57,860 --> 00:00:59,280
באופן מלאכותי את גודל סדרת האימון שלי. אז אני

26
00:00:59,500 --> 00:01:01,460
מגביל את עצמי בכוונה להשתמש רק,

27
00:01:01,840 --> 00:01:03,440
למשל, ב-10 או 20 או

28
00:01:03,660 --> 00:01:06,040
30 או 40 דוגמאות הכשרה

29
00:01:06,170 --> 00:01:07,610
ומשרטט את שגיאת האימון

30
00:01:07,740 --> 00:01:09,640
ואת שגיאת האימות עבור

31
00:01:10,040 --> 00:01:12,260
הקבוצה המוקטנת הזו של דוגמאות. אז

32
00:01:12,620 --> 00:01:14,090
בואו נראה איך נראים הגרפים האלה.

33
00:01:14,270 --> 00:01:15,530
נניח שיש לי רק

34
00:01:15,730 --> 00:01:17,210
דוגמת אימון אחת כמו זו

35
00:01:17,390 --> 00:01:18,450
שמופיעה בדוגמה הראשונה כאן,

36
00:01:18,860 --> 00:01:19,970
ונניח שאני מתאים לה פונקציה ריבועית. אז

37
00:01:22,470 --> 00:01:24,490
יש לי רק דוגמת הכשרה אחת. אז

38
00:01:25,040 --> 00:01:26,100
ברור שאני יכול לעשות כאן התאמה מושלמת,

39
00:01:26,650 --> 00:01:28,590
נכון? אתם מבינים, פשוט להתאים לה פונקציה ריבועית. אז

40
00:01:28,760 --> 00:01:30,000
תהיה לי שגיאה של

41
00:01:30,150 --> 00:01:32,240
0 על דוגמת האימון האחת הזו. מה אם יש

42
00:01:32,570 --> 00:01:34,170
לי שתי דוגמאות הכשרה. ובכן, גם כאן אפשר להתאים בצורה מושלמת פונקציה ריבועית.

43
00:01:37,050 --> 00:01:38,550
וגם אם אני משתמש בהסדרה,

44
00:01:38,750 --> 00:01:40,220
אני יכול כנראה להתאים אותה די טוב.

45
00:01:41,080 --> 00:01:41,970
ואם אני לא משתמש בהסדרה,

46
00:01:42,030 --> 00:01:45,200
אז נוכל לקבל התאמה מושלמת.

47
00:01:45,440 --> 00:01:46,400
ואם יש לי שלוש דוגמאות הכשרה,

48
00:01:47,260 --> 00:01:48,380
שוב, כן, אפשר להתאים להן פונקציה

49
00:01:48,660 --> 00:01:51,320
ריבועית בצורה מושלמת. אז אם

50
00:01:51,550 --> 00:01:52,590
m שווה 1 או m שווה ל-2 או m שווה 3,

51
00:01:54,850 --> 00:01:56,770
שגיאת האימון שלי

52
00:01:57,350 --> 00:01:58,870
על קבוצת האימון

53
00:01:59,110 --> 00:02:01,180
תהיה 0 אם אני

54
00:02:01,220 --> 00:02:02,760
לא משתמש בהסדרה או שהיא יכולה

55
00:02:03,150 --> 00:02:04,290
להיות מעט גדולה מ-0 אם

56
00:02:04,560 --> 00:02:06,400
אני כן משתמש בהסדרה,

57
00:02:06,500 --> 00:02:07,350
ודרך אגב גם אם יש לי

58
00:02:07,740 --> 00:02:08,980
קבוצת אימון גדולה ואני מגביל

59
00:02:09,940 --> 00:02:11,040
באופן מלאכותי את הגודל

60
00:02:11,120 --> 00:02:13,080
שלה כדי לשרטט את J-אימון.

61
00:02:13,830 --> 00:02:14,770
כאן אם אני קובע

62
00:02:15,110 --> 00:02:16,720
m שווה 3, נניח, ואני

63
00:02:17,040 --> 00:02:18,290
מאמן רק על שלוש דוגמאות,

64
00:02:19,270 --> 00:02:21,030
אז עבור הגרף הזה אני

65
00:02:21,110 --> 00:02:22,430
אמדוד את שגיאת האימון

66
00:02:22,830 --> 00:02:24,450
רק על שלוש הדוגמאות

67
00:02:24,550 --> 00:02:25,580
שלמעשה התאמתי את הפונקציה אליהן,

68
00:02:27,150 --> 00:02:28,130
וכך גם אם יש לי

69
00:02:28,290 --> 00:02:31,160
100 דוגמאות אימון, אבל כשאני משרטט את

70
00:02:31,430 --> 00:02:32,620
שגיאת האימון על m שווה 3, מה שאני אעשה

71
00:02:34,270 --> 00:02:35,200
הוא למדוד את

72
00:02:35,340 --> 00:02:36,660
שגיאת האימון רק על

73
00:02:36,750 --> 00:02:39,870
שלוש הדוגמאות שאליהם התאמתי את ההשערה שלי,

74
00:02:41,290 --> 00:02:42,900
ולא את כל הדוגמאות האחרות

75
00:02:43,010 --> 00:02:44,940
שהשמטתי בכוונה מתהליך

76
00:02:45,140 --> 00:02:46,750
ההכשרה. אז רק כדי לסכם, מה

77
00:02:46,960 --> 00:02:48,460
שראינו הוא שאם גודל קבוצת האימון

78
00:02:48,820 --> 00:02:50,560
הוא קטן אז

79
00:02:50,630 --> 00:02:52,630
שגיאת האימון גם היא תהיה קטנה.

80
00:02:52,960 --> 00:02:53,900
כי כמובן, כשיש לנו

81
00:02:53,930 --> 00:02:55,150
קבוצת אימון קטנה

82
00:02:55,350 --> 00:02:56,790
אז יהיה קל מאוד

83
00:02:56,900 --> 00:02:58,080
להתאים את קבוצת האימון

84
00:02:58,720 --> 00:02:59,490
בצורה טובה מאוד או אולי אפילו

85
00:02:59,790 --> 00:03:02,970
בצורה מושלמת. עכשיו

86
00:03:03,190 --> 00:03:04,460
בואו נחשוב על m שווה 4 למשל. ובכן,

87
00:03:04,680 --> 00:03:06,800
כאן פונקציה ריבועית כבר

88
00:03:06,920 --> 00:03:07,900
לא יכולה להיות מתאימה מאד

89
00:03:08,100 --> 00:03:09,680
לנתונים, ואם

90
00:03:09,790 --> 00:03:11,350
m שווה 5 אז

91
00:03:11,460 --> 00:03:13,830
אולי פונקציה ריבועית תהיה איכשהוא מתאימה לנתונים,

92
00:03:14,090 --> 00:03:15,940
אבל ככל שקבוצת האימון נהיית יותר גדולה,

93
00:03:16,980 --> 00:03:18,460
זה הופך להיות קשה יותר ויותר

94
00:03:18,620 --> 00:03:19,860
להבטיח שנוכל

95
00:03:20,060 --> 00:03:21,820
למצוא פונקציה ריבועית שתתאים

96
00:03:21,960 --> 00:03:25,460
לכל הדוגמאות שלנו בצורה מושלמת.

97
00:03:25,840 --> 00:03:27,300
אז למעשה כשקבוצת האימון

98
00:03:27,690 --> 00:03:28,770
גדלה, מה שאנחנו מוצאים

99
00:03:29,300 --> 00:03:30,960
הוא שהממוצע של שגיאת האימון

100
00:03:31,310 --> 00:03:33,080
למעשה גדל, אז אם נשרטט

101
00:03:33,500 --> 00:03:34,650
את הגרף הזה מה שאתה מוצא

102
00:03:35,220 --> 00:03:36,860
הוא שהשגיאה של סדרת האימון,

103
00:03:37,130 --> 00:03:38,520
ממוצע השגיאה על

104
00:03:38,940 --> 00:03:40,660
ההשערה, גדל

105
00:03:41,300 --> 00:03:44,730
כש-m גדל ופשוט לחזור על זה, האינטואיציה היא כי כאשר

106
00:03:45,020 --> 00:03:46,200
m הוא קטן, כאשר יש לך

107
00:03:46,500 --> 00:03:48,070
מעט דוגמאות אימון, זה די

108
00:03:48,350 --> 00:03:49,420
קל להתאים כל אחת

109
00:03:49,790 --> 00:03:51,350
מדוגמאות האימון שלך באופן מושלם,

110
00:03:51,610 --> 00:03:52,840
ולכן שגיאת האימון שלך

111
00:03:52,940 --> 00:03:54,540
תהיה קטנה, ואילו

112
00:03:54,710 --> 00:03:56,100
כאשר m גדול אז

113
00:03:56,460 --> 00:03:57,900
זה נהיה יותר קשה להתאים

114
00:03:58,220 --> 00:03:59,900
התאמה מושלמת לכל דוגמאות האימון

115
00:04:00,430 --> 00:04:01,830
ולכן שגיאת האימון

116
00:04:02,370 --> 00:04:05,840
גדלה. עכשיו, מה בקשר לשגיאת האימות הצולב?

117
00:04:06,720 --> 00:04:08,460
ובכן, שגיאת האימות הצולב היא

118
00:04:08,590 --> 00:04:10,100
השגיאה על קבוצת

119
00:04:10,350 --> 00:04:12,660
האימות שעדיין לא נכנסו למשוואה,

120
00:04:12,880 --> 00:04:14,600
אז כאשר יש לנו

121
00:04:14,720 --> 00:04:15,900
קבוצה אימון קטנה מאוד, היא

122
00:04:16,080 --> 00:04:16,890
בוודאי לא תתן לנו הכללה טובה, ולכן היא

123
00:04:17,020 --> 00:04:19,610
לא תיתן ביצועים טובים על קבוצות אחרות,

124
00:04:19,850 --> 00:04:21,220
אז ההשערה הזו כאן לא

125
00:04:21,620 --> 00:04:22,720
תהיה טובה במיוחד,

126
00:04:23,020 --> 00:04:23,970
ורק כאשר אנחנו

127
00:04:24,050 --> 00:04:25,270
משתמשים בקבוצת אימון גדולה יותר,

128
00:04:25,500 --> 00:04:26,380
נתחיל לקבל

129
00:04:26,890 --> 00:04:28,100
השערות שאולי מתאימות

130
00:04:28,480 --> 00:04:30,810
לנתונים של קבוצת האימות קצת יותר טוב.

131
00:04:31,380 --> 00:04:32,050
אז גם שגיאת האימות

132
00:04:32,260 --> 00:04:35,650
וגם שגיאת המבחן נוטות

133
00:04:35,890 --> 00:04:37,160
לרדת כאשר מגדילים

134
00:04:37,470 --> 00:04:39,150
את קבוצת האימון כי

135
00:04:39,250 --> 00:04:40,700
ככל שיש יותר נתונים, כך נקבל

136
00:04:40,990 --> 00:04:43,410
השערות יותר טובות בהכללות לדוגמאות חדשות.

137
00:04:44,010 --> 00:04:46,730
כמה שיותר נתונים יש לך, יותר טובה ההשערה שאתה מתאים.

138
00:04:47,560 --> 00:04:48,560
אז אם אתה משרטט את J-אימון

139
00:04:49,420 --> 00:04:51,670
ואת J-cv אתה תקבל מין דבר כזה.

140
00:04:52,490 --> 00:04:53,550
עכשיו בואו נסתכל איך

141
00:04:53,770 --> 00:04:54,940
נראים עקומות הלמידה

142
00:04:55,360 --> 00:04:56,550
אם יש לנו או בעית

143
00:04:56,930 --> 00:04:58,210
הטיה גבוהה או בעית שונות גבוהה.

144
00:04:58,920 --> 00:05:00,530
נניח שלהשערה שלנו יש הטיה

145
00:05:00,830 --> 00:05:02,150
גבוהה, וכדי להסביר את זה

146
00:05:02,370 --> 00:05:03,780
אני הולך להשתמש

147
00:05:03,940 --> 00:05:05,250
בדוגמא של התאמת קו

148
00:05:05,440 --> 00:05:06,500
ישר לנתונים, אתם מבינים,

149
00:05:06,770 --> 00:05:08,240
לא ממש יכולה להיות התאמה טובה כשההשערה היא קו ישר.

150
00:05:09,540 --> 00:05:12,330
אז יש לנו השערה שאולי נראית כך.

151
00:05:13,910 --> 00:05:15,450
עכשיו בואו נחשוב מה

152
00:05:15,750 --> 00:05:16,840
יקרה אם נגדיל

153
00:05:17,470 --> 00:05:18,880
את קבוצת האימון או ההכשרה. אז אם

154
00:05:19,160 --> 00:05:20,480
במקום חמש דוגמאות כמו

155
00:05:20,590 --> 00:05:22,400
שציירתי כאן, דמיינו

156
00:05:22,570 --> 00:05:24,080
שיש לנו הרבה יותר דוגמאות הכשרה.

157
00:05:25,280 --> 00:05:27,230
אז מה קורה, אם אנחנו מתאימים את הקו הישר הזה.

158
00:05:27,980 --> 00:05:29,700
מה שנגלה הוא שבעצם

159
00:05:30,040 --> 00:05:31,360
יהיה לנו פחות או יותר אותו קו ישר.

160
00:05:31,690 --> 00:05:32,940
והרי ברור שהקו הזה

161
00:05:33,530 --> 00:05:35,110
פשוט לא יכול להתאים

162
00:05:35,270 --> 00:05:37,320
טוב לנתונים וגם אם יהיו לנו טונות של נתונים נוספים,

163
00:05:37,890 --> 00:05:39,460
הקו הישר הזה לא ישתנה הרבה.

164
00:05:40,230 --> 00:05:41,400
זה הקו הישר הכי טוב

165
00:05:41,840 --> 00:05:42,770
האפשרי להתאים לנתונים, אבל

166
00:05:42,890 --> 00:05:44,160
קו ישר פשוט לא יכול להתאים

167
00:05:44,320 --> 00:05:45,630
היטב לערכת הנתונים שלנו. אז

168
00:05:45,870 --> 00:05:47,420
אם נשרטט את שגיאת האימות,

169
00:05:49,260 --> 00:05:50,170
היא תיראה כך.

170
00:05:51,320 --> 00:05:54,470
כאן למעלה משמאל, אם יש לנו כבר גודל מינימלי של סדרת אימון כמו

171
00:05:55,410 --> 00:05:57,710
לדוגמא אולי רק דוגמת אימון אחת וזה בוודאי לא ייתן התאמה טובה,

172
00:05:58,550 --> 00:05:59,470
אבל כשהגענו

173
00:05:59,660 --> 00:06:00,760
למספר מסוים של דוגמאות

174
00:06:00,940 --> 00:06:02,350
אימון, אנחנו נגיע כבר

175
00:06:02,810 --> 00:06:04,010
כמעט לקו הישר הטוב ביותר

176
00:06:04,200 --> 00:06:05,400
האפשרי מבחינת ההתאמה, וגם אם

177
00:06:05,490 --> 00:06:06,260
בסופו של דבר נקבל קבוצת אימון

178
00:06:06,480 --> 00:06:07,790
הרבה יותר גדולה,

179
00:06:07,970 --> 00:06:09,170
ערך הרבה יותר גדול של m,

180
00:06:10,010 --> 00:06:12,040
בעצם נקבל מחדש את אותו קו ישר,

181
00:06:12,370 --> 00:06:14,190
וכך, שגיאת האימות -

182
00:06:14,480 --> 00:06:15,420
תרשו לי לסמן את זה בתווית -

183
00:06:15,650 --> 00:06:17,040
וגם שגיאת קבוצת המבחן,

184
00:06:17,140 --> 00:06:18,660
תשתטח או ישתטחו

185
00:06:18,990 --> 00:06:20,480
די מהר, לאחר שהגענו

186
00:06:20,910 --> 00:06:22,920
מעבר למספר מסוים

187
00:06:23,270 --> 00:06:24,700
של דוגמאות הכשרה, מפני

188
00:06:25,130 --> 00:06:27,480
שדי מהר אנחנו נתאים את הקו הישר הטוב ביותר האפשרי.

189
00:06:28,390 --> 00:06:29,540
ומה לגבי שגיאת האימון?

190
00:06:30,120 --> 00:06:33,050
ובכן, שגיאת האימון תהיה קטנה כש-m קטן.

191
00:06:34,620 --> 00:06:36,280
ומה שנראה

192
00:06:36,760 --> 00:06:38,080
במקרה של הטיה גבוהה הוא

193
00:06:38,210 --> 00:06:40,770
ששגיאת האימון תתקרב

194
00:06:41,000 --> 00:06:42,510
מאד לשגיאת האימות

195
00:06:42,830 --> 00:06:44,700
הצולב, כי יש לנו

196
00:06:44,810 --> 00:06:46,370
כל כך מעט פרמטרים וכל כך

197
00:06:46,590 --> 00:06:48,070
הרבה נתונים, לפחות כאשר m הוא גדול,

198
00:06:48,900 --> 00:06:49,840
אז הביצועים של הפונקציה על מערך

199
00:06:50,220 --> 00:06:52,500
ההכשרה ועל מערך האימות הצולב יהיו דומים מאוד.

200
00:06:53,800 --> 00:06:54,750
אז כך נראית

201
00:06:54,870 --> 00:06:56,460
עקומת למידה

202
00:06:56,770 --> 00:06:58,850
אם יש לנו אלגוריתם בעל הטיה גבוהה.

203
00:07:00,220 --> 00:07:01,470
ולבסוף, הבעיה עם

204
00:07:01,630 --> 00:07:03,260
הטיה גבוהה משתקפת גם

205
00:07:03,450 --> 00:07:04,930
בעובדה שהן

206
00:07:05,580 --> 00:07:07,350
שגיאת האימות והן

207
00:07:07,420 --> 00:07:09,130
שגיאת האימון הן גבוהות,

208
00:07:09,560 --> 00:07:10,440
ואנחנו מקבלים

209
00:07:10,650 --> 00:07:12,040
ערך גבוה יחסית של

210
00:07:12,280 --> 00:07:14,250
שתיהם, J-cv ו-J-אימון.

211
00:07:15,370 --> 00:07:16,820
זה גם אומר משהו מעניין

212
00:07:17,120 --> 00:07:18,520
מאוד, דהיינו,

213
00:07:18,800 --> 00:07:19,990
אם לאלגוריתם למידה יש הטיה

214
00:07:20,360 --> 00:07:22,250
גבוהה, ככל שאנו

215
00:07:22,390 --> 00:07:23,430
מקבלים יותר ויותר דוגמאות אימונים,

216
00:07:24,060 --> 00:07:25,100
כלומר, ככל שאנחנו עוברים

217
00:07:25,210 --> 00:07:26,600
ימינה על הגרף הזה, נוכל

218
00:07:26,740 --> 00:07:27,880
להבחין ששגיאת

219
00:07:28,220 --> 00:07:29,430
האימות איננה יורדת

220
00:07:29,740 --> 00:07:31,020
בצורה משמעותית, אלא למעשה משתטחת,

221
00:07:31,560 --> 00:07:32,820
ולכן אם

222
00:07:32,950 --> 00:07:35,020
אלגוריתם הלמידה אכן סובל מהטיה גבוהה,

223
00:07:36,640 --> 00:07:38,200
תוספת גרידא של נתוני

224
00:07:38,370 --> 00:07:39,710
אימון בפני עצמה לא תועיל

225
00:07:40,190 --> 00:07:41,580
למעשה בהרבה, וכמו הדוגמה

226
00:07:41,760 --> 00:07:43,120
שלנו בגרף

227
00:07:43,210 --> 00:07:45,670
מימין, בה היו לנו רק חמש דוגמאות

228
00:07:46,060 --> 00:07:47,970
אימון, וובנינו מהן קו ישר מסוים,

229
00:07:48,550 --> 00:07:49,270
אז גם כאשר היו לנו המון

230
00:07:49,540 --> 00:07:50,730
דוגמאות אימון נוספות, נשארנו

231
00:07:51,040 --> 00:07:52,710
למעשה עם בערך אותו קו ישר.

232
00:07:53,200 --> 00:07:54,290
ולכן אם לאלגוריתם הלמידה

233
00:07:54,440 --> 00:07:57,090
יש הטיה גבוהה, אז להוסיף לו הרבה יותר נתוני הכשרה

234
00:07:57,650 --> 00:07:59,060
לא ממש עוזר לנו

235
00:07:59,830 --> 00:08:01,290
להוריד את שגיאת האימות

236
00:08:01,890 --> 00:08:02,890
או את שגיאת המבחן.

237
00:08:03,730 --> 00:08:04,950
אז הידיעה אם אלגוריתם

238
00:08:05,250 --> 00:08:06,600
הלמידה שלך סובל מהטיה

239
00:08:06,780 --> 00:08:07,620
גבוהה נראית שימושית

240
00:08:08,100 --> 00:08:09,500
כי היא עשויה

241
00:08:09,640 --> 00:08:11,140
למנוע ממך מבזבוז של

242
00:08:11,290 --> 00:08:12,520
הרבה זמן באיסוף נתוני אימון

243
00:08:12,920 --> 00:08:15,440
נוספים במקום שבו זה פשוט לא יכול להועיל.

244
00:08:16,200 --> 00:08:17,070
עכשיו בואו ונסתכל על

245
00:08:17,140 --> 00:08:18,530
מצב של אלגוריתם למידה

246
00:08:19,470 --> 00:08:20,340
שבו עשויה להיות שונות גבוהה.

247
00:08:21,590 --> 00:08:22,880
בואו נסתכל קודם כל על

248
00:08:23,550 --> 00:08:24,260
שגיאת האימון.

249
00:08:25,120 --> 00:08:26,350
אם יש לך סדרת אימון קטנה

250
00:08:26,680 --> 00:08:28,730
מאוד כמו חמש דוגמאות ההכשרה המוצגות על

251
00:08:29,130 --> 00:08:30,720
הגרף בצד ימין,

252
00:08:31,150 --> 00:08:32,170
ואם אנחנו מנסים להתאים

253
00:08:32,200 --> 00:08:33,050
נניח פולינום מסדר גבוה מאוד,

254
00:08:34,380 --> 00:08:36,530
ואני כתבתי פולינום ממעלה מאה

255
00:08:37,090 --> 00:08:38,750
שבאמת אף פעם לא משתמשים בו, אבל רק לשם הדוגמה.

256
00:08:39,920 --> 00:08:41,460
ואם אנו משתמשים

257
00:08:41,550 --> 00:08:43,160
בערך קטן למדי של λ,

258
00:08:43,800 --> 00:08:44,920
אולי לא אפס, אבל ערך

259
00:08:45,070 --> 00:08:46,830
קטן למדי של λ, אז

260
00:08:47,040 --> 00:08:47,980
נגיע להתאמה

261
00:08:48,190 --> 00:08:50,590
טובה מאד של הנתונים

262
00:08:50,860 --> 00:08:53,390
עם הפונקציה שיש לה התאמת-יתר.

263
00:08:54,380 --> 00:08:55,640
אז אם גודל סדרת

264
00:08:55,990 --> 00:08:57,820
האימון הוא קטן, שגיאת

265
00:08:58,320 --> 00:08:59,530
האימון שלנו, כלומר, J-אימון

266
00:09:00,030 --> 00:09:01,810
של תטא יהיה קטן.

267
00:09:03,130 --> 00:09:04,330
וכשסדרת האימון הזו גדלה

268
00:09:04,940 --> 00:09:05,870
קצת, אנחנו עדיין עשויים

269
00:09:06,000 --> 00:09:07,160
להיות במצב התאמת-יתר

270
00:09:07,330 --> 00:09:08,810
לנתונים אבל זה

271
00:09:09,780 --> 00:09:11,880
גם נהיה קצת יותר קשה

272
00:09:12,020 --> 00:09:12,970
להתאים את הנתונים בצורה מושלמת,

273
00:09:13,940 --> 00:09:15,140
ולכן, ככל שסדרת האימון הזו

274
00:09:15,350 --> 00:09:16,810
גדלה, אנו מוצאים

275
00:09:16,960 --> 00:09:19,390
ש-J-אימון עולה, כי

276
00:09:19,840 --> 00:09:21,040
זה נהיה קצת יותר קשה להתאים

277
00:09:21,260 --> 00:09:22,720
את סדרת האימון באופן מושלם ככל

278
00:09:22,890 --> 00:09:25,700
שיש לנו יותר דוגמאות, אבל שגיאת האימון תהיה עדיין נמוכה למדי.

279
00:09:26,530 --> 00:09:28,600
עכשיו, מה עם שגיאת האימות?

280
00:09:29,220 --> 00:09:30,590
ובכן, במצב שונות

281
00:09:31,040 --> 00:09:32,760
גבוהה, ההשערה

282
00:09:32,980 --> 00:09:34,190
במצב התאמת-יתר ולכן

283
00:09:34,290 --> 00:09:35,680
שגיאת האימות תישאר

284
00:09:36,120 --> 00:09:37,650
גבוהה, גם כאשר

285
00:09:37,750 --> 00:09:38,930
אנחנו מגיעים למספר בינוני

286
00:09:39,260 --> 00:09:40,520
של דוגמאות הכשרה, אז

287
00:09:41,170 --> 00:09:42,950
אולי שגיאת האימות

288
00:09:43,730 --> 00:09:45,520
הצולב נראית ככה.

289
00:09:45,660 --> 00:09:47,720
והאינדיקציה המעידה על כך שיש

290
00:09:47,830 --> 00:09:49,200
לנו בעיית שונות גבוהה

291
00:09:50,210 --> 00:09:51,490
היא העובדה שיש

292
00:09:51,720 --> 00:09:54,010
הפרש גדול בין

293
00:09:54,340 --> 00:09:56,440
שגיאת האימון לבין שגיאת האימות הצולב.

294
00:09:57,440 --> 00:09:58,180
וכשמסתכלים על הגרף הזה

295
00:09:58,720 --> 00:10:00,170
אם אנחנו חושבים על הוספת

296
00:10:00,440 --> 00:10:01,810
נתונים נוספים לסדרת האימון, כלומר, אם ניקח

297
00:10:02,110 --> 00:10:03,660
את הגרף הזה ונלך עוד

298
00:10:03,790 --> 00:10:05,220
ימינה, נוכל

299
00:10:05,330 --> 00:10:06,830
לומר ששתי

300
00:10:07,030 --> 00:10:08,120
העקומות, העקומה הכחולה

301
00:10:08,480 --> 00:10:10,480
והעקומה הורודה, מתכנסות זו לזו.

302
00:10:11,420 --> 00:10:12,360
אז אם היינו

303
00:10:12,520 --> 00:10:13,840
מאריכים את הגרף הזה

304
00:10:13,980 --> 00:10:21,230
ימינה, זה

305
00:10:21,360 --> 00:10:23,000
נראה סביר

306
00:10:23,170 --> 00:10:24,120
ששגיאת האימון תמשיך

307
00:10:24,270 --> 00:10:25,740
לעלות

308
00:10:27,130 --> 00:10:29,040
ושגיאת האימות הצולב תמשיך לרדת.

309
00:10:30,000 --> 00:10:32,340
והדבר שבאמת אכפת לנו הוא שגיאת האימות הצולב

310
00:10:33,010 --> 00:10:35,150
ושגיאת ערכת המבחן, נכון?

311
00:10:35,300 --> 00:10:36,460
אז בסוג כזה

312
00:10:36,730 --> 00:10:37,850
של גרף, אנחנו יכולים לומר

313
00:10:38,230 --> 00:10:39,420
שאם אנחנו נמשיך ונוסיף דוגמאות

314
00:10:39,820 --> 00:10:40,930
אימון ונמשיך את הגרף

315
00:10:41,050 --> 00:10:42,650
ימינה, אז שגיאת

316
00:10:43,290 --> 00:10:44,610
האימות הצולב תמשיך לרדת.

317
00:10:45,120 --> 00:10:46,090
ולכן, במצב של

318
00:10:46,330 --> 00:10:47,980
שונות גבוהה, הוספת

319
00:10:48,180 --> 00:10:49,550
נתוני אימון אכן

320
00:10:50,170 --> 00:10:51,240
עשויה לעזור.

321
00:10:51,520 --> 00:10:52,810
אז כמו מקודם זה נראה

322
00:10:53,060 --> 00:10:54,180
שימושי לדעת אם

323
00:10:54,330 --> 00:10:55,830
אלגוריתם הלמידה שלך סובל

324
00:10:56,150 --> 00:10:57,460
מבעיית שונות גבוהה, כי

325
00:10:57,810 --> 00:10:59,150
זה אומר לך, למשל, שזה

326
00:10:59,220 --> 00:11:00,100
כן עשוי להיות שווה להשקיע את הזמן

327
00:11:00,680 --> 00:11:02,430
כדי לראות אם אתה יכול ללכת ולמצוא עוד קצת נתוני אימון.

328
00:11:03,700 --> 00:11:04,920
עכשיו, בשקופית הקודמת

329
00:11:05,330 --> 00:11:06,450
ובשקופית הזאת, אני שרטטתי

330
00:11:06,970 --> 00:11:08,510
גרפים עם עקומות די נקיות ואידיאליות.

331
00:11:08,900 --> 00:11:10,050
אם תשרטט עקומות כאלה עבור

332
00:11:10,170 --> 00:11:11,970
אלגוריתם למידה אמיתי, לפעמים

333
00:11:12,500 --> 00:11:13,910
אתה באמת תראה

334
00:11:14,560 --> 00:11:15,900
עקומות די דומות למה שציירתי כאן.

335
00:11:16,600 --> 00:11:17,730
אבל הרבה פעמים תראה עקומות

336
00:11:18,150 --> 00:11:19,160
שהם קצת יותר רועשות

337
00:11:19,230 --> 00:11:20,820
ופחות מסודרות יפה מאלה.

338
00:11:21,090 --> 00:11:22,440
אבל השרטוט של עקומות למידה כאלה

339
00:11:22,620 --> 00:11:23,850
יכול לעתים קרובות לומר

340
00:11:24,120 --> 00:11:25,460
לך, יכול לעתים קרובות לעזור לך

341
00:11:25,570 --> 00:11:26,650
להבין אם אלגוריתם הלמידה שלך

342
00:11:26,950 --> 00:11:29,080
סובל מהטיה או שונות או אפילו קצת משתיהם.

343
00:11:29,170 --> 00:11:31,030
אז כשאני

344
00:11:31,200 --> 00:11:32,700
מנסה לשפר את הביצועים של

345
00:11:32,760 --> 00:11:34,060
אלגוריתם למידה, אחד הדברים

346
00:11:34,260 --> 00:11:35,720
שאני כמעט תמיד עושה

347
00:11:35,960 --> 00:11:37,440
הוא לשרטט עקומות

348
00:11:37,970 --> 00:11:39,460
למידה כאלה, ובדרך כלל זה ייתן

349
00:11:39,490 --> 00:11:41,710
לך מושג טוב יותר אם יש בעיית הטיה או שונות.

350
00:11:44,280 --> 00:11:45,180
ובסרטון הבא

351
00:11:45,420 --> 00:11:46,440
נראה כיצד זה יכול

352
00:11:46,650 --> 00:11:48,370
לעזור להצביע על פעולות ספציפיות

353
00:11:48,450 --> 00:11:49,580
שכדאי לנקוט בהם או לא לנקוט בהם

354
00:11:50,260 --> 00:11:53,250
כדי לנסות לשפר את הביצועים של אלגוריתם הלמידה שלך.