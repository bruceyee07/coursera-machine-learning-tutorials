אם אתה מפעיל אלגוריתם למידה והביצועים שלו אינם כפי שקיווית, כמעט תמיד זה יהיה או בגלל בעיית הטיה גבוהה או בגלל בעיית שונות גבוהה. במילים אחרות או בגלל התאמת יתר או בגלל התאמת חסר. ובמקרה זה חשוב מאוד להבין איזו מבין שתי הבעיות הללו קיימות, הטיה, או שונות, או אולי קצת מכל אחת מהן. כי הידיעה איזה משני הדברים האלה קורה תיתן לך אינדיקטור חזק מאוד לגבי הדרכים השימושיות והיותר מבטיחות כדי לנסות ולשפר את האלגוריתם שלך. בסרטון הזה, אני רוצה להעמיק יותר לתוך נושאי ההטיה והשונות ולהבין אותם טוב יותר, כמו גם להבין איך להסתכל ולהעריך ולדעת האם יש לנו בעיית הטייה או בעיית שונות. מכיוון שזה יהיה קריטי כדי להבין כיצד לשפר את הביצועים של אלגוריתם הלמידה שלכם. אז כבר ראיתם את הגרפים האלה כמה פעמים, בהם אם אתם מתאימים השערה פשוטה מדי, כמו קו ישר, אז אתם מקבלים התאמת חסר, ואם אתם מתאימים היפותזה מורכבת מדי, אז זה עשוי להתאים היטב לסדרת האימון אבל לסבול מהתאמת יתר, ויכול להיות שהשערה באיזו רמת ביניים של מורכבות, אולי השערה עם פולינום מסדר שני אינה נמוכה מדי ולא גבוהה מדי היא בדיוק מתאימה. והיא תיתן לנו את השגיאה הטובה ביותר על דוגמאות חדשות מתוך כל האפשרויות האלה. עכשיו, כשאנחנו כבר מכירים את הרעיון של קבוצות האימון, האימות והמבחן, אנחנו יכולים להבין את המושגים של הטיה ושונות קצת יותר טוב. באופן קונקרטי, הבה נגדיר את שגיאת האימון שלנו ואת שגיאת האימות הצולב להיות מוגדרות כמו בקטעי הוידאו הקודמים, זאת אומרת, השגיאה בריבוע, הממוצע של השגיאה בריבוע כפי שנמדד על קבוצת האימון או כפי שנמדד על קבוצת האימות הצולב. ועכשיו בואו ונשרטט את הגרף הבא. על הציר האופקי אני עומד לרשום את הדרגה של הפולינום משמאל לימין, כך שבצד ימין ישנם פולינומים מסדר גבוה יותר ויותר. אז אנחנו נתחיל בצד שמאל של הגרף הזה, שבו אולי d שווה 1, וכאן תהיינה פונקציות מאוד פשוטות, ולעומת זאת כאן מימין על הציר האופקי, יהיו לנו דרגות גבוהות יותר של d, של דרגת פולינום, ולכן כאן זה מתאים לפונקציות הרבה יותר מסובכות שמותאמות לסדרת האימון שלנו. הבה נתחיל בדיון על שגיאת האימון ושגיאת האימות ונשרטט אותם על הגרף. נתחיל עם שגיאת האימון. ככל שנגדיל את דרגת הפולינום, נוכל להתאים את סדרת האימון יותר ויותר טוב, ולכן אם d = 1, נקבל שגיאת אימון גדולה, וכשיש לנו דרגת פולינום גבוהה מאד, שגיאת האימון תהיה מאד קטנה, אולי אפילו 0, כי נתאים לסדרת האימון ממש היטב. וכך כשאנחנו מגדילים את דרגת הפולינום, אנחנו מוצאים שבאופן טיפוסי שגיאת האימון יורדת, אז J-אימון של θ נוטה לקטון, עם עליית דרגת הפולינום שאנחנו מתאימים לנתונים. עכשיו בואו נסתכל על שגיאת האימות. או בעצם גם אם נסתכל על שגיאת סדרת המבחן, נקבל תוצאות דומות כמו לו נשרטט את שגיאת האימות. אז כאשר d = 1 אנחנו מתאימים פונקציה מאד פשוטה, אז אנחנו נוטים להתאמת חסר של סדרת האימון, ולכן נקבל שגיאת אימות גדולה. אם נתאים פולינום מדרגה בינונית, כמו שהיה לנו d = 2 בשקף הקודם, תהיה לנו שגיאת אימות הרבה יותר נמוכה, כי אנחנו מוצאים התאמה הרבה יותר טובה לנתונים, ומצד שני, אם נעלה גבוה מדי, לדוגמא אם d עכשיו יהיה שווה 4, אז נגיע להתאמת יתר. ואז נגיע לערך גבוה עבור שגיאת האימות הצולב. אז אם נשנה את דרגת הפולינום בצורה רציפה ונשרטט עקומה, נקבל עקומה כזאת שבה זהו (Jcv(θ. ושוב, אם נשרטט את J-מבחן של θ נקבל משהו דומה מאוד. אז הסוג הזה של גרף עוזר לנו גם להבין יותר טוב את המושגים של הטיה ושונות. באופן קונקרטי, נניח שהפעלתם אלגוריתם למידה והביצועים שלו אינם כפי שקיוויתם, דהיינו אם שגיאת האימות הצולב שלכם או שגיאת המבחן שלכם היא גבוהה, כיצד נוכל להבין אם אלגוריתם הלמידה סובל מהטיה גבוהה או משונות גבוהה? אז המצב של שגיאה גדולה בסדרת האימות מתאים גם למצב הזה וגם למצב הזה. המצב הזה משמאל מתאים לבעיה של הטיה גבוהה. כלומר, להתאמה של פולינום מסדר נמוך מדי כגון d = 1 כאשר אנחנו בעצם צריכים פולינום מסדר יותר גבוה כדי להתאים לנתונים, ולעומת זאת המצב הזה מתאים לבעיה של שונות גבוהה. כלומר, אם דרגת הפולינום d היא גדולה מדי עבור סדרת הנתונים שלנו, והציור הזה נותן לנו מושג איך להבחין בין שני המקרים. באופן קונקרטי, במקרה של הטיה גבוהה, המקרה של התאמת-חסר, מה שנגלה הוא שהן שגיאת האימות הצולב והן שגיאת האימון תהיינה גבוהות. אז אם האלגוריתם שלך סובל מבעיה של הטיה, שגיאת ערכת האימון תהיה גבוהה, ואתה עשוי לגלות שגם שגיאת האימות הצולב תהיה גבוהה. היא יכולה להיות דומה, ואולי גבוהה במקצת, מאשר שגיאת האימון. אז אם אתה רואה את השילוב הזה, זה סימן שהאלגוריתם שלך סובל מהטיה גבוהה. לעומת זאת, אם האלגוריתם שלך סובל משונות גבוהה, אז שימו לב כאן, נראה כי J-אימון, שגיאת האימון, תהיה נמוכה. כלומר, אתה מתאים את סדרת האימון בצורה טובה מאוד, ואילו שגיאת האימות הצולב שלך בהנחה שהיא מוגדרת למשל כריבוע השגיאה שאותו אנחנו מנסים למזער, שגיאת האימות הצולב שלך תהיה הרבה יותר גדולה מאשר השגיאה על סדרת האימון. הסימן הזה של "גדול גדול" זהו הסימן המתמטי שמשמעותו "הרבה יותר גדול" והוא מסומן על ידי שני סימני "גדול מ". אז אם אתה רואה את השילוב הזה של ערכים, אז זה רמז שאלגוריתם הלמידה שלך עשוי להיות סובל משונות גבוהה ומהתאמת-יתר. המפתח להבחנה בין שני המקרים הוא, אם יש לך בעית הטיה גבוהה, שגיאת סדרת האימון גם היא תהיה גבוהה, ההשערה שלך פשוט לא מתאימה היטב לסדרת האימון. ואם יש לך בעית שונות גבוהה, שגיאת סדרת האימון שלך תהיה בדרך כלל נמוכה, דהיינו הרבה יותר נמוכה מאשר השגיאה בסדרת האימות הצולב. אז אני מקווה שזה נתן לכם הבנה טובה יותר של שתי הבעיות, הטיה ושונות. אני אדבר עוד הרבה על הטיה ושונות בסרטונים הבאים, אבל מה שנראה בהמשך הוא שבאמצעות אבחון האם אלגוריתם למידה עלול לסבול מהטיה גבוהה או משונות גבוהה, אני אראה לכם יותר פרטים על איך לעשות את זה בסרטונים מאוחרים יותר. אבל נראה שעל ידי גילוי האם אלגוריתם למידה סובל מהטיה גבוהה או משונות גבוהה או שילוב של שניהם, שזה ייתן לנו הדרכה טובה יותר בקשר לשאלה מה עשויה להיות הדרך הנכונה לנסות כדי לשפר את הביצועים של אלגוריתם למידה.