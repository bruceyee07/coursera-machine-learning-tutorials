בסרטון זה, אני רוצה לדבר על איך להעריך את איכות פונקצית ההשערה שנלמדה על ידי האלגוריתם שלך. בסרטונים מאוחרים יותר, אנחנו נבנה על זה כדי לדבר על איך מונעים את הבעיות גם של התאמת-יתר וגם של התאמת-חסר. כאשר אנו מכווננים את הפרמטרים של אלגוריתם הלמידה שלנו אנחנו חושבים על בחירת הפרמטרים כך שימזערו את השגיאה בסדרת האימון. הגיוני לחשוב כי אם נקבל ערך באמת נמוך של שגיאה בסדרת האימון זה יהיה דבר טוב, אבל כבר ראינו שרק בגלל להשערה יש שגיאה נמוכה בסדרת האימון, זה לא אומר שזו בהכרח השערה טובה. וכבר ראינו דוגמה של איך יכולה ההשערה לסבול מהתאמת-יתר. והיא נכשלת בלהכליל דוגמאות חדשות שאינן בסדרת האימון. אז איך יודעים אם להשערה יש התאמת-יתר? בדוגמא הפשוטה הזאת נוכל לשרטט את ההשערה (h(x ופשוט לראות מה קורה. אבל באופן כללי עבור בעיות עם יותר מאשר תכונה אחת, עבור בעיות עם מספר רב של תכונות כמו זו, זה הופך להיות קשה או בלתי אפשרי לשרטט את ההשערה ולכן אנחנו צריכים דרך אחרת להעריך את איכות ההשערה שלנו. הדרך הסטנדרטית להעריך הערכה שנלמדה היא כדלקמן. נניח שיש לנו מערך נתונים כזה. כאן הראיתי רק 10 דוגמאות הכשרה, אבל כמובן, בדרך כלל יש לנו עשרות או מאות ואולי אלפי דוגמאות הכשרה. כדי לוודא שאנחנו יכולים להעריך את ההשערה שלנו, מה שאנחנו הולכים לעשות הוא לפצל את הנתונים שיש לנו לשני חלקים. החלק הראשון הולך להיות סדרת האימון הרגילה שלנו, והשני יהיה סדרת מבחן או בדיקה, ופיצול אופייני למדי של כל הנתונים שיש לנו לערכת אימון וקבוצת בדיקה עשוי להיות פיצול סביב נניח 70% : 30%. עם יותר דוגמאות בסדרת האימון ויחסית פחות בסדרת הבדיקה. אז עכשיו, אם יש לנו איזו ערכת נתונים, אנו מקצים נניח 70% מהנתונים לסדרת האימון, כאן "m" הוא כרגיל גודל סדרת האימון שלנו, ואת שאר הנתונים אנחנו מקצים להיות ערכת הבדיקה שלנו. וכאן, אני משתמש בסימון התחתון "מבחן" או ""test" כדי לציין את מספר דוגמאות הבדיקה. וכך, באופן כללי, סימון תחתון "מבחן" הזה משמש אותנו לדוגמאות שמגיעות מסדרת הבדיקה, כך לדוגמא x1 "מבחן", y1 "מבחן" הוא דוגמת המבחן הראשונה שלי, שכאן אני מניח שהדוגמה הזו יכולה להיות הדוגמה הזו כאן. לבסוף, פרט אחד אחרון, למרות שכאן ציירתי את זה כאילו ה-70% הראשונים משמשים כסדרת האימון ו-30% האחרונים כסדרת הבדיקה, אם יש איזשהו סדר בנתונים, זה יהיה יותר טוב להקצות אקראית את הנתונים שלך, 70% אקראיים לסדרת האימון ושאר ה-30% האקראיים לסדרת הבדיקה. אז אם הנתונים שלך כבר ממוינים באופן אקראי, אתה יכול פשוט לקחת את 70% הראשונים, ואת 30% האחרונים, אבל אם הנתונים שלך לא מסודרים אקראית, זה יהיה יותר טוב לערבב אותם אקראית או לסדר מחדש את הדוגמאות בקבוצת האימון שלך באופן אקראי. לפני שנחלק את הדוגמאות ל-70% הראשונים בקבוצת האימון ו-30% האחרונים בקבוצת הבדיקה. אז הנה תהליך טיפוסי למדי של איך בונים ובודקים את אלגוריתם הלמידה ואת הרגרסיה. ראשית, אנחנו לומדים את הפרמטרים θ מסדרת האימון וממזערים כרגיל את השגיאה של סדרת האימון (J(θ, כשכאן (J(θ הוגדר בעזרת 70% מהנתונים שיש לנו. רק בעזרת נתוני האימון. ואז אנחנו מחשבים את השגיאה על סדרת הבדיקה או המבחן. ואנחנו נציין את שגיאת הבדיקה כ-J סימן תחתון test. אז מה שאנחנו עושים זה לקחת את הפרמטר θ שלמדנו מסדרת האימון, ומציבים אותו כאן כדי לחשב את השגיאה בסדרת הבדיקה. שאני אכתוב כדלקמן. זו בעצם השגיאה הממוצעת בריבוע כפי שהיא נמדדת על סט הבדיקה. זה פחות או יותר מה שאתם מצפים שיהיה פה. אנחנו מריצים כל דוגמה מסדרת הבדיקה דרך פונקציית ההשערה עם הפרמטר θ ופשוט מודדים את השגיאה בריבוע שההשערה נותנת על דוגמת המבחן הספציפית. זוהי כמובן ההגדרה של שגיאת ערכת המבחן כשאנחנו משתמשים ברגרסיה לינארית ובמדד השגיאה בריבוע. מה לדעתך היה המצב לו עשינו בעיית סיווג באמצעות רגרסיה לוגיסטית במקום זה? במקרה הזה, התהליך לאימון ובדיקה, זאת אומרת של הרגרסיה הלוגיסטית, יהיה דומה למדי לקודם. נחשב את הפרמטרים על פי נתוני האימון, שהם 70% הראשונים של הנתונים. ואז נחשב את שגיאת הבדיקה כדלקמן. זוהי אותה פונקצית מטרה בה אנו משתמשים תמיד ברגרסיה לוגיסטית, אלא שעכשיו אנחנו משתמשים בתת הקבוצה של דוגמאות הבדיקה כדי לחשב את השגיאה. למרות שההגדרה הזו של שגיאת ערכת המבחן על הפונקציה J היא הגדרה לגמרי טבעית, לפעמים יש מטריקה אלטרנטיבית של סדרת הבדיקה שעשויה להיות קלה יותר להבנה, וזו השגיאה של "סיווג שגוי". היא נקראת גם שגיאת סיווג-שגוי אפס-אחת, כשהאפס-אחת מציין שסיווגת את הדוגמה נכון או לא נכון. אסביר את כוונתי. תנו לי להגדיר את פונקצית שגיאת החיזוי. פונקצית החיזוי h של x. לגבי תווית y השגיאה שווה 1 אם ההשערה שלי מוציאה ערך גדול יותר או שווה ל-0.5 ו-y שווה לאפס או אם ההשערה שלי מוציאה ערך של פחות מ 0.5 ו-y שווה אחד, ברור, אלה שני המקרים האלה מתאימים למקרים שההשערה מוציאה שגיאה לגבי הדוגמא, בהנחה שהסף שלנו הוא 0.5. אז או חשבנו שיותר סביר שהתוצאה תהיה 1, אבל היא למעשה היתה 0, או שלפי ההשערה היה סביר יותר שהתוצאה היא 0, אבל התווית היתה למעשה 1. ואחרת, אנו מגדירים את פונקציית השגיאה הזו לאפס. אם ההשערה מסווגת את הדוגמה בצורה נכונה. ואז ניתן להגדיר את שגיאת הבדיקה, תוך שימוש במדד שגיאת החיזוי שכרגע הגדרנו להיות פשוט הממוצע של הסכום על כל סדרת הבדיקה מ- i שווה 1 עד m של סדרת המבחן של השגיאה של h של (x(i),y(i, חלקי מספר הדוגמאות. זו פשוט הדרך שלי לכתוב שזה בדיוק החלק של הדוגמאות בסדרת הבדיקה שלי בהם ההשערה שלי טעתה. אז זוהי ההגדרה של שגיאת ערכת הבדיקה באמצעות מדד שגיאת סיווג של אפס אחת. אז זוהי טכניקה סטנדרטית להערכת טיבה של ההשערה שנלמדה. בסרטון הבא, נתחיל להתאים את הרעיונות האלה כדי לעזור לנו לעשות דברים כמו לבחור אילו תכונות ודרגות של פולינום להשתמש באלגוריתם הלמידה שלנו, ואיך לבחור את פרמטר הרגולציה עבור אלגוריתם הלמידה.