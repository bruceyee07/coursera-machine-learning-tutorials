נניח שאתה רוצה להחליט איזו דרגה של פולינום להתאים לסדרת הנתונים. או אילו תכונות לכלול בנוסחה של אלגוריתם הלמידה. או נניח שברצונך לבחור בפרמטר הרגולציה λ עבור אלגוריתם הלמידה. למידה ללא השגחה. איך עושים את זה לזה קוראים בעיית בחירת המודל. ובדיון שלנו על איך לעשות את זה, נדבר על לא רק איך לפצל את הנתונים שלך לערכת לימוד וערכת בדיקה, אלא איך לחלק נתונים למה שאנחנו נקרא ערכות לימוד, אימות ובדיקה. אנחנו נראה בסרטון הזה בדיוק מה הם הדברים האלה, וכיצד להשתמש בהם לבחירת המודל. כבר ראינו הרבה פעמים את הבעיה של התאמת-יתר, שבה רק בגלל שאלגוריתם למידה מתאים היטב לסדרת האימון, זה לא אומר שזאת השערה טובה. באופן כללי יותר, זו הסיבה ששגיאה שנוצרת בקבוצת האימון אינה מנבאת בצורה טובה את מידת ההצלחה של ההיפותזה בדוגמאות חדשות. דהיינו, אם אתה מתאים כמה פרמטרים, θ0, θ1, θ2, וכן הלאה, לסדרת האימון, אז העובדה שההשערה שלך מצליחה היטב על סדרת האימון, לא אומרת הרבה במונחים של ניבוי עד כמה ההשערה שלך תצליח בהכללה לדוגמאות חדשות שלא נראו בסדרת האימון. ויש עיקרון כללי יותר והוא שברגע שהפרמטרים שלך מתאימים לקבוצה מסוימת של נתונים, בין אם סדרת האימון, ובין אם קבוצה אחרת, אז השגיאה של ההשערה שלך כפי שהיא נמדדת על אותה קבוצת נתונים, כגון השגיאה בסדרת האימון, לא סביר שתהיה הערכה טובה של השגיאה בפועל על נתונים כלליים. דהיינו, טיב ההנחה כאשר מכלילים אותה לדוגמאות חדשות. עכשיו בואו נחשוב על בעיית בחירת המודל. נניח שאתה מנסה לבחור את דרגת הפולינום המתאימה לנתונים. האם אתה צריך לבחור פונקציה ליניארית, פונקציה ריבועית, פונקציה משולשת? או אולי פולינום אפילו מסדר 10? אז זה כאילו יש לנו פרמטר נוסף באלגוריתם הזה, שאני אציין ב-d, כלומר, הדרגה של הפולינום שאתה רוצה לבחור. אז זה כאילו, בנוסף לפרמטרים θ, זה כאילו יש פרמטר אחד נוסף, d, שאותו אנחנו מנסים לקבוע באמצעות סדרת הנתונים. אז האפשרות הראשונה היא d שווה 1, אם נתאים פונקציה ליניארית. אנחנו יכולים לבחור d = 2, d = 3, ואפשר להמשיך עד d = 10. אז אנחנו רוצים להתאים את הסוג הנוסף הזה של פרמטר שאני מציין באמצעות d. אז בואו נניח שאנחנו רוצים לבחור מודל, זאת אומרת לבחור דרגה של פולינום, לבחור אחד מה-10 מודלים האלה. גם להתאים את המודל הזה וגם לקבל איזושהי הערכה של כמה טוב תצליח ההיפותזה הזו להכליל לדוגמאות חדשות. הנה מין דבר שאפשר לעשות. מה שאפשר לעשות, קודם כל לקחת את המודל הראשון ואיתו למזער את שגיאת האימון. וזה ייתן לנו איזה שהוא וקטור פרמטרים θ. ואז אפשר לקחת את המודל השני, את הפונקציה הריבועית, ולהתאים אותו לסדרת האימון וזה ייתן לנו איזה וקטור פרמטרים אחר. כדי להבדיל בין וקטורי הפרמטרים השונים האלה, אני אשתמש בסימן עליון אחד וסימן עליון שתיים, וכאן θ סימן עליון אחד פשוט אומר הפרמטרים שאני מקבל על ידי התאמת המודל הראשון לנתוני האימון שלי. ו-θ סימן עליון 2 פשוט אומר הפרמטרים שאני מקבל על ידי התאמת הפונקציה הריבועית לנתוני האימון שלי וכן הלאה. על ידי התאמת מודל מדרגה שלוש אני מקבל θ סימן עליון סוגריים שלוש עד, נניח, θ10. דבר אחד שאנחנו יכולים לעשות זה לקחת את הפרמטרים האלה ולהסתכל על שגיאת הבדיקה. אז אני יכול לחשב על סדרת הבדיקה את השגיאה של (J(θ1, השגיאה של (J(θ2, וכן הלאה. השגיאה של (J(θ3, וכן הלאה. אז אנחנו ניקח כל אחת מההשערות עם הפרמטרים המתאימים ופשוט נמדוד את הביצועים שלה על סט הבדיקה. עכשיו, אחד מהדברים שאפשר לעשות אז הוא, על מנת להחליט איזה מהמודלים לבחור, אנחנו נבדוק לאיזה דגם יש את השגיאה הנמוכה ביותר על סט המבחן. ובואו נאמר שבמקרה שלנו, בסופו של דבר בחרנו במקרה את הפולינום מדרגה חמישית. עד עכשיו זה נראה הגיוני. אבל עכשיו נניח שאני רוצה לקחת את ההיפותזה החמישית שלי, את זה, המודל מסדר חמישי, ונניח שאני רוצה לשאול, עד כמה המודל הזה טוב בהכללות? דבר אחד שאני יכול לעשות הוא להסתכל על כמה טובה ההשערה הפולינומית הזו מסדר חמישי על דוגמאות הבדיקה שלי. אבל הבעיה היא שזו לא תהיה הערכה הוגנת של כמה ההשערה שלי תהיה טובה לדוגמאות חדשות. והסיבה היא כי מה שעשינו היה שהתאמנו את הפרמטר הנוסף הזה d, שהוא דרגת הפולינום. והחלטנו איזה d מתאים באמצעות ערכת הבדיקה, כלומר, בחרנו את הערך של d שנתן לנו את הביצועים הטובים ביותר על דוגמאות הבדיקה. אז הביצועים של וקטור הפרמטרים שלי θ5 על סט הבדיקה, היא הערכה אופטימית מדי לגבי מה תהיה השגיאה בדוגמא אקראית מהעולם. נכון, כי כך בנינו את הפרמטר הזה d לפי דוגמאות המבחן ולכן זה "לא הוגן" להעריך את טיב ההשערה על קבוצת המבחן הזו, כי אנחנו התאמנו את הפרמטרים על קבוצת המבחן, בחרנו את הדרגה d של הפולינום באמצעות ערכת הבדיקה. אז ההשערה עשויה להצליח יותר על דוגמאות המבחן מאשר על דוגמאות חדשות שהיא לא ראתה קודם לכן, שזה מה שבאמת אכפת לי. אז רק לחזור, בשקופית הקודמת ראינו שאם אנחנו מתאימים איזו קבוצת פרמטרים, לדוגמא θ0, θ1, וכן הלאה, לסדרת האימון, אז הביצועים של המודל המאומן הזה על קבוצת האימון לא מנבאים עד כמה תהיה ההשערה מסוגלת להכליל לדוגמאות חדשות. הסיבה לכך היא שהפרמטרים הללו אומנו לפי סדרת האימון, ולכן זה צפוי שהם יפעלו היטב על דוגמאות האימון, גם אם הפרמטרים לא מצליחים עם דוגמאות אחרות. ובפרוצדורה שתיארתי כרגע בשורה הזאת, פשוט עשינו את אותו הדבר. מה שעשינו היה בדיוק להתאים את הפרמטר הזה d לסדרת המבחן. ובגלל ההתאמה הזו של הפרמטר למערך הבדיקה, משמעות הדבר היא שהביצועים של ההשערה על אותה סדרת מבחן עשויים לא להיות הערכה הוגנת של כמה טובה סביר שתהיה ההשערה על דוגמאות שלא ראינו קודם לכן. כדי לטפל בבעיה זו, בהגדרת בחירת המודל, אם ברצוננו גם להעריך את ההיפותזה, הנה מה שאנחנו עושים בדרך כלל במקום זה. כשמקבלים סדרת נתונים, במקום לפצל אותה רק לערכת הכשרה וסדרת בדיקה, מה שאנחנו עושים הוא לפצל אותה לשלושה חלקים. החלק הראשון ייקרא סדרת האימון כרגיל. אז תנו לי לקרוא לחלק הראשון סדרת אימון. ולחלק השני של הנתונים אנחנו נקרא סדרת הוידוא או האימות הצולב. אימות צולב. נקצר את זה ל-CV. לפעמים זה גם נקרא פשוט סדרת אימות במקום סדרת אימות צולב. ולחלק האחרון נקרא כרגיל סדרת הבדיקה. ויחס טיפוסי למדי, שבו מפצלים את הדברים האלה יהיה להקצות 60% מהנתונים לקבוצת האימונים, אולי 20% לקבוצת האימות הצולב, ו-20% לסט המבחן. המספרים האלה יכולים להשתנות מעט אבל שילוב כזה הוא אופייני למדי. אז ערכת ההדרכה שלנו תכיל כעת רק 60% מהנתונים, וקבוצת האימות הצולב שלנו, או קבוצת האימות שלנו, תכלול מספר דוגמאות שאני אציין ב-m עם סימן תחתון cv. זה מספר דוגמאות האימות הצולב. ובהתאמה להסכם שלנו מקודם לגבי סימון של דוגמאות, אני אשתמש ב-x(i)-cv,y(i)-cv כדי לציין את דוגמת האימות מספר i. וכמובן בנוסף יש לנו גם קבוצת מבחן והסימון m-test כסימון תחתון משמש כמספר דוגמאות הבדיקה. אז עכשיו לאחר שהגדרנו קבוצת אימון, קבוצת אימות או אימות צולב, וקבוצת מבחן, אנו יכולים להגדיר גם את שגיאת האימון, שגיאת האימות הצולב ושגיאת המבחן. אז הנה שגיאת האימון שלנו, ואני כותב את זה פשוט כ-J סמון תחתון אימון של θ. זה די דומה למה שעשינו למעלה. זה אותו דבר כמו (J(θ שכבר כתבנו מקודם, אלא שהשגיאה מחושבת על קבוצת האימון, על פי תוצאות ערכת האימון, ואז יש לנו השגיאה של J-cv שהיא קבוצת האימות, וגם זה די מה שהיינו מצפים, בדיוק כמו השגיאה על קבוצת האימון, אבל הפעם נמדד על קבוצת האימות הצולבת, ולבסוף יש לנו שגיאת המבחן שנמדדת על קבוצת המבחן. אז כשיש לנו בעיה של בחירת המודל כמו כאן, מה שאנחנו נעשה הוא, במקום להשתמש בקבוצת המבחן כדי לבחור את המודל, אנחנו נשתמש בערכת האימות, או בערכת האימות הצולב, כדי לבחור את המודל. אז כמו מקודם אנחנו ניקח את ההשערה הראשונה שלנו, את המודל הראשון, נמזער את פונקצית העלות וזה ייתן לנו איזשהו וקטור פרמטרים θ עבור המודל הליניארי. וכמו מקודם, אני אסמן אותו ב-1, כדי לציין שזהו וקטור הפרמטרים של המודל הליניארי. ואז נעשה אותו דבר עבור המודל הריבועי. נקבל איזה וקטור פרמטרים θ2. נקבל וקטור פרמטר θ3, וכן הלאה, עד θ10 עבור הפולינום מדרגה 10. ואז מה שנעשה הוא, במקום לבדוק את ההשערות האלה על סדרת הבדיקה, אנחנו נבדוק אותם על סט האימות הצולב. ונמדוד את J-cv, כדי לראות עד כמה טובה כל אחת מההשערות האלה על סדרת האימות הצולב שלנו. ואז אנחנו נבחר את ההשערה עם השגיאה הנמוכה ביותר על סדרת האימות. אז בדוגמה זו, נניח למען הדוגמה, כי זה היה הפולינום מסדר 4, שהיה הנמוך ביותר בשגיאת האימות. אז במקרה זה אנחנו נבחר את המודל הפולינומי מסדר רביעי . כזכור, מה זאת אומרת שהפרמטר d, זוכרים ש-d היה הדרגה של הפולינום, נכון? d שווה שתיים, d שווה שלוש, עד d שווה 10. מה שעשינו הוא שהתאמנו את הפרמטר הזה והחלטנו שהוא שווה 4. ועשינו זאת באמצעות ערכת האימות הצולב. ולכן הדרגה של הפולינום, הפרמטר, לא נבנתה להיות מתאימה למערך הבדיקה, ולכן לא השתמשנו עדיין בקבוצת המבחן, וניתן להשתמש בקבוצת המבחן כדי למדוד או כדי לאמוד את שגיאת ההכללה של הדגם שנבחר על ידי האלגוריתם. אז כאן תיארנו את מודל הבחירה ואיך אפשר לקחת את הנתונים, לפצל אותם לערכות אימון, אימות ומבחן. ולהשתמש בנתוני האימות הצולב כדי לבחור את המודל ואז להעריך אותו במערך המבחן. הערה אחת אחרונה שאני צריך לומר בלמידת מכונה כמו זו שנהוג לעשות אותה כיום, הרבה אנשים עושים את הדבר עליו דיברתי מקודם, ואמרתי שזה לא רעיון טוב, דהיינו לבחור את המודל באמצעות סדרת המבחן, ואז באמצעות אותה סדרת מבחן לחשב את השגיאה, כמו לבחור את דרגת הפולינום לפי קבוצת הבדיקה, ולאחר מכן לחשב את השגיאה לפי אותה קבוצת בדיקה כאילו שזו הערכה טובה של שגיאת ההכללה. זהו סוג של נוהג שלמרבה הצער נהוג כיום על ידי רבים. אם קבוצת המבחן היא באמת ענקית, אז אולי זה לא דבר כל כך נורא, אבל הרבה מהמומחים, רוב המומחים בלימוד ממוחשב נוטים לייעץ נגד הנוהג הזה. וזה נחשב למנהג יותר טוב ונכון אם יש סדרות או קבוצות נפרדות לאימון, אימות ומבחן. אני רק מסב את תשומת לבכם לכך שלפעמים אנשים אכן משתמשים באותם ערכת נתונים לצורך אימות ולצורך בדיקה. אבל צריך קבוצת אימון נפרדת מקבוצת בדיקה, וזה נוהג טוב, אם כי תראה כמה אנשים שלא עושים את זה. אבל, אם אפשר, אני ממליץ לכם להפריד את הערכות.