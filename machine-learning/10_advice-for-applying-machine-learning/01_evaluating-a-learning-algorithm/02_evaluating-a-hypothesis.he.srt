1
00:00:00,146 --> 00:00:02,515
בסרטון זה, אני רוצה לדבר על איך

2
00:00:02,523 --> 00:00:06,662
להעריך את איכות פונקצית ההשערה שנלמדה על ידי האלגוריתם שלך.

3
00:00:06,685 --> 00:00:09,200
בסרטונים מאוחרים יותר, אנחנו נבנה על זה

4
00:00:09,231 --> 00:00:11,846
כדי לדבר על איך מונעים את הבעיות גם

5
00:00:11,869 --> 00:00:14,908
של התאמת-יתר וגם של התאמת-חסר.

6
00:00:15,615 --> 00:00:19,023
כאשר אנו מכווננים את הפרמטרים של אלגוריתם הלמידה שלנו

7
00:00:19,038 --> 00:00:23,154
אנחנו חושבים על בחירת הפרמטרים כך שימזערו את השגיאה בסדרת האימון.

8
00:00:23,169 --> 00:00:26,077
הגיוני לחשוב כי אם נקבל ערך באמת נמוך של

9
00:00:26,100 --> 00:00:28,108
שגיאה בסדרת האימון זה יהיה דבר טוב,

10
00:00:28,108 --> 00:00:29,562
אבל כבר ראינו

11
00:00:29,562 --> 00:00:32,400
שרק בגלל להשערה יש שגיאה נמוכה בסדרת האימון,

12
00:00:32,400 --> 00:00:35,254
זה לא אומר שזו בהכרח השערה טובה.

13
00:00:35,254 --> 00:00:40,223
וכבר ראינו דוגמה של איך יכולה ההשערה לסבול מהתאמת-יתר.

14
00:00:40,415 --> 00:00:45,785
והיא נכשלת בלהכליל דוגמאות חדשות שאינן בסדרת האימון.

15
00:00:45,962 --> 00:00:50,000
אז איך יודעים אם להשערה יש התאמת-יתר?

16
00:00:50,015 --> 00:00:54,346
בדוגמא הפשוטה הזאת נוכל לשרטט את ההשערה (h(x

17
00:00:54,365 --> 00:00:56,338
ופשוט לראות מה קורה.

18
00:00:56,346 --> 00:01:00,538
אבל באופן כללי עבור בעיות עם יותר מאשר תכונה אחת,

19
00:01:00,554 --> 00:01:03,531
עבור בעיות עם מספר רב של תכונות כמו זו,

20
00:01:03,546 --> 00:01:06,692
זה הופך להיות קשה או בלתי אפשרי

21
00:01:06,708 --> 00:01:09,515
לשרטט את ההשערה

22
00:01:09,531 --> 00:01:13,046
ולכן אנחנו צריכים דרך אחרת להעריך את איכות ההשערה שלנו.

23
00:01:13,062 --> 00:01:17,315
הדרך הסטנדרטית להעריך הערכה שנלמדה היא כדלקמן.

24
00:01:17,331 --> 00:01:19,308
נניח שיש לנו מערך נתונים כזה.

25
00:01:19,323 --> 00:01:21,977
כאן הראיתי רק 10 דוגמאות הכשרה,

26
00:01:21,992 --> 00:01:23,969
אבל כמובן, בדרך כלל יש לנו

27
00:01:23,985 --> 00:01:27,254
עשרות או מאות ואולי אלפי דוגמאות הכשרה.

28
00:01:27,269 --> 00:01:30,246
כדי לוודא שאנחנו יכולים להעריך את ההשערה שלנו,

29
00:01:30,262 --> 00:01:32,808
מה שאנחנו הולכים לעשות הוא לפצל

30
00:01:32,823 --> 00:01:35,554
את הנתונים שיש לנו לשני חלקים.

31
00:01:35,569 --> 00:01:40,723
החלק הראשון הולך להיות סדרת האימון הרגילה שלנו,

32
00:01:42,638 --> 00:01:47,446
והשני יהיה סדרת מבחן או בדיקה,

33
00:01:47,462 --> 00:01:50,398
ופיצול אופייני למדי של

34
00:01:50,413 --> 00:01:53,482
כל הנתונים שיש לנו לערכת אימון וקבוצת בדיקה

35
00:01:53,498 --> 00:01:57,936
עשוי להיות פיצול סביב נניח 70% : 30%.

36
00:01:57,952 --> 00:02:00,052
עם יותר דוגמאות בסדרת האימון

37
00:02:00,067 --> 00:02:02,367
ויחסית פחות בסדרת הבדיקה.

38
00:02:02,382 --> 00:02:05,782
אז עכשיו, אם יש לנו איזו ערכת נתונים,

39
00:02:05,790 --> 00:02:08,459
אנו מקצים נניח 70%

40
00:02:08,475 --> 00:02:11,529
מהנתונים לסדרת האימון, כאן "m"

41
00:02:11,544 --> 00:02:14,336
הוא כרגיל גודל סדרת האימון שלנו,

42
00:02:14,352 --> 00:02:16,913
ואת שאר הנתונים

43
00:02:16,929 --> 00:02:19,310
אנחנו מקצים להיות ערכת הבדיקה שלנו.

44
00:02:19,325 --> 00:02:23,410
וכאן, אני משתמש בסימון התחתון "מבחן" או ""test"

45
00:02:23,425 --> 00:02:27,187
כדי לציין את מספר דוגמאות הבדיקה.

46
00:02:27,202 --> 00:02:32,225
וכך, באופן כללי, סימון תחתון "מבחן" הזה משמש אותנו

47
00:02:32,241 --> 00:02:34,987
לדוגמאות שמגיעות מסדרת הבדיקה, כך

48
00:02:35,002 --> 00:02:40,810
לדוגמא x1 "מבחן", y1 "מבחן" הוא דוגמת המבחן

49
00:02:40,825 --> 00:02:43,648
הראשונה שלי, שכאן אני מניח שהדוגמה הזו

50
00:02:43,664 --> 00:02:45,656
יכולה להיות הדוגמה הזו כאן.

51
00:02:45,671 --> 00:02:47,495
לבסוף, פרט אחד אחרון,

52
00:02:47,510 --> 00:02:50,795
למרות שכאן ציירתי את זה כאילו ה-70% הראשונים

53
00:02:50,810 --> 00:02:54,479
משמשים כסדרת האימון ו-30% האחרונים כסדרת הבדיקה,

54
00:02:54,495 --> 00:02:57,518
אם יש איזשהו סדר בנתונים,

55
00:02:57,533 --> 00:03:01,048
זה יהיה יותר טוב להקצות אקראית את הנתונים שלך,

56
00:03:01,048 --> 00:03:02,948
70% אקראיים לסדרת האימון

57
00:03:02,964 --> 00:03:05,556
ושאר ה-30% האקראיים לסדרת הבדיקה.

58
00:03:05,571 --> 00:03:08,579
אז אם הנתונים שלך כבר ממוינים באופן אקראי,

59
00:03:08,595 --> 00:03:12,110
אתה יכול פשוט לקחת את 70% הראשונים, ואת 30% האחרונים,

60
00:03:12,125 --> 00:03:14,718
אבל אם הנתונים שלך לא מסודרים אקראית,

61
00:03:14,733 --> 00:03:16,756
זה יהיה יותר טוב לערבב אותם אקראית

62
00:03:16,771 --> 00:03:19,718
או לסדר מחדש את הדוגמאות בקבוצת האימון שלך באופן אקראי.

63
00:03:19,733 --> 00:03:23,310
לפני שנחלק את הדוגמאות ל-70% הראשונים בקבוצת האימון

64
00:03:23,325 --> 00:03:26,669
ו-30% האחרונים בקבוצת הבדיקה.

65
00:03:27,054 --> 00:03:30,169
אז הנה תהליך טיפוסי למדי

66
00:03:30,185 --> 00:03:32,008
של איך בונים ובודקים

67
00:03:32,023 --> 00:03:34,492
את אלגוריתם הלמידה ואת הרגרסיה.

68
00:03:34,508 --> 00:03:38,115
ראשית, אנחנו לומדים את הפרמטרים θ מסדרת האימון

69
00:03:38,131 --> 00:03:41,798
וממזערים כרגיל את השגיאה של סדרת האימון (J(θ,

70
00:03:41,813 --> 00:03:44,713
כשכאן (J(θ הוגדר בעזרת

71
00:03:44,729 --> 00:03:47,059
70% מהנתונים שיש לנו.

72
00:03:47,075 --> 00:03:49,759
רק בעזרת נתוני האימון.

73
00:03:49,882 --> 00:03:52,167
ואז אנחנו מחשבים את השגיאה על סדרת הבדיקה או המבחן.

74
00:03:52,182 --> 00:03:56,298
ואנחנו נציין את שגיאת הבדיקה כ-J סימן תחתון test.

75
00:03:56,313 --> 00:03:59,229
אז מה שאנחנו עושים זה לקחת את הפרמטר θ

76
00:03:59,259 --> 00:04:02,190
שלמדנו מסדרת האימון, ומציבים אותו כאן

77
00:04:02,205 --> 00:04:04,875
כדי לחשב את השגיאה בסדרת הבדיקה.

78
00:04:04,890 --> 00:04:08,529
שאני אכתוב כדלקמן.

79
00:04:08,698 --> 00:04:11,275
זו בעצם

80
00:04:11,290 --> 00:04:15,244
השגיאה הממוצעת בריבוע

81
00:04:15,269 --> 00:04:18,154
כפי שהיא נמדדת על סט הבדיקה.

82
00:04:18,169 --> 00:04:19,915
זה פחות או יותר מה שאתם מצפים שיהיה פה.

83
00:04:19,931 --> 00:04:23,415
אנחנו מריצים כל דוגמה מסדרת הבדיקה דרך פונקציית ההשערה

84
00:04:23,431 --> 00:04:28,008
עם הפרמטר θ ופשוט מודדים את השגיאה בריבוע

85
00:04:28,023 --> 00:04:33,338
שההשערה נותנת על דוגמת המבחן הספציפית.

86
00:04:33,354 --> 00:04:37,054
זוהי כמובן ההגדרה של

87
00:04:37,069 --> 00:04:40,815
שגיאת ערכת המבחן כשאנחנו משתמשים ברגרסיה לינארית

88
00:04:40,831 --> 00:04:44,362
ובמדד השגיאה בריבוע.

89
00:04:44,377 --> 00:04:47,477
מה לדעתך היה המצב לו עשינו בעיית סיווג

90
00:04:47,492 --> 00:04:50,654
באמצעות רגרסיה לוגיסטית במקום זה?

91
00:04:50,669 --> 00:04:53,877
במקרה הזה, התהליך לאימון

92
00:04:53,892 --> 00:04:57,085
ובדיקה, זאת אומרת של הרגרסיה הלוגיסטית, יהיה דומה למדי לקודם.

93
00:04:57,100 --> 00:04:59,985
נחשב את הפרמטרים על פי נתוני האימון,

94
00:05:00,000 --> 00:05:02,331
שהם 70% הראשונים של הנתונים.

95
00:05:02,346 --> 00:05:05,115
ואז נחשב את שגיאת הבדיקה כדלקמן.

96
00:05:05,131 --> 00:05:07,015
זוהי אותה פונקצית מטרה

97
00:05:07,031 --> 00:05:09,592
בה אנו משתמשים תמיד ברגרסיה לוגיסטית,

98
00:05:09,608 --> 00:05:11,569
אלא שעכשיו אנחנו משתמשים בתת הקבוצה

99
00:05:11,585 --> 00:05:15,115
של דוגמאות הבדיקה כדי לחשב את השגיאה.

100
00:05:15,131 --> 00:05:17,600
למרות שההגדרה הזו של שגיאת ערכת המבחן

101
00:05:17,631 --> 00:05:20,238
על הפונקציה J היא הגדרה לגמרי טבעית,

102
00:05:20,254 --> 00:05:22,231
לפעמים יש מטריקה אלטרנטיבית

103
00:05:22,246 --> 00:05:25,469
של סדרת הבדיקה שעשויה להיות קלה יותר להבנה,

104
00:05:25,485 --> 00:05:27,877
וזו השגיאה של "סיווג שגוי".

105
00:05:27,892 --> 00:05:30,792
היא נקראת גם שגיאת סיווג-שגוי אפס-אחת,

106
00:05:30,808 --> 00:05:32,692
כשהאפס-אחת מציין

107
00:05:32,708 --> 00:05:36,146
שסיווגת את הדוגמה נכון או לא נכון.

108
00:05:36,162 --> 00:05:37,910
אסביר את כוונתי.

109
00:05:37,925 --> 00:05:41,795
תנו לי להגדיר את פונקצית שגיאת החיזוי.

110
00:05:41,825 --> 00:05:44,202
פונקצית החיזוי h של x.

111
00:05:44,218 --> 00:05:47,518
לגבי תווית y השגיאה

112
00:05:47,533 --> 00:05:51,848
שווה 1 אם ההשערה שלי

113
00:05:51,864 --> 00:05:54,633
מוציאה ערך גדול יותר או שווה ל-0.5

114
00:05:54,641 --> 00:05:57,510
ו-y שווה לאפס

115
00:05:57,525 --> 00:06:03,718
או אם ההשערה שלי מוציאה ערך של פחות מ 0.5

116
00:06:03,733 --> 00:06:05,402
ו-y שווה אחד,

117
00:06:05,418 --> 00:06:08,118
ברור, אלה שני המקרים האלה מתאימים

118
00:06:08,133 --> 00:06:11,833
למקרים שההשערה מוציאה שגיאה לגבי הדוגמא,

119
00:06:11,833 --> 00:06:14,518
בהנחה שהסף שלנו הוא 0.5.

120
00:06:14,533 --> 00:06:18,171
אז או חשבנו שיותר סביר שהתוצאה תהיה 1, אבל היא למעשה היתה 0,

121
00:06:18,187 --> 00:06:20,733
או שלפי ההשערה היה סביר יותר שהתוצאה

122
00:06:20,748 --> 00:06:23,556
היא 0, אבל התווית היתה למעשה 1.

123
00:06:23,571 --> 00:06:28,471
ואחרת, אנו מגדירים את פונקציית השגיאה הזו לאפס.

124
00:06:28,487 --> 00:06:34,841
אם ההשערה מסווגת את הדוגמה בצורה נכונה.

125
00:06:34,864 --> 00:06:38,841
ואז ניתן להגדיר את שגיאת הבדיקה,

126
00:06:38,856 --> 00:06:42,371
תוך שימוש במדד שגיאת החיזוי שכרגע הגדרנו

127
00:06:42,387 --> 00:06:46,779
להיות פשוט הממוצע של הסכום על כל סדרת הבדיקה

128
00:06:46,795 --> 00:06:49,941
מ- i שווה 1 עד m של סדרת המבחן

129
00:06:49,956 --> 00:06:55,164
של השגיאה של

130
00:06:55,179 --> 00:06:57,971
h של (x(i),y(i, חלקי מספר הדוגמאות.

131
00:06:57,987 --> 00:07:02,010
זו פשוט הדרך שלי לכתוב שזה בדיוק

132
00:07:02,025 --> 00:07:05,587
החלק של הדוגמאות בסדרת הבדיקה שלי

133
00:07:05,602 --> 00:07:08,864
בהם ההשערה שלי טעתה.

134
00:07:08,871 --> 00:07:10,602
אז זוהי ההגדרה

135
00:07:10,618 --> 00:07:13,687
של שגיאת ערכת הבדיקה

136
00:07:13,718 --> 00:07:16,948
באמצעות מדד שגיאת סיווג של אפס אחת.

137
00:07:16,971 --> 00:07:19,995
אז זוהי טכניקה סטנדרטית להערכת

138
00:07:20,010 --> 00:07:22,833
טיבה של ההשערה שנלמדה.

139
00:07:22,848 --> 00:07:25,579
בסרטון הבא, נתחיל להתאים את הרעיונות האלה

140
00:07:25,595 --> 00:07:28,525
כדי לעזור לנו לעשות דברים כמו לבחור אילו תכונות

141
00:07:28,541 --> 00:07:31,641
ודרגות של פולינום להשתמש באלגוריתם הלמידה שלנו,

142
00:07:31,656 --> 00:07:34,964
ואיך לבחור את פרמטר הרגולציה עבור אלגוריתם הלמידה.