בסרטון הזה, אני רוצה לדבר על איך לאתחל את K-מרכזים ודבר יותר חשוב, זה גם יוביל לדיון איך לגרום לK-מרכזים להימנע מאופטימום מקומי. הנה אלגוריתם האישכול K-מרכזים עליו דיברנו קודם. צעד אחד שאף פעם לא ממש דיברנו עליו הוא השלב הזה של איתחול אקראי של מרכזי אשכולות. ישנן מספר דרכים שונות שניתן לחשוב עליהן של איך לאתחל באקראי מרכזי אשכולות. אבל מתברר שיש שיטה אחת שהיא הרבה יותר מומלצת מאשר רוב האפשרויות האחרות שאפשר להעלות על הדעת. אז תרשו לי לספר לכם על האפשרות הזו כי נראה שהיא בדרך כלל עובדת הכי טוב. כך אני בדרך כלל מאתחל את מרכזי האשכולות שלי. כשמריצים את K-מרכזים, חייבים להגדיר את מספר מרכזי האשכולות K, להיות קטן ממספר דוגמאות ההכשרה m. זה יהיה ממש מוזר להפעיל את K-מרכזים כשמספר מרכזי האשכולות גדול או שווה למספר הדוגמאות, נכון? אז הדרך שבה אני בדרך כלל מאתחל את K-מרכזים היא, אני בוחר באקראי K דוגמאות אימון. ואז אני מגדיר את μ1 עד μK להיות שווים ל-K הדוגמאות האלה. תנו לי להראות לכם דוגמה קונקרטית. נניח ש-K שווה 2 ושבדוגמה הזו מימין אני רוצה למצוא שני אשכולות. אז מה שאעשה כדי לאתחל את מרכזי האשכולות הוא לבחור כמה דוגמאות באופן אקראי. ונניח שאני בוחר את זו ואת זו. והאופן שבו אני מאתחל את מרכזי האשכולות הוא כזה, אני פשוט מאתחל את מרכזי האשכול להיות ממש על הדוגמאות האלה. אז זה מרכז האשכול הראשון וזה מרכז האשכול השני, וזו שיטה אחת לאתחול אקראי של K-מרכזים. הבחירה שלי נראית כבחירה טובה במיוחד. לפעמים יש לי פחות מזל ואולי יוצא לי לבחור את זה בתור הראשון באקראי, ואת זה בתור השני. וכזכור אני בוחר שתי דוגמאות כי K שווה 2. אז בחרנו באופן אקראי שתי דוגמאות אימון ואם בחרתי את שתי אלה אז קיבלנו את המרכז הראשוני של האשכול הראשון כאן ואת המיקום הראשוני של המרכז השני כאן. אז, ככה אפשר לאתחל באופן אקראי מרכזי אשכולות. אז בעת האתחול, מרכז האשכול הראשון μ1 יהיה שווה ל-(x(i עבור ערך אקראי כלשהו של i ו-μ2 יהיה שווה ל-(x(j עבור איזשהו ערך אקראי שונה של j וכן הלאה, אם יש לנו יותר אשכולות ויותר מרכזים. והערת אגב, אני חייב לומר שבוידאו הקודם שבו איירנו את K-מרכזים עם האנימציה, בקבוצה ההיא של שקופיות, רק לצורך המחשה, אני בעצם השתמשתי בשיטה שונה של אתחול מרכזי האשכולות. אבל השיטה המתוארת בשקופית הזו, זו באמת הדרך המומלצת. וזו הדרך שבה אתם מן הסתם צריכים להשתמש, כאשר אתם מממשים K-מרכזים. אז כפי אולי ניתן להבין משתי הדוגמאות המצוירות כאן מימין, אתם בעצם יכולים לנחש שK-מרכזים יכול להתכנס לפתרונות שונים בתלות באיתחול האשכולות, זאת אומרת שבהתאם לאתחול האקראי, K-מרכזים יכול להגיע לפתרונות שונים. ובפרט, K-מרכזים בעצם עלול להגיע לאופטימום מקומי. אם אתה מקבל ערכת נתונים כזו, אז זה נראה כאילו יש כאן שלושה אשכולות, אז אם אתה מפעיל את K-מרכזים ואם הוא מתכנס למינימום מקומי טוב שיכול גם להיות המינימום הגלובלי, אתה עשוי לקבל אישכול כזה. אבל אם היה לך איתחול אקראי רע במיוחד, K-מרכזים יכול גם להיתקע במינימום מקומי כלשהו. אז בדוגמה הזו בצד שמאל זה נראה כאילו האשכול הכחול לכד הרבה נקודות משמאל ואילו האשכולות האדום והירוק לכדו מספר קטן יחסית של נקודות כל אחד. אז זה מתאים למינימום מקומי גרוע, משום שהוא לקח את שני האשכולות הללו ומיזג אותם לאחד, ויתרה מזאת, פיצל את האשכול השני לשני תת-אשכולות נפרדים, והוא גם פיצל את האשכול השלישי לשני אשכולות משנה נפרדים כמו זה, אז שתי הדוגמאות האלה מימין למטה מתאימות למינימום מקומיים שונים של K-מרכזים ולמעשה, בדוגמה הימנית, האשכול האדום בעצם לכד רק דוגמה אחת. המונח אופטימום מקומי, אגב, מתייחס לאופטימום המקומי של פונקצית העיוות J, והפתרונות האלה כאן למטה, האופטימומים המקומיים תואמים לפתרונות כאלה שבהם K-מרכזים נתקע במינימום מקומי ולא באמת מצליח למזער את פונקצית העיוות J. אז אם אתם מודאגים לגבי כך שK-מרכזים יתקע במינימום מקומי, אם אתם רוצים להגדיל את הסיכויים שK-מרכזים ימצא את חלוקת האשכולות הטובה ביותר האפשרית, כמו זו שמוצגת כאן למעלה, מה שאפשר לעשות הוא לנסות התאמות אקראיות מרובות. במקום לאתחל את K-מרכזים פעם אחת ולקוות שהוא יעבוד, מה שאנחנו יכולים לעשות הוא, לאתחל את K-מרכזים הרבה פעמים ולהפעיל את K-מרכזים הרבה פעמים, ולהשתמש בזה כדי לנסות להיות בטוחים שאנחנו מקבלים פתרון טוב לפחות כמו מינימום מקומי או גלובלי טוב ככל האפשר. באופן קונקרטי, הנה איך אפשר לעשות את זה. נניח, אני יכול להחליט להפעיל את K-מרכזים מאה פעמים, אז אני אבצע את הלולאה הזאת מאה פעמים וזה מספר אופייני למדי של פעמים בK-מרכזים, כשהטווח עשוי להיות בין 50 ל-1000. אז נניח שאתה מחליט להריץ את K-מרכזים מאה פעמים. אז מה שזה אומר הוא שאנחנו נאתחל את K-מרכזים באופן אקראי. ועבור כל פעם שאנחנו מאתחלים אקראית, אנחנו נפעיל את K-מרכזים וזה ייתן לנו קבוצה של אשכולות, ומערכת של מרכזים של אשכולות, ואז נחשב את פונקצית העיוות J, זאת אומרת נחשב את פונקצית העלות על קבוצת ההקצאות לאשכולות ומרכזי האשכולות שקיבלנו. ואז, לאחר שעשינו את כל התהליך הזה מאה פעמים, יהיו לך מאה דרכים שונות לאישכול של הנתונים ואז בסופו של דבר מה שצריך לעשות הוא מבין כל מאה הדרכים האלה שמצאת לבנות אשכולות נתונים, פשוט לבחור דרך אחת, את זו שנותנת לנו את העלות הנמוכה ביותר. זאת שנותנת לנו את העיוות הנמוך ביותר. מתברר שאם אתה מפעיל את K-מרכזים עם מספר קטן יחסית של אשכולות, אם מספר האשכולות הוא איזה שהוא מספר בין שתיים עד אולי 10, אז להריץ מספר גדול של אתחולים אקראיים יכול לפעמים לוודא שתמצא מינימום מקומי טוב יותר. לוודא שתמצא דרך טובה יותר לקיבוץ אשכולות. אבל אם K הוא גדול מאוד, אם K הוא הרבה יותר גדול מ-10, בוודאות אם K הוא, אם אתה מנסה למצוא מאות אשכולות, אז להרצה של מספר אתחולים אקראיים יש סיכוי קטן יותר לשנות הרבה, ויש סיכוי הרבה יותר גבוה שכבר האתחול האקראי הראשון שלך ייתן לך פתרון די סביר, ואולי, וכנראה, להריץ כמה נסיונות ייתן לך פתרון קצת יותר טוב אבל אולי לא בהרבה. רק באזור שבו יש לך מספר קטן יחסית של אשכולות, במיוחד אם יש לך נניח 2 או 3 או 4 אשכולות, אז להריץ כמה נסיונות של אתחול אקראי יכול לעשות הבדל עצום בוידוא של הצלחה במיזעור של פונקצית העיוות ולתת לך סידור אשכולות טוב. אז זהו הנושא של אתחול אקראי בK-מרכזים. אם אתה מנסה ללמוד אשכולות עם מספר קטן יחסית של אשכולות, 2, 3, 4, 5, אולי, 6, 7, אז מספר רב של אתחולים אקראיים יכול לפעמים לעזור לך למצוא חלוקת אשכולות הרבה יותר טובה של הנתונים. אבל אם אתה לומד מספר רב של אשכולות, אז שיטת האתחול האקראית שתיארתי כאן אמורה לתת לK-מרכזים נקודת התחלה סבירה להתחיל כדי למצוא חלוקה טובה לאשכולות.