Uvek se potvrdi kao tačno to da, najpouzdaniji način da dobijete jako kvalitetan sistem mašinskog učenja je da uzmete algoritam učenja sa malim pretpostavkama i da ga trenirate na velikom skupu podataka. Ali gde da nabavite tako veliki skup podataka? Ispostavilo se da u mašinskom učenju postoji ideja koja se zove veštačka sinteza podataka, ne primenjuje se na svaki pojedinačni problem, i, da bi se primenio na određeni problem, često je potrebna neka misao, inovacija ili shvatanje. Ali ako ova ideja može da se primeni na vaš problem mašinskog učenja, to ponekad može da bude lak način da dobijete ogroman skup trening podataka za vaš algoritam učenja. Ideja sinteze veštačkih podataka obuhvata dve varijacije, prva i glavna je ako u suštini kreiramo podatke iz [xx], kreiramo ih iz početka. A drugi je da, ako već imamo mali skup podataka natpisa i nekako ga proširimo ili koristimo mali skup trening podataka da bismo ga umetnuli u u veći skup trening podataka a u ovom videu preći ćemo obe ideje. Da bismo pričali o ideji sinteze veštačkih podataka, koristićemo skup znakova OCR foto kanala, želimo da uzmemo ulaznu sliku i prepoznamo koji je to znak. Ako idemo dalje i prikupimo veliki skup podataka natpisa evo šta je to i kako izgleda. Za ovaj konkretan primer, 
odabrao sam kvadratnu razmeru, Dakle, uzimamo kvadratne zakrpe od slika. Cilj je da uzmemo sliku i prepoznamo znak u sredini te slike. Zbog jednostavnosti smatraću te slike kao slike u sivom tonu, a ne kao slike u boji. Ispostavilo se da korištenje boje ne pomaže mnogo za ovaj konkretan problem. Za datu sliku, hteli bismo da prepoznamo da je to T. Za ovu sliku, hteli bismo da prepoznamo da je to S. Za datu sliku hteli bismo da prepoznamo to kao 'I' i tako dalje. Sve to su naši primeri slika u redovima, kako bismo izašli na kraj sa mnogo većim trening skupom? Savremeni računari često imaju ogromnu biblioteku fontova i ako koristite program za obradu reči, u zavisnosti od toga koju reč procesor koristi, mogli biste imati sve te fontove i mnogo, mnogo više već sačuvanih. U stvari, ako posećujete različite veb sajtove, tamo opet imamo ogromne biblioteke besplatnih fontova i sa interneta možemo da skinemo mnogo, mnogo različitih tipova fontova, stotine 
i možda hiljade različitih fontova. Dakle, ako želite više trening primera, ono što možete da uradite jeste da samo uzmete znakove različitih fontova i zalepite ih preko različitih, slučajno odabranih pozadina. Znači, mogli biste uzeti ovo 
i zalepiti to c preko neke pozadine. Ako to uradite, imaćete trening skup od jedne slike znaka C. Dakle, nakon malo rada, znate ovo, to je malo posla da biste spojili podatke stvarnog izgleda. Ali nakon malo rada, možete da dobijete vještački 
trening skup podataka kao taj. Svaka slika na desnoj strani je u stvari veštačka. Možete da uzmete font, možda slučajan font skinut sa veba i zalepite sliku jednog znaka ili nekoliko znakova tog fonta preko ove slučajno odabrane slike. I tad možda da uradite malo operacija zamagljivanja, malo pretrage, izvrtanja znači samo deljenje i promene veličine i malo operacija rotacije i ako uradite sve to dobićete veštački trening skup, kao ovaj prikazani. I to je posao razvrstavanje, to zahteva razmišljanje na poslu, da bi se postiglo da veštački podaci izgledaju stvrano, i ako budete nemarni kada budete kreirali veštačke podatke, 
sistem vam neće raditi kako treba. Ali ako pogledate, veštački podaci izgledaju 
izuzetno slično stvarnim podacima. Dakle, korištenjem veštačkih podataka vi u suštini imate neograničenu nabavku trening primera za veštačku sintezu podataka. i tako, ako koristite ovaj izvor veštačkih podataka, imate suštinski neprekidnu snabdevenost primerima da biste kreirali improvizovani algoritam učenja za problem prepoznavanja znakova. Dakle, ovo je primer sinteze veštačkih podataka gde u osnovi kreirate nove podatke iz početka, vi samo generišete 
potpuno nove slike iz početka. Drugi glavni pritsup sintezi veštačkih podataka je da uzmete primere koje već imate, uzmete stvaran primer, možda sa stvarne slike, i kreirate dodatne podatke, da biste obogatili vaš skup trening podataka. Dakle, ovde je slika u poređenju sa jednom stvarnom slikom, nesintetizovanom, i prekrio sam to linijama mreže radi ilustracije. U stvari imate ovo. Šta možete da uradite jeste da uzmete ovaj alfabet ovde, uzmete ovu sliku i uvedete veštački poremećaj ili veštačko izobličenje na slici tako da može da se uzme slika i umetne u 16 novih primera. Znači da na ovaj način možete da uzmete mali označeni trening skup i obogatite vaš trening skup i uskoro imate mnogo više primera, sve njih. Još jednom, da biste uradili ovo za aplikaciju, treba da se razmisli i treba da se shvati šta su razumni skupovi poremećaja, ili da li su pravi načini da biste obogatili i umnožili vaš trening skup, i za specifičan primer prepoznavanja znakova, uvođenje ovog poremećaja se čini kao prirodan izbor, ali za različite aplikacije mašinskog učenja, mogu da budu različita izobličavanja koja imaju više smisla. Dozvolite mi da vam pokažem jedan primer iz potpuno drugačijeg domena prepoznavanja govora. Dakle, prepoznavanje govora, recimo imate audio klipove i želite da učite iz audio klipa da biste prepoznali koje su reči izgovorene u tom klipu. Dakle, hajde da vidimo jedan označeni trening primer. Recimo da imate jedan označeni trening primer, neko kaže par određenih reči. Hajde da pokrenemo taj klip ovde. 0-1-2-3-4-5. U redu, znači neko broji od 0 do 5, znači, želite da pokušate da primenite algoritam učenja da biste prepoznali rečene reči. Kako da obogatimo skup podataka? Dakle, ono šta radimo je da uvodimo dodatna udio 
izobličenja u skup podataka. Evo ovde ću da dodam pozadinske zvukove da 
bih simulirao lošu telefonsku vezu. Kad budete čuli bip zvukove, to je u stvari dio audio trake, zvučnici su u redu, pustiću to sad. 0-1-2-3-4-5. U redu, znači možete da slušate tu vrstu audio klipa i možete prepoznati zvukove, čini se kao još jedan koristan trening primer, ovo je još jedan primer, bučna pozadina. Nula, jedan, dva, tri četiri, pet znate auta koji prolaze, ljudi koji hodaju u pozadini, ovde je još jedan, tako da, uzimajući originalni neizmenjeni audio klip, znači uzimajući čist audio nekog ko govori 0 1 2 3 4 5 možemo tad automatski da sintetišemo dodatne trening primere i tako obogatimo jednim trening primerom možda 
i četiri trening primera. Hajde da pustim ovaj konačni primer. 0-1-2-3-4-5. Znači, uzimajući samo jedan označen primer, moramo da uložimo napor da bi se pribavio samo jedan označen primer sačinjen od 01205, i uvodeći dodatna izobličenja, uvodeći različite pozadinske zvukove, umnožili smo ovaj jedan primer u mnogo više. Veliki posao, a samo smo automatski dodali različite pozadinske zvukove na čist audio. Samo još jedna reč upozorenja u vezi sa sintezom podataka pomoću izobličenja: ako to radite za sebe, izobličenja koja uvodite bi trebala da budu pogodan izvor buke, ili izobličenja, koja biste mogli da vidite u testnom skupu. Dakle, za primer prepoznavanja znakova, znate, sve ovi pojmovi koje smo uveli su nekako sa razlogom, jer slika koja izgleda kao ta bi mogla da bude slika koju bismo mogli da vidimo u testnom skupu,
 odražava stvarnost. Znate, ta slika gore-desno, to bi mogla da bude slika 
koju bismo mogli da zamislimo. A za audio, dakle, želimo da prepoznamo govor, uprkos lošoj internoj vezi, uprkos različitim tipovima pozadinske buke, i za audio, ponovo pravimo primere koji su u stvari reprezentativne vrste primera koje želimo da klasifikujemo, koje želimo tačno da prepoznamo. Suprotno tome, obično vam možda ne pomaže značenje kao što je buka vašim podacima. Nisam siguran da možete da vidite ovo, ono što smo uradili ovde je da smo uzeli sliku, i za svaku tačku, u svakoj od ove 4 slike, je samo dodat neki slučajan Gausov šum svakoj tački. Svakoj tački, na osvetljenost tačke, se dodaje neki, znate, možda 
slučajan Gausov šum. Dakle, to je potpuno besmislen šum, u redu? I, ukoliko ne očekujete da vidite ove vrste šuma na tačkama u vašem testnom skupu, ova vrsta potpuno slučajnog besmislenog 
šuma je verovatno beskorisna. Ali proces sinteze veštačkih podataka je, znate, pomalo i umetnost i ponekad samo treba da je probate i vidite da li radi. Ali ako pokušavate da odlučite koju vrstu izobličenja da dodate, znate, razmislite koja još smislena izobličenja biste mogli da dodate da biste generisali dodatne trening primere koji su barem neka reprezentativna vrsta slika koje očekujete u svom testnom skupu. Konačno, da završimo ovaj video, samo želim da kažem par reči, više o ovoj ideji dobijanja izgubljenih podataka putem sinteze veštačkih podataka. Kao i uvek, pre nego uložite mnogo napora, znate, da shvatite kako da kreirate veštačke trening podatke, često je dobra praksa da se uverite da stvarno niste pristrasni, i da će mnogo trening podataka da bude od pomoći. Standardan način da to uradite jeste da unesete krive učenja, i da budete sigurni da jedino imate nisko, kao i visoko srednje kvadratno odstupanje. Ili ako nemate nisku srednju kvadratnu devijaciju, znate, još jedna stvar koju vredi da probate je da nastavite da povećavate broj karakteristika koje ima vaš klasifikator povećavajući broj sakrivenih jedinica u vašoj mreži, recimo, dok god ne dobijete nisku srednju kvadratnu devijaciju, i samo tad, treba da uložite napor da biste kreirali veliki skup veštačkih podataka, dakle, šta u stvari želite da izbegnete je da, znate, potrošite celu sedmicu ili par meseci otkrivajući kako da dobijete sjajno sintetizovan skup veštačkih podataka. Samo da zaključimo, znate, vaš algoritam učenja, performanse se neće poboljšati toliko mnogo, 
iako imate ogroman trening skup. Dakle, to je moj uobičajeni savet o testiranju da budete sigurni da 
stvarno možete da koristite veliki trening skup pre nego uložite mnogo truda da biste 
dobili taj trening skup. Drugo, kada rešavam probleme mašinskog učenja, jedno pitanje koje često pitam tim sa kojim radim, često pitam svoje studente, jeste koliko posla bi trebalo da se uradi da se dobije
 10 puta više podataka od onoga što imamo sad. Kada se sretnem sa novom aplikacijom mašinskog učenja, veoma često sednem sa timom i pitam upravo to pitanje, postavljam to pitanje opet i opet i opet i budem veoma iznenađen koliko često ovaj odgovor bude. Znate, stvarno nije tako teško, možda dva dana posla uglavnom, da dobijete deset puta više podataka od onoga što sada imamo za aplikaciju mašinskog učenja i veoma često ako možete da dobijete deset puta više podataka, postojaće način da mnogo poboljšate vaš algoritam. Dakle, ako se ikada pridružite timu koji radi na nekoj aplikaciji mašinskog učenja, ovo je veoma dobro pitanje da sebi postavite, ako pitate tim, nemojte biti previše iznenađeni ako posle par minuta mozganja vaš tim se pojavi sa načinom da dobije deset puta više podataka, u tom slučaju biste bili heroj za taj tim, jer sa deset puta većim skupom podataka, mislim da biste stvarno dobili mnogo bolje performanse,
 zbog učenja iz tako velikog skupa. Dakle, postoji nekoliko načina koji dele ideje generisanja podataka iz početka koristeći slučajne fontove i tako dalje. Kao i druga ideja uzimanja postojećeg primera i upotreba izobličavanja koja povećavaju trening skup, par drugih načina da se dobije više podataka su prikupljanje podataka ili obeležavanje. Jedan koristan proračun koji često pravim jeste, znate, koliko minuta, koliko sati traje prikupljanje određenog broja primera, dakle, sedite i shvatite, znate, pretpostavimo da traje deset sekundi da označite jedan primer i, pretpostavimo da, za našu aplikaciju, trenutno imamo 1000 obeleženih primera pa bi deset puta više od toga bilo da je n jednako deset hiljada. Drugi način da dobijete mnogo podataka je da samo prikupite podatke i obeležite ih. Dakle, šta mislim ovim je da bih često seo i pravio proračun da shvatim koliko vremena, znate, kao koliko sati će da traje, koliko sati ili koliko dana će da traje za mene ili za nekoga drugoga da prikupi deset puta više podataka, nego što imamo trenutno, prikupljanjem i obeležavanjem ručno. Na primer, za našu aplikaciju mašinskog učenja, trenutno imamo 1000 primera, dakle M 1,000. Šta mi uradimo je da sednemo i zapitamo se, koliko će nam trebati vremena da sakupimo i obeležimo jedan primer. Ponekad će možda trebati, znate, desed sekundi za označavanje jednog novog primera, i tako ako želim 10 x veći primer, pravim proračun. Ako mi za jedan trening primer treba 10 sekundi, ako želim da dobijem 10 puta više podataka, trebaće mi 10,000 primera. Dakle, pravim proračun, koliko će mi trebati vremena da ručno obeležim 10,000 primera, ako mi treba 10 sekundi da obeležim jedan primer. Kada napravite taj proračun, često vidim da su mnogi od vas iznenađeni, znate, koliko malo, ponekad par dana posla, ponekad mali broj dana posla, dakle, viđao sam mnoge timove koji su iznenađeni koliko je to malo posla da dobijete mnogo više podataka, i neka to bude način da vaša aplikacija učenja ima mnogo bolje performanse, i obavezno, znate, ponekad kad trebate da uradite to, bićete junak, bez obzira u kom timu radite, jer ovo može da bude sjajan način da dobijete mnogo bolje performanse. Treće i poslednje, ponekad je dobar način da dobijete mnogo podataka da koristite ono što sad zovemo izvor gomile. Dakle danas postoji par veb sajtova ili par servisa koji vam omogućavaju da zaposlite ljude na vebu da, znate, prilično jeftino obeležite veliki trening skup. Dakle, ova ideja izvora gomile, ili obeležavanje podataka od gomile, je nešto, očigledno, kao potpuna akademska literatura, ima svoje komplikacije i tako dalje, čuvajući pouzdanost obeleživača. Možda, znate, stotine hiljada obeleživača celog sveta radi prilično jeftino da bi pomoglo da se podaci obeleže, i to sam upravo spomenuo, ovo je takođe jedna od alternativa. I Amazon Mehanikal Turk sistem je verovatno najpopularnija opcija izvora gomile sistema. To je često popriličan posao, popriličan posao, ako želite da dobijete veoma kvalitetna obeležja, ali je ponekad opcija vredna razmatranja. Ako želite da pokušate da zaposlite mnogo ljudi, prilično jeftino, naši obeleživači lansiraju milione podataka za vas. Dakle, u ovom videu govorili smo o ideji sinteze veštačke inteligencije putem kreiranja podataka od početka, gledajući, koristeći skinute fontove na primer, ili obogaćujući postojeći trening skup, uzimajući postojeće obeležene primere i primenjujući izobličavanja nad njima, da biste kreirali dodatne obeležene primere. I konačno, nadam se da ste zapamtili jednu stvar iz ovog videa, ako se susretnete sa problemom mašinskog učenja, često vredi da se urade dve stvari. Jedna je provera, sa krivom učenja, da li bi pomoglo da imate još podataka. I drugo, pretpostavimo da je to slučaj, ja bih često seo i ozbiljno se zapitao: koliko bi trebalo vremena da se dobiju deset puta kreativniji podaci nego što trenutno imate, i ne uvek, već ponekad, možda ćete biti iznenađeni time kako to može da bude lako, možda par dana, par sedmica posla, i to bi mogao da bude sjajan način da svom algoritmu učenja poboljšate performanse.