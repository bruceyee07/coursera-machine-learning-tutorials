1
00:00:00,240 --> 00:00:04,540
עבור רגרסיה ליניארית, דיברנו כבר על שני אלגוריתמי למידה.

2
00:00:04,540 --> 00:00:08,780
האחד מבוסס על ירידה במדרון והשני מבוסס על המשוואה הנורמלית.

3
00:00:08,780 --> 00:00:11,607
בסרטון הזה ניקח את שני האלגוריתמים

4
00:00:11,607 --> 00:00:15,087
ונכליל אותם למקרה של רגרסיה ליניארית מוסדרת.

5
00:00:17,363 --> 00:00:20,994
הנה יעד האופטימיזציה שהגענו אליו בפעם שעברה

6
00:00:20,994 --> 00:00:23,390
עבור רגרסיה ליניארית מוסדרת.

7
00:00:23,390 --> 00:00:27,795
החלק הראשון הוא המטרה הרגילה שלנו עבור רגרסיה ליניארית.

8
00:00:27,795 --> 00:00:32,682
וחוץ מזה יש לנו את מונח ההסדרה הנוסף, שבו למבדה

9
00:00:32,682 --> 00:00:37,170
הוא הפרמטר שלנו, והיינו רוצים למצוא את הפרמטרים תטא

10
00:00:37,170 --> 00:00:41,880
שממזערים את פונקצית העלות הזו, פונקציית העלות המוסדרת הזו, J של תטא.

11
00:00:41,880 --> 00:00:44,780
בעבר, השתמשנו בירידה במדרון עבור

12
00:00:44,780 --> 00:00:49,370
פונקציית העלות המקורית ללא מונח ההסדרה.

13
00:00:49,370 --> 00:00:53,680
והשתמשנו באלגוריתם הבא, עבור רגרסיה ליניארית רגילה, ללא

14
00:00:53,680 --> 00:00:58,490
הסדרה, חזרנו שוב ושוב ועדכנו את הפרמטרים תטא-j כך:

15
00:00:58,490 --> 00:01:00,840
עבור j שווה 0, 1, 2, ועד n.

16
00:01:02,040 --> 00:01:07,240
תרשו לי לקחת את זה ופשוט לכתוב את המקרה עבור תטא-0 בנפרד.

17
00:01:07,240 --> 00:01:12,690
אני פשוט הולך לכתוב את העדכון עבור תטא-0 בנפרד מאשר

18
00:01:12,690 --> 00:01:17,150
העדכון עבור הפרמטרים 1, 2, 3, וכן הלאה עד n.

19
00:01:17,150 --> 00:01:19,990
וכך זה, אני לא שיניתי כאן שום דבר עדיין, נכון?

20
00:01:19,990 --> 00:01:24,670
זה אותו דבר רק שהעדכון עבור תטא-0 כתוב בנפרד מן העדכונים עבור תטא-1,

21
00:01:24,670 --> 00:01:26,870
תטא-2, תטא-3, עד תטא-n.

22
00:01:26,870 --> 00:01:30,590
והסיבה שאני רוצה לעשות את זה היא כי כפי שאתם אולי זוכרים עבור

23
00:01:30,590 --> 00:01:35,000
רגרסיה ליניארית מוסדרת, אנו קונסים את הפרמטרים תטא-1, תטא-2,

24
00:01:35,000 --> 00:01:36,740
וכן הלאה עד תטא-n.

25
00:01:36,740 --> 00:01:38,950
אבל אנחנו לא קונסים את תטא-0.

26
00:01:38,950 --> 00:01:43,730
אז כאשר נשנה את האלגוריתם הזה עבור רגרסיה ליניארית מוסדרת,

27
00:01:43,730 --> 00:01:47,480
אנחנו עומדים לטפל בתטא-אפס מעט אחרת.

28
00:01:48,550 --> 00:01:52,350
למעשה, אם אנחנו רוצים לקחת את האלגוריתם הזה

29
00:01:52,350 --> 00:01:55,449
ולשנות אותו ולהשתמש במטרה המוסדרת, כל מה שאנחנו

30
00:01:55,449 --> 00:02:00,460
צריכים לעשות זה לקחת את המונח הזה כאן למטה ולשנות אותו כדלקמן.

31
00:02:00,460 --> 00:02:03,820
ניקח את המונח הזה

32
00:02:03,820 --> 00:02:08,950
ונוסיף לו "מינוס למבדה חלקי m כפול תטא j".

33
00:02:08,950 --> 00:02:13,090
ואם נעשה את זה, אנחנו מקבלים ירידה במדרון

34
00:02:13,090 --> 00:02:18,050
שמנסה למזער את פונקצית העלות המוסדרת J של תטא.

35
00:02:18,050 --> 00:02:22,390
ובאופן קונקרטי, אני לא הולך לעשות כאן מתמטיקה כדי להוכיח את זה, אבל

36
00:02:22,390 --> 00:02:27,790
באופן קונקרטי אם מסתכלים על המונח הזה שכתבתי כאן בסוגריים מרובעים,

37
00:02:27,790 --> 00:02:31,170
אם אתה יודע מספיק חשבון דיפרנציאלי אפשר להוכיח כי המונח הזה

38
00:02:31,170 --> 00:02:35,050
הוא הנגזרת החלקית ביחס ל-J של תטא

39
00:02:35,050 --> 00:02:39,722
על פי ההגדרה החדשה של J של תטא עם מונח ההסדרה.

40
00:02:39,722 --> 00:02:48,030
ושימו לב שהמונח הזה כאן למעלה שמסביבו אני מצייר תיבה בטורקיז,

41
00:02:48,030 --> 00:02:53,040
זו עדיין הנגזרת החלקית על פי תטא אפס של J של תטא.

42
00:02:53,040 --> 00:02:56,220
אם תסתכלו על העדכון עבור תטא j,

43
00:02:56,220 --> 00:02:59,005
אפשר להראות משהו מעניין מאוד.

44
00:02:59,005 --> 00:03:03,760
מה שקורה הוא שתטא j מתעדכן כתטא j מינוס אלפא כפול

45
00:03:03,760 --> 00:03:07,950
המונח האחר הזה כאן שתלוי בתטא j.

46
00:03:07,950 --> 00:03:11,170
אז אם נקבץ את כל התנאים התלויים בתטא j,

47
00:03:11,170 --> 00:03:15,850
אפשר לראות שהעדכון הזה יכול להיכתב באופן שקול כדלקמן.

48
00:03:15,850 --> 00:03:20,280
וכל מה שעשיתי היה להוסיף תטא j כאן, אז תטא j כפול 1.

49
00:03:20,280 --> 00:03:25,650
והמונח הזה כאן הוא למבדה חלקי m, יש כאן גם אלפא,

50
00:03:25,650 --> 00:03:29,390
אז מה שיוצא בסוף הוא אלפא כפול למבדה חלקי m כפול תטא j.

51
00:03:30,540 --> 00:03:38,090
והמונח הזה כאן, 1 פחות אלפא כפול למבדה חלקי m, הוא מונח מעניין למדי.

52
00:03:38,090 --> 00:03:39,820
יש לו השפעה די מעניינת.

53
00:03:42,370 --> 00:03:46,320
המונח הזה, 1 פחות אלפא כפול למבדה חלקי m,

54
00:03:46,320 --> 00:03:51,340
יהיה מספר שהוא בדרך כלל קצת פחות מאחת,

55
00:03:51,340 --> 00:03:55,895
כי אלפא כפול למבדה חלקי m הוא חיובי, ובדרך כלל

56
00:03:55,895 --> 00:03:59,765
אם שיעור הלמידה אלפא הוא קטן ואם m הוא גדול, הוא בדרך כלל יוצא די קטן.

57
00:03:59,765 --> 00:04:03,275
אז המונח הזה כאן יהיה מספר שהוא בדרך כלל קצת קטן מ-1,

58
00:04:03,275 --> 00:04:07,115
אז בואו נחשוב עליו כעל משהו כמו 0.99, נניח.

59
00:04:07,115 --> 00:04:10,515
ולכן ההשפעה של העדכון שלנו לתטא j היא

60
00:04:10,515 --> 00:04:15,915
שאנחנו נאמר משהו כמו שתטא j מקבל ערך של תטא j כפול 0.99, ברור?

61
00:04:16,915 --> 00:04:21,300
תטא j כפול 0.99 יש לו את ההשפעה

62
00:04:21,300 --> 00:04:23,780
של הקטנה קטנה של תטא j.

63
00:04:23,780 --> 00:04:26,070
אז זה עושה את תטא j קצת יותר קטן.

64
00:04:26,070 --> 00:04:31,510
זה מקטין קצת את הנורמה הריבועית של תטא - הפרמטרים נעשים יותר קטנים.

65
00:04:31,510 --> 00:04:35,980
והמונח השני כאן, הוא ממש אותו מונח

66
00:04:35,980 --> 00:04:40,830
של העדכון המקורי של הירידה במדרון שהיה לנו,

67
00:04:40,830 --> 00:04:44,250
לפני שהוספנו את כל ענייני ההסדרה.

68
00:04:44,250 --> 00:04:49,188
אז אני מקווה שהעדכון הזה נראה הגיוני.

69
00:04:49,188 --> 00:04:52,110
כאשר אנו משתמשים ברגרסיה ליניארית מוסדרת,

70
00:04:52,110 --> 00:04:56,190
מה שאנו עושים הוא בכל איטרציה, אנחנו מכפילים את תטא j במספר

71
00:04:56,190 --> 00:05:00,270
שהוא קצת קטן מ-1, כך שזה מקטין קצת את הפרמטר,

72
00:05:00,270 --> 00:05:04,170
ואז אנחנו עושים עדכון דומה למה שעשינו בעבר.

73
00:05:04,170 --> 00:05:09,005
כמובן זו רק האינטואיציה מאחורי מה שהעדכון המסוים הזה עושה.

74
00:05:09,005 --> 00:05:12,995
מבחינה מתמטית מה שהוא עושה הוא בדיוק ירידה במדרון

75
00:05:12,995 --> 00:05:18,175
על פונקציית העלות J של תטא שהגדרנו בשקופית הקודמת, זו המשתמשת

76
00:05:18,175 --> 00:05:19,825
במונח ההסדרה.

77
00:05:19,825 --> 00:05:24,500
ירידה במדרון הייתה רק אחד משני האלגוריתמים

78
00:05:24,500 --> 00:05:26,660
שלנו עבור התאמת מודל רגרסיה לינארית.

79
00:05:26,660 --> 00:05:30,200
האלגוריתם השני היה זה המבוסס על המשוואה הנורמלית,

80
00:05:30,200 --> 00:05:34,840
כאשר מה שעשינו היה שיצרנו את מטריצת העיצוב X שבה

81
00:05:34,840 --> 00:05:38,900
כל שורה מתאימה לדוגמת אימון אחת.

82
00:05:38,900 --> 00:05:45,440
ויצרנו וקטור y, וקטור, וקטור m ממדי.

83
00:05:45,440 --> 00:05:48,480
שהכיל את התוויות של סדרת האימון.

84
00:05:48,480 --> 00:05:57,030
זאת אומרת ש-X הוא מטריצה עם ממדים (m x (n + 1, ואילו y הוא וקטור מממד m.

85
00:05:57,030 --> 00:06:02,970
וכדי למזער את פונקצית העלות J, ראינו

86
00:06:02,970 --> 00:06:07,295
שאחת מהדרכים לעשות את זה היא להגדיר את תטא להיות שווה לזה.

87
00:06:07,295 --> 00:06:13,090
זוכרים, ההופכי של (X משוחלפת כפול X), כפול X משוחלפת כפול y.

88
00:06:13,090 --> 00:06:15,730
אני משאיר כאן מקום כדי למלא דברים כמובן.

89
00:06:15,730 --> 00:06:20,160
ומה שהערך הזה עבור תטא עושה

90
00:06:20,160 --> 00:06:25,040
הוא למזער את פונקצית העלות J של תטא, הפונקציה ללא הסדרה.

91
00:06:26,340 --> 00:06:31,240
כעת, כאשר אנו כן משתמשים בהסדרה, אם ננסה לגזור ולמצוא את המינימום,

92
00:06:31,240 --> 00:06:35,060
ורק כדי לתת לכם תחושה איך עושים את החישוב הזה, הדרך בה עושים את זה

93
00:06:35,060 --> 00:06:39,494
היא לעשות נגזרות חלקיות לגבי כל פרמטר.

94
00:06:39,494 --> 00:06:42,880
להשוות אותן לאפס, ואז לעשות קצת מתמטיקה

95
00:06:42,880 --> 00:06:48,600
ואפשר להראות שזו נוסחה כמו זו שממזערת את פונקציית העלות.

96
00:06:48,600 --> 00:06:53,930
וכפי שנראה, אם כן משתמשים בהסדרה,

97
00:06:53,930 --> 00:06:55,940
אז הנוסחה הזו משתנה כדלקמן.

98
00:06:55,940 --> 00:06:59,490
בתוך הסוגריים האלה, נכניס מין מטריצה כזאת.

99
00:06:59,490 --> 00:07:04,530
0, 1, 1, 1, וכן הלאה, 1 באלכסון, עד לתחתית.

100
00:07:04,530 --> 00:07:08,060
אז הדבר הזה כאן הוא מטריצה שהאיבר השמאלי העליון שלה הוא 0.

101
00:07:08,060 --> 00:07:13,050
יש 1-ים על האלכסון, ואפסים בכל המקומות האחרים במטריצה הזו.

102
00:07:13,050 --> 00:07:16,780
אני מצייר את זה לא הכי יפה בעולם.

103
00:07:16,780 --> 00:07:19,266
אבל לדוגמה, אם n = 2,

104
00:07:19,266 --> 00:07:24,370
אז המטריצה הזו תהיה שלוש על שלוש.

105
00:07:24,370 --> 00:07:31,660
באופן כללי יותר, המטריצה היא בעלת ממדים (n + 1) על (n + 1).

106
00:07:31,660 --> 00:07:36,070
אז אם n = 2, אז המטריצה הזו נהיית משהו שנראה ככה.

107
00:07:36,070 --> 00:07:39,305
פה יש 0, וחוץ מזה יש 1 על האלכסונים,

108
00:07:39,305 --> 00:07:42,290
ו-0 על שאר המטריצה.

109
00:07:42,290 --> 00:07:46,080
ושוב, אני לא הולך להראות את תהליך הגזירה, שהיא קצת ארוכה

110
00:07:46,080 --> 00:07:51,295
ומסובכת, אבל אפשר להוכיח שאם אנחנו משתמשים בהגדרה החדשה

111
00:07:51,295 --> 00:07:56,320
של J של תטא עם האיבר של ההסדרה, אז הנוסחה החדשה הזו

112
00:07:56,320 --> 00:08:00,440
היא זו שנותנת את המינימום הגלובלי של J של תטא.

113
00:08:01,470 --> 00:08:06,800
לפני שנסיים אני רוצה רק לתאר במהירות את הנושא של אי-הפיכות.

114
00:08:06,800 --> 00:08:10,736
זה חומר מתקדם יחסית, אז תראו את הנושא כאופציונלי.

115
00:08:10,736 --> 00:08:13,620
ואל תהססו לדלג על זה, או אם אתם מקשיבים לזה

116
00:08:13,620 --> 00:08:16,420
וזה לא נשמע לכם ממש הגיוני, אל תדאגו בקשר לזה.

117
00:08:16,420 --> 00:08:19,720
אבל קודם לכן, כשדיברתי על שיטת המשוואה הנורמלית,

118
00:08:19,720 --> 00:08:23,760
גם אז היה לנו סרטון אופציונלי בנושא אי ההפיכות.

119
00:08:23,760 --> 00:08:26,420
אז זה עוד חלק אופציונלי כזה,

120
00:08:26,420 --> 00:08:31,658
סוג של הרחבה לוידאו האופציונלי הקודם בקשר לאי הפיכות.

121
00:08:31,658 --> 00:08:36,070
עכשיו, תחשבו על מקרה שבו m, מספר הדוגמאות, קטן או שווה

122
00:08:36,070 --> 00:08:38,700
ל- n, שהוא מספר התכונות.

123
00:08:38,700 --> 00:08:42,860
אם יש לכם פחות דוגמאות מאשר תכונות, אז המטריצה הזו,

124
00:08:42,860 --> 00:08:49,660
X משוחלפת כפול X, תהיה בלתי הפיכה, או סינגולרית.

125
00:08:49,660 --> 00:08:53,050
או מונח אחר עבור זה הוא שהמטריצה תהיה מנוונת.

126
00:08:53,050 --> 00:08:57,100
ואם תיישמו את זה באוקטבה בכל מקרה ותשתמשו בפונקציה pinv

127
00:08:57,100 --> 00:09:01,600
שעושה פסאודו אינוורט, היא בעצם תשתדל לעשות את הדבר הנכון, אבל

128
00:09:01,600 --> 00:09:05,990
זה לא ברור שהתשובה הנכונה תיתן לכם פונקצית השערה טובה מאוד, למרות

129
00:09:05,990 --> 00:09:12,270
שמספרית פונקציה pinv באוקטבה תיתן תוצאה שהיא די הגיונית.

130
00:09:13,270 --> 00:09:16,470
אבל אם הייתם עושים את זה בשפה אחרת,

131
00:09:16,470 --> 00:09:21,530
או אם הייתם מנסים למצוא את ההופכי הרגיל, שבאוקטבה נעשה עם

132
00:09:21,530 --> 00:09:26,320
הפונקציה inv, כשננסה לקבל את ההופכי הרגיל של X משוחלפת כפול X

133
00:09:26,320 --> 00:09:31,150
אז במקרה הזה נגלה ש-X משוחלפת כפול X היא סינגולרית,

134
00:09:31,150 --> 00:09:35,540
בלתי הפיכה, ואם תעשו את זה בשפות תכנות שונות

135
00:09:35,540 --> 00:09:39,890
באמצעות איזושהי ספריית אלגברה ליניארית ותנסו למצוא את ההופכי של המטריצה הזו,

136
00:09:39,890 --> 00:09:44,690
הפונקציה פשוט תיכשל כי המטריצה אינה הפיכה, או סינגולרית.

137
00:09:44,690 --> 00:09:48,595
למרבה המזל, ההסדרה מטפלת גם בזה בשבילנו.

138
00:09:48,595 --> 00:09:52,280
ולמעשה, כל עוד פרמטר ההסדרה למבדה

139
00:09:52,280 --> 00:09:56,780
הוא ממש גדול מ-0, אפשר להוכיח כי המטריצה הזו,

140
00:09:56,780 --> 00:10:02,040
X משוחלפת כפול X פלוס למבדה כפול המטריצה הזו, אפשר להוכיח

141
00:10:02,040 --> 00:10:07,430
שהמטריצה הזו לא תהיה סינגולרית ושהיא תהיה הפיכה.

142
00:10:07,430 --> 00:10:11,990
אז ההסדרה גם מטפלת בסוגיה של אי-ההפיכות

143
00:10:11,990 --> 00:10:15,350
של המטריצה X משוחלפת כפול X.

144
00:10:15,350 --> 00:10:18,960
אז עכשיו אתם יודעים איך ליישם רגרסיה ליניארית עם הסדרה.

145
00:10:18,960 --> 00:10:22,060
באמצעות זה תוכלו להימנע מהתאמת-יתר

146
00:10:22,060 --> 00:10:25,470
גם אם יש לכם הרבה תכונות וקבוצת אימון קטנה יחסית.

147
00:10:25,470 --> 00:10:28,860
וזה אמור לעזור לכם לגרום לרגרסיה ליניארית לעבוד הרבה יותר טוב

148
00:10:28,860 --> 00:10:30,130
עבור בעיות רבות.

149
00:10:30,130 --> 00:10:33,270
בסרטון הבא ניקח את רעיון ההסדרה הזה

150
00:10:33,270 --> 00:10:35,230
ונשתמש בו לרגרסיה לוגיסטית.

151
00:10:35,230 --> 00:10:38,960
כך שתוכלו לגרום לרגרסיה לוגיסטית להימנע מהתאמת-יתר

152
00:10:38,960 --> 00:10:40,020
ולהשיג ביצועים הרבה יותר טובים.