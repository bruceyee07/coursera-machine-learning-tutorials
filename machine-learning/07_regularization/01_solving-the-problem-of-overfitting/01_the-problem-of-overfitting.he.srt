1
00:00:00,360 --> 00:00:01,753
עד עכשיו, כבר ראיתם

2
00:00:01,760 --> 00:00:04,097
כמה אלגוריתמים שונים של למידה, רגרסיה

3
00:00:04,097 --> 00:00:06,504
ליניארית ורגרסיה לוגיסטית.

4
00:00:06,510 --> 00:00:08,583
הם עובדים היטב עבור בעיות רבות,

5
00:00:08,583 --> 00:00:09,684
אבל כאשר אתה מיישם אותם

6
00:00:09,684 --> 00:00:11,903
על יישומי למידת מכונה מסוימים, הם

7
00:00:11,903 --> 00:00:13,889
עלולים להיתקל בבעיה שנקראת

8
00:00:13,900 --> 00:00:18,052
overfitting או עודף התאמה, שתגרום להם לביצועים גרועים מאוד.

9
00:00:18,052 --> 00:00:18,866
מה שאני רוצה לעשות

10
00:00:18,866 --> 00:00:20,393
בסרטון הזה הוא להסביר

11
00:00:20,393 --> 00:00:22,400
לכם מהי בעיית עודף

12
00:00:22,400 --> 00:00:24,083
ההתאמה, ואז

13
00:00:24,083 --> 00:00:25,861
בסרטונים הבאים לאחר מכן,

14
00:00:25,861 --> 00:00:27,759
נדבר על טכניקה שנקראת

15
00:00:27,760 --> 00:00:29,787
הסדרה, שתאפשר

16
00:00:29,787 --> 00:00:31,529
לנו לשפר או

17
00:00:31,529 --> 00:00:33,607
להפחית את בעיית עודף ההתאמה הזו

18
00:00:33,607 --> 00:00:36,844
ולגרום לאלגוריתמי הלמידה האלה אולי לעבוד הרבה יותר טוב.

19
00:00:36,860 --> 00:00:39,607
אז מה הוא עודף התאמה?

20
00:00:39,607 --> 00:00:41,616
בואו נמשיך להשתמש בדוגמה

21
00:00:41,620 --> 00:00:44,030
הקבועה שלנו לחיזוי מחירי

22
00:00:44,050 --> 00:00:46,146
הדירות באמצעות רגרסיה ליניארית,

23
00:00:46,146 --> 00:00:47,123
בה אנו רוצים לחזות את

24
00:00:47,123 --> 00:00:50,730
המחיר כפונקציה של גודל הבית.

25
00:00:50,730 --> 00:00:51,870
דבר אחד שאנחנו יכולים לעשות הוא

26
00:00:51,910 --> 00:00:53,620
להתאים פונקציה ליניארית

27
00:00:53,620 --> 00:00:54,892
לנתונים אלה, ואם

28
00:00:54,892 --> 00:00:56,296
נעשה את זה, אולי נקבל

29
00:00:56,296 --> 00:00:58,913
סוג כזה של קו ישר שמתאים יפה לנתונים.

30
00:00:58,913 --> 00:01:01,012
אבל זה לא מודל ממש טוב.

31
00:01:01,012 --> 00:01:02,543
כאשר מסתכלים על הנתונים, נראה

32
00:01:02,560 --> 00:01:04,100
די ברור שככל

33
00:01:04,100 --> 00:01:06,274
שגודל הדירות עולה,

34
00:01:06,274 --> 00:01:08,268
מחירי הדיור מתקרבים לאסימפטוטה, או סוג

35
00:01:08,270 --> 00:01:11,721
של השתטחות כאשר אנחנו נעים ימינה ולכן

36
00:01:11,740 --> 00:01:14,020
האלגוריתם הזה לא

37
00:01:14,020 --> 00:01:15,898
מתאים לסדרת האימון ואנחנו

38
00:01:15,898 --> 00:01:19,166
קוראים לבעיה הזו חוסר התאמה,

39
00:01:19,180 --> 00:01:20,494
ומונח נוסף לכך הוא

40
00:01:20,500 --> 00:01:24,666
שלאלגוריתם הזה יש הטיה גבוהה.

41
00:01:25,140 --> 00:01:26,841
שני אלה בערך

42
00:01:26,890 --> 00:01:30,760
אומרים בפשטות שהאלגוריתם לא מתאים לנתוני האימון בצורה טובה מאוד.

43
00:01:30,760 --> 00:01:32,328
המונח הטיה הוא מין

44
00:01:32,328 --> 00:01:34,515
מונח היסטורי או טכני,

45
00:01:34,515 --> 00:01:36,109
אבל הרעיון הוא

46
00:01:36,110 --> 00:01:37,303
שאם מתאימים קו ישר

47
00:01:37,303 --> 00:01:38,909
לנתונים, זה כאילו

48
00:01:38,920 --> 00:01:40,290
לאלגוריתם יש

49
00:01:40,330 --> 00:01:42,638
דעה קדומה חזקה מאוד, או

50
00:01:42,638 --> 00:01:44,633
הטיה חזקה מאוד שמחירי

51
00:01:44,650 --> 00:01:46,339
הדירות הולכים להשתנות

52
00:01:46,339 --> 00:01:49,988
באופן ליניארי לפי הגודל שלהם למרות שהנתונים לא מראים כך.

53
00:01:50,000 --> 00:01:51,281
למרות הראיות

54
00:01:51,290 --> 00:01:54,174
שהמצב הפוך, הדעה הקדומה

55
00:01:54,174 --> 00:01:55,413
או ההטייה, עדיין מתעקשת

56
00:01:55,440 --> 00:01:56,974
להתאים לו קו ישר

57
00:01:56,974 --> 00:02:00,638
ובסופו של דבר מקבלים התאמה גרועה לנתונים.

58
00:02:00,638 --> 00:02:02,173
עכשיו, כגישת ביניים, אנחנו יכולים

59
00:02:02,210 --> 00:02:04,626
להתאים כאן פונקציה ריבועית,

60
00:02:04,626 --> 00:02:06,222
ועם נתוני האימון האלה, אנו מתאימים

61
00:02:06,222 --> 00:02:07,793
פונקציה ריבועית, ואז אנחנו אולי מקבלים

62
00:02:07,810 --> 00:02:10,211
סוג כזה של עקומה

63
00:02:10,211 --> 00:02:14,361
וזה עובד די טוב.

64
00:02:14,361 --> 00:02:17,543
ובקצה הקיצוני האחר, אנחנו יכולים להתאים,
נניח, פולינום מדרגה רביעית לנתונים.

65
00:02:17,550 --> 00:02:19,442
אז כאן יש לנו חמישה פרמטרים,

66
00:02:19,470 --> 00:02:23,196
תטא-אפס עד תטא-ארבע,

67
00:02:23,210 --> 00:02:23,926
ועם אלה, אנחנו יכולים למעשה ליצור עקומה

68
00:02:23,926 --> 00:02:26,727
שעוברת ממש דרך כל חמש דוגמאות האימון שלנו.

69
00:02:26,727 --> 00:02:29,507
אתה יכול לקבל עקומה שנראית ככה.

70
00:02:31,260 --> 00:02:32,454
זה, מצד

71
00:02:32,460 --> 00:02:33,791
אחד, נראה שעושה

72
00:02:33,791 --> 00:02:35,052
עבודה טובה מאוד בהתאמת

73
00:02:35,052 --> 00:02:36,291
ערכת האימון, כי הוא

74
00:02:36,291 --> 00:02:38,269
עובר דרך כל הנתונים שלי, לפחות.

75
00:02:38,270 --> 00:02:40,284
אבל, זו עדיין עקומה מתפתלת מאוד, נכון?

76
00:02:40,300 --> 00:02:41,660
היא עולה ויורדת בכל

77
00:02:41,660 --> 00:02:43,430
מיני מקומות, ולכן אנחנו לא חושבים

78
00:02:43,430 --> 00:02:46,996
שזה מודל כל כך טוב לניבוי מחירי הדירות.

79
00:02:47,000 --> 00:02:48,924
אז לבעיה הזו אנו

80
00:02:48,924 --> 00:02:51,967
קוראים עודף התאמה, ויש

81
00:02:51,970 --> 00:02:53,165
עוד מונח אחר עבור זה

82
00:02:53,170 --> 00:02:57,304
והוא שלאלגוריתם הזה יש שונות גבוהה.

83
00:02:57,890 --> 00:02:59,951
המונח 'שונות גבוהה' הוא עוד

84
00:02:59,951 --> 00:03:02,110
מונח היסטורי או טכני.

85
00:03:02,130 --> 00:03:03,797
אבל האינטואיציה היא

86
00:03:03,800 --> 00:03:05,080
שאם אנחנו מתאימים את הנתונים

87
00:03:05,080 --> 00:03:07,326
לפולינום מדרגה כזו

88
00:03:07,330 --> 00:03:08,603
גבוהה אזי ההשערה יכולה להתאים, כך נראה,

89
00:03:08,620 --> 00:03:09,584
כמעט כאילו היא יכולה

90
00:03:09,584 --> 00:03:11,995
להתאים לכל פונקציה,

91
00:03:11,995 --> 00:03:14,159
והמקדמים של ההשערה האפשרית

92
00:03:14,159 --> 00:03:16,601
הזו הם רבים מדי, יותר מדי משתנים.

93
00:03:16,610 --> 00:03:18,052
ואין לנו מספיק נתונים

94
00:03:18,052 --> 00:03:19,279
כדי להגביל את זה ולתת

95
00:03:19,279 --> 00:03:22,714
לנו השערה טובה אז זה נקרא עודף התאמה.

96
00:03:22,740 --> 00:03:24,340
ובאמצע, אין לזה באמת

97
00:03:24,350 --> 00:03:26,990
שם, אבל אני פשוט אקרא לזה "בדיוק טוב".

98
00:03:26,990 --> 00:03:29,911
כאשר פולינום מדרגה שניה, פונקציה ריבועית

99
00:03:29,911 --> 00:03:32,559
נראית מתאימה בדיוק להתאמה לנתונים האלה.

100
00:03:32,559 --> 00:03:34,684
כדי לסכם קצת את

101
00:03:34,690 --> 00:03:37,042
הבעיה של התאמת יתר, היא קורה

102
00:03:37,042 --> 00:03:38,258
כאשר יש לנו

103
00:03:38,258 --> 00:03:40,729
יותר מדי תכונות, אז

104
00:03:40,729 --> 00:03:43,881
ההשערה הנלמדת עשויה להתאים
לקבוצת האימון בצורה טובה מאוד.

105
00:03:43,881 --> 00:03:46,023
אז פונקציית העלות שלך

106
00:03:46,023 --> 00:03:47,344
עשויה להיות קרובה מאוד

107
00:03:47,344 --> 00:03:48,446
לאפס או אולי

108
00:03:48,446 --> 00:03:50,750
אפילו אפס בדיוק, אבל

109
00:03:50,750 --> 00:03:52,063
אתה בסופו של דבר מקבל

110
00:03:52,063 --> 00:03:53,950
עקומה כמו זו,

111
00:03:53,950 --> 00:03:55,314
שמנסה יותר מדי

112
00:03:55,314 --> 00:03:57,103
להתאים לערכת האימון, כך שהיא

113
00:03:57,110 --> 00:03:59,233
נכשלת בהכללה

114
00:03:59,250 --> 00:04:01,117
לדוגמאות חדשות ולא מצליחה

115
00:04:01,120 --> 00:04:03,018
לחזות מחירים בדוגמאות חדשות,

116
00:04:03,050 --> 00:04:04,337
וכאן המונח

117
00:04:04,350 --> 00:04:06,853
"הכללה" מתייחס

118
00:04:06,853 --> 00:04:10,868
לעד כמה ההשערה חלה גם על דוגמאות חדשות.

119
00:04:10,868 --> 00:04:12,274
כלומר לנתונים לגבי

120
00:04:12,320 --> 00:04:16,467
בתים שהיא לא ראתה במערך ההדרכה.

121
00:04:16,600 --> 00:04:17,910
בשקופית זו, הסתכלנו על

122
00:04:17,910 --> 00:04:20,802
התאמת יתר במקרה של רגרסיה ליניארית.

123
00:04:20,810 --> 00:04:24,182
דבר דומה יכול לחול גם על רגרסיה לוגיסטית.

124
00:04:24,190 --> 00:04:26,090
הנה דוגמה של רגרסיה

125
00:04:26,090 --> 00:04:28,871
לוגיסטית עם שתי תכונות X1 ו-X2.

126
00:04:28,910 --> 00:04:30,136
דבר אחד שאנחנו יכולים לעשות הוא

127
00:04:30,140 --> 00:04:31,522
לבנות רגרסיה לוגיסטית הולמת

128
00:04:31,522 --> 00:04:34,518
עם השערה פשוטה כמו זו,

129
00:04:34,530 --> 00:04:38,076
שבה, כרגיל, G היא הפונקציה הסיגמואידית שלי.

130
00:04:38,120 --> 00:04:39,334
ואם אתה עושה את זה, אתה מקבל

131
00:04:39,334 --> 00:04:41,593
השערה שמנסה

132
00:04:41,600 --> 00:04:42,923
אולי להשתמש פשוט בקו

133
00:04:42,923 --> 00:04:45,713
ישר להפריד בין דוגמאות חיוביות ושליליות.

134
00:04:45,713 --> 00:04:49,071
וזה לא נראה כהתאמה יותר מדי טובה להשערה.

135
00:04:49,100 --> 00:04:50,659
אז, שוב, זוהי

136
00:04:50,659 --> 00:04:52,577
דוגמה של התאמת חסר

137
00:04:52,577 --> 00:04:56,040
או של השערה בעלת הטיה גבוהה.

138
00:04:56,210 --> 00:04:57,504
לעומת זאת, אם היינו

139
00:04:57,504 --> 00:04:59,146
מוסיפים לתכונות שלנו

140
00:04:59,170 --> 00:05:01,032
את המונחים הריבועיים האלה,

141
00:05:01,032 --> 00:05:02,613
נוכל לקבל גבול או סף

142
00:05:02,613 --> 00:05:05,620
החלטה שעשוי להיראות יותר כך.

143
00:05:05,620 --> 00:05:07,784
וכפי שניתן לראות, זה מתאים לנתונים בצורה די טובה,

144
00:05:07,784 --> 00:05:10,838
כנראה, בערך

145
00:05:10,860 --> 00:05:13,991
הכי טוב שאפשר לקבל בהינתן קבוצת האימון הזו.

146
00:05:14,010 --> 00:05:15,157
ולבסוף, בקצה

147
00:05:15,170 --> 00:05:16,169
השני, אם הייתם

148
00:05:16,169 --> 00:05:18,207
בונים התאמה לפולינום גבוה מאוד, אם

149
00:05:18,207 --> 00:05:20,036
הייתם מייצרים הרבה

150
00:05:20,036 --> 00:05:22,461
מונחים פולינומים מסדר גבוה,

151
00:05:22,490 --> 00:05:24,730
אזי הרגרסיה הלוגיסטית עלולה לעוות

152
00:05:24,750 --> 00:05:26,551
את עצמה כדי

153
00:05:26,560 --> 00:05:28,233
לקבל

154
00:05:28,233 --> 00:05:31,742
גבול החלטה שמתאים

155
00:05:31,742 --> 00:05:33,013
לנתוני האימון או היא

156
00:05:33,030 --> 00:05:35,006
תעשה מאמצים רבים ותעוות את עצמה,

157
00:05:35,006 --> 00:05:37,689
כדי להתאים בצורה טובה לכל דוגמאות האימון.

158
00:05:37,700 --> 00:05:38,757
וכמו שאמרנו קודם, זה

159
00:05:38,757 --> 00:05:39,547
יחזה טוב את התכונות X1

160
00:05:39,550 --> 00:05:41,435
וX2, אולי,

161
00:05:41,435 --> 00:05:43,350
אבל את הסרטן,

162
00:05:43,390 --> 00:05:46,448
אתם זוכרים, גידולים של סרטן שד
הם ממאירים או שפירים,

163
00:05:46,448 --> 00:05:47,988
זה לא, זה באמת לא

164
00:05:47,988 --> 00:05:51,893
נראה כמו ההשערה הטובה ביותר
על מנת לבצע תחזיות.

165
00:05:51,930 --> 00:05:53,463
וכך, שוב, זהו

166
00:05:53,463 --> 00:05:55,432
מקרה של התאמת יתר

167
00:05:55,432 --> 00:05:57,128
ושל השערה בעלת

168
00:05:57,128 --> 00:05:59,403
שונות גבוהה והיא לא ממש,

169
00:05:59,403 --> 00:06:04,243
כן, לא סביר שתהיה מוצלחת במיוחד
בהכללה לדוגמאות חדשות.

170
00:06:04,560 --> 00:06:06,158
מאוחר יותר, בקורס הזה,

171
00:06:06,158 --> 00:06:08,453
כשנדבר על איתור באגים ואבחון

172
00:06:08,460 --> 00:06:09,794
של דברים שיכולים להשתבש

173
00:06:09,810 --> 00:06:11,490
באלגוריתמים של למידה, אנחנו נספק

174
00:06:11,490 --> 00:06:13,297
כלים ספציפיים כדי לזהות

175
00:06:13,297 --> 00:06:14,953
מתי יש התאמת יתר, וגם

176
00:06:14,953 --> 00:06:17,503
מתי עשויה להתרחש התאמת חסר.

177
00:06:17,503 --> 00:06:18,775
אבל בינתיים, לעכשיו, בואו ונדבר על

178
00:06:18,780 --> 00:06:20,342
הבעיה שאם אנחנו

179
00:06:20,360 --> 00:06:22,206
חושבים שיש לנו התאמת יתר,

180
00:06:22,250 --> 00:06:24,864
מה אנחנו יכולים לעשות כדי לטפל בה?

181
00:06:24,864 --> 00:06:26,640
בדוגמאות הקודמות, היו לנו

182
00:06:26,660 --> 00:06:28,701
אחד או שניים ממדי נתונים אז

183
00:06:28,701 --> 00:06:31,335
יכולנו פשוט לשרטט את ההשערה ולראות מה

184
00:06:31,335 --> 00:06:34,612
קורה ולבחור את דרגת הפולינום המתאימה.

185
00:06:34,620 --> 00:06:36,836
לדוגמא, מוקדם יותר בדוגמת

186
00:06:36,836 --> 00:06:38,405
מחירי הדירות, יכולנו פשוט

187
00:06:38,410 --> 00:06:40,597
לשרטט את ההשערה, אתם

188
00:06:40,600 --> 00:06:41,628
זוכרים, ואולי לראות שהיתה

189
00:06:41,628 --> 00:06:42,830
לנו התאמה עם סוג של

190
00:06:42,830 --> 00:06:46,339
פונקציה מפותלת מאוד שעולה ויורדת בצורה מוזרה
על מנת לנסות ולחזות את מחירי הדירות.

191
00:06:46,339 --> 00:06:47,701
ואז יכולנו להשתמש בגרפים

192
00:06:47,740 --> 00:06:50,667
כאלו כדי לבחור פולינום מדרגה מתאימה.

193
00:06:50,680 --> 00:06:54,166
אז שרטוט של פונקצית ההשערה יכול

194
00:06:54,166 --> 00:06:55,728
להיות דרך אחת לנסות

195
00:06:55,750 --> 00:06:58,160
להחליט באיזו דרגה של פולינום להשתמש.

196
00:06:58,160 --> 00:07:00,163
אבל זה לא תמיד עובד.

197
00:07:00,180 --> 00:07:02,019
ולמעשה, לעתים קרובות יותר אנו

198
00:07:02,019 --> 00:07:06,075
עשויים להיתקל בבעיות שיש להן פשוט המון תכונות.

199
00:07:06,075 --> 00:07:07,563
וזה לא רק

200
00:07:07,563 --> 00:07:10,599
עניין של בחירת דרגת הפולינום.

201
00:07:10,630 --> 00:07:12,147
ולמעשה, כאשר יש

202
00:07:12,170 --> 00:07:13,779
לנו כל כך הרבה תכונות, זה גם

203
00:07:13,779 --> 00:07:15,593
הופך להיות הרבה יותר קשה לשרטט

204
00:07:15,630 --> 00:07:17,698
את הנתונים וזה הופך להיות

205
00:07:17,710 --> 00:07:19,211
הרבה יותר קשה לדמיין את זה,

206
00:07:19,211 --> 00:07:22,396
כדי להחליט אילו תכונות לשמור או לא.

207
00:07:22,420 --> 00:07:24,142
אז באופן קונקרטי, אם אנחנו מנסים

208
00:07:24,160 --> 00:07:27,849
לחזות את מחירי הדירות,
לפעמים פשוט יש לנו הרבה תכונות שונות.

209
00:07:27,880 --> 00:07:31,373
וכל התכונות האלה נראות, אתם מבינים,
אולי הם נראות קצת שימושיות.

210
00:07:31,373 --> 00:07:32,609
אבל אם יש לנו

211
00:07:32,609 --> 00:07:34,123
הרבה תכונות, ומעט מאוד

212
00:07:34,123 --> 00:07:35,820
נתוני אימון, אז התאמת

213
00:07:35,840 --> 00:07:37,776
יתר יכולה להיות בעיה.

214
00:07:37,776 --> 00:07:39,180
כדי לענות על התאמת

215
00:07:39,180 --> 00:07:40,651
יתר, יש שתי אפשרויות

216
00:07:40,651 --> 00:07:43,780
עיקריות עבור דברים שאנחנו יכולים לעשות.

217
00:07:43,780 --> 00:07:45,759
האפשרות הראשונה היא לנסות

218
00:07:45,770 --> 00:07:47,976
לצמצם את מספר התכונות.

219
00:07:47,990 --> 00:07:49,337
באופן קונקרטי, דבר אחד שאנחנו

220
00:07:49,337 --> 00:07:51,383
יכולים לעשות הוא לעבור על

221
00:07:51,383 --> 00:07:53,236
רשימת התכונות אחת אחת, ולהשתמש

222
00:07:53,236 --> 00:07:54,894
בזה כדי לנסות להחליט אילו

223
00:07:54,894 --> 00:07:57,256
תכונות חשובות יותר, או

224
00:07:57,256 --> 00:07:58,476
אילו תכונות אנחנו צריכים

225
00:07:58,476 --> 00:08:01,844
לשמור, ואילו תכונות אנחנו צריכים לזרוק.

226
00:08:01,844 --> 00:08:03,401
בהמשך הקורס, כשנדבר

227
00:08:03,401 --> 00:08:06,018
על אלגוריתמים לבחירת מודל.

228
00:08:06,040 --> 00:08:08,361
שהם אלגוריתמים היודעים אוטומטית

229
00:08:08,361 --> 00:08:09,788
להחליט אילו תכונות

230
00:08:09,800 --> 00:08:12,500
לשמור ואילו תכונות לזרוק החוצה.

231
00:08:12,500 --> 00:08:13,987
רעיון זה של הפחתת

232
00:08:13,987 --> 00:08:15,562
מספר תכונות יכול לעבוד

233
00:08:15,562 --> 00:08:17,853
טוב, ויכול להפחית התאמת יתר.

234
00:08:17,853 --> 00:08:19,383
וכאשר נדבר על בחירת

235
00:08:19,383 --> 00:08:22,534
המודל, נדון בזה הרבה יותר לעומק.

236
00:08:22,534 --> 00:08:24,386
אבל החיסרון הוא, שעל ידי

237
00:08:24,386 --> 00:08:25,603
זריקת חלק

238
00:08:25,603 --> 00:08:27,010
מהתכונות אנחנו גם זורקים

239
00:08:27,370 --> 00:08:30,615
חלק מהמידע שיש לנו על הבעיה.

240
00:08:30,650 --> 00:08:31,942
לדוגמה, אולי כל

241
00:08:31,942 --> 00:08:33,760
התכונות הללו הם למעשה רלוונטיות

242
00:08:33,780 --> 00:08:35,050
לניבוי מחיר של

243
00:08:35,070 --> 00:08:36,636
בית, אז אולי אנחנו לא באמת

244
00:08:36,640 --> 00:08:37,687
רוצים לזרוק חלק

245
00:08:37,687 --> 00:08:40,990
מהמידע שלנו או לזרוק חלק מהתכונות שלנו החוצה.

246
00:08:41,540 --> 00:08:44,515
האפשרות השנייה, שעליה

247
00:08:44,515 --> 00:08:45,995
נדבר

248
00:08:46,010 --> 00:08:49,268
בסרטונים הבאים, היא הסדרה - רגולריזציה.

249
00:08:49,268 --> 00:08:50,390
כאן, אנחנו הולכים לשמור

250
00:08:50,390 --> 00:08:52,579
את כל התכונות, אבל אנחנו

251
00:08:52,579 --> 00:08:55,063
הולכים להפחית את הגודל

252
00:08:55,063 --> 00:08:56,506
או את הערכים של הפרמטרים

253
00:08:56,520 --> 00:08:58,745
תטא-J. ושיטה

254
00:08:58,750 --> 00:09:00,690
זו פועלת היטב, כפי שנראה,

255
00:09:00,690 --> 00:09:01,925
כאשר יש לנו הרבה

256
00:09:01,925 --> 00:09:03,822
תכונות, שכל אחת מהם תורמת

257
00:09:03,822 --> 00:09:05,502
קצת לניבוי

258
00:09:05,502 --> 00:09:07,723
הערך של Y, כמו

259
00:09:07,740 --> 00:09:10,283
שראינו בדוגמה חיזוי מחיר הדירות.

260
00:09:10,283 --> 00:09:11,413
שבה אנחנו עשויים לקבל הרבה

261
00:09:11,413 --> 00:09:12,720
תכונות, שכל אחת מהם,

262
00:09:12,750 --> 00:09:16,902
אתה יודע, קצת שימושית,
אז אולי אנחנו לא רוצים לזרוק אותם.

263
00:09:16,930 --> 00:09:19,247
אז זה מסביר

264
00:09:19,250 --> 00:09:22,790
את הרעיון של הסדרה ברמה גבוהה מאוד.

265
00:09:22,790 --> 00:09:24,354
ואני מבין שכל

266
00:09:24,360 --> 00:09:26,763
הפרטים האלה כנראה עדיין לא נשמעים לכם הגיוניים.

267
00:09:26,763 --> 00:09:28,316
אבל בסרטון הבא

268
00:09:28,316 --> 00:09:30,960
נתחיל לנסח בדיוק כיצד

269
00:09:30,960 --> 00:09:35,117
ליישם הסדרה, בדיוק מה פירושה של הסדרה.

270
00:09:35,140 --> 00:09:36,810
ואז נתחיל

271
00:09:36,810 --> 00:09:38,310
להבין איך להשתמש בה

272
00:09:38,310 --> 00:09:40,412
כדי לגרום ללמידה האלגוריתמית לעבוד

273
00:09:40,412 --> 00:09:42,460
יותר טוב ולהימנע מהתאמת יתר.