בסרטונים האחרונים דיברנו על ירידה סטוכסטית במדרון, ועל וריאציות שונות של אלגוריתם הירידה הסטוכסטית, כולל ההתאמות ללמידה מקוונת, אך כל האלגוריתמים האלה ניתנים להפעלה על מכונה או מחשב אחד. חלק מהבעיות בלמידת מכונה הן פשוט גדולות מכדי שיוכלו לרוץ על מחשב אחד, לפעמים אולי יש פשוט כל כך הרבה נתונים שפשוט לא נרצה להריץ את כל הנתונים האלה דרך מחשב אחד, לא משנה באיזה אלגוריתם היינו משתמשים במחשב הזה. אז בוידאו הזה אני רוצה לדבר על גישה שונה ללמידת מכונה בקנה מידה גדול, גישה שנקראת מיפוי וצמצום (map/reduce). ולמרות שהיו לנו לא מעט קטעי וידאו על ירידה סטוכסטית במדרון ואנחנו עומדים לבלות פחות זמן על מיפוי וצמצום, אל תשפטו את החשיבות היחסית של מיפוי וצמצום לעומת הירידה הסטוכסטית במדרון על בסיס כמות הזמן שאנחנו נבלה על הרעיונות האלה בפרט. לפי דעת רבים, מיפוי וצמצום חשוב לפחות באותה מידה, ולפי דעתם של רבים אחרים הרעיון חשוב אפילו יותר, מאשר הירידה הסטוכסטית במדרון, אבל הרעיון הזה הוא יחסית פשוט להסביר, ולכן אנחנו נבלה בו פחות זמן, אבל באמצעות הרעיונות האלה ייתכן שתוכלו לבנות אלגוריתמי למידה לבעיות גדולות בהרבה מאשר מה שאפשרי באמצעות ירידה סטוכסטית במדרון. הנה הרעיון. נניח שאנחנו רוצים להתאים מודל רגרסיה ליניארית או מודל רגרסיה לוגיסטית או משהו כזה, ונתחיל שוב עם הירידה במדרון באצווה, אז הנה כלל הלימוד של הירידה במדרון באצווה. וכדי לפשט את הכתיבה בשקופית הזו, אני כל הזמן מניח שיש לנו 400=m דוגמאות. כמובן, לפי הסטנדרטים שלנו, במונחים של למידת מכונה בקנה מידה גדול, m כזה הוא די קטן ובעצם המיפוי וצמצום עשוי להיות מיושם יותר על בעיות שבהם יש לנו אולי מספר יותר קרוב ל-m שווה 400 מיליון דוגמאות או משהו כזה, אבל רק כדי לעשות את הכתיבה על השקופית פשוטה יותר, אני אעמיד פנים שיש לנו 400 דוגמאות. אז במקרה הזה, כלל הלימוד של ירידה במדרון באצווה יש לו ה-m=400 ויש הסכום מ-i שווה 1 עד 400 ועוברים על 400 הדוגמאות כאן, וכזכור אם m הוא גדול, אז זה צעד יקר מבחינה חישובית. אז הרעיון של MapReduce עושה את הדברים הבאים, ואני חייב לומר שהרעיון של המיפוי וצמצום הוא פרי עבודתם של שני חוקרים, ג'ף דין וסאנג'יי גימאוואט. ג'ף דין, אגב, הוא אחד המהנדסים האגדיים ביותר בכל עמק הסיליקון והוא מעין בנה חלק גדול מהתשתית הארכיטקטונית עליה פועלת כל גוגל כיום. אבל הנה הרעיון של מיפוי וצמצום. נניח שיש לי איזו סדרת אימון, נניח שנציין אותם על ידי התיבה זו כאן של זוגות x,y כשכאן x1,y1, ומכאן דרך סדרת האימון עד דוגמת ההכשרה ה-400 xm,ym. אז זוהי סדרת ההכשרה עם 400 דוגמאות. ברעיון ה-MapReduce, דרך אחת לבצע את המשימה היא לפצל את סדרת האימון לתת-קבוצות. אני אניח לשם הדוגמה הזו שיש לנו 4 מחשבים, או 4 מכונות שירוצו במקביל על סדרת ההדרכה, ולכן אני מחלק את זה ל-4 מכונות. אם יש לנו 10 מכונות או 100 מכונות, אז נפצל את ערכת האימון ל-10 תת-קבוצות או 100, או מה שיהיה. ומה שתעשה המכונה הראשונה מ-4 המכונות, למשל, הוא להשתמש רק ברבע הראשון של קבוצת האימון - היא תשתמש רק ב-100 דוגמאות ההכשרה הראשונות. ובפרט, מה שהיא תעשה הוא להסתכל על הסכימה הזו, ולחשב את הסכום רק על פי 100 דוגמאות ההכשרה הראשונות. אז תנו לי לכתוב את זה, אני עומד לחשב משתנה שנקרא לו (temp(1 עם אינדקס j, שווה לסכום מ-1 עד 100, ואז אנחנו נחבר בדיוק את הביטוי כאן - דהיינו יש לי (hθ(xi פחות yi, כפול xij, כן? אז זה פשוט המונח של הירידה במדרון שם למעלה. ובאופן דומה, אנחנו ניקח את הרבע השני של הנתונים ונשלח אותו אל המחשב השני, והמכונה השנייה תשתמש בסדרת האימון באינדקסים 101 עד 200 ותחשב משתנה דומה, דהיינו temp(2)j שהוא יהיה סכום דומה של האינדקסים, של הדוגמאות 101 עד 200. ומכונות 3 ו-4 ישתמשו ברבע השלישי והרביעי של קבוצת האימון. אז עכשיו כל מכונה צריכה לסכם 100 במקום 400 דוגמאות ולכן היא צריכה לעשות רק רבע מהעבודה ולכן היא יכולה לעשות את זה פי ארבעה מהר. לבסוף, אחרי שכל המכונות האלה עשו את העבודה הזאת, אנחנו לוקחים את המשתנים הזמניים האלה ומחברים אותם. אז אנחנו לוקחים את המשתנים האלה ושולחים את כולם לשרת מרכזי והוא ישלב את התוצאות הללו. ובפרט, הוא יעדכן את הפרמטרים θj לפי: θj מקבל θj פחות שיעור הלמידה α כפול אחד חלקי 400 כפול temp(1)j, ועוד temp(2)j ועוד temp(3)j ועוד temp(4)j וכמובן יש לעשות זאת בנפרד עבור j שווה 0. וכמובן לכל אחת מהתכונות בנפרד. פתרון המשוואה העליונה יעשה צעד בירידה במדרון. ומה שהמשוואה הזו עושה הוא בדיוק אותו דבר כמו זאת, כי כאשר יש לנו שרת מרכזי שלוקח את התוצאות הזמניות, temp(1)j עד temp(4)j ומחבר אותם מה שנותן כמובן את הסכום של ארבעת הדברים האלה, כן, זה פשוט הסכום הזה, ועוד הסכום הזה, ועוד הסכום הזה, ועוד הסכום הזה, וארבעת המחוברים האלה פשוט מסתכמים בסכום זה שאותו היינו צריכים מלכתחילה כדי לחשב את הצעד של הירידה במדרון באצווה. ואז יש לנו את α כפול 1 חלקי 400, α כפול 1 חלקי 400, שזה בדיוק שווה לאלגוריתם של ירידה במדרון באצווה, אלא שבמקום להיאלץ לעשות את הסיכום של כל ארבע מאות דוגמאות ההדרכה על מכונה אחת, אנחנו יכולים לחלק את עומס העבודה על ארבע מכונות. אז כך נראית התמונה הכללית של טכניקת MapReduce. יש לנו איזו ערכת אימון, ואנחנו רוצים לחלק אותה לארבע מכונות, אז אנחנו לוקחים את ערכת האימון ומפצלים אותה לקבוצות שוות. מפצלים אותה באופן שווה ככל האפשר לארבע תת-קבוצות. ואז אנחנו לוקחים את 4 הקבוצות של נתוני האימון ושולחים אותם ל-4 מחשבים שונים. וכל אחד מארבעת המחשבים מחשב סיכום רק על רבע ממערך ההדרכה, ואז בסוף אנחנו לוקחים, כל אחד מהמחשבים לוקח את התוצאות, שולח אותם לשרת מרכזי, שמסכם את התוצאות. בשקופית הקודמת בדוגמא הזו, רוב העבודה של הירידה במדרון היתה החישוב של סכום של i שווה 1-400 של משהו. או באופן כללי יותר, סכום מ-i שווה 1 עד m של הנוסחה עבור הירידה במדרון. ועכשיו, מכיוון שכל אחד מארבעת המחשבים צריך לעשות רק רבע מהעבודה, אפשר להשיג מהירות גדולה פי ארבעה. בעצם, אם אין ברשת הזו השהיות (latencies) ועלויות תקשורת של שליחת הנתונים הנה ושמה, אפשר לקבל עד פי 4 מהירות. כמובן, בפועל, בגלל השהיות הרשת, ובגלל התקורה של הסיכום הסופי של התוצאות וגורמים אחרים, בפועל נקבל האצה קצת קטנה מפי 4. אבל למרות זאת, הגישה הזו של MapReduce מציעה לנו דרך לעבד ערכות נתונים הרבה יותר גדולות מאשר זה אפשרי באמצעות מחשב אחד. כשתשקלו יישום של מיפוי וצמצום בשביל איזשהו אלגוריתם למידה, כדי להאיץ אותו על ידי מיקבול החישוב על פני מחשבים שונים, שאלת המפתח שתשאלו את עצמכם היא, האם אלגוריתם הלמידה שלכם ניתן להיכתב כסיכום על מערך ההדרכה? ומתברר שאלגוריתמים רבים ללמידה יכולים למעשה להיות מבוטאים כחישוב של סכומים של פונקציות על מערך האימון והעלות החישובית של הפעלתם על קבוצות נתונים גדולות היא כי הם צריכים לסכם על קבוצה אימון גדולה מאוד. אז כל פעם שאלגוריתם הלמידה שלכם יכול להיות מנוסח כסיכום של קבוצת הדרכה, כאשר עיקר העבודה של אלגוריתם הלמידה ניתן לביטוי כסכימה על קבוצת ההדרכה, אזי מיפוי וצמצום יכול להיות מועמד טוב לשיפור הזמנים של אלגוריתם הלמידה על סדרות נתונים מאוד מאוד גדולות. בואו נסתכל רק על עוד דוגמה אחת. נניח שאנחנו רוצים להשתמש באחד מאלגוריתמי האופטימיזציה המתקדמים. דברים כמו L-BFGS, מדרון מוטה, וכן הלאה, נניח שאנחנו רוצים לאמן רגרסיה לוגיסטית של האלגוריתם. לשם כך, אנחנו צריכים לחשב שני חלקים עיקריים. האחד הוא, עבור אלגוריתמי אופטימיזציה מתקדמים כמו L-BFGS ומדרון מוטה, אנחנו צריכים לספק פונקציה כדי לחשב את פונקציית העלות של מטרת האופטימיזציה. אז עבור רגרסיה לוגיסטית, אתם זוכרים כי בפונקציית העלות יש סיכום כזה על סדרת האימון, ולכן אם אנחנו ממקבלים אותה על עשר מכונות, היינו מפצלים את סדרת האימון על עשר מכונות, ועל כל אחת מעשר המכונות עכשיו מוטל לחשב את הסכום של הביטוי הזה רק על עשירית מנתוני האימון. ... והדבר השני שאלגוריתם אופטימיזציה מתקדם צריך הוא פונקציה לחישוב הנגזרות החלקיות האלה. שוב, הביטויים של הנגזרות האלה, עבור הרגרסיה הלוגיסטית, ניתנים לביטוי כסכום על מערך ההדרכה, ולכן שוב, בדומה לדוגמה הקודמת שלנו, אנחנו יכולים לחלק קטע לכל מחשב ולחשב את הסיכום הזה על חלק קטן בלבד של נתוני ההכשרה. ולבסוף, לאחר חישוב כל הדברים האלה, הם יכולים לשלוח את התוצאות שלהם לשרת מרכזי, שיכול אז לחבר את הסכומים החלקיים. דהיינו לחבר את המשתנים (temp(i או temp(i)j, שחושבו מקומית על מכונה מספר i, והשרת המרכזי יכול לסכם את הדברים האלה ולחשב את פונקצית העלות הכוללת ואת הנגזרת החלקית הכוללת, שאותה אפשר להעביר לאלגוריתם האופטימיזציה המתקדמת. אז באופן כללי יותר, על ידי לקיחת אלגוריתמים שונים של למידה וניסוחם במין צורה של סיכום או הבעתם במונחים של חישוב של סכומי פונקציות על סדרת האימון, אפשר להשתמש בטכניקת MapReduce כדי למקבל אלגוריתמי למידה שונים, ולשפר אותם כך שיעבדו היטב עם ערכות אימון גדולות מאוד. לבסוף, הערה אחת אחרונה, עד כה דנו ב-MapReduce כאלגוריתמים המאפשרים לנו לבצע מיקבול בין מחשבים מרובים, לפעמים מחשבים מרובים באשכול של מחשבים או מחשבים מרובים במרכז הנתונים. מתברר שלפעמים, גם אם יש לנו רק מחשב אחד, MapReduce עדיין יכול להיות ישים. בפרט, על מחשבים בודדים רבים בימינו אפשר לקבל ליבות עיבוד מרובות. אפשר לקבל מספר מעבדים, ובתוך כל מעבד יכולות להיות ליבות מרובות. אז אם יש לנו ערכת אימון גדולה, מה שאפשר לעשות אם, למשל, יש לנו מחשב עם 4 ליבות, מה שאפשר לעשות הוא, אפילו במחשב אחד אפשר לפצל את ערכות האימון לחתיכות ולשלוח את ערכות האימון לליבות שונות בתוך קופסא אחת, כגון בתוך מחשב שולחני אחד או שרת יחיד, ולהשתמש ב-MapReduce בדרך הזה כדי לפצל את עומס העבודה. כל אחת מהליבות יכולה לבצע את הסיכום, למשל, של רבע מהסדרה, ואז הם יכולים לקחת את הסכומים החלקיים ולאחד אותם, כדי לקבל את הסיכום על כל סדרת האימון. היתרון של לחשוב על MapReduce בדרך זו, כעל מיקבול על ליבות בתוך מחשב בודד, ולאו דווקא מיקבול על מספר מכונות הוא, שבדרך הזו לא צריך לדאוג להשהיות ברשת, כי כל התקשורת, כל שליחת המידע הזמני קדימה ואחורה, כל זה קורה בתוך מכונה אחת. וכך ההשהיות הופכות להיות בעיה הרבה יותר קטנה מאשר אם היינו משתמשים בזה כדי למקבל על פני מחשבים שונים בתוך מרכז הנתונים. ולבסוף, אזהרה אחרונה על מקביליות בתוך מכונת מרובת ליבות. בהתאם לפרטי היישום שלך, אם יש לך מכונה מרובת ליבות ואם יש לך ספריות נומריות מסוימות של אלגברה ליניארית. מתברר שחלק מהספריות של אלגברה ליניארית יודעות באופן אוטומטי למקבל פעולות אלגברה ליניארית על ליבות מרובות בתוך המכונה. אז אם אתה מספיק בר מזל כדי להשתמש באחת מאותן ספריות נומריות של אלגברה ליניארית וזה בהחלט איננו נכון לגבי כל ספריה וספריה. אבל אם אתה משתמש באחת מהספריות האלה, ואם יש לך יישום וקטורי טוב מאוד של אלגוריתם הלמידה. לפעמים אתה יכול פשוט ליישם אלגוריתם למידה סטנדרטית בצורה וקטורית ולא לדאוג למיקבול בכלל, והספריה של האלגברה הלינארית תטפל בחלק מהעסק הזה בשבילך. אז אתה לא צריך ליישם MapReduce. אבל עבור בעיות אחרות, ניצול של הסוג הזה של מיפוי וצמצום, מציאה ושימוש בניסוח שיאפשר מיקבול של MapReduce של חישובי הנתונים עשוי להיות רעיון טוב וגם עשוי לאפשר לך להאיץ את אלגוריתם הלמידה שלך. בסרטון זה, דיברנו על הגישה שנקראת MapReduce למיקבול למידת המכונה על ידי לקיחת הנתונים ופיזורם על פני מחשבים רבים במרכז הנתונים. למרות שהרעיונות האלה ניתנים ליישום גם כדי לאפשר עיבוד מקבילי על פני ליבות מרובות גם בתוך מחשב בודד. היום יש כמה יישומי קוד פתוח טובים של MapReduce, ישנם משתמשים רבים במערכת קוד פתוח בשם Hadoop ושימוש אם ביישום משלך ואם ביישום קוד פתוח של מישהו אחר, אפשר להשתמש ברעיונות אלה כדי למקבל אלגוריתמי למידה ולגרום להם לרוץ על ערכות נתונים הרבה יותר גדולות מאשר זה אפשרי באמצעות מכונה בודדת.