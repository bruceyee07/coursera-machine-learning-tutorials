בסרטון הקודם דיברנו על ניתוח שגיאות ועל החשיבות לכך שיהיה לנו מדד של השגיאה, שהוא מספר ממשי יחיד שמעריך את איכותו של אלגוריתם הלמידה שלך. בהקשר של הערכה ושל מדדי שגיאה, יש מקרה חשוב אחד, שבו זה מסובך במיוחד להגדיר מדד שגיאה מתאים, או מדד הערכה, עבור אלגוריתם הלמידה שלך. המקרה הזה הוא המקרה של מה שמכונה יחסים מוטים או מחלקות מוטות. הרשו לי לספר לכם מה זה אומר. תחשבו על הבעיה של סיווג סרטן, שבו אנחנו מקבלים תכונות של חולים ואנחנו רוצים להחליט אם יש להם סרטן או לא. אז זה כמו הדוגמה של גידול ממאיר לעומת גידול שפיר שהיתה לנו בעבר. ונניח ש-y שווה 1 אם לחולה יש סרטן ו-y שווה 0 אם לא. יש לנו מסווג שלימדנו אותו, נניח שאנחנו בודקים את המסווג שלנו על ערכת המבחן ומוצאים שאנחנו מקבלים שגיאה של 1 אחוז. אז 99% מהאבחנות שלנו נכונות. ללא ספק, זה נראה כמו תוצאה מרשימה באמת, נכון. אנחנו צודקים 99% אחוז מהזמן. אבל עכשיו, נניח שנגלה שרק ל-0.5% מהחולים בסדרת המבחן שלנו יש למעשה סרטן. רק לחצי אחוז מהחולים שעברו דרך תהליך הסינון שלנו יש סרטן. במקרה כזה, השגיאה של 1% כבר לא נראית כל כך מרשימה. והנה, אני אראה לכם פיסת קוד, הנה קטע של קוד של אי-למידה ממוחשבת שלוקח את הקלט הזה x של תכונות ופשוט מתעלם ממנו. הוא פשוט תמיד מחזיר y שווה 0 ומנבא שלאף אחד אין סרטן. לאלגוריתם הזה יש למעשה רק 0.5 אחוז שגיאה. אז הוא אפילו יותר טוב מאשר השגיאה של 1% שכרגע קיבלנו וזה אלגוריתם שאינו לומד כי הוא פשוט חוזה ש-y שווה 0 כל הזמן. אז במצב הזה כאשר היחס בין דוגמאות חיוביות לדוגמאות שליליות קרוב מאוד לאחד משני הקצוות, כאשר במקרה הזה, מספר הדוגמאות החיוביות הוא ממש הרבה יותר קטן ממספר הדוגמאות השליליות, מכיוון ש-y שווה ל-1 לעתים כל כך נדירות, זה מה שאנחנו מכנים מקרה של מחלקות מוטות. יש לנו הרבה יותר דוגמאות ממחלקה אחת מאשר מהמחלקה השניה. ועל ידי חיזוי ש-y שווה 0 כל הזמן, או אולי על ידי חיזוי ש-y שווה 1 כל הזמן, האלגוריתם שלנו די מצליח. אז הבעיה שיש לנו עם מדדי שגיאות או מדדי דיוק במצב כזה היא זו. נניח שיש לך אלגוריתם למידה שמגיע לדיוק של 99.2%. זוהי שגיאה של 0.8%. נניח שאתה מבצע שינוי באלגוריתם שלך ואתה מקבל כעת 99.5% דיוק. זוהי שגיאה של 0.5%. אז האם זה שיפור באלגוריתם או לא? אחד הדברים הנחמדים בכך שיש ערך אחד בודד להערכה, שיש מספר ממשי הוא שזה עוזר לנו להחליט במהירות אם אנחנו עשינו שינוי טוב באלגוריתם או לא. על ידי מעבר מ-99.2% דיוק לדיוק של 99.5%. ועכשיו נשאלת השאלה האם באמת עשינו משהו מועיל או שפשוט שינינו את הקוד שלנו לקוד שפשוט מנבא ש-y שווה אפס לעתים קרובות יותר? אז אם יש לך יחסים מאוד מוטים זה נהיה הרבה יותר קשה להשתמש פשוט במדד של הסיווג, כי אתה יכול לקבל סיווג בדיוק גבוה מאוד או מדד שגיאות מאוד נמוך, וזה לא תמיד ברור אם זה באמת שיפור איכותי במסווג שלך, כי ניבוי ש-y שווה 0 כל הזמן לא נראה כמו מסווג טוב במיוחד. אבל על ידי חיזוי ש-y שווה 0 לעתים קרובות יותר אתה יכול להוריד את אחוזי השגיאה, אולי עד ערך נמוך כמו 0.5%. כאשר אנו מתמודדים עם יחסים מוטים כאלה, אנו רוצים להשתמש במדד שגיאה שונה או מדד הערכה שונה. מדד הערכה כזה הוא מה שנקרא דיוק (precision) וקליעה (recall). תנו לי להסביר מה זה. נניח שאנו מעריכים מסווג על ידי קבוצת המבחן. עבור הדוגמאות בסדרת המבחן התוצאה או המחלקה בפועל של הדוגמה הזו בסדרת המבחן תהיה תמיד או אחד או אפס, נכון? הרי אנחנו עוסקים בבעיית סיווג בינארי. ומה שאלגוריתם הלימוד שלנו יעשה הוא לחזות ערך כלשהו עבור המחלקה והוא חוזה ערך עבור כל דוגמה בקבוצת המבחן, וגם הערך החזוי יהיה או אחת או אפס. אז אני אצייר פה טבלה של שתיים על שתיים כדלקמן, לפי המחלקות והתוצאות, מה היו הדוגמאות האלה בפועל ומה היו המחלקות שהאלגוריתם חישב. אם יש לנו דוגמה שבה המחלקה בפועל היא אחת וגם המחלקה החזויה היא אחת אז זה נקרא מקרה חיובי אמיתי, כלומר גם האלגוריתם שלנו ניבא שהוא חיובי וגם במציאות הוא חיובי. אם אלגוריתם הלמידה שלנו ניבא שדוגמא היא שלילית, במחלקה אפס, והמחלקה בפועל גם היא אפס אז זה מה שנקרא שלילי אמיתי. ניבאנו אפס וזה אפס. בשתי המשבצות האחרות, אם אלגוריתם הלמידה שלנו חוזה שהמחלקה היא אחת, אבל בפועל המחלקה היא אפס, אז זה נקרא חיובי כוזב. זה אומר שהאלגוריתם שלנו חזה סרטן למטופל, אבל במציאות לנבדק אין סרטן. ולבסוף, המשבצת האחרונה היא אפס אחת. זה נקרא שלילי כוזב כי האלגוריתם שלנו חזה אפס, אבל המחלקה בפועל היתה אחת. אז יש לנו מין טבלה שתיים על שתיים לפי מה היתה המחלקה בפועל ומה חזה האלגוריתם. ועכשיו נגיע לדרך שלנו להעריך את הביצועים של האלגוריתם שלנו. אנחנו הולכים לחשב שני מספרים. הראשון נקרא דיוק - ומה שזה אומר, מבין כל החולים שניבאנו שיש להם סרטן, לאיזה אחוז מהם באמת יש סרטן? אז תנו לי לכתוב את זה, הדיוק של מסווג הוא מספר התוצאות החיוביות באמת, חלקי המספר שאנחנו ניבאנו שיהיה חיובי, ברור? מכל החולים שהלכנו אליהם ואמרנו להם: "אנחנו חושבים שיש לכם סרטן". מבין כל החולים הללו, איזה אחוז מהם אכן חולה בסרטן? זה נקרא "דיוק". ועוד דרך לכתוב את זה יהיה לשים במונה את החיובי האמיתי ובמכנה מספר אלה שחזינו כחיוביים שהוא הסכום של הערכים בשורה הראשונה של הטבלה. דהיינו החיובי האמיתי חלקי החיובי האמיתי, ... ... ועוד החיובי הכוזב, ... אז זה נקרא דיוק, וכפי שאתם רואים, דיוק גבוה יהיה טוב. זה אומר שמכל החולים שהלכנו אליהם ואמרנו, "אתה יודע, אנחנו מצטערים מאוד. אנחנו חושבים שיש לך סרטן", המשמעות של דיוק גבוה היא שבאותה קבוצה של חולים, ביצענו בפועל תחזיות מדויקות על רובם הגדול והם סובלים מסרטן. המספר השני שאנו אמורים לחשב נקרא "קליעה", והמשמעות של זה היא מתוך כל החולים, נניח, בקבוצת המבחן או במערך האימות הצולב, מתוך כל אלה שבקבוצה, שיש להם באמת סרטן, איזה אחוז מהם אנו מזהים כראוי כסרטן. אם לחלק מסוים מהחולים בקבוצה יש סרטן, כמה מהם באמת הלכנו אליהם ואמרנו להם את האמת - שאנחנו חושבים שהם זקוקים לטיפול. אז הקליעה מוגדרת כמספר הדוגמאות החיוביות, כלומר מספר האנשים עם y חיובי, כלומר מספר האנשים שאכן סובלים מסרטן, ושאנחנו חזינו נכונה את הסרטן, ואנחנו לוקחים את זה ומחלקים את זה במספר של כלל התוצאות החיוביות, המספר האמיתי של החיוביים בפועל, דהיינו כל האנשים בקבוצה שיש להם סרטן. איזה חלק מהם אנחנו חזינו נכונה ושלחנו אותם לטיפול. אז נכתוב גם את זה מחדש בצורה אחרת, המכנה יהיה מספר החיוביים בפועל, שכפי שברור הוא סכום של הערכים בעמודה הראשונה כאן. נכתוב את הדברים בצורה שונה, זה מספר החיוביים האמיתיים חלקי מספר החיוביים האמיתיים ועוד מספר השליליים הכוזבים. אז גם כאן מספר גבוה יהיה דבר טוב. אז על ידי חישוב של דיוק וקליעה נקבל בדרך כלל תחושה טובה יותר של איכות המסווג שלנו. ובפרט, אם יש לנו אלגוריתם למידה שמנבא ש-y שווה אפס כל הזמן, אם הוא מנבא שאף אחד לא סובל מסרטן, אז במסווג הזה הקליעה וגם הדיוק שווים לאפס, כי אין שום חיובי אמיתי, אז זו דרך מהירה לפסול מסווג כזה שמנבא y שווה 0 כל הזמן, הוא פשוט לא המסווג הכי טוב. ובאופן כללי יותר, אפילו עבור מקרים שבהם השיעורים מאוד מוטים, זה לא יהיה אפשרי לאלגוריתם "לרמות" ואיכשהו לקבל דיוק גבוה מאוד וקליעה גבוהה מאוד על ידי משהו פשוט כמו לחזות ש-y שווה 0 כל הזמן או לחזות ש-y שווה 1 כל הזמן. ולכן אנחנו הרבה יותר בטוחים שמסווג עם דיוק גבוה או קליעה גבוהה הוא מסווג טוב, וזה נותן לנו סוג של מדד יותר טוב ודרך יותר נכונה להבין באמת אם האלגוריתם שלנו עשוי להיות טוב. עוד הערה אחת, בהגדרות של דיוק וקליעה, כשאנחנו מגדירים את הדיוק והקליעה, אנחנו בדרך כלל משתמשים בקונבנציה ש-y שווה 1 במחלקה הנדירה יותר. אז כשאנחנו מנסים לזהות מצבים נדירים כגון סרטן, שאנחנו מקווים שהוא מצב נדיר, דיוק וקליעה מוגדרים כך ש-y שווה 1, ולא y שווה 0, להיות המקרה של הקבוצה הנדירה שאנחנו מנסים לזהות. על ידי שימוש בדיוק וקליעה, מה שקורה הוא שאפילו אם יש לנו מחלקות מאוד מוטות, זה בלתי-אפשרי עבור אלגוריתם "לרמות" ולחזות ש-y שווה 1 כל הזמן, או לחזות ש-y שווה 0 כל הזמן, ולקבל דיוק וקליעה גבוהים. ובפרט, אם למסווג יש דיוק גבוה וקליעה גבוהה, אז אנחנו בטוחים שהאלגוריתם צריך להיות טוב, גם אם יש לנו יחסים מאוד מוטים. אז עבור הבעיה של יחסים מוטים, הקליעה והדיוק נותנים לנו תובנה ישירה יותר על איכותו של אלגוריתם הלמידה וזו בדרך כלל דרך טובה יותר להעריך את אלגוריתמים הלמידה שלנו מאשר להסתכל על מדד שגיאת הסיווג או דיוק הסיווג, כאשר המחלקות מוטות מאוד .