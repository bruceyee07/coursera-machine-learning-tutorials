בסרטון הקודם דיברנו על מדדי הערכה. בסרטון הזה, אני רוצה קצת לשנות את המסלול ולגעת בהיבט חשוב נוסף של עיצוב מערכת למידה ממוחשבת, שעולה לעתים קרובות, והוא הנושא של כמות הנתונים עליהם לאמן את המערכת. בכמה קטעי וידאו מוקדמים יותר, הזהרתי מפני הנטייה ללכת בעיוורון ופשוט לבזבז המון זמן באיסוף הרבה נתונים, שזה דבר שעוזר באמת רק לפעמים. אבל מתברר שבתנאים מסוימים, ואני אגדיר בסרטון הזה מהם התנאים האלה, להשיג הרבה נתונים ולאמן עליהם בסוגים מסוימים של אלגוריתמי למידה כן יכולה להיות דרך יעילה מאוד לגרום לאלגוריתם למידה להגיע לביצועים טובים מאוד. והדבר הזה קורה לעתים מספיק קרובות שאם התנאים האלה מתאימים לבעיה שלך, ואם אתה מסוגל להשיג הרבה נתונים, זו יכולה להיות דרך טובה מאוד לייצר אלגוריתם למידה עם ביצועים גבוהים מאוד. אז בסרטון הזה, בואו נדבר על זה עוד. תנו לי להתחיל עם סיפור. לפני שנים רבות, שני חוקרים שאני מכיר, מישל בנקו ואריק בריל ניהלו את המחקר המרתק הבא. הם רצו ללמוד את האפקט של שימוש באלגוריתמים שונים ללמידה לעומת אימון אותו אלגוריתם על סדרות אימון שונות. הם עסקו בבעיית סיווג בין מילים מבלבלות, כך למשל במשפט כאן: לארוחת הבוקר אכלתי ___ ביצים. האם "to", "two" או "too"? אז בדוגמה הזו, זה צריך להיות לארוחת בוקר אכלתי 2 (two) ביצים. אז זוהי דוגמה אחת של קבוצה של מילים שניתן לבלבל ביניהם, והנה עוד קבוצה. אז הם לקחו בעיות למידה כמו אלה, מין בעיות למידה מונחית, כדי לנסות לסווג מה היא המילה הנכונה שאותה צריך להשלים במקום הזה במשפט באנגלית. הם לקחו כמה אלגוריתמים שונים של למידה שהיו הדברים הכי מתקדמים בימים ההם, כאשר הם ניהלו את המחקר ב-2001, אז הם השתמשו במין גרסה אחרת, שונה, של רגרסיה לוגיסטית שנקראת פרספטרון. הם גם לקחו קצת אלגוריתמים שהיו די בשימוש בתקופה ההיא אבל קצת פחות בשימוש עכשיו, אלגוריתם ניפוי (winnow) דומה מאוד לרגרסיה לוגיסטית אבל שונה בכמה פרטים, שעכשיו הוא כבר לא כל כך בשימוש, וגם אלגוריתם למידה "מבוסס זיכרון" שגם הוא קצת פחות נפוץ בימינו. אני אספר לכם קצת על זה יותר מאוחר. והם השתמשו באלגוריתם בייס נאיבי, שהוא משהו שאנחנו בהחלט נדבר עליו בקורס. הפרטים המדויקים של האלגוריתמים האלה אינם חשובים. תחשבו על זה כעל בחירה של ארבעה אלגוריתמי סיווג שונים, ובאמת האלגוריתמים המדויקים אינם חשובים. אבל מה שהם עשו היה לנסות גדלים שונים של סדרת האימון וניסו את אלגוריתמי הלמידה האלה על טווח של גדלים של סדרת אימון וזוהי התוצאה שהם קיבלו. והמגמות מאוד ברורות. קודם כל, רוב האלגוריתמים האלה נותנים ביצועים דומים להפליא. ושנית, כאשר סדרת האימון גדלה, על הציר האופקי יש לנו גודל סדרת האימון במיליונים, אז כשהסדרה גדלה ממאה אלף לאלף מיליון דהיינו מיליארד דוגמאות הכשרה, הביצועים של האלגוריתמים גדלים באופן מונוטוני, והעובדה היא שאם בוחרים באלגוריתם כלשהו, ואנחנו עלולים לבחור אלגוריתם "נחות", אבל אם ניתן לאלגוריתם ה"נחות" הזה יותר נתונים, אז ממה שרואים כאן, נראה שזה יהיה סביר שהוא ינצח לנצח אפילו אלגוריתם "מעולה". לאחר המחקר המקורי הזה, שהיה בעל השפעה רבה, נערכו עוד מגוון של מחקרים שונים המראים תוצאות דומות, המראים שאלגוריתמים שונים של למידה נוטים לעיתים, בהתאם לפרטים, יכולים לתת טווחי ביצועים דומים למדי, ושמה שיכול באמת לשפר את הביצועים הוא אם נותנים לאלגוריתם טונות של נתוני אימון. ותוצאות כמו אלה הובילה לאימרה בלמידת מכונה שהרבה פעמים בלמידת מכונה זה לא מי שיש לו האלגוריתם הכי טוב שמנצח, זה מי שיש לו הכי הרבה נתונים. אז השאלה היא מתי זה נכון ומתי זה לא נכון. כי כשיש לנו אלגוריתם למידה שעבורו זה נכון, אז להשיג המון נתונים היא לעתים קרובות הדרך הכי טובה להבטיח שיהיה לנו אלגוריתם עם ביצועים גבוהים מאוד, ולא דיונים ממושכים לגבי באיזה אלגוריתם להשתמש. בואו ננסה לקבוע שורה של הנחות שכשהן מתקיימות אנחנו חושבים שזה יוכל לעזור לנו אם יהיה לנו מערך אימון ענקי. נניח שבבעיית הלמידה של המכונה שלנו, בתכונות x אכן קיים מספיק מידע כדי לחזות את y באופן מדויק. לדוגמה, אם ניקח את המילים המבלבלות שהיתה לנו בשקופית הקודמת. נניח שוקטור התכונות x כולל את מה שמסביב, את המרחב הריק מסביב לחלק שאנחנו מנסים למלא. התכונות כוללות את מה שאנחנו צריכים, יש לנו המשפט לפעמים לארוחת בוקר אני אוכל רווח ביצים. זה בעצם מספיק מידע כדי לומר לנו שהמילה שאנחנו רוצים במקום הריק היא "שתי" - TWO - ולא TO ולא TOO. אז התכונות כוללות את המילים המקיפות מה שנותן לנו מספיק מידע כדי להחליט בצורה חד משמעית מה היא התווית y, או במילים אחרות מה היא המילה שאני צריך להשתמש בה כדי למלא את המקום הריק מתוך הקבוצה הזו של שלוש מילים מבלבלות. אז זו דוגמה שבה סט התכונות x מכיל מספיק מידע לחשב את y. כדוגמה נגדית בואו נחשוב על בעיה של חיזוי מחירו של בית רק מתוך גודל הבית ולא משום תכונות אחרות. אז אז אם תדמיינו שאני אומר לכם שגודל הבית הוא 500 רגל מרובע אבל אני לא נותן לכם שום תכונות אחרות. אני לא אומר לכם שהבית נמצא באזור יקר של העיר. או אם אני לא אומר לכם את מספר החדרים בבית, או כמה יפה מרוהט הבית, או אם הבית חדש או ישן. אם אני לא אומר לכם שום דבר חוץ מאשר שגודלו הוא 500 רגל מרובע, יש כל כך הרבה גורמים אחרים שישפיעו על מחיר של בית חוץ מאשר רק הגודל של הבית שאם כל מה שאנחנו יודעים הוא הגודל שלו, אז זה ממש קשה לחזות את המחיר במדויק. אז זו תהיה דוגמה נגדית להנחה הזו, ההנחה שהתכונות מכילות מספיק מידע כדי לחזות את המחיר ברמת הדיוק הרצוי. האופן שבו אני חושב על בדיקת ההנחה הזאת, דרך אחת שבה אני חושב על זה, אני שואל את עצמי במצב הזה. בהינתן וקטור תכונות x, בהינתן התכונות, בהינתן אותו מידע זמין, כמו גם אלגוריתם למידה. אם היינו הולכים למומחה אנושי בתחום הזה האם מומחה אנושי יכול או האם יכול מומחה אנושי לחזות בביטחון את הערך של y. עבור הדוגמה הראשונה הזו אם נלך למומחה דובר אנגלית, אתה הולך למישהו שמדבר אנגלית טוב, נכון, אז מומחה אנושי באנגלית כמו לדוגמא אני או רוב האנשים כמוך וכמוני כנראה נצליח לחזות איזו מילה צריכה להיכנס לכאן, דוברי אנגלית טובה יכולה לחזות את זה בביטחון, ולכן זה נותן לי ביטחון ש-x מאפשר לנו לחזות את y במדויק, אבל לעומת זאת אם אנחנו הולכים למומחה אנושי במחירים, אולי סוכן נדל"ן מומחה, כן, מישהו שמוכר בתים לפרנסתו. אם אני רק אומר להם את גודל הבית ואני שואל אותם מה המחיר, גם אם הוא מומחה למחירים או למכירת בתים, הוא לא יוכל לעזור לי, ולכן אני מסיק שעבור הדוגמה של מחיר הדיור, ידיעת הגודל איננה נותנת לנו מספיק מידע כדי לחזות את מחיר הבית. אז בואו נניח ש-x כן נותן מספיק מידע. בוא נראה מתי זה שיש לנו הרבה נתונים עשוי לעזור. נניח שבתכונות יש מספיק מידע כדי לחזות את הערך של y. ונניח שאנחנו משתמשים באלגוריתם למידה עם מספר רב של פרמטרים, רגרסיה לוגיסטית או רגרסיה ליניארית עם מספר רב של תכונות. דבר אחד שאני עושה לפעמים, דבר אחד שאני עושה לעתים קרובות בעצם הוא להשתמש ברשת עצבית עם הרבה יחידות נסתרות. זה עוד סוג של אלגוריתם למידה עם הרבה פרמטרים. אז כל אלה הם אלגוריתמי למידה חזקים עם הרבה פרמטרים שיכולים להתאים פונקציות מורכבות מאוד לנתונים. אני קורא להם, אני חושב עליהם כאלגוריתמים בעלי הטייה נמוכה כי אנחנו יכולים להתאים פונקציות מורכבות מאוד, ומאחר ויש לנו אלגוריתמי למידה חזקים מאוד, ולכן הם יכולים להתאים פונקציות מורכבות מאוד. רוב הסיכויים הם שאם נפעיל את האלגוריתמים הללו על ערכות הנתונים, הם יוכלו להתאים את סדרת האימון היטב, ולכן אנחנו מצפים ששגיאת האימון תהיה קטנה. עכשיו נניח שאנחנו משתמשים בסדרת אימון ממש ענקית, במקרה זה, אם יש לנו קבוצת אימון ענקית, אז יש לקוות שלמרות שיש לנו הרבה פרמטרים אבל מכיוון שסדרת האימון הוא בעצם אפילו הרבה יותר גדולה ממספר הפרמטרים אז בתקווה האלגוריתמים האלה לא יחוו התאמת-יתר. ברור? כי יש לנו כזו קבוצת אימון מסיבית והכוונה בכך ש"לא סביר שתהיה התאמת-יתר" היא ששגיאת האימון תהיה בתקווה קרובה לשגיאת הבדיקה. אז כשמחברים את שני המשפטים, שלסדרת האימון יש שגיאה קטנה ולסדרת המבחן יש שגיאה קרובה לשגיאת האימון, מה ששני אלה ביחד רומזים הוא שאנחנו מקווים שגם השגיאה של ערכת הבדיקה תהיה קטנה. דרך נוספת לחשוב על זה היא שכדי שיהיה לנו אלגוריתם למידה בעל ביצועים גבוהים, אנחנו רוצים שהוא לא יהיה בעל הטיה גבוהה וגם לא תהיה לו שונות גבוהה. אז את בעיית ההטיה אנחנו פותרים על ידי כך שמוודאים שיש לנו אלגוריתם למידה עם הרבה פרמטרים מה שנותן לנו אלגוריתם בעל הטיה נמוכה ובאמצעות סדרת אימון גדולה מאוד, אנחנו מבטיחים שאין לנו כאן גם בעיה שונות. אז אנחנו מקווים שלאלגוריתם שלנו תהיה שונות נמוכה ולכן על ידי חיבור שני הדברים האלה, אנחנו מקבלים אלגוריתם למידה עם הטיה נמוכה ושונות נמוכה וזה מאפשר לנו להצליח על ערכת הבדיקה. וביסודו של דבר אלה מרכיבי המפתח, ההנחה שהתכונות מכילות מספיק מידע ושיש לנו פונקציה מספיק כוללת, זה מה שמבטיח הטיה נמוכה, ואז סדרת אימון מסיבית זה מה שמבטיח גם שונות נמוכה. אז זה נותן לנו סט של תנאים שבתקווה שופכים קצת אור על הסוג הזה של בעיה שבה אם יש לך הרבה נתונים ואתה בנית אלגוריתם למידה עם הרבה פרמטרים, זו יכולה להיות דרך טובה להעניק לאלגוריתם הלמידה שלך ביצועים גבוהים, ובאמת אני חושב שמבחן המפתח שאני שואל את עצמי לעתים קרובות הוא קודם כל, האם מומחים אנושיים יכולים מתוך הסתכלות על התכונות x לחזות בביטחון את הערך של y. כי זה סוג של הבטחה ש-y ניתן לחיזוי במדויק מן התכונות x והדבר השני הוא האם אנחנו באמת יכולים להשיג סט אימון גדול, ולאמן את אלגוריתם הלמידה עם הרבה פרמטרים על סט האימון ואם אתה יכול לעשות את שניהם אז זה לעתים קרובות יתן לנו אלגוריתם למידה בעל ביצועים טובים מאוד.