1
00:00:00,150 --> 00:00:04,540
U ovom i narednom snimku želim da
detaljno razradim primer

2
00:00:04,540 --> 00:00:08,970
izračunavanja kompleksne nelinearne funkcije
pomoću neuronske mreže.

3
00:00:08,970 --> 00:00:13,686
Nadam se da će Vam to pojasniti
zašto se neuronske mreže

4
00:00:13,686 --> 00:00:16,717
koriste za učenje kompleksnih
nelinearnih hipoteza.

5
00:00:16,717 --> 00:00:20,848
Razmotrimo primer u kome
imamo promenljive

6
00:00:20,848 --> 00:00:22,760
X1 i X2 koje uzimaju binarne vrednosti.

7
00:00:22,760 --> 00:00:24,030
Dakle, mogu biti ili 0 ili 1.

8
00:00:24,030 --> 00:00:28,700
Znači, svaka od te dve promenljive može imati
samo jednu od te dve vrednosti.

9
00:00:28,700 --> 00:00:31,550
U ovom primeru nacrtao sam samo 
dva pozitivna i

10
00:00:31,550 --> 00:00:33,060
dva negativna primera.

11
00:00:33,060 --> 00:00:37,750
Možete na ovo gledati kao na
pojednostavljenu verziju

12
00:00:37,750 --> 00:00:40,770
problema u kojima imamo mnogo pozitivnih
primera gore desno

13
00:00:40,770 --> 00:00:44,810
i dole levo i mnogo negativnih primera
obeleženih kružićima.

14
00:00:44,810 --> 00:00:49,950
Mi želimo da naučimo nelinearnu
granicu

15
00:00:49,950 --> 00:00:52,700
koja odvaja pozitivne od
negativnih primera.

16
00:00:53,750 --> 00:00:57,630
Kako to može uraditi neuronska mreža?

17
00:00:57,630 --> 00:01:02,850
Umesto ovog primera razmotrićemo
njegovu uprošćenu verziju sa leve strane.

18
00:01:02,850 --> 00:01:04,952
Konkretno, ovo predstavlja

19
00:01:04,952 --> 00:01:09,643
izračunavanje y je jednako
x1 xor x2,

20
00:01:09,643 --> 00:01:15,371
preciznije ovo je x1 xnor x2 funkcija
gde je xnor

21
00:01:15,371 --> 00:01:20,040
alternativna oznaka za
nije x1 ili x2.

22
00:01:20,040 --> 00:01:27,995
Dakle, x1 xor x2 je tacno samo ako je
jedno od X1 ili X2 jednako 1.

23
00:01:27,995 --> 00:01:32,606
Ispostavlja se da je ovaj primer
lakše razumeti ako

24
00:01:32,606 --> 00:01:35,595
koristimo xnor primer umesto njega.

25
00:01:35,595 --> 00:01:38,215
Ova dva su ista, naravno.

26
00:01:38,215 --> 00:01:43,465
Ovo je negacija od x1 xor x2
koja je tačna

27
00:01:43,465 --> 00:01:49,335
samo ako su oba tačna ili ako su oba netačna
i tada je y jednako 1.

28
00:01:49,335 --> 00:01:54,020
Imaćemo da je y jednako 0 samo kada
je jedno od njih tačno i

29
00:01:54,020 --> 00:01:57,610
pokušaćemo da napravimo neuronsku
mrežu za ovaj skup podataka za treniranje.

30
00:01:59,200 --> 00:02:05,080
Da bismo napravili mrežu koja
modelira xnor primer

31
00:02:05,080 --> 00:02:10,810
počećemo sa jednostavnijim primerom
mreže koja modelira "i" funkciju.

32
00:02:10,810 --> 00:02:14,933
Konkretno, recimo da imamo ulazne
promenljive x1 i x2

33
00:02:14,933 --> 00:02:19,491
koje su, ponovo, binarne
znači ili 0 ili 1.

34
00:02:19,491 --> 00:02:24,174
Recimo da je modeliramo informaciju y
 jednako x1 i x2.

35
00:02:24,174 --> 00:02:25,485
Ovo je logičko "i".

36
00:02:30,577 --> 00:02:37,267
Možemo li napraviti mrežu sa jednom
jedinicom za izračunavanje funkcije logičkog "i"?

37
00:02:37,267 --> 00:02:38,513
Da bismo to uradili,

38
00:02:38,513 --> 00:02:43,352
nacrtaću i jedinicu pristrasnosti, +1 jedinicu.

39
00:02:45,022 --> 00:02:50,150
Sada ću dodeliti neke vrednosti
težinama tj. parametrima ove mreže.

40
00:02:50,150 --> 00:02:56,332
Zapisaću parametre na ovom
dijagramu,

41
00:02:56,332 --> 00:02:59,026
-30 ovde i +20 i +20.

42
00:02:59,026 --> 00:03:03,817
Ovo označava to da dodeljujem
vrednost -30

43
00:03:03,817 --> 00:03:08,521
vrednosti koju ima x0,
ovo +1 ide u ovu jedinicu.

44
00:03:08,521 --> 00:03:13,756
Parametar sa vrednošću +20
množi x1,

45
00:03:13,756 --> 00:03:16,890
vrednost +20 ima i parametar
koji množi x2.

46
00:03:16,890 --> 00:03:21,901
Konkretno, to je isto kao da sam napisao

47
00:03:21,901 --> 00:03:30,600
da je hipoteza h Teta od x jednako
g od -30 plus 20 x1 plus 20 x2.

48
00:03:30,600 --> 00:03:34,485
Ponekad je korisno nacrtati
ove težine,

49
00:03:34,485 --> 00:03:40,453
nacrtati te parametre na dijagramu.
I naravno ovo -30

50
00:03:40,453 --> 00:03:45,622
to je zapravo Teta(1)10.

51
00:03:45,622 --> 00:03:50,323
Ovo je Teta(1)11, a ovo je

52
00:03:50,323 --> 00:03:54,711
Teta(1)12, ali je lakše o tome razmišljati

53
00:03:54,711 --> 00:03:59,010
kao o vezi parametara sa
ivicama neuronske mreže.

54
00:04:01,200 --> 00:04:05,060
Pogledajmo šta će izračunati ova neuronska mreža
koja ima samo jedan jedini neuron.

55
00:04:05,060 --> 00:04:08,950
Samo da Vas podsetim, sigmoidna funkcija
aktivacije, g od z, izgleda ovako.

56
00:04:08,950 --> 00:04:13,614
Počinje u nuli, zatim glatko raste,
prolazi kroz 0,5 i

57
00:04:13,614 --> 00:04:18,712
asimptotski se približava jedinici.
Da bolje razumete ovu funkciju,

58
00:04:18,712 --> 00:04:23,484
znajte da, kada za vrednost na
horizontalnoj osi 4,6

59
00:04:23,484 --> 00:04:27,506
sigmoidna funkcija ima vrednost 0,99,

60
00:04:27,506 --> 00:04:31,818
što je veoma blizu jedinice.
Simetrično,

61
00:04:31,818 --> 00:04:39,270
za vrednost -4,6 sigmoidna funkcija ima
vrednost 0,01, što je blizu nule.

62
00:04:39,270 --> 00:04:43,037
Razmotrimo koje su četiri moguće vrednosti
koje promenljive x1 i x2 mogu da imaju

63
00:04:43,037 --> 00:04:46,252
i koje će vrednosti hipoteza imati
u tim slučajevima.

64
00:04:46,252 --> 00:04:49,440
Ako su i x1 i x2 jednaki nuli,

65
00:04:49,440 --> 00:04:51,100
vidimo ovde da

66
00:04:51,100 --> 00:04:56,410
ako su x1 i x2 jednaki nuli onda je
hipoteza, g od z, jednaka -30.

67
00:04:56,410 --> 00:05:01,429
Ta vrednost je na levom kraju ovog dijagrama,
znači hipoteza je skoro nula.

68
00:05:01,429 --> 00:05:06,562
Ako je x1 nula, a x2 jedan
onda je prema ovoj formuli

69
00:05:06,562 --> 00:05:11,521
g, tj. sigma funkcija jednaka -10
i ponovo

70
00:05:11,521 --> 00:05:16,744
to je na levom kraju grafika
pa je hipoteza bliska nuli.

71
00:05:17,950 --> 00:05:22,662
Ovo je, takođe, g od -10
to je slučaj kada je x1 jedan

72
00:05:22,662 --> 00:05:27,477
i x2 nula, tada imamo -30 plus 20
što je -10.

73
00:05:27,477 --> 00:05:34,868
Na kraju, ako su i x1 i x2 jednaki 1
onda imamo g od -30 plus 20 plus 20.

74
00:05:34,868 --> 00:05:38,365
Znači imamo g od 10,
što je veoma blizu 1.

75
00:05:39,650 --> 00:05:45,879
Ako pogledate ovu kolonu
videćete da je to upravo funkcija logičkog "i".

76
00:05:45,879 --> 00:05:50,729
Dakle, računali smo hipotezu
h od x približno

77
00:05:50,729 --> 00:05:55,510
jednako x1 i x2.

78
00:05:55,510 --> 00:05:59,937
Drugim rečima, ona ima vrednost 1
ako i samo ako su

79
00:05:59,937 --> 00:06:03,157
x1 i x2 oba jednaka jedinici.

80
00:06:03,157 --> 00:06:08,078
Time što smo nacrtali ovu
tablicu istinitosti

81
00:06:08,078 --> 00:06:12,771
uspeli smo otkriti koju
logičku funkciju

82
00:06:12,771 --> 00:06:17,015
naša neuronska mreža računa.

83
00:06:17,015 --> 00:06:20,070
Ova mreža izračunava funkciju "ili".

84
00:06:20,070 --> 00:06:22,600
Samo da Vam pokažem kako
sam ja to zaključio.

85
00:06:22,600 --> 00:06:27,858
Ako zapišete hipotezu videćete da
je ona

86
00:06:27,858 --> 00:06:33,344
g od -10 plus 20 x1 plus 20 x2
pa ako je izračunate za ove vrednosti

87
00:06:33,344 --> 00:06:37,446
videćete da je ovo g od -10,
što je približno 0,

88
00:06:37,446 --> 00:06:42,430
ovo je g od 10, a to je približno 1,
i tako dalje i ovo je približno jedan

89
00:06:42,430 --> 00:06:48,110
i ovo je približno 1, i ovi brojevi 
predstavljaju funkciju logičkog "ili".

90
00:06:49,890 --> 00:06:54,812
Nadam se da nakon ovoga razumete
kako neuronske mreže sa jednim neuronom

91
00:06:54,812 --> 00:06:58,755
mogu izračunati logičke funkcije
kao što su "i" i "ili" i druge.

92
00:06:58,755 --> 00:07:02,362
U sledećem snimku nastavićemo sa
ovim primerom i

93
00:07:02,362 --> 00:07:04,510
videćemo jedan kompleksniji primer.

94
00:07:04,510 --> 00:07:09,340
Videćete i kako neuronske mreže
sa više slojeva mogu da

95
00:07:09,340 --> 00:07:13,107
se koriste za složenije funkcije
kao što je xor funkcija

96
00:07:13,107 --> 00:07:14,330
ili xnor funkcija.