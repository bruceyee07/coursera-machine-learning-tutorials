בסרטון הזה ברצוני לספר לכם כיצד מייצגים רשתות עצביות. במילים אחרות, כיצד מייצגים השערות. או איך אנו מציגים את המודל שלנו בשימוש ברשת עצבית. רשתות עצביות פותחו מניסיון לדמות נוירונים, או רשתות נוירונים במוח. במטרה להסביר את הייצוג, בואו נבחן קודם איך נראה נוירון יחיד. המוח שלכם ושלי מורכב מהמוני נוירונים כמו זה, הנוירונים הם תאים במוח שימו לב לשני דברים. האחד הוא לנוירון יש גוף התא, שנמצא כאן. ולנוירון יש חוטי קלט, ששמם הוא "דנדריטים". חישבו עליהם כעל קולטנים שמקבלים קלטים ממקומות אחרים. לנוירון יש גם חוט פלט, שנקרא "אקסון". באמצעות האקסון, הנוירון יכול לשלוח אותות לנוירונים אחרים. כך הנוירונים מתקשרים ביניהם. בהסתכלות פשטנית, נוירון הוא למעשה יחידה חישובית שמקבלת מספר קלטים דרך הדנדריטים, מבצעת עליהם חישובים, ושולחת את הפלט דרך האקסון לנוירונים אחרים במוח. כאן אתם רואים איור של מקבץ נוירונים. הנוירונים מתקשרים זה עם זה על ידי שליחת פולסים חשמליים בעוצמה נמוכה. הם נקראים גם "spikes", כלומר קפיצה במתח. כאשר נוירון צריך לשלוח הודעה לנוירון או לנוירונים אחרים, הוא שולח פולס קטן של חשמל דרך האקסון לנוירון אחר, וכאן האקסון הזה שהוא החוט העליון מתחבר לדנדריט של הנוירון השני שנמצא כאן. הנוירון קולט את ההודעה מהנוירון הראשון, ומבצע בעזרתו חישוב כלשהו. ואז הוא אולי ישלח הודעה מהאקסון שלו לנוירונים אחרים. זהו התהליך שבו מתבצעת המחשבה האנושית. הנוירונים הללו מבצעים חישובים, מעבירים הודעות לנוירונים אחרים בהתאם לקלטים שהם קיבלו. דרך אגב, זהו גם אופן הפעולה של החושים והשרירים שלנו. אם תרצו להזיז את אחד השרירים, הנוירון בעצם ישלח אות חשמלי לשריר. האות החשמלי יגרום לשריר להתכווץ. העיניים שלכם. אם חוש כלשהו מעוניין לשלוח אות למוח, הוא שולח אות חשמלי אל הנוירון במוח. ברשת עצבית, או ליתר דיוק ברשת עצבית מלאכותית שאנו מממשים במחשב, אנו משתמשים במודל מאוד פשוט לנוירונים אמיתיים. אנו נתייחס לנוירון כאל יחידה לוגיסטית. כשאני מצייר עיגול צהוב כמו זה, עליכם להתייחס אליו כאל יחידה שמתפקדת בדומה לגוף הנוירון. אנו מאכילים את הנוירון במספר קלטים, באמצעות הדנדריטים או חוטי הקלט. ואז הנוירון מבצע חישובים, ומוציא כפלט את התוצאה דרך חוט הפלט. בנוירון ביולוגי, חוט הפלט הוא האקסון. כאשר אני מצייר תרשים כמו זה, משמעותו היא חישוב של h של x. כאשר הנוסחה היא 1 חלקי 1 ועוד e בחזקת מינוס θ משוחלפת כפול x, כאשר בדרך כלל, x ו-θ הם וקטורי פרמטרים. זו דוגמה די פשוטה, ברמת הפשטה גבוהה מאוד של החישובים שנוירון עושה, הוא מקבל את הקלטים x1 x3 ,x2 ומוציא פלט כלשהו. כשאני מצייר רשת עצבית, בד"כ אני רושם רק את צמתי הקלטים x1,x2,x3. בעת הצורך ניתן גם להוסיף את הצומת x0. הרשומה ה-x0 נקראת גם יחידת הסטיה או נוירון הסטיה. אבל מכיוון ש-x0 תמיד שווה ל-1, אני לפעמים לא מוסיף את x0 לתרשים. הוספת הערך x0 תלויה בדוגמה שעליה אנו עובדים. ולבסוף, נדבר על מונח אחרון. כאשר אנו מדברים על רשתות עצביות, לעיתים נאמר שמדובר בנוירון או בנוירון מלאכותי עם סיגמויד או עם פונקצית הפעלה לוגיסטית. על פי הטרמינולוגיה ברשתות עצביות, פונקציית הפעלה היא מונח נוסף עבור הפונקציה הבלתי ליניארית g של z שערכה 1 חלקי 1 ועוד e בחזקת z-. עד כה קראתי ל-θ פרמטר של המודל, ולרוב גם אמשיך להשתמש בטרמינולוגיה הזו. כאן, אנחנו קוראים ל-θ פרמטר, אך בעולם הרשתות העצביות, תוכלו לראות בספרות המקצועית את המונח "משקל" של מודל. פירוש המונח "משקל" הינו זהה למונח פרמטרים של מודל. לרוב, אני אשתמש במונח "פרמטרים" במהלך הסירטונים הללו. לעיתים תשמעו אחרים המשתמשים במונח "משקלים". ובכן, התרשים שכאן מייצג נוירון בודד. רשת עצבית הינה קבוצה של נוירונים שונים מחוברים יחדיו. כאן יש לנו יחידות קלט x1,x2,x3 ושוב, גם כאן אפשר להוסיף את הרשומה x0, אבל זה לא חובה. וכאן יש לנו שלושה נוירונים המיוצגים על ידי המספרים a(2)1, a(2)2 ו-a(2)3 אסביר על האינדקסים האלה בהמשך. ושוב, אם נרצה נוכל להוסיף את a0. להוסיף לכאן את יחידת הסטייה או ההטייה. ערכה תמיד יהיה 1. ולבסוף, יש לנו את הצומת השלישי בשכבה האחרונה. בשכבה הזו אנו מוציאים את הפלט, הערך שחושב על ידי ההשערה (h(x. נציג עוד כמה טרמינולוגיות בנושא. ברשת עצבית השכבה הראשונה נקראת גם שכבת הקלט, מכיוון שמכאן מגיעים התכונות שלנו x1,x2,x3. השכבה האחרונה נקראת גם שכבת הפלט, מכיוון שכאן נמצא נוירון יחיד שאחראי על החישוב הסופי ומוציא כפלט את התוצאה של ההשערה. השכבה האמצעית נקראת גם השכבה החבויה. "השכבה החבויה" אינו מינוח טוב במיוחד, אבל הרעיון הוא שמדובר בשכבת ביניים. שכבה זו מקשרת בין שתי השכבות האחרות. אתם יכולים לראות את הקלטים ואת הפלטים, אבל בשכבה החבויה לא תוכלו לצפות בערכי המשתנים, כי הם חלק מתוכנית האימון. זה לא x וזה לא y, וזו הסיבה שבגללה אנו קוראים לה חבויה. בהמשך אנו נראה רשתות עצביות בעלות שכבות חבויות מרובות, אבל בדוגמה הזו ישנה שכבת קלט אחת, שכבה חבויה אחת, ושכבת פלט אחת אחרונה. בעיקרון, כל שכבה שאינה שכבת קלט או שכבת פלט, נקראת שכבה חבויה. אני רוצה להבהיר במדויק מה הרשת העצבית הזו עושה. בואו נסתכל צעד אחר צעד על שלבי החישוב המיוצגים בתרשים הזה. על מנת להסביר את החישובים המיוצגים על ידי רשת עצבית, הנה עוד קצת סימונים. אני אשתמש ב-a(j)i כדי לציין את פונקצית ההפעלה של הנוירון i או של היחידה i בשכבה j. אז באופן ספציפי, a(2)1, זו ההפעלה של היחידה הראשונה (1) בשכבה השנייה (2), השכבה החבויה או הסמויה שלנו. וכשאני אומר "הפעלה", אני מתכוון לערך שמחושב על ידי ושמוצא כפלט על ידי יחידה מסוימת. בנוסף, לרשת עצבית יש פרמטר שהוא מטריצה Θ (תטא גדולה) עם אינדקס j, כש-Θj הוא מטריצת משקלות השולטת בפונקציה הממפה משכבה לשכבה הבאה, לדוגמא מהשכבה הראשונה לשנייה. או מהשכבה השנייה לשלישית. אז הנה הם החישובים שמיוצגים על ידי התרשים. הערך של התא החבוי העליון שכאן, מחושב כדלקמן: a(2)1 מקבל את הערך של g פונקצית הסיגמואיד, הנקראת גם פונקצית ההפעלה הלוגיסטית, המופעלת על הקומבינציה הליניארית הזו של הקלטים האלה, והתא החבוי השני מקבל את ערך ההפעלה של הביטוי הזה, וכן לגבי התא הנסתר השלישי המקבל את ערך הפונקציה הזו, אז כאן יש לנו שלשה ערכי קלט ושלשה תאים חבויים, זאת אומרת שהממדים של Θ1 שהיא מטריצת הפרמטרים השולטת בטרנספורמציה מהקלט אל השכבה הסמויה Θ1 תהיה לכן... Θ1 תהיה לכן מטריצה עם ממדים 3 על 4 ובאופן כללי יותר, אם לרשת יש sj יחידות בשכבה j ו-(s(j+1 בשכבה j+1, אז המטריצה Θj, ששולטת במיפוי בין שתי השכבות האלה, תהיה בעלת ממדים (s(j+1 על (s(j) + 1). אל תתבלבלו כאן. הראשון הוא s עם אינדקס j+1, והשני s עם אינדקס j, וכל זה ועוד 1. ברור? אז זה s במקום j+1 אז זה s במקום j+1, כפול s במקום j, ועוד 1, כאשר כשה"ועוד" כאן איננו חלק מהאינדקס. אז דיברנו על מה עושות היחידות החבויות האלה כדי לחשב את ערכיהן, יש עוד השכבה האחרונה יש לנו שכבה אחרונה שמחשבת את h של x, אפשר לכתוב אותה גם כ-a(3)1, והערך שלה הוא זה. ושימו לב שה-Θ כאן הם עם אינדקס עליון 2, כי Θ עם אינדקס עליון 2 היא המטריצה של הפרמטרים או מטריצת המשקלות ששולטת במעבר מהשכבה החבויה שהיא שכבה 2, לשכבה 3 שהיא שכבת הפלט. לסיכום, הראינו איך תמונה כמו כאן למעלה משמאל מגדירה רשת ניורונים מלאכותית שמגדירה פונקציה h שממפה מx-ים לערכים שאנו מקווים נותנים הערכה טובה של y. ופונקציות השערה כאלה יש להם פרמטרים שמסומנים ב-Θ (תטא גדולה), כך שכשאנחנו משנים את Θ, אנחנו מקבלים פונקציות השערה שונות שממפות מ-x ל-y. זה נותן לנו הגדרה מתמטית של איך לייצג פונקצית השערה ברשת עצבית. בסרטונים הבאים אני אוסיף לכם עוד אינטואיציות לגבי מה עושים הייצוגים האלה של פונקציות השערה, וגם אעבור על כמה דוגמאות ונדבר על איך לחשב אותם בצורה יעילה.