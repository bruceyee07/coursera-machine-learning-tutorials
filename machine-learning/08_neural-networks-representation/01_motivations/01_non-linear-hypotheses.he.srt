1
00:00:00,440 --> 00:00:01,400
בסירטון הנוכחי

2
00:00:01,480 --> 00:00:02,640
ובסירטונים הבאים, אני מעוניין

3
00:00:02,780 --> 00:00:04,270
לספר לכם על אלגוריתם למידה

4
00:00:04,550 --> 00:00:06,110
הנקרא "רשת נוירונים" או "רשת עצבית".

5
00:00:07,190 --> 00:00:07,900
תחילה, אדבר על הייצוג,

6
00:00:08,079 --> 00:00:09,330
ולאחר מכן במקבץ הסירטונים שאחריו,

7
00:00:09,600 --> 00:00:10,390
נדבר על אלגוריתמי למידה

8
00:00:10,410 --> 00:00:12,160
המיישמים את הרשת העצבית.

9
00:00:12,660 --> 00:00:14,070
רשת נוירונים היא למעשה

10
00:00:14,510 --> 00:00:15,870
רעיון די ותיק, אבל הוא

11
00:00:16,290 --> 00:00:17,680
נעזב לזמן מה.

12
00:00:18,200 --> 00:00:19,270
אבל כיום זהו

13
00:00:19,580 --> 00:00:20,820
אחד הרעיונות החדשניים המשמש בטכניקות רבות

14
00:00:21,090 --> 00:00:22,390
בפתרון בעיות ביישומי למידת מכונה.

15
00:00:23,740 --> 00:00:25,740
מדוע אנו זקוקים לאלגוריתם למידה נוסף?

16
00:00:26,300 --> 00:00:28,030
כבר יש לנו רגרסיה ליניארית,

17
00:00:28,180 --> 00:00:31,260
כבר יש לנו רגרסיה לוגיסטית, אז למה צריך גם רשת עצבית?

18
00:00:32,280 --> 00:00:34,260
על מנת להתניע את הדיון

19
00:00:34,790 --> 00:00:35,970
על רשת נוירונים,

20
00:00:36,120 --> 00:00:37,130
אציג בפניכם מספר

21
00:00:37,310 --> 00:00:38,720
דוגמאות לבעיות בנושא למידת מכונה

22
00:00:38,930 --> 00:00:40,100
שבהן אנו צריכים

23
00:00:40,300 --> 00:00:41,850
ללמוד השערות לא-ליניאריות מורכבות.

24
00:00:43,850 --> 00:00:45,650
לצורך ההדגמה, ניקח בעיית למידה מונחית

25
00:00:46,530 --> 00:00:48,440
כאשר ערכת האימון נראית כך.

26
00:00:49,280 --> 00:00:50,530
אם נרצה ליישם רגרסיה ליניארית

27
00:00:50,960 --> 00:00:52,710
על הבעיה הזו,

28
00:00:52,900 --> 00:00:54,250
דבר אחד שנוכל לבצע

29
00:00:54,660 --> 00:00:56,140
הוא יישום של רגרסיה לוגיסטית

30
00:00:56,190 --> 00:00:57,720
עם מאפיינים בלתי ליניארים רבים כמו כאן מימין,

31
00:00:58,170 --> 00:00:59,580
אז הנה לדוגמה,

32
00:01:00,070 --> 00:01:01,710
g היא פונקציית סיגמואיד,

33
00:01:01,780 --> 00:01:04,680
ונוכל להוסיף איברים פולינומיאלים נוספים,

34
00:01:05,450 --> 00:01:06,790
אם נוסיף מספיק איברים פולינומיאלים,

35
00:01:07,370 --> 00:01:08,280
אז אולי

36
00:01:08,950 --> 00:01:10,280
נצליח להשיג השערה

37
00:01:11,600 --> 00:01:13,780
שמפרידה בין הדוגמאות החיוביות והשליליות.

38
00:01:14,630 --> 00:01:16,080
השיטה הזו עובדת היטב כאשר

39
00:01:16,470 --> 00:01:18,400
מדובר רק בשני צירים

40
00:01:18,620 --> 00:01:20,180
x1 ו-x2

41
00:01:20,190 --> 00:01:20,980
מכיוון שכך נוכל להכניס

42
00:01:21,500 --> 00:01:22,880
את כל הביטויים הפולינומיים של

43
00:01:23,400 --> 00:01:24,620
x1 ו-x2.

44
00:01:24,810 --> 00:01:26,280
אבל בשביל הרבה בעיות

45
00:01:26,520 --> 00:01:27,730
בלמידה חישובית, יש לנו

46
00:01:27,910 --> 00:01:29,230
הרבה יותר משני מאפיינים.

47
00:01:30,780 --> 00:01:31,760
אנחנו מדברים זה זמן מה על

48
00:01:32,320 --> 00:01:34,560
חיזוי מחירי דיור. נניח

49
00:01:35,130 --> 00:01:36,990
שיש לנו בעיית סיווג של דיור

50
00:01:38,020 --> 00:01:39,280
ולא בעיית

51
00:01:39,390 --> 00:01:41,170
רגרסיה, כמו למשל

52
00:01:41,580 --> 00:01:43,350
מצב שבו יש לנו מאפיינים שונים

53
00:01:43,440 --> 00:01:44,760
של הבית,

54
00:01:45,010 --> 00:01:46,000
ואנחנו רוצים לחזות

55
00:01:46,050 --> 00:01:47,590
את הסיכוי שהבית

56
00:01:47,700 --> 00:01:48,710
יימכר בחצי השנה הקרובה.

57
00:01:48,910 --> 00:01:51,040
אז זוהי בעיית סיווג.

58
00:01:52,100 --> 00:01:53,060
כפי שראינו, אנחנו יכולים

59
00:01:53,260 --> 00:01:55,130
להמציא די הרבה

60
00:01:55,260 --> 00:01:56,480
מאפיינים, אולי אפילו מאה

61
00:01:56,840 --> 00:01:58,270
מאפיינים שונים של בתים שונים.

62
00:02:00,130 --> 00:02:01,610
בשביל בעיה כזו,

63
00:02:01,880 --> 00:02:03,260
אם נרצה להוסיף את כל

64
00:02:03,370 --> 00:02:04,980
המשתנים הפולינומיים,

65
00:02:05,100 --> 00:02:06,260
אפילו רק את

66
00:02:06,540 --> 00:02:07,540
הריבועיים, הפולינומיים

67
00:02:07,930 --> 00:02:10,450
מסדר שני, יהיו לנו המון משתנים.

68
00:02:10,560 --> 00:02:11,580
יהיו לנו ביטויים כמו x1 בריבוע,

69
00:02:12,960 --> 00:02:17,610
x1x2, x1x3, x1x4

70
00:02:18,750 --> 00:02:21,880
וכן הלאה עד x1x100

71
00:02:21,980 --> 00:02:23,620
ואז x2 בריבוע, x2x3

72
00:02:25,620 --> 00:02:25,980
וכן הלאה.

73
00:02:26,510 --> 00:02:27,770
ואם נכלול רק את

74
00:02:28,060 --> 00:02:29,200
הרכיבים מהסדר השני, כלומר

75
00:02:29,330 --> 00:02:30,750
רכיבים שהמכפלה ביניהם

76
00:02:30,840 --> 00:02:32,090
מביאה לתוצאה ריבועית

77
00:02:32,220 --> 00:02:33,390
של שני הרכיבים,

78
00:02:33,510 --> 00:02:35,010
x1 כפול x1, וכן הלאה.

79
00:02:35,780 --> 00:02:36,920
עבור המקרה של n=100,

80
00:02:38,180 --> 00:02:40,280
יהיו לנו בערך 5,000 משתנים מסוגים שונים.

81
00:02:41,890 --> 00:02:44,880
מבחינה אסימפטוטית,

82
00:02:45,000 --> 00:02:46,330
מספר המשתנים הריבועיים גדל

83
00:02:46,770 --> 00:02:48,670
בערך בסדר גודל של n בריבוע.

84
00:02:48,820 --> 00:02:50,330
כאשר n מייצג את

85
00:02:50,460 --> 00:02:52,790
כמות המשתנים המקורית,

86
00:02:53,370 --> 00:02:54,780
מ-x1 עד x100.

87
00:02:55,700 --> 00:02:58,750
ומספר זה קרוב יותר ל-n בריבוע חלקי 2.

88
00:02:59,920 --> 00:03:01,440
אם ניקח את כל

89
00:03:01,560 --> 00:03:02,920
המשתנים הריבועיים, נראה

90
00:03:03,220 --> 00:03:04,220
שלא מדובר

91
00:03:04,300 --> 00:03:05,380
ברעיון כל כך טוב.

92
00:03:05,580 --> 00:03:07,050
יש יותר מדי משתנים.

93
00:03:07,220 --> 00:03:08,920
מספר כזה של ביטויים יגרום להתאמת-יתר

94
00:03:09,330 --> 00:03:10,500
וחוץ מזה

95
00:03:10,740 --> 00:03:12,800
עלות החישוב עלולה להיות גבוהה.

96
00:03:14,080 --> 00:03:15,120
שכן מדובר בכמות מאסיבית של משתנים.

97
00:03:16,450 --> 00:03:17,540
דבר אחד שניתן לעשות,

98
00:03:17,770 --> 00:03:19,090
הוא להשתמש רק בתת-קבוצה של הביטויים,

99
00:03:19,290 --> 00:03:20,950
לדוגמא אם נשתמש רק

100
00:03:21,050 --> 00:03:22,630
במשתנים x1 בריבוע, x2 בריבוע,

101
00:03:23,590 --> 00:03:25,180
x3 בריבוע, עד

102
00:03:25,580 --> 00:03:27,750
x100 בריבוע, ואז

103
00:03:28,100 --> 00:03:29,500
מספר המשתנים יהיה קטן משמעותית.

104
00:03:29,980 --> 00:03:31,720
כאן יש לנו רק 100

105
00:03:32,070 --> 00:03:33,850
משתנים ריבועיים, אבל

106
00:03:34,120 --> 00:03:35,950
זה לא מספיק משתנים

107
00:03:36,100 --> 00:03:37,170
והחישוב לא יוביל לתוצאה

108
00:03:37,290 --> 00:03:39,330
כמו בגרף בצד שמאל למעלה.

109
00:03:39,570 --> 00:03:40,550
למעשה, אם נכניס

110
00:03:41,040 --> 00:03:42,720
את המשתנים הריבועיים

111
00:03:43,170 --> 00:03:44,870
יחד עם x1 המקורי,

112
00:03:45,350 --> 00:03:46,500
וכן הלאה עד x100,

113
00:03:47,460 --> 00:03:48,530
אז לא נוכל להתאים

114
00:03:48,910 --> 00:03:50,210
השערות ממש מעניינות.

115
00:03:50,330 --> 00:03:52,350
נוכל להתאים דברים כמו אליפסות

116
00:03:52,490 --> 00:03:53,860
מאונכות לצירים, לדוגמא,

117
00:03:55,080 --> 00:03:56,240
אבל בהחלט לא נוכל

118
00:03:56,340 --> 00:03:57,930
להתאים צורה כמו זו שבגרף.

119
00:03:59,360 --> 00:04:00,530
5000

120
00:04:00,620 --> 00:04:03,090
משתנים זה נשמע כמו הרבה.

121
00:04:03,230 --> 00:04:04,860
אם נכליל גם את החזקה השלישית,

122
00:04:05,140 --> 00:04:06,100
הפולינומים מסדר שלישי,

123
00:04:06,440 --> 00:04:08,050
ה-x1*x2*x3

124
00:04:08,400 --> 00:04:09,800
וגם x1 בריבוע כפול

125
00:04:10,310 --> 00:04:12,240
x10, x2 כפול

126
00:04:12,900 --> 00:04:15,280
x17 כפול x11 וכיוצא באלה,

127
00:04:15,700 --> 00:04:18,110
אתם יכולים לתאר לעצמכם שיהיו לנו כאן המון משתנים.

128
00:04:19,040 --> 00:04:19,770
למעשה, מספר המשתנים יהיה

129
00:04:20,050 --> 00:04:21,260
בסדר גודל של n בשלישית,

130
00:04:22,210 --> 00:04:23,830
ואם n הוא 100

131
00:04:24,150 --> 00:04:25,660
אז ניתן לחשב

132
00:04:25,740 --> 00:04:26,870
שנגיע לסדר גודל של

133
00:04:27,730 --> 00:04:29,650
בערך 170,000 (102 מעל 3) משתנים מסדר שלישי.

134
00:04:30,040 --> 00:04:31,670
והמשתנים

135
00:04:32,260 --> 00:04:34,470
הפולינומיים מסדר גבוה, כאשר

136
00:04:34,920 --> 00:04:36,050
מספר התכונות המקורי הוא גדול,

137
00:04:36,230 --> 00:04:37,730
מספרם הכולל יהיה גדול מאד,

138
00:04:38,530 --> 00:04:40,440
זה מגדיל באופן משמעותי את מרחב התכונות,

139
00:04:41,070 --> 00:04:42,180
זו לא נראית כמו

140
00:04:42,320 --> 00:04:43,320
דרך טובה להשיג

141
00:04:43,560 --> 00:04:45,050
משתנים נוספים שבעזרתם נוכל

142
00:04:45,240 --> 00:04:48,100
לבנות גבול לא-ליניארי כאשר n הוא גדול.

143
00:04:49,590 --> 00:04:52,560
עבור בעיות רבות של למידת מכונה, n יהיה עצום.

144
00:04:53,270 --> 00:04:53,560
הנה דוגמה.

145
00:04:55,000 --> 00:04:58,140
בואו נחשוב על בעיית ראייה ממוחשבת.

146
00:04:59,670 --> 00:05:00,770
ונניח שנרצה

147
00:05:01,260 --> 00:05:02,620
להשתמש בלמידת מכונה כדי לאמן

148
00:05:02,710 --> 00:05:04,610
יכולות סיווג כדי לבחון

149
00:05:04,710 --> 00:05:05,880
תמונה, ולספר לנו האם

150
00:05:06,160 --> 00:05:08,030
מדובר בתמונה של מכונית או לא.

151
00:05:09,480 --> 00:05:11,900
אנשים רבים תוהים מדוע ראייה ממוחשבת הינה עניין מסובך.

152
00:05:12,390 --> 00:05:13,140
כשאתם ואני מסתכלים

153
00:05:13,270 --> 00:05:15,670
על התמונה, היא ברורה לנו כשמש.

154
00:05:15,900 --> 00:05:17,000
הם תוהים כיצד

155
00:05:17,190 --> 00:05:18,320
אלגוריתם למידה יכול בכלל

156
00:05:18,910 --> 00:05:20,880
להיכשל בלהבין מה מייצגת התמונה.

157
00:05:22,110 --> 00:05:23,330
על מנת להבין למה ראייה ממוחשבת

158
00:05:23,720 --> 00:05:25,380
היא מסובכת, הבה נתמקד

159
00:05:25,650 --> 00:05:26,690
בחלק קטנטן של התמונה.

160
00:05:26,940 --> 00:05:28,180
האזור שמסומן בריבוע אדום,

161
00:05:28,510 --> 00:05:30,240
על דלת המכונית.

162
00:05:30,400 --> 00:05:31,330
מסתבר שכאשר אתם ואני

163
00:05:31,450 --> 00:05:34,270
רואים מכונית, המחשב רואה את זה.

164
00:05:34,780 --> 00:05:35,930
הוא רואה מטריצה של נתונים,

165
00:05:36,600 --> 00:05:38,110
ייצוג של עוצמה של פיקסלים,

166
00:05:38,580 --> 00:05:40,350
ערכים שמפרטים

167
00:05:40,610 --> 00:05:42,930
את הבהירות של כל פיקסל בתמונה.

168
00:05:43,640 --> 00:05:45,170
בעיית הראייה הממוחשבת היא

169
00:05:45,550 --> 00:05:47,230
להסתכל על טבלת

170
00:05:47,310 --> 00:05:49,140
בהירות הפיקסלים הזו,

171
00:05:49,410 --> 00:05:52,440
ולהסיק שהמספרים הללו מייצגים ידית של דלת מכונית.

172
00:05:54,230 --> 00:05:55,740
באופן קונקרטי, כשמשתמשים

173
00:05:56,030 --> 00:05:57,220
בלמידת מכונה כדי לבנות

174
00:05:57,430 --> 00:05:59,060
מערכת המזהה מכוניות,

175
00:05:59,360 --> 00:06:00,510
אנו בונים למערכת

176
00:06:00,800 --> 00:06:02,690
ערכת אימון המכילה

177
00:06:02,890 --> 00:06:04,250
מספר דוגמאות לתמונות

178
00:06:04,730 --> 00:06:05,850
שבחלקן יש מכונית

179
00:06:06,000 --> 00:06:07,150
ובחלקן מצולמים

180
00:06:07,380 --> 00:06:08,780
דברים שהם לא מכוניות.

181
00:06:09,090 --> 00:06:10,590
נביא את ערכת האימון

182
00:06:10,720 --> 00:06:12,230
לאלגוריתם הלומד כדי לאמן

183
00:06:12,310 --> 00:06:13,500
את יכולות הסיווג שלו.

184
00:06:13,680 --> 00:06:14,700
נבחן את יכולותיו,

185
00:06:14,890 --> 00:06:16,710
נראה לו תמונה חדשה ונשאל "מה אתה רואה?"

186
00:06:17,980 --> 00:06:20,030
בתקווה שהאלגוריתם יזהה את המכונית.

187
00:06:21,410 --> 00:06:24,000
כדי להבין למה

188
00:06:24,120 --> 00:06:26,810
אנו זקוקים להשערות בלתי ליניאריות,

189
00:06:27,050 --> 00:06:27,940
הבה נסתכל

190
00:06:28,190 --> 00:06:29,360
על התמונות שאנחנו מביאים לאלגוריתם:

191
00:06:29,480 --> 00:06:31,780
תמונות של מכוניות ושל לא-מכוניות כחלק מערכת האימון.

192
00:06:32,960 --> 00:06:33,920
בואו ניקח מיקומים של

193
00:06:34,090 --> 00:06:35,630
מספר פיקסלים בתמונה,

194
00:06:35,750 --> 00:06:37,040
לדוגמא, זהו המיקום של פיקסל 1

195
00:06:37,180 --> 00:06:39,500
וזהו המיקום של פיקסל 2.

196
00:06:39,730 --> 00:06:42,390
נתווה את המכונית הזו

197
00:06:42,510 --> 00:06:44,010
במיקום

198
00:06:44,360 --> 00:06:45,890
של אחת הנקודות, כתלות בעוצמה

199
00:06:46,430 --> 00:06:47,870
של פיקסל 1 ופיקסל 2.

200
00:06:49,260 --> 00:06:50,630
ונעשה את זה גם לגבי עוד כמה תמונות.

201
00:06:51,060 --> 00:06:52,450
ניקח דוגמה של מכונית אחרת

202
00:06:52,980 --> 00:06:53,980
ונסתכל על

203
00:06:54,080 --> 00:06:55,010
אותו המיקום של שני הפיקסלים הקודמים

204
00:06:56,160 --> 00:06:57,570
בתמונה זו ישנה

205
00:06:57,770 --> 00:06:58,970
עצימות שונה עבור פיקסל 1

206
00:06:59,230 --> 00:07:00,660
ועצימות שונה עבור פיקסל 2.

207
00:07:00,960 --> 00:07:02,940
מה שאומר שהם נמצאים במקומות שונים על הגרף.

208
00:07:03,360 --> 00:07:05,740
כעת נחקור תמונות שגויות מתוך ערכת האימון.

209
00:07:05,990 --> 00:07:07,590
כאן אין מכונית,

210
00:07:07,720 --> 00:07:09,470
וגם כאן אין.

211
00:07:09,730 --> 00:07:10,910
אם נעשה זאת

212
00:07:11,070 --> 00:07:12,720
עם הרבה דוגמאות

213
00:07:13,280 --> 00:07:14,680
בעודנו מסמנים מכוניות בחיוב,

214
00:07:15,080 --> 00:07:16,310
ומסמנים העדר מכונית בשלילה,

215
00:07:16,890 --> 00:07:18,500
נגלה כי

216
00:07:18,830 --> 00:07:20,680
המכוניות והלא-מכוניות ימצאו

217
00:07:20,890 --> 00:07:22,430
באזורים שונים

218
00:07:22,570 --> 00:07:24,910
במרחב, ולכן

219
00:07:25,180 --> 00:07:26,570
אנחנו נצטרך

220
00:07:26,750 --> 00:07:28,790
השערה בלתי ליניארית כדי

221
00:07:29,000 --> 00:07:30,900
לנסות להפריד בין המחלקות שנוצרו.

222
00:07:32,480 --> 00:07:34,300
מהו המימד של מרחב התכונות?

223
00:07:35,290 --> 00:07:38,210
נניח שנשתמש בתמונות בגודל 50x50 פיקסלים בלבד.

224
00:07:38,770 --> 00:07:40,050
מדובר בתמונות די קטנות,

225
00:07:40,520 --> 00:07:42,760
רק 50 פיקסלים לאורך ולרוחב.

226
00:07:43,470 --> 00:07:44,990
סה"כ 2500 פיקסלים לתמונה.

227
00:07:46,330 --> 00:07:47,650
וכך המימד של המשתנה

228
00:07:47,740 --> 00:07:49,310
שמייצג גודל יהיה

229
00:07:49,520 --> 00:07:51,450
n = 2500, כאשר וקטור

230
00:07:51,700 --> 00:07:52,910
המשתנים x הוא רשימה

231
00:07:53,180 --> 00:07:54,570
של כל בהירויות הפיקסלים,

232
00:07:54,710 --> 00:07:56,690
בהירות פיקסל 1,

233
00:07:57,080 --> 00:07:58,030
בהירות פיקסל 2,

234
00:07:58,330 --> 00:07:59,580
וכן הלאה עד לבהירות

235
00:07:59,870 --> 00:08:01,310
של הפיקסל האחרון.

236
00:08:01,400 --> 00:08:03,420
כאשר הייצוג הממוחשב

237
00:08:03,590 --> 00:08:05,450
של כל אחד מהם נע בין

238
00:08:05,540 --> 00:08:07,190
המספרים 0 עד 255

239
00:08:07,480 --> 00:08:09,020
עבור תמונות של דרגות אפור,

240
00:08:09,230 --> 00:08:12,110
כלומר בשחור לבן.

241
00:08:12,520 --> 00:08:13,290
אז n שלנו שווה ל-2500,

242
00:08:13,950 --> 00:08:15,580
ואם היינו משתמשים

243
00:08:15,740 --> 00:08:17,140
בתמונות צבעוניות- RGB

244
00:08:17,790 --> 00:08:18,800
עם ערכי אדום, ירוק וכחול

245
00:08:19,440 --> 00:08:21,140
התמונות היו מקבלות עוצמות שונות לכל צבע

246
00:08:21,420 --> 00:08:23,870
וה-n שלנו היה שווה 7500.

247
00:08:27,650 --> 00:08:28,630
אם היינו מנסים

248
00:08:29,000 --> 00:08:29,920
לפתח השערה בלתי לינארית

249
00:08:30,370 --> 00:08:32,020
בכך שנכליל את כל

250
00:08:32,300 --> 00:08:33,710
המשתנים הריבועיים,

251
00:08:33,810 --> 00:08:34,680
כלומר את כל סוגי

252
00:08:35,430 --> 00:08:38,900
xi כפול xj, כאשר ברשותנו

253
00:08:39,130 --> 00:08:40,370
2500 פיקסלים,

254
00:08:40,580 --> 00:08:42,500
אז יהיו לנו 3 מליון משתנים.

255
00:08:43,050 --> 00:08:44,620
וזה כבר יותר מדי,

256
00:08:44,720 --> 00:08:46,430
זה כבר לא סביר.

257
00:08:46,600 --> 00:08:48,680
החישוב יהיה יקר מאוד.

258
00:08:48,840 --> 00:08:50,070
וזה לא הגיוני להציג

259
00:08:50,310 --> 00:08:52,250
3 מליון משתנים לכל תמונת אימון.

260
00:08:55,470 --> 00:08:57,580
שימוש ברגרסיה לוגיסטית פשוטה

261
00:08:58,100 --> 00:08:59,230
בשילוב עם משתנים

262
00:08:59,300 --> 00:09:00,510
ריבועיים או מסדר שלישי

263
00:09:00,930 --> 00:09:01,910
זו לא דרך טובה

264
00:09:01,980 --> 00:09:03,950
להשיג השערה

265
00:09:04,550 --> 00:09:06,090
בלתי ליניארית מורכבת כאשר n

266
00:09:06,310 --> 00:09:08,410
גדול כל כך. נוצרים יותר מדי משתנים.

267
00:09:09,370 --> 00:09:10,620
בסירטונים הבאים,

268
00:09:10,840 --> 00:09:11,890
אספר לכם על הרשת

269
00:09:12,080 --> 00:09:13,670
העצבית, שהיא

270
00:09:13,980 --> 00:09:15,370
דרך טובה יותר לשער

271
00:09:15,650 --> 00:09:17,720
השערות מורכבות בלתי ליניאריות.

272
00:09:17,960 --> 00:09:19,780
גם כאשר

273
00:09:20,070 --> 00:09:22,080
וקטור המשתנים הוא ענק, גם אם n גדול.

274
00:09:22,860 --> 00:09:24,080
באותה הזדמנות

275
00:09:24,420 --> 00:09:25,580
אראה לכם מספר

276
00:09:25,780 --> 00:09:26,730
סירטונים משעשעים

277
00:09:27,240 --> 00:09:29,030
על יישומים חשובים היסטורית

278
00:09:30,300 --> 00:09:31,290
של רשתות עיצביות.

279
00:09:32,100 --> 00:09:33,480
אני מקווה שהסירטונים הללו

280
00:09:33,570 --> 00:09:35,460
יהיו משעשעים גם עבורכם.