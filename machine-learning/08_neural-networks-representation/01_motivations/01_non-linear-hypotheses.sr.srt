1
00:00:00,440 --> 00:00:01,400
U ovom i u sledećim

2
00:00:01,480 --> 00:00:02,640
video snimcima,

3
00:00:02,780 --> 00:00:04,270
pričaću o algoritmu učenja

4
00:00:04,550 --> 00:00:06,110
koji se zove Neuronska mreža.

5
00:00:07,190 --> 00:00:07,900
Prvo ćemo pričati o

6
00:00:08,079 --> 00:00:09,330
njegovoj reprezentaciji, a zatim ćemo

7
00:00:09,600 --> 00:00:10,390
u narednim video snimcima

8
00:00:10,410 --> 00:00:12,160
pričati i o samom algoritmu. 

9
00:00:12,660 --> 00:00:14,070
Neuronska mreža je zapravo

10
00:00:14,510 --> 00:00:15,870
poprilično stara ideja, ali je

11
00:00:16,290 --> 00:00:17,680
neko vreme bila zapostavljena.

12
00:00:18,200 --> 00:00:19,270
Međutim, danas je ona

13
00:00:19,580 --> 00:00:20,820
najsavremenija tehnika za

14
00:00:21,090 --> 00:00:22,390
rešavanje mnogih problema mašinskog učenja.

15
00:00:23,740 --> 00:00:25,740
Zašto nam je potreban i ovaj novi algoritam učenja?

16
00:00:26,300 --> 00:00:28,030
Već znamo za linearnu regresiju i

17
00:00:28,180 --> 00:00:31,260
logističku regresiju, i zašto nam je
 onda potrebna i neuronska mreža?

18
00:00:32,280 --> 00:00:34,260
Da bih motivisao diskusiju

19
00:00:34,790 --> 00:00:35,970
o neuronskim mrežama,

20
00:00:36,120 --> 00:00:37,130
počeću sa prikazom nekih

21
00:00:37,310 --> 00:00:38,720
primera mašinskog učenja

22
00:00:38,930 --> 00:00:40,100
za koje je potrebno naći

23
00:00:40,300 --> 00:00:41,850
kompleksnu nelinearnu hipotezu.

24
00:00:43,850 --> 00:00:45,650
Razmotrimo problem nadgledane klasifikacije

25
00:00:46,530 --> 00:00:48,440
za koji imamo ovakav skup
 podataka za treniranje modela.

26
00:00:49,280 --> 00:00:50,530
Ukoliko želite da primenite logističku

27
00:00:50,960 --> 00:00:52,710
regresiju na ovaj problem,

28
00:00:52,900 --> 00:00:54,250
mogli biste da primenite

29
00:00:54,660 --> 00:00:56,140
logističku regresiju sa

30
00:00:56,190 --> 00:00:57,720
mnogo nelinearnih promenljivih,
 kao što je ovde prikazano.

31
00:00:58,170 --> 00:00:59,580
Ovde je g, kao i obično,

32
00:01:00,070 --> 00:01:01,710
sigmoidna funkcija i

33
00:01:01,780 --> 00:01:04,680
možemo uključiti puno polinomskih članova,
 kao što su ovi.

34
00:01:05,450 --> 00:01:06,790
I, ukoliko uključite dovoljno
 polinomskih članova,

35
00:01:07,370 --> 00:01:08,280
onda ćete, znate, možda

36
00:01:08,950 --> 00:01:10,280
dobiti hipotezu

37
00:01:11,600 --> 00:01:13,780
koja odvaja pozitivne od negativnih primera.

38
00:01:14,630 --> 00:01:16,080
Ovaj metod je dobar ukoliko

39
00:01:16,470 --> 00:01:18,400
imate samo, na primer, dve

40
00:01:18,620 --> 00:01:20,180
promenljive - x1 i x2

41
00:01:20,190 --> 00:01:20,980
jer tada možete uključiti

42
00:01:21,500 --> 00:01:22,880
sve ove polinomske članove

43
00:01:23,400 --> 00:01:24,620
x1 i x2.

44
00:01:24,810 --> 00:01:26,280
Međutim, mnogi interesantni problemi

45
00:01:26,520 --> 00:01:27,730
mašinskog učenja imaju

46
00:01:27,910 --> 00:01:29,230
mnogo više promenljivih.

47
00:01:30,780 --> 00:01:31,760
Već neko vreme pominjemo

48
00:01:32,320 --> 00:01:34,560
predviđanje cena nekretnina,
 pa pretpostavimo

49
00:01:35,130 --> 00:01:36,990
da razmatramo problem

50
00:01:38,020 --> 00:01:39,280
klasifikacije kuća, a ne

51
00:01:39,390 --> 00:01:41,170
problem regresije, kao na primer

52
00:01:41,580 --> 00:01:43,350
da imate različite promenljive

53
00:01:43,440 --> 00:01:44,760
vezane za kuću, i da želite

54
00:01:45,010 --> 00:01:46,000
da predvidite koja je verovatnoća

55
00:01:46,050 --> 00:01:47,590
da će kuća biti

56
00:01:47,700 --> 00:01:48,710
prodata u sledećih

57
00:01:48,910 --> 00:01:51,040
šest meseci, tako da imate
 klasifikacioni problem.

58
00:01:52,100 --> 00:01:53,060
I, kao što smo videli, možemo

59
00:01:53,260 --> 00:01:55,130
osmisliti mnogo

60
00:01:55,260 --> 00:01:56,480
promenljivih, možda čak i stotinu

61
00:01:56,840 --> 00:01:58,270
različitih promenljivih za različite kuće.

62
00:02:00,130 --> 00:02:01,610
Za ovakav problem,

63
00:02:01,880 --> 00:02:03,260
ako uključite sve

64
00:02:03,370 --> 00:02:04,980
kvadrate tih promenljivih,

65
00:02:05,100 --> 00:02:06,260
čak i ako uključimo samo

66
00:02:06,540 --> 00:02:07,540
kvadrate, odnosno druge

67
00:02:07,930 --> 00:02:10,450
stepene, bilo bi ih previše.

68
00:02:10,560 --> 00:02:11,580
Imali bismo članove kao što su
 x1 na kvadrat,

69
00:02:12,960 --> 00:02:17,610
x1x2, x1x3, znate, x1x4

70
00:02:18,750 --> 00:02:21,880
i tako sve do x1x100, pa onda

71
00:02:21,980 --> 00:02:23,620
imamo x2 na kvadrat, x2x3

72
00:02:25,620 --> 00:02:25,980
i tako dalje.

73
00:02:26,510 --> 00:02:27,770
Dakle, ako uključite samo

74
00:02:28,060 --> 00:02:29,200
druge stepene, odnosno

75
00:02:29,330 --> 00:02:30,750
članove koji su

76
00:02:30,840 --> 00:02:32,090
proizvodi, znate,

77
00:02:32,220 --> 00:02:33,390
dve promenljive, na primer

78
00:02:33,510 --> 00:02:35,010
x1 puta x1 i tako dalje,
onda

79
00:02:35,780 --> 00:02:36,920
za slučaj kada je n=100,

80
00:02:38,180 --> 00:02:40,280
imaćete oko 5000 članova.

81
00:02:41,890 --> 00:02:44,880
I, asimptotički,

82
00:02:45,000 --> 00:02:46,330
broj kvadrata promenljivih

83
00:02:46,770 --> 00:02:48,670
raste otprilike brzinom reda
n na kvadrat,

84
00:02:48,820 --> 00:02:50,330
gde je n broj

85
00:02:50,460 --> 00:02:52,790
originalnih promenljivih,

86
00:02:53,370 --> 00:02:54,780
x1 do x100 od kojih smo krenuli.

87
00:02:55,700 --> 00:02:58,750
Zapravo, to je bliže n na kvadrat
podeljeno sa 2.

88
00:02:59,920 --> 00:03:01,440
Dakle, uključivanje svih

89
00:03:01,560 --> 00:03:02,920
kvadrata promenljivih ne deluje baš

90
00:03:03,220 --> 00:03:04,220
kao da je možda dobra ideja,

91
00:03:04,300 --> 00:03:05,380
jer dobijamo previše

92
00:03:05,580 --> 00:03:07,050
promenljivih i onda ćemo

93
00:03:07,220 --> 00:03:08,920
možda preprilagoditi model podacima

94
00:03:09,330 --> 00:03:10,500
za treniranje, i

95
00:03:10,740 --> 00:03:12,800
možda će biti skupo za računanje, znate,

96
00:03:14,080 --> 00:03:15,120
sa toliko mnogo promenljivih.

97
00:03:16,450 --> 00:03:17,540
Jedna stvar koju možete uraditi

98
00:03:17,770 --> 00:03:19,090
je da uključite samo podskup

99
00:03:19,290 --> 00:03:20,950
promenljivih, tako da
ako uključite samo

100
00:03:21,050 --> 00:03:22,630
promenljive x1 na kvadrat,
x2 na kvadrat,

101
00:03:23,590 --> 00:03:25,180
x3 na kvadrat, sve do

102
00:03:25,580 --> 00:03:27,750
možda x100 na kvdarat,

103
00:03:28,100 --> 00:03:29,500
onda će broj promenljivih
 biti mnogo manji.

104
00:03:29,980 --> 00:03:31,720
Ovde imate samo 100

105
00:03:32,070 --> 00:03:33,850
članova drugog stepena, ali

106
00:03:34,120 --> 00:03:35,950
to nije dovoljno promenljivih i

107
00:03:36,100 --> 00:03:37,170
svakako neće biti dovoljno za

108
00:03:37,290 --> 00:03:39,330
prilagođavanje podacima kao
na slici gore levo.

109
00:03:39,570 --> 00:03:40,550
Zapravo, ako uključimo

110
00:03:41,040 --> 00:03:42,720
samo ove druge stepene,
zajedno sa

111
00:03:43,170 --> 00:03:44,870
polaznim promenljivama, x1

112
00:03:45,350 --> 00:03:46,500
i tako dalje do x100,

113
00:03:47,460 --> 00:03:48,530
onda nije moguće prilagoditi model

114
00:03:48,910 --> 00:03:50,210
interesantnim hipotezama.
Tako da,

115
00:03:50,330 --> 00:03:52,350
možete ga prilagoditi, znate,
modelima za koje

116
00:03:52,490 --> 00:03:53,860
je dovoljna elipsa,
kao ova, ali

117
00:03:55,080 --> 00:03:56,240
svakako ga ne možete prilagoditi

118
00:03:56,340 --> 00:03:57,930
kompleksnim podacima,
poput ovih na slici.

119
00:03:59,360 --> 00:04:00,530
Dakle, 5000 promenljivih se čini

120
00:04:00,620 --> 00:04:03,090
kao mnogo, ako

121
00:04:03,230 --> 00:04:04,860
uključite treće stepene, ili

122
00:04:05,140 --> 00:04:06,100
članove trećeg reda promenljivih,

123
00:04:06,440 --> 00:04:08,050
x1x2x3,

124
00:04:08,400 --> 00:04:09,800
znate, x1 na kvadrat,

125
00:04:10,310 --> 00:04:12,240
x2, x10x11x17

126
00:04:12,900 --> 00:04:15,280
i tako dalje.

127
00:04:15,700 --> 00:04:18,110
Možete zamisliti koliko će puno ovakvih članova biti.

128
00:04:19,040 --> 00:04:19,770
Zapravo, njihov broj

129
00:04:20,050 --> 00:04:21,260
će biti reda n na treći

130
00:04:22,210 --> 00:04:23,830
i ako je n=100

131
00:04:24,150 --> 00:04:25,660
možete izračunati,

132
00:04:25,740 --> 00:04:26,870
imaćete broj reda

133
00:04:27,730 --> 00:04:29,650
oko 170 000 takvih

134
00:04:30,040 --> 00:04:31,670
članova trećeg reda i ako

135
00:04:32,260 --> 00:04:34,470
uključimo ove članove višeg reda

136
00:04:34,920 --> 00:04:36,050
kada je broj polaznih promenljivih, n,

137
00:04:36,230 --> 00:04:37,730
veliki, to zaista dramatično

138
00:04:38,530 --> 00:04:40,440
povećava prostor promenljivih i

139
00:04:41,070 --> 00:04:42,180
to više ne izgleda kao

140
00:04:42,320 --> 00:04:43,320
dobar način da se dođe do

141
00:04:43,560 --> 00:04:45,050
dodatnih članova za pravljenje

142
00:04:45,240 --> 00:04:48,100
nelinearnog klasifikatora kada je n veliko.

143
00:04:49,590 --> 00:04:52,560
Za mnoge probleme mašinskog učenja,
n će biti veoma veliko.

144
00:04:53,270 --> 00:04:53,560
Evo primera.

145
00:04:55,000 --> 00:04:58,140
Razmotrimo problem računarskog vida.

146
00:04:59,670 --> 00:05:00,770
Pretpostavimo da želite da

147
00:05:01,260 --> 00:05:02,620
iskoristite mašinsko učenje da naučite

148
00:05:02,710 --> 00:05:04,610
klasifikator da analizira sliku

149
00:05:04,710 --> 00:05:05,880
i kaže nam da li je to

150
00:05:06,160 --> 00:05:08,030
slika automobila ili nije.

151
00:05:09,480 --> 00:05:11,900
Mnogi se pitaju zašto su problemi
računarskog vida tako teški.

152
00:05:12,390 --> 00:05:13,140
Kada Vi i ja

153
00:05:13,270 --> 00:05:15,670
pogledamo ovu sliku,
očigledno nam je šta je na njoj.

154
00:05:15,900 --> 00:05:17,000
Pitate se kako je moguće da

155
00:05:17,190 --> 00:05:18,320
algoritam za učenje može da

156
00:05:18,910 --> 00:05:20,880
ne prepozna šta je na slici.

157
00:05:22,110 --> 00:05:23,330
Da bismo razumeli zašto je to

158
00:05:23,720 --> 00:05:25,380
tako teško, uvećajmo

159
00:05:25,650 --> 00:05:26,690
ovaj mali deo

160
00:05:26,940 --> 00:05:28,180
slike na kome je

161
00:05:28,510 --> 00:05:30,240
mali crveni pravougaonik.

162
00:05:30,400 --> 00:05:31,330
Ispostavlja se da iako

163
00:05:31,450 --> 00:05:34,270
Vi i ja vidimo automobil,
kompjuter vidi ovo.

164
00:05:34,780 --> 00:05:35,930
On vidi ovakvu matricu,

165
00:05:36,600 --> 00:05:38,110
ili tabelu brojeva koji predstavljaju

166
00:05:38,580 --> 00:05:40,350
intenzitet piksela koji

167
00:05:40,610 --> 00:05:42,930
nam kaže koliko je svaki piksel na slici svetao.

168
00:05:43,640 --> 00:05:45,170
Problem računarskog vida je

169
00:05:45,550 --> 00:05:47,230
da se iz ove matrice

170
00:05:47,310 --> 00:05:49,140
intenziteta piksela zaključi

171
00:05:49,410 --> 00:05:52,440
da ti brojevi predstavljaju kvaku na kolima.

172
00:05:54,230 --> 00:05:55,740
Konkretno, kada koristimo

173
00:05:56,030 --> 00:05:57,220
mašinsko učenje za izgradnju

174
00:05:57,430 --> 00:05:59,060
detektora automobila,

175
00:05:59,360 --> 00:06:00,510
mi zapravo pravimo

176
00:06:00,800 --> 00:06:02,690
obeleženi skup podataka za treniranje modela

177
00:06:02,890 --> 00:06:04,250
sa recimo nekoliko obeleženih

178
00:06:04,730 --> 00:06:05,850
primera automobila i par obeleženih

179
00:06:06,000 --> 00:06:07,150
primera nekih stvari

180
00:06:07,380 --> 00:06:08,780
koje nisu automobili i onda

181
00:06:09,090 --> 00:06:10,590
taj skup podataka iskoristimo

182
00:06:10,720 --> 00:06:12,230
za treniranje algoritma za učenje,

183
00:06:12,310 --> 00:06:13,500
dobijamo klasifikator i onda ga,

184
00:06:13,680 --> 00:06:14,700
znate, možete testirati i

185
00:06:14,890 --> 00:06:16,710
prikazati mu novu sliku i pitati
"Šta je na ovoj slici?"

186
00:06:17,980 --> 00:06:20,030
i, nadajmo se, on će prepoznati da je to automobil.

187
00:06:21,410 --> 00:06:24,000
Da biste razumeli zašto nam trebaju

188
00:06:24,120 --> 00:06:26,810
nelinearne hipoteze, hajde da

189
00:06:27,050 --> 00:06:27,940
pogledamo neke od slika

190
00:06:28,190 --> 00:06:29,360
automobila i možda nečega što

191
00:06:29,480 --> 00:06:31,780
nisu automobili koje ćemo prikazati
našem algoritmu za učenje.

192
00:06:32,960 --> 00:06:33,920
Izaberimo par lokacija

193
00:06:34,090 --> 00:06:35,630
piksela na slikama, na primer

194
00:06:35,750 --> 00:06:37,040
ovo je lokacija prvog piksela,

195
00:06:37,180 --> 00:06:39,500
ovo je lokacija rugog piksela i hajde da

196
00:06:39,730 --> 00:06:42,390
nacrtamo ovaj auto, znate,

197
00:06:42,510 --> 00:06:44,010
kao lokaciju, kao određenu

198
00:06:44,360 --> 00:06:45,890
tačku koja zavisi od intenziteta

199
00:06:46,430 --> 00:06:47,870
piksela 1 i piksela 2.

200
00:06:49,260 --> 00:06:50,630
I uradimo to isto sa još nekim slikama.

201
00:06:51,060 --> 00:06:52,450
Pogledajmo drugi primer

202
00:06:52,980 --> 00:06:53,980
automobila i, znate,

203
00:06:54,080 --> 00:06:55,010
odredimo iste te dve lokacije piksela

204
00:06:56,160 --> 00:06:57,570
i ova slika ima

205
00:06:57,770 --> 00:06:58,970
drugačiji intenzitet piksela 1

206
00:06:59,230 --> 00:07:00,660
i drugačiji intenzitet piksela 2.

207
00:07:00,960 --> 00:07:02,940
Tako da je ona na nekom drugom mestu na grafiku.

208
00:07:03,360 --> 00:07:05,740
I docrtajmo neke negativne primere, takođe.

209
00:07:05,990 --> 00:07:07,590
Ovo nije auto, i

210
00:07:07,720 --> 00:07:09,470
ovo nije auto.

211
00:07:09,730 --> 00:07:10,910
Ako uradimo ovo za

212
00:07:11,070 --> 00:07:12,720
sve više i više primera, gde

213
00:07:13,280 --> 00:07:14,680
plusevi označavaju automobile, a

214
00:07:15,080 --> 00:07:16,310
minusevi označavaju sve što nije automobil,

215
00:07:16,890 --> 00:07:18,500
otkrićemo da se

216
00:07:18,830 --> 00:07:20,680
automobili i sve ostalo

217
00:07:20,890 --> 00:07:22,430
nalaze u različitim delovima ovog

218
00:07:22,570 --> 00:07:24,910
prostora i ono što nam

219
00:07:25,180 --> 00:07:26,570
treba je neka vrsta

220
00:07:26,750 --> 00:07:28,790
nelinearne hipoteze koja

221
00:07:29,000 --> 00:07:30,900
će razdvojiti te dve klase.

222
00:07:32,480 --> 00:07:34,300
Koje je dimenzije prostor promenljivih?

223
00:07:35,290 --> 00:07:38,210
Ako bismo koristili slike od samo 50 puta 50 piksela.

224
00:07:38,770 --> 00:07:40,050
Dakle, pretpostavimo da su naše slike

225
00:07:40,520 --> 00:07:42,760
veoma male, samo 50 piksela po dužini.

226
00:07:43,470 --> 00:07:44,990
Tada imamo 2500 piksela,

227
00:07:46,330 --> 00:07:47,650
i onda je dimenzija našeg

228
00:07:47,740 --> 00:07:49,310
prostora promenljivih

229
00:07:49,520 --> 00:07:51,450
n=2500, gde je naš vektor

230
00:07:51,700 --> 00:07:52,910
promenljivih, x, lista

231
00:07:53,180 --> 00:07:54,570
intenziteta svih piksela,

232
00:07:54,710 --> 00:07:56,690
znate, intenzitet piksela 1,

233
00:07:57,080 --> 00:07:58,030
intenzitet piksela 2

234
00:07:58,330 --> 00:07:59,580
i tako dalje sve do

235
00:07:59,870 --> 00:08:01,310
intenziteta poslednjeg piksela

236
00:08:01,400 --> 00:08:03,420
gde, znate, uobičajena

237
00:08:03,590 --> 00:08:05,450
kompjuterska reprezentacija svakog od njih

238
00:08:05,540 --> 00:08:07,190
mogu biti vrednosti od

239
00:08:07,480 --> 00:08:09,020
0 do 255 ako koristimo grayscale,

240
00:08:09,230 --> 00:08:12,110
tj. crno-bele slike.

241
00:08:12,520 --> 00:08:13,290
Dakle, imamo da je n=2500

242
00:08:13,950 --> 00:08:15,580
i to ako koristimo

243
00:08:15,740 --> 00:08:17,140
crno-bele slike.

244
00:08:17,790 --> 00:08:18,800
Ako koristimo slike u boji

245
00:08:19,440 --> 00:08:21,140
one imaju RGB, vrednosti za crvenu, zelenu

246
00:08:21,420 --> 00:08:23,870
i plavu nijansu piksela, pa je n=7500.

247
00:08:27,650 --> 00:08:28,630
Tako da, ako pokušamo

248
00:08:29,000 --> 00:08:29,920
da dođemo do nelinearne

249
00:08:30,370 --> 00:08:32,020
hipoteze uključujući sve

250
00:08:32,300 --> 00:08:33,710
članove drugog reda, odnosno

251
00:08:33,810 --> 00:08:34,680
sve članove koji su oblika, znate,

252
00:08:35,430 --> 00:08:38,900
xi puta xj, sa 2500

253
00:08:39,130 --> 00:08:40,370
piksela imali bismo

254
00:08:40,580 --> 00:08:42,500
ukupno 3 miliona promenljivih.

255
00:08:43,050 --> 00:08:44,620
I to je jednostavno previše,

256
00:08:44,720 --> 00:08:46,430
nije razumno jer bi izračunavanje

257
00:08:46,600 --> 00:08:48,680
bilo preskupo da otkrijemo

258
00:08:48,840 --> 00:08:50,070
i predstavimo svaku od ovih

259
00:08:50,310 --> 00:08:52,250
3 miliona promenljivih za svaki primer
iz skupa za treniranje.

260
00:08:55,470 --> 00:08:57,580
Dakle, obična logistička regresija, zajedno sa

261
00:08:58,100 --> 00:08:59,230
uključivanjem možda

262
00:08:59,300 --> 00:09:00,510
članova drugog ili trećeg reda,

263
00:09:00,930 --> 00:09:01,910
to jednostavno nije

264
00:09:01,980 --> 00:09:03,950
dobar način za dobijanje

265
00:09:04,550 --> 00:09:06,090
nelinearne hipoteze kada je

266
00:09:06,310 --> 00:09:08,410
n veliko jer imamo previše promenljivih.

267
00:09:09,370 --> 00:09:10,620
U narednih nekoliko snimaka

268
00:09:10,840 --> 00:09:11,890
pričaću o neuronskim mrežama

269
00:09:12,080 --> 00:09:13,670
za koje se ispostavlja

270
00:09:13,980 --> 00:09:15,370
da su mnogo bolje za

271
00:09:15,650 --> 00:09:17,720
nalaženje kompleksnih hipoteza, kompleksnih

272
00:09:17,960 --> 00:09:19,780
nelinearnih hipoteza, čak i kada

273
00:09:20,070 --> 00:09:22,080
je prostor polaznih promenljivih,
odnosno n, veliko.

274
00:09:22,860 --> 00:09:24,080
Usput ću Vam,

275
00:09:24,420 --> 00:09:25,580
takođe, pokazati

276
00:09:25,780 --> 00:09:26,730
i nekoliko interesantnih snimaka

277
00:09:27,240 --> 00:09:29,030
istorijski važnih primena

278
00:09:30,300 --> 00:09:31,290
neuronskih mreža i

279
00:09:32,100 --> 00:09:33,480
nadam se daće ti snimci

280
00:09:33,570 --> 00:09:35,460
koje ćemo videti kasnije, i Vama biti zabavni.