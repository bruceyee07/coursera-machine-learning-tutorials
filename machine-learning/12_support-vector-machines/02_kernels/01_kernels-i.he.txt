בסרטון הזה, אני רוצה להתחיל להתאים מכונות תמך וקטורי לפיתוח של מסווגים בלתי לינאריים מורכבים. הטכניקה העיקרית לעשות את זה נקראת גרעינים או קֶרְנֶלִים - kernels. בואו נראה מה זה גרעינים וכיצד להשתמש בהם. אם יש לך סדרת אימון שנראית כך, ואתה רוצה למצוא גבול החלטה לא ליניארי כדי להבדיל בין דוגמאות חיוביות ושליליות, אולי גבול החלטה שנראה ככה. אחת הדרכים לעשות זאת היא להשתמש בתכונות פולינומיות מורכבות, נכון? מין קבוצה של תכונות שנראות ככה, כך שאתה מקבל השערה (h(x שחוזה 1 אם θ0 + θ1*x1 פלוס וכו' כל התכונות הפולינומיות האלה גדול מ-0, ו-0 אחרת. ועוד דרך לכתוב את זה, כדי להציג מין סימון חדש שבו אשתמש מאוחר יותר, היא שאנחנו יכולים לחשוב על ההשערה כחישוב גבול החלטה באמצעות הביטוי הזה. θ0 + θ1*f1 + θ2*f2 + θ3*f3 + וכן הלאה. ואני משתמש בסימון החדש הזה, f1, f2, f3 וכו' כדי לציין את הסוג החדש הזה של תכונות שאנחנו מחשבים, f1 הוא פשוט x1, ו- f2 שווה x2, ו-f3 שווה לדבר הזה כאן, דהיינו, x1x2. ו-f4 שווה x1 בריבוע, f5 הוא x2 בריבוע וכן הלאה, וראינו בעבר ששימוש בפולינומים כאלה מסדר גבוה הוא אחת הדרכים לקבל יותר תכונות, השאלה היא, האם יש בחירה אחרת של תכונות או האם יש סוג טוב יותר של תכונות מאשר הפולינומים מסדר גבוה כי זה לא ברור שפולינום מסדר גבוה הוא באמת מה שאנחנו צריכים, וכאשר דיברנו על ראייה ממוחשבת, כשדיברנו על המקרה שהקלט הוא תמונה עם הרבה פיקסלים ראינו גם כיצד שימוש בפולינומים מסדר גבוה נהיה יקר מאוד מבחינה חישובית כי יש הרבה מונחים כאלה בפולינום מסדר יותר גבוה. אז האם יש בחירה אחרת או בעצם בחירה טובה יותר של תכונות שאנחנו יכולים להשתמש בהם כדי להציב בהשערה מהסוג הזה. אז הנה רעיון אחד כיצד להגדיר תכונות חדשות f1, f2, f3. בשקופית הזו אני עומד להגדיר רק שלוש תכונות חדשות, אבל בבעיות אמיתיות אנחנו יכולים להגיע להגדיר מספר הרבה יותר גדול. אבל הנה מה שאני הולך לעשות, בשלב זה עם התכונות x1, x2, ואני הולך להתעלם מיחידת ההסטה x0, ולהשתמש בשלב הזה ב-x1 ו-x2. אז אני מתכוון עכשיו לבחור ידנית כמה נקודות, ולקרוא לנקודות האלה l1, ואנחנו נבחר נקודה אחרת, ובואו נקרא לה l2 ובואו ניקח עוד נקודה שלישית ונקרא לה l3, ועכשיו אני רק מזכיר שאני כרגע בוחר את שלוש הנקודות הללו באופן ידני. אני קורא לשלוש הנקודות האלה ציוני דרך, l1, l2 ו-l3. מה שאני הולך לעשות אחרי זה הוא להגדיר את התכונות החדשות שלי כדלקמן, בהינתן דוגמה x, אני אגדיר את התכונה הראשונה שלי f1 להיות מידה מסוימת של דמיון בין דוגמת האימון שלנו x ובין נקודת הציון הראשונה שלי, והנוסחה הספציפית שבה אני אשתמש כדי למדוד דמיון תהיה זו: e בחזקת מינוס האורך של הוקטור (x מינוס l1) בריבוע, חלקי שני סיגמא בריבוע. הערה למי שלא צפה בוידאו האופציונלי הקודם, הסימון הזה של קוים מאונכים מסביב ל-w הוא האורך של הוקטור w. אז הדבר הזה כאן, x מינוס l1, זה בעצם פשוט המרחק האוקלידי בריבוע, הוא המרחק האוקלידי שבין הנקודה x ובין נקודת הציון l1. בהמשך נדבר על זה עוד. אבל זו התכונה הראשונה שלי, והתכונה השנייה שלי f2 תהיה אותה פונקצית הדמיון והפעם מודדת עד כמה x דומה ל-l2, ושוב זה יהיה מוגדר כפונקציה הבאה. זה e בחזקת מינוס הריבוע של המרחק האוקלידי בין x לבין ציון-הדרך השני, זה מה שיש במונה, ובמכנה חלקי 2 סיגמא בריבוע, ובדומה f3 הוא, כמובן, הדמיון בין x ו- l3, שהוא שווה שוב, נוסחה דומה. ופונקצית הדמיון הזו היא, המונח המתמטי של זה, זה מה שאנחנו קוראים פונקצית הקרנל או הגרעין. והקרנל הספציפי שאני משתמש בו נקרא ליבה גאוסיאנית. אז הנוסחה הזו, הבחירה המסוימת הזו של פונקצית הדמיון, נקראת ליבה גאוסיאנית. אבל הדרך שבה משתמשים במינוחים היא כזו, בצורה מופשטת יש לנו פונקציות דמיון שונות והן נקראות גרעינים, ואנחנו יכולים להשתמש בפונקציות דמיון שונות, והדוגמה הספציפית שאני נתתי כאן נקראת ליבה גאוסיאנית. נראה דוגמאות אחרות של גרעינים אחרים. אבל בינתיים פשוט תחשבו עליהן כפונקציות דמיון. אז במקום לכתוב פונקצית דמיון בין x ו-l, לפעמים אנחנו גם כותבים את זה כך - פונקצית קרנל ,המסומנת ב-k קטנה, בין x וציון-דרך. אז בואו נראה מה עושים הגרעינים האלה בפועל, ומדוע פונקציות הדמיון האלה, מדוע הביטויים האלה עשויים להיות הגיוניים. אז בואו ניקח את ציון הדרך הראשון שלי. הציון l1, שהוא אחת מאותן הנקודות שבחרתי על הגרף שלנו עכשיו. אז הדמיון או הקרנל בין x ו-l1 ניתן על ידי הביטוי הזה. רק כדי להיות בטוחים שאנחנו מבינים באותה צורה מה הביטוי במונה, המונה ניתן גם להיכתב כסכום מ-j שווה 1 עד n של הרכיבים של המרחק. זה המרחק המחושב לפי רכיבים בין הווקטור x לבין הוקטור l. ושוב לצורך השקופיות האלה אני מתעלם מ-x0. פשוט נתעלם מהחלק של ההסטה x0, שהוא תמיד שווה 1. אז כך מחשבים את פונקצית הקרנל או הדמיון בין x וציון הדרך l. בואו נראה מה עושה הפונקציה. נניח ש-x קרוב לאחד מציוני הדרך. אז נוסחת המרחק האוקלידית במונה תהיה קרובה ל-0, ברור. אז המונח הזה כאן, המרחק בריבוע הזה שבין x ו-l1 יהיה קרוב לאפס, ולכן f1, התכונה הפשוטה, יהיה בערך e בחזקת מינוס 0 חלקי שני סיגמא בריבוע או e בחזקת 0, e בחזקת מינוס 0, e בחזקת 0 יהיה קרוב ל-1. ואני שם כאן סימון של "בקירוב" כי יכול להיות שהמרחק הוא לא בדיוק 0, אבל אם x קרוב לנקודת הציון המרחק יהיה קרוב ל-0 ולכן f1 יהיה קרוב ל-1. לעומת זאת, אם x הוא רחוק מ-l1 אז התכונה הראשונה f1 תהיה e בחזקת מינוס מספר גדול בריבוע, חלקי שני סיגמא בריבוע, ו-e בחזקת מינוס מספר גדול הוא קרוב ל-0. אז מה שעושות התכונות האלה הוא למדוד כמה דומה x לאחד מציוני הדרך שלך והערך של התכונה f יהיה קרוב לאחד כאשר x קרוב לציון הדרך שלך והוא יהיה 0 או קרוב לאפס כאשר x רחוק מציון הדרך שלך. כל אחד מציוני הדרך האלה. בשקופית הקודמת ציירתי שלושה ציוני דרך, l1, l2, l3. כל אחד מציוני הדרך האלה, מגדיר תכונה חדשה f1, f2 ו- f3. כלומר, בהינתן דוגמת אימון x, אנו יכולים כעת לחשב שלוש תכונות חדשות: f1, f2 ו- f3, לפי שלושת ציוני הדרך האלה שציירנו. אבל ראשית, בואו נסתכל על פונקציית האקספוננט הזו, בואו נסתכל על פונקצית הדמיון הזאת ונצייר כמה ציורים, פשוט בשביל להבין טוב יותר איך זה באמת נראה. לדוגמה, נניח שיש לי שתי תכונות x1 ו-x2. ונניח שציון הדרך הראשון שלי, l1, נמצא במיקום 3,5. ובואו נחליט שנגדיר סיגמא בריבוע - σ² - שווה אחת לעת עתה. אם אני משרטט איך התכונה הזו נראית, מה שאני מקבל זו התמונה הזו. הציר האנכי, גובה פני השטח הוא הערך של f1, כאן למטה על הציר האופקי, נניח שיש לי דוגמת אימון x, יש לה ערכים x1 ו-x2. בהינתן דוגמת הדרכה מסוימת, דוגמת ההדרכה כאן, היא מציגה את ערך ה-f המתאים ל-x1 ו-x2 כגובה מעל פני השטח, היא מראה את הערך המתאים של f1. כאן למטה, הגרף השני, זה בעצם אותו גרף, אבל בשימוש במפה טופוגרפית - מפת קווי גובה, כש-x1 על הציר האופקי האחד, ו-x2 על הציר האופקי השני. אז הגרף הזה כאן למטה הוא פשוט מתאר דו-ממדי של משטח תלת-ממדי. אתם יכולים לראות שכאשר x שווה בדיוק ל-3,5, אז f1 מקבל את הערך 1, שהוא המקסימום וכש-x מתרחק מהנקודה, כש-x מתרחק יותר אז התכונה מקבלת ערכים קרובים ל-0. אז זו בעצם התכונה, f1 מודד עד כמה קרובה הנקודה x לציון הדרך הראשון, והערך משתנה בין 0 ל-1 בתלות בקרבה של x לנקודת הציון הראשונה l1. עכשיו הדבר השני שרציתי לעשות בשקופית הזו הוא להראות את ההשפעה של המשתנה σ². אז σ² הוא פרמטר של הליבה הגאוסיאנית, וכשנשנה אותו נקבל השפעות שונות במקצת. אז בואו נגדיר σ² להיות שווה 0.5 ונראה מה אנחנו מקבלים. הגדרנו σ² שווה 0.5, מה שאנחנו רואים הוא שהקרנל נראה דומה, למעט זה שרוחב הבליטה, החרוט, נהיה צר יותר. גם קווי המתאר מתכווצים מעט. אז אם σ² שווה 0.5 אז כשמתחילים מ-x שווה 3,5 ומתרחקים, אז הערך של התכונה f1 יורד לאפס הרבה יותר מהר. ובכיוון ההפוך, אם מעלים את σ², שלוש בגרף הזה, אז כאשר מתרחקים, אתם זוכרים שהנקודה הזאת היא בעצם l1 והיא במיקום 3,5, נכון. זה מופיע כאן למעלה. ואם σ² הוא גדול, אז כשמתרחקים מ-l1, הערך של התכונה יורד הרבה יותר לאט. אז בהינתן הגדרה כזו של תכונות, בואו נראה איזה סוג השערה אנחנו יכולים ללמוד. בהינתן דוגמת אימון x, אנחנו הולכים לחשב את התכונות הללו f1, f2, f3, וההשערה תחזה 1 כאשר θ0 + θ1*f1 + θ2*f2, וכו' גדול או שווה ל-0. עבור הדוגמה המסוימת הזו, נניח שכבר מצאתי אלגוריתם למידה ונניח שאיכשהו קיבלתי את הערכים האלה של הפרמטרים. θ0 שווה 0.5-, θ1 שווה 1, θ2 שווה 1, ו-θ3 שווה 0 ומה שאני רוצה לעשות הוא לחשוב על מקרה שבו יש לנו דוגמת אימון שנמצאת במיקום הזה, הנקודה בוורוד, ממש בדיוק איפה שאני ציירתי את הנקודה הזאת. אז נניח שיש לי דוגמת אימון x, מה תחזה ההשערה שלי? אז אם אני מסתכל על הנוסחה הזו. מאחר והדוגמה שלי x קרובה ל-l1, אז נקבל ש-f1 עומד להיות קרוב ל-1, ומאחר ודוגמת האימון x רחוקה מ-l2 ומ-l3 אנחנו נקבל ש-f2 יהיה קרוב ל-0 ו-f3 יהיה גם הוא קרוב ל-0. אז אם אני מסתכל על הנוסחה, יש לנו θ0 פלוס θ1 כפול 1 ועוד θ2 כפול ערך כלשהו, שאיננו בדיוק 0 אבל אנחנו מניחים שהוא קרוב ל-0. פלוס θ3 כפול משהו קרוב ל-0. וזה הולך להיות שווה, בואו נציב את הערכים האלה עכשיו. אז זה נותן 0.5- פלוס 1 כפול 1 שהן 1, וכן הלאה. שזה שווה 0.5 שהוא גדול או שווה ל-0. אז, לפי זה, אנחנו הולכים לחזות ש-y שווה 1, כי התוצאה גדולה או שווה לאפס. עכשיו בואו ניקח נקודה אחרת. עכשיו בואו נניח שאני לוקח נקודה אחרת, שאני אצייר בצבע אחר, נניח בתכלת, הנקודה שם, ואם זו היא דוגמת אימון x, אז אם תעשו חישוב דומה, תמצאו כי f1, f2, f3 כולם הולכים להיות קרובים ל-0. אז יש לנו θ0 פלוס θ1 כפול f1, וכן הלאה וזה יהיה בערך שווה 0.5-, כי θ0 הוא 0.5- ו-f1, f2, ו-f3 כולם בערך אפס. אז התוצאה תהיה 0.5-, שזה קטן מאפס. אז במקרה הזה אנחנו נחזה ש-y שווה אפס. ואם תעשו את זה בעצמכם עבור מגוון של נקודות שונות, אתם תשכנעו את עצמכם בוודאי שאם יש דוגמת אימון שקרובה ל-l2, נניח, אז גם במקרה הזה אנחנו נחזה ש-y שווה אחת. ולמעשה, מה שקורה הוא שאם אתה מסתכל מסביב לגבול הזה, באזור השטח הזה, מה שנמצא הוא שלגבי נקודות בסביבה של l1 ו-l2 אנחנו נחזה תחזית חיובית. ולנקודות רחוקות מ-l1 ו-l2, זאת אומרת לנקודות שהן רחוקות משני ציוני הדרך האלה, אנחנו ננבא שהמחלקה היא 0. אז מה שקורה בסופו של דבר הוא שגבול ההחלטה של ההשערה הזו הוא משהו כזה, שבו אם אנחנו בתוך גבולות העקום האדום הזה, גבול ההחלטה שלנו, אנחנו חוזים אנו צופים ש-y שווה 0 ש-y שווה 1 ומחוץ לגבול הזה אנו צופים ש-y שווה 0. . אז ככה זה איך שעם ההגדרה הזו של ציוני דרך, ושל פונקציית הקרנל או הגרעין, אנחנו מצליחים ללמוד גבולות החלטה די מסובכים ולא ליניאריים, כמו מה שאני כרגע ציירתי שאנחנו מנבאים תשובה חיובית כאשר אנחנו קרובים לאחד משני ציוני-הדרך. ואנחנו מנבאים תשובה שלילית כאשר אנו מספיק רחוקים מכל אחד משני ציוני הדרך האלה. אז זה חלק מהרעיון של גרעינים וכיצד אנחנו משתמשים בהם עם מכונת תמך וקטורי, כשאנחנו מגדירים את התכונות הנוספות האלה באמצעות ציוני דרך ופונקציות דמיון, כדי ללמוד מסווגים מורכבים יותר ולא ליניאריים. אז אני מקווה שזה נתן לכם תובנה לגבי הרעיון של גרעינים וכיצד נוכל להשתמש בהם כדי להגדיר תכונות חדשות עבור מכונת תמך וקטורי. אבל יש כמה שאלות שעדיין לא ענינו עליהם. שאלה אחת היא, איך אנחנו משיגים ציוני דרך כאלה? כיצד אנו בוחרים את ציוני הדרך האלה? ושאלה שניה היא, באילו פונקציות דמיון נוספות, אם בכלל, נוכל להשתמש חוץ מזו שדיברנו עליה, שנקראת הגרעין או הליבה הגאוסיאנית. בסרטון הבא אנו ניתן תשובות לשאלות האלו ונסכם את הכל כדי להראות כיצד מכונות תמך וקטורי עם גרעינים יכולות להיות דרך רבת עוצמה כדי ללמוד פונקציות לא לינאריות מורכבות.