1
00:00:00,530 --> 00:00:01,550
בסרטון האחרון, התחלנו

2
00:00:01,950 --> 00:00:03,230
לדבר על הרעיון של הגרעין - קרנל

3
00:00:03,710 --> 00:00:04,590
וכיצד ניתן להשתמש בו

4
00:00:04,860 --> 00:00:07,900
כדי להגדיר תכונות חדשות עבור מכונת תמך וקטורי.

5
00:00:08,100 --> 00:00:08,910
בסרטון הזה, אני רוצה להשלים

6
00:00:09,230 --> 00:00:10,670
כמה פרטים חסרים

7
00:00:11,020 --> 00:00:12,070
וגם לומר כמה מילים על

8
00:00:12,270 --> 00:00:14,100
איך להשתמש ברעיונות האלה בפועל.

9
00:00:14,650 --> 00:00:15,850
כגון, איך הם נוגעים,

10
00:00:16,340 --> 00:00:20,120
למשל, ליחסי הגומלין בין ההטיה והשונות במכונת תמך וקטורי.

11
00:00:22,690 --> 00:00:23,680
בסרטון האחרון דיברתי

12
00:00:24,000 --> 00:00:25,970
על תהליך של בחירת מספר ציוני דרך.

13
00:00:26,660 --> 00:00:28,890
אתם זוכרים, l1, l2, l3,

14
00:00:29,150 --> 00:00:30,220
מה שאפשר לנו להגדיר

15
00:00:30,300 --> 00:00:31,900
את פונקצית הדמיון המכונה גם

16
00:00:32,200 --> 00:00:33,500
הקרנל או

17
00:00:33,690 --> 00:00:34,830
בדוגמה הזו היתה

18
00:00:35,070 --> 00:00:37,410
לנו פונקצית דמיון שהיתה ליבה גאוסיאנית.

19
00:00:38,610 --> 00:00:40,370
וזה אפשר לנו לבנות

20
00:00:40,660 --> 00:00:42,070
את הסוג הזה של פונקציה השערה.

21
00:00:43,180 --> 00:00:44,880
אבל מאיפה אנחנו מקבלים את ציוני הדרך?

22
00:00:45,150 --> 00:00:45,670
מאיפה אנחנו מקבלים את l1, l2, l3?

23
00:00:45,690 --> 00:00:49,080
חוץ מזה, נראה שלבעיות למידה מורכבות,

24
00:00:49,610 --> 00:00:50,830
אנחנו מן הסתם רוצים

25
00:00:50,920 --> 00:00:53,060
הרבה יותר ציוני דרך מאשר שלושה שאפשר לבחור ידנית.

26
00:00:55,160 --> 00:00:56,450
אז בפועל כך

27
00:00:56,580 --> 00:00:57,730
נבחרות הנקודות.

28
00:00:57,830 --> 00:00:59,910
כשיש לנו

29
00:01:00,150 --> 00:01:01,110
בעית למידה ממוחשבת, יש לנו

30
00:01:01,370 --> 00:01:02,230
נתונים של מספר דוגמאות

31
00:01:02,710 --> 00:01:04,460
חיוביות ושליליות. אז הרעיון כאן

32
00:01:05,310 --> 00:01:06,270
הוא שאנחנו לוקחים

33
00:01:06,630 --> 00:01:08,200
את כל הדוגמאות

34
00:01:08,470 --> 00:01:09,780
ועל כל דוגמת אימון שיש לנו,

35
00:01:10,490 --> 00:01:11,430
אנחנו פשוט,

36
00:01:11,980 --> 00:01:13,270
אנחנו פשוט

37
00:01:13,440 --> 00:01:14,850
נשים ציוני דרך בדיוק

38
00:01:15,490 --> 00:01:17,600
באותן מקומות כמו דוגמאות האימון.

39
00:01:18,930 --> 00:01:20,360
אז אם יש לי דוגמת אימון

40
00:01:20,680 --> 00:01:21,880
אחת שנקרא לה x1,

41
00:01:22,120 --> 00:01:23,460
אז אני אבחר 

42
00:01:23,670 --> 00:01:24,550
את ציון הדרך הראשון שלי l1

43
00:01:25,100 --> 00:01:26,470
להיות בדיוק באותו מיקום

44
00:01:27,250 --> 00:01:28,170
כמו דוגמת האימון הראשונה שלי.

45
00:01:29,260 --> 00:01:30,180
ואם יש לי עוד דוגמת

46
00:01:30,470 --> 00:01:32,340
אימון x2, אז אנחנו

47
00:01:32,500 --> 00:01:33,980
נגדיר את ציון הדרך השני l2

48
00:01:35,060 --> 00:01:37,300
להיות המיקום של דוגמת האימון השנייה שלי.

49
00:01:38,480 --> 00:01:39,320
על התרשים מימין

50
00:01:39,480 --> 00:01:40,480
השתמשתי בנקודות אדומות וכחולות

51
00:01:40,820 --> 00:01:41,930
רק להדגמה, הצבע

52
00:01:42,420 --> 00:01:44,320
של התרשים, הצבע של

53
00:01:44,370 --> 00:01:46,030
הנקודות על התרשים בצד ימין איננו משמעותי.

54
00:01:47,120 --> 00:01:47,930
אבל מה שיהיה לי בסופו של דבר

55
00:01:48,110 --> 00:01:49,660
בשימוש בשיטה הזו הוא

56
00:01:49,790 --> 00:01:51,450
שיהיו לנו m

57
00:01:52,160 --> 00:01:53,690
ציוני דרך l1, l2 וכו'

58
00:01:54,950 --> 00:01:56,320
עד lm אם יש

59
00:01:56,380 --> 00:01:58,180
לי m דוגמאות אימון, עם

60
00:01:58,420 --> 00:02:00,500
ציון דרך אחד לכל מיקום

61
00:02:00,810 --> 00:02:02,680
לפי המיקום של כל אחת

62
00:02:02,860 --> 00:02:04,810
מדוגמאות האימון שלנו.

63
00:02:04,950 --> 00:02:05,920
וזה נחמד כי זה אומר

64
00:02:06,120 --> 00:02:07,630
שהתכונות שלי בעצם

65
00:02:07,700 --> 00:02:09,300
ימדדו עד כמה קרובה

66
00:02:09,380 --> 00:02:10,800
דוגמה לאחד

67
00:02:10,970 --> 00:02:13,150
מהדברים שראיתי בסדרת האימון שלי.

68
00:02:13,440 --> 00:02:14,180
אז רק כדי לכתוב את התיאור הזה

69
00:02:14,350 --> 00:02:16,270
בצורה קצת יותר מעשית, בהינתן m

70
00:02:16,470 --> 00:02:17,870
דוגמאות אימון, אני

71
00:02:18,050 --> 00:02:19,100
אבחר את המיקום

72
00:02:19,310 --> 00:02:20,430
של ציוני הדרך שלי להיות בדיוק

73
00:02:21,190 --> 00:02:23,920
על המקומות של m דוגמאות האימון שלי.

74
00:02:25,430 --> 00:02:26,600
כאשר אנחנו מקבלים דוגמה x,

75
00:02:26,920 --> 00:02:28,090
והדוגמה הזו x יכולה להיות

76
00:02:28,230 --> 00:02:29,260
משהו ממערך האימון,

77
00:02:29,570 --> 00:02:30,800
היא יכולה להיות משהו ממערך האימות הצולב,

78
00:02:31,490 --> 00:02:32,470
או שהיא יכולה להיות משהו ממערך המבחן.

79
00:02:33,320 --> 00:02:34,090
בהינתן דוגמה x אנחנו

80
00:02:34,320 --> 00:02:35,470
נחשב, כפי שאתם רואים,

81
00:02:35,750 --> 00:02:37,220
תכונות כאלה כמו f1,

82
00:02:37,560 --> 00:02:39,180
f2, וכן הלאה.

83
00:02:39,580 --> 00:02:41,120
שבהם l1 למעשה שווה

84
00:02:41,490 --> 00:02:42,850
ל-x1 וכן הלאה.

85
00:02:43,570 --> 00:02:46,080
ואז אלה הם מה שנותן לי וקטור תכונות.

86
00:02:46,840 --> 00:02:49,540
אז אני אכתוב את זה כוקטור תכונות.

87
00:02:50,270 --> 00:02:52,090
אני לוקח את f1, f2

88
00:02:52,290 --> 00:02:53,370
וכן הלאה, ופשוט מקבץ

89
00:02:53,580 --> 00:02:55,330
אותם לוקטור תכונות.

90
00:02:56,330 --> 00:02:58,000
מההתחלה ועד fm.

91
00:02:59,320 --> 00:03:01,080
ואתם יודעים, רק בגלל הקונבנציה,

92
00:03:01,610 --> 00:03:02,870
אם אנחנו רוצים, אנחנו יכולים להוסיף

93
00:03:02,990 --> 00:03:06,250
תכונה נוספת f0, שתמיד שווה 1.

94
00:03:06,450 --> 00:03:08,530
אז זה משחק תפקיד דומה למה שהיה לנו בעבר

95
00:03:09,480 --> 00:03:11,200
עבור x0, שהיה ההיסט - האינטרספטור - שלנו.

96
00:03:13,200 --> 00:03:14,450
אז לדוגמה, אם יש לנו

97
00:03:14,580 --> 00:03:16,550
דוגמת הדרכה (x(i), y(i

98
00:03:18,270 --> 00:03:19,300
התכונות שנחשב עבור

99
00:03:20,080 --> 00:03:21,330
הדוגמא הזו תהיינה

100
00:03:21,440 --> 00:03:23,440
כדלקמן: בהינתן ⁽x⁽ⁱ אנחנו

101
00:03:23,640 --> 00:03:26,560
נְמַפֶּה אותו ל-(f1(i,

102
00:03:27,980 --> 00:03:29,670
שערכו פונקצית הדמיון בין (x(i ו-l1.

103
00:03:29,960 --> 00:03:31,980
שאני הולך לקצר לאותיות SIM

104
00:03:32,090 --> 00:03:33,380
במקום לכתוב את כל

105
00:03:35,540 --> 00:03:35,540
המילה הארוכה "דמיון", בסדר?

106
00:03:37,050 --> 00:03:39,180
ו-(f2(i שווה לפונקצית הדמיון

107
00:03:40,090 --> 00:03:42,780
בין (x(i ו-l2,

108
00:03:43,140 --> 00:03:45,050
וכן הלאה

109
00:03:45,230 --> 00:03:48,370
עד (fm(i שהוא

110
00:03:49,600 --> 00:03:54,480
הדמיון בין (x(i ו-lm.

111
00:03:55,700 --> 00:03:58,700
ואיפשהו באמצע,

112
00:03:59,160 --> 00:04:01,320
אי שם ברשימה הזו,

113
00:04:01,480 --> 00:04:03,930
ברכיב ה-i, אנחנו

114
00:04:04,230 --> 00:04:05,740
למעשה נקבל תכונה אחת

115
00:04:06,150 --> 00:04:07,590
שהיא (fi(i,

116
00:04:08,170 --> 00:04:09,930
שהיא

117
00:04:10,050 --> 00:04:11,180
הדמיון

118
00:04:13,080 --> 00:04:14,550
בין x ו-(l(i.

119
00:04:15,680 --> 00:04:16,990
אבל הרי li שווה בדיוק

120
00:04:17,190 --> 00:04:18,560
ל-(x(i, ולכן

121
00:04:19,140 --> 00:04:20,320
כמובן (fi(i יהיה פשוט

122
00:04:20,410 --> 00:04:22,250
הדמיון בין x לבין עצמו.

123
00:04:23,960 --> 00:04:25,380
ואם אתה משתמש בליבה הגאוסיאנית

124
00:04:25,620 --> 00:04:26,720
אתה מקבל בעצם e בחזקת מינוס 0

125
00:04:27,170 --> 00:04:29,440
חלקי 2 סיגמא בריבוע אז זה יהיה שווה ל-1 וזה בסדר.

126
00:04:29,790 --> 00:04:31,060
אז אחת התכונות שלי

127
00:04:31,370 --> 00:04:32,940
עבור דוגמת האימון הזו יהיה שווה ל-1.

128
00:04:34,290 --> 00:04:35,570
ואז בדומה למה שיש לנו

129
00:04:35,990 --> 00:04:36,940
אנחנו יכולים לקחת את כל

130
00:04:37,870 --> 00:04:39,910
m התכונות האלה ולרשום אותם כוקטור של תכונות.

131
00:04:40,340 --> 00:04:41,730
אז במקום לייצג את הדוגמה שלי,

132
00:04:42,710 --> 00:04:44,200
באמצעות (x(i שהוא

133
00:04:44,430 --> 00:04:46,970
וקטור מממד (R(n או (R(n+1,

134
00:04:48,290 --> 00:04:49,590
תלוי אם הגדרנו

135
00:04:49,990 --> 00:04:51,120
מונח קבוע (0)f, הוקטור הוא או ב-(R(n

136
00:04:52,070 --> 00:04:52,750
או ב-(R(n+1.

137
00:04:53,440 --> 00:04:55,140
כעת אנו יכולים לייצג

138
00:04:55,300 --> 00:04:56,700
את דוגמאות ההדרכה שלנו באמצעות

139
00:04:56,980 --> 00:04:58,810
וקטור התכונות הזה f.

140
00:04:58,920 --> 00:05:01,240
אני אכתוב את זה כ-f סימן עילי i.

141
00:05:01,400 --> 00:05:03,060
שלוקח את כל

142
00:05:03,300 --> 00:05:06,010
הדברים האלה ומציב אותם בתוך וקטור.

143
00:05:06,540 --> 00:05:09,180
דהיינו (f1(i

144
00:05:09,430 --> 00:05:12,740
עד (fm(i, וכמו שאמרנו קודם

145
00:05:13,030 --> 00:05:15,160
אפשר וגם נהוג להוסיף

146
00:05:15,420 --> 00:05:16,990
את (f0(i, כאשר

147
00:05:17,130 --> 00:05:19,370
(f0(i שווה תמיד 1.

148
00:05:19,370 --> 00:05:20,970
אז הוקטור הזה כאן 

149
00:05:21,300 --> 00:05:23,260
נותן לי

150
00:05:23,430 --> 00:05:25,180
וקטור חדש של תכונות

151
00:05:25,480 --> 00:05:28,310
שמייצגות את דוגמאות האימון.

152
00:05:29,040 --> 00:05:30,980
אז בהינתן פונקציות הדמיון

153
00:05:31,530 --> 00:05:33,160
והקרנלים האלה, הנה

154
00:05:33,400 --> 00:05:35,030
שיטה לשימוש במכונת תמך וקטורי פשוטה.

155
00:05:35,720 --> 00:05:37,100
אם כבר חישבנו ולמדנו

156
00:05:37,300 --> 00:05:39,040
את קבוצת הפרמטרים θ, אז אם עכשיו אנחנו מקבלים ערך של x ורוצים לעשות חיזוי,

157
00:05:41,680 --> 00:05:42,850
מה שאנחנו עושים הוא לחשב

158
00:05:43,060 --> 00:05:44,170
את התכונות f, שהם עכשיו

159
00:05:44,450 --> 00:05:46,920
וקטור תכונות בעל ממד m+1.

160
00:05:49,040 --> 00:05:50,640
ויש לנו m כאן כי יש לנו

161
00:05:51,610 --> 00:05:53,190
m דוגמאות אימון ולכן

162
00:05:53,570 --> 00:05:56,370
יש לנו m ציוני דרך

163
00:05:57,330 --> 00:05:58,310
ומה שאנחנו עושים הוא לחזות

164
00:05:58,600 --> 00:06:00,180
1 אם θᵀf

165
00:06:00,780 --> 00:06:01,860
גדול או שווה ל-0.

166
00:06:02,230 --> 00:06:02,430
בסדר.

167
00:06:02,640 --> 00:06:03,770
θᵀf, כמובן,

168
00:06:04,090 --> 00:06:07,200
זה שווה פשוט ל-θ0*f0 + θ1*f1

169
00:06:07,900 --> 00:06:08,990
פלוס נקודה נקודה,

170
00:06:09,120 --> 00:06:11,200
פלוס θm

171
00:06:12,170 --> 00:06:13,900
כפול (f(m.

172
00:06:14,050 --> 00:06:15,720
וגם וקטור הפרמטרים θ שלנו

173
00:06:16,170 --> 00:06:17,730
הוא עכשיו וקטור

174
00:06:17,990 --> 00:06:21,260
בעל ממד m + 1.

175
00:06:21,780 --> 00:06:23,100
ויש לנו כאן m כי

176
00:06:23,260 --> 00:06:25,030
מספר ציוני הדרך שווה

177
00:06:25,450 --> 00:06:26,600
לגודל סדרת האימון.

178
00:06:26,910 --> 00:06:28,190
אז m היה גודל סדרת האימון

179
00:06:29,100 --> 00:06:31,950
ועכשיו וקטור הפרמטרים θ יהיה בעל ממד m + 1.

180
00:06:32,990 --> 00:06:33,990
אז כך עושים חיזוי

181
00:06:34,360 --> 00:06:36,870
אם כבר יש לנו הגדרה עבור וקטור הפרמטרים θ.

182
00:06:37,840 --> 00:06:39,160
אבל איך אתה מקבל את הערכים של וקטור הפרמטרים θ?

183
00:06:39,680 --> 00:06:40,650
ובכן את זה אנחנו עושים באמצעות

184
00:06:40,920 --> 00:06:43,040
אלגוריתם הלמידה SVM, וספציפית

185
00:06:43,850 --> 00:06:46,460
מה שעושים הוא לפתור את בעיית המינימיזציה הזו.

186
00:06:46,690 --> 00:06:48,170
אנחנו צריכים למזער את

187
00:06:48,540 --> 00:06:51,630
הביטוי C כפול פונקצית העלות הזו שהגדרנו מקודם.

188
00:06:52,430 --> 00:06:54,770
אלא שעכשיו, במקום לעשות

189
00:06:55,040 --> 00:06:56,650
תחזיות

190
00:06:56,970 --> 00:06:59,300
באמצעות (θᵀx(i,

191
00:07:00,020 --> 00:07:01,410
בעזרת

192
00:07:01,720 --> 00:07:03,320
התכונות המקוריות שלנו, (x(i. במקום זאת לקחנו

193
00:07:03,520 --> 00:07:04,840
את התכונות (x(i

194
00:07:05,090 --> 00:07:06,260
והחלפנו אותם בתכונות חדשות,

195
00:07:07,270 --> 00:07:09,080
אז אנחנו משתמשים ב-θᵀ

196
00:07:09,380 --> 00:07:10,840
כפול (f(i כדי לבצע

197
00:07:11,130 --> 00:07:12,480
חיזוי על דוגמת האימון

198
00:07:12,860 --> 00:07:13,860
ה-i, צריך להחליף

199
00:07:14,230 --> 00:07:16,580
בשני המקומות,

200
00:07:16,700 --> 00:07:18,270
ועל ידי פתרון בעית המזעור הזו

201
00:07:18,760 --> 00:07:22,130
אנחנו מקבלים את הפרמטרים עבור מכונת התמך הוקטורי שלנו.

202
00:07:23,240 --> 00:07:24,640
עוד פרט אחד אחרון,

203
00:07:24,870 --> 00:07:26,880
בבעיית

204
00:07:27,510 --> 00:07:29,580
האופטימיזציה הזו בעצם יש לנו

205
00:07:30,570 --> 00:07:32,300
m תכונות וגם m וקטורים.

206
00:07:32,860 --> 00:07:33,650
המספר הזה כאן.

207
00:07:34,520 --> 00:07:36,010
זה מספר התכונות שיש לנו.

208
00:07:37,100 --> 00:07:38,240
ובעצם המספר המעשי של

209
00:07:38,410 --> 00:07:39,390
תכונות שיש לנו הוא המימד

210
00:07:39,670 --> 00:07:41,020
של f. אז הוא

211
00:07:41,730 --> 00:07:42,690
למעשה שווה

212
00:07:42,900 --> 00:07:44,470
ל-m. אז אם תרצו אתם יכולים

213
00:07:44,610 --> 00:07:45,530
לחשוב על זה כסכום

214
00:07:46,340 --> 00:07:47,280
וזה אכן הסכום

215
00:07:47,590 --> 00:07:48,680
מ-j שווה 1 עד

216
00:07:49,490 --> 00:07:50,390
m. דרך אחת לחשוב

217
00:07:50,470 --> 00:07:51,500
על זה, אפשר

218
00:07:51,620 --> 00:07:53,250
לחשוב על זה כמצב שבו n

219
00:07:53,550 --> 00:07:55,060
שווה ל-m, כי אם

220
00:07:55,570 --> 00:07:57,320
הגודל של f הוא מספר התכונות,

221
00:07:57,970 --> 00:07:59,650
אז יש לנו m+1

222
00:08:00,120 --> 00:08:02,920
תכונות, כשה1+ מגיע מההיסט f0.

223
00:08:05,090 --> 00:08:06,760
וכאן במחובר השני, אנחנו עדיין עושים

224
00:08:06,990 --> 00:08:08,110
סכום מ j שווה 1 עד n או m,

225
00:08:08,440 --> 00:08:10,070
כי כמו

226
00:08:10,380 --> 00:08:11,700
בקטעי הוידאו הקודמים שלנו לגבי ההסדרה,

227
00:08:12,580 --> 00:08:14,110
אנחנו עדיין לא מסדירים

228
00:08:14,180 --> 00:08:15,650
את הפרמטר θ₀,

229
00:08:15,780 --> 00:08:16,560
ולכן זה סכום

230
00:08:16,740 --> 00:08:17,930
עבור j הולך מ-1 עד m

231
00:08:18,880 --> 00:08:19,840
במקום j שווה 0 עד

232
00:08:20,000 --> 00:08:22,200
m. אז זהו

233
00:08:22,580 --> 00:08:23,760
אלגוריתם הלמידה של מכונת תמך וקטורי.

234
00:08:24,660 --> 00:08:26,260
יש עוד איזה

235
00:08:27,160 --> 00:08:28,310
פרט מתמטי שאני

236
00:08:28,440 --> 00:08:29,840
צריך להזכיר, והוא

237
00:08:29,930 --> 00:08:30,780
שבדרך שבה מיושמת

238
00:08:31,310 --> 00:08:33,020
מכונת תמך וקטורי,

239
00:08:33,320 --> 00:08:34,750
הביטוי האחרון הזה נעשה למעשה קצת אחרת.

240
00:08:35,680 --> 00:08:36,730
אתם לא באמת חייבים

241
00:08:36,770 --> 00:08:38,080
לדעת את הפרט האחרון הזה

242
00:08:38,190 --> 00:08:39,190
כדי להשתמש במכונת תמך וקטורי,

243
00:08:39,700 --> 00:08:41,330
ולמעשה המשוואות

244
00:08:41,450 --> 00:08:42,500
הכתובות כאן כבר אמורות

245
00:08:42,620 --> 00:08:45,160
לתת לכם את כל האינטואיציות שאתם זקוקים לה.

246
00:08:45,310 --> 00:08:46,190
אבל באופן שבו מכונת תמך וקטורי

247
00:08:46,450 --> 00:08:48,450
מיושמת, הביטוי הזה,

248
00:08:48,570 --> 00:08:50,960
הסכום של θj בריבוע, כן?

249
00:08:53,110 --> 00:08:54,780
אפשר לכתוב את זה בדרך נוספת

250
00:08:55,580 --> 00:08:57,660
והיא פשוט θᵀ

251
00:08:58,500 --> 00:08:59,530
כפול θ, אם נתעלם

252
00:09:00,120 --> 00:09:02,730
מהפרמטר θ₀.

253
00:09:03,570 --> 00:09:05,640
θ1 עד

254
00:09:05,800 --> 00:09:10,090
θm. תוך התעלמות מ-θ0.

255
00:09:11,130 --> 00:09:13,790
הסכום הזה

256
00:09:14,510 --> 00:09:15,900
של j מ-1 עד m של θj בריבוע,

257
00:09:16,040 --> 00:09:18,870
יכול גם להיכתב כ-θᵀθ.

258
00:09:19,930 --> 00:09:21,520
ומה שרוב התוכנות שעושות יישומי

259
00:09:21,730 --> 00:09:23,380
מכונת תמך וקטורי עושות, הוא למעשה

260
00:09:23,720 --> 00:09:25,520
להחליף את θᵀθ

261
00:09:26,280 --> 00:09:28,270
ובמקומו לכתוב θᵀ,

262
00:09:28,590 --> 00:09:30,140
כפול איזושהי מטריצה

263
00:09:30,820 --> 00:09:33,930
שתלויה בקרנל בו משתמשים, כפול θ.

264
00:09:34,160 --> 00:09:35,500
ולכן זה נותן לנו פונקצית מרחק מעט שונה.

265
00:09:36,140 --> 00:09:37,770
הוא משתמש במדידה

266
00:09:38,070 --> 00:09:40,050
שונה במקצת, במקום למזער בדיוק

267
00:09:41,320 --> 00:09:43,250
את הנורמה של θ בריבוע,

268
00:09:43,790 --> 00:09:45,990
אנחנו נמזער משהו די דומה לזה.

269
00:09:46,140 --> 00:09:47,610
זה משהו כמו גרסה בקנה מידה קצת שונה

270
00:09:47,770 --> 00:09:50,150
של וקטור הפרמטרים θ, תלוי בקרנל.

271
00:09:50,950 --> 00:09:52,440
אבל זה רק איזה עניין מתמטי שולי.

272
00:09:53,210 --> 00:09:54,360
שמאפשר לתוכנה של

273
00:09:54,650 --> 00:09:56,350
מכונת התמך הוקטורי לרוץ הרבה יותר ביעילות.

274
00:09:58,300 --> 00:09:59,410
והסיבה שמכונת התמך הוקטורי

275
00:09:59,700 --> 00:10:01,500
עושה את זה עם השינוי הקטן הזה היא

276
00:10:02,020 --> 00:10:03,250
שזה מאפשר למכונה

277
00:10:03,300 --> 00:10:05,740
לרוץ בקנה מידה הרבה יותר גדול של ערכות אימון.

278
00:10:06,370 --> 00:10:07,800
כי למשל, אם יש לנו

279
00:10:07,970 --> 00:10:11,530
קבוצת אימון עם 10,000 דוגמאות הכשרה.

280
00:10:12,590 --> 00:10:13,560
אז לפי הדרך בה אנו מגדירים

281
00:10:13,950 --> 00:10:15,750
ציוני דרך, אנחנו נגיע ל-10,000 ציוני דרך.

282
00:10:16,780 --> 00:10:18,060
אז הוקטור θ נהיה 10,000 מימדי.

283
00:10:18,490 --> 00:10:20,450
זה עדיין אולי עובד, אבל כאשר m

284
00:10:20,450 --> 00:10:21,710
הופך להיות באמת, באמת גדול

285
00:10:22,470 --> 00:10:24,020
אז לחשב

286
00:10:24,150 --> 00:10:25,480
כשיש לנו כל הפרמטרים האלה, נניח אם m

287
00:10:25,590 --> 00:10:26,590
היה 50,000 או 100,000

288
00:10:26,880 --> 00:10:28,170
אז החישוב של

289
00:10:28,340 --> 00:10:29,660
כל הפרמטרים האלה יכול להיות

290
00:10:29,890 --> 00:10:31,240
יקר עבור תוכנת

291
00:10:31,420 --> 00:10:33,690
האופטימיזציה של מכונת תמך וקטורי, ולכן

292
00:10:33,870 --> 00:10:35,750
יקר לפתור את בעיית המינימיזציה שתיארתי כאן.

293
00:10:36,490 --> 00:10:37,570
אז כל זה הוא קצת

294
00:10:37,860 --> 00:10:39,580
פרטים מתמטיים, שאתם באמת לא חייבים לדעת.

295
00:10:41,000 --> 00:10:43,070
אז בשביל הייעול, אנחנו בעצם משנים

296
00:10:43,350 --> 00:10:44,380
קצת את הביטוי האחרון

297
00:10:44,500 --> 00:10:45,940
למזעור של משהו קצת שונה

298
00:10:46,080 --> 00:10:48,560
מאשר פשוט למזער את הנורמה בריבוע של θ.

299
00:10:49,370 --> 00:10:50,600
אבל אם אתם רוצים,

300
00:10:51,080 --> 00:10:52,450
תרגישו חופשיים

301
00:10:52,710 --> 00:10:54,880
לחשוב על זה כעל סוג של פרט יישומי

302
00:10:55,340 --> 00:10:56,750
שאכן משנה מעט את

303
00:10:56,880 --> 00:10:58,260
מטרת האופטימיזציה, אבל הוא נעשה בעיקר

304
00:10:58,930 --> 00:11:01,590
מסיבות של יעילות חישובית,

305
00:11:02,260 --> 00:11:04,390
אז בדרך כלל זה באמת לא צריך לענייו אתכם.

306
00:11:07,640 --> 00:11:09,460
ודרך אגב, אם

307
00:11:09,560 --> 00:11:10,730
אתם תוהים מדוע אנחנו לא מחילים

308
00:11:11,100 --> 00:11:12,210
את הרעיון של קרנל על

309
00:11:12,570 --> 00:11:13,690
אלגוריתמים אחרים כגון על רגרסיה

310
00:11:14,040 --> 00:11:15,450
לוגיסטית, מתברר

311
00:11:15,670 --> 00:11:16,770
שאם נרצה, נוכל

312
00:11:16,900 --> 00:11:18,120
ליישם את הרעיון

313
00:11:18,550 --> 00:11:19,850
של הקרנל ולהגדיר את סוג התכונות האלה

314
00:11:19,990 --> 00:11:22,920
באמצעות ציוני דרך על רגרסיה לוגיסטית.

315
00:11:23,880 --> 00:11:25,860
אבל הטריקים החישוביים שעובדים טוב

316
00:11:26,440 --> 00:11:28,110
במכונות תמך וקטורי אי אפשר להכליל אותם היטב

317
00:11:28,430 --> 00:11:30,700
לעבודה על אלגוריתמים אחרים כמו רגרסיה לוגיסטית.

318
00:11:31,310 --> 00:11:33,110
אז שימוש בקרנלים

319
00:11:33,260 --> 00:11:34,390
עם רגרסיה לוגיסטית יעבוד

320
00:11:34,580 --> 00:11:36,330
יותר מדי לאט, בעוד

321
00:11:36,440 --> 00:11:37,940
שבזכות הטריקים החישוביים,

322
00:11:38,150 --> 00:11:39,490
כמו המטריצה הנוספת כאן

323
00:11:39,900 --> 00:11:41,130
וכיצד היא משנה את החישוב

324
00:11:41,320 --> 00:11:43,140
והפרטים של אופן היישום של מכונת תמך וקטורי,

325
00:11:43,240 --> 00:11:44,990
יוצא שמכונת תמך וקטורי

326
00:11:45,300 --> 00:11:47,090
וקרנל נוטים ללכת טוב במיוחד יד ביד.

327
00:11:47,930 --> 00:11:49,450
ולעומת זאת עם רגרסיה לוגיסטית וקרנלים,

328
00:11:50,250 --> 00:11:51,990
אפשר לעשות את זה, אבל זה יפעל לאט מאוד.

329
00:11:52,890 --> 00:11:53,670
וזה לא יוכל

330
00:11:53,750 --> 00:11:55,420
לנצל את טכניקות האופטימיזציה המתקדמות

331
00:11:56,040 --> 00:11:57,360
שאנשים המציאו

332
00:11:57,530 --> 00:11:58,530
עבור המקרה המיוחד

333
00:11:59,140 --> 00:12:00,950
של הפעלת מכונת תמך וקטורי בעזרת גרעין.

334
00:12:01,540 --> 00:12:03,340
אבל כל זה נוגע בעצם רק

335
00:12:03,710 --> 00:12:04,850
לצורה בה מיישמים

336
00:12:05,230 --> 00:12:06,900
תוכנה כדי למזער את פונקצית העלות.

337
00:12:07,870 --> 00:12:08,940
אני אדבר על זה עוד

338
00:12:09,040 --> 00:12:09,950
בסרטון הבא, אבל בעצם אתם

339
00:12:10,150 --> 00:12:11,530
לא צריכים ממש לדעת

340
00:12:12,200 --> 00:12:13,520
איך לכתוב תוכנה

341
00:12:13,670 --> 00:12:14,890
למזער את פונקצית העלות הזו,

342
00:12:15,170 --> 00:12:17,560
כי אפשר למצוא בקלות תוכנות-מדף מעולות לעשות את זה.

343
00:12:18,670 --> 00:12:19,890
ובדיוק כמו שאני לא

344
00:12:20,140 --> 00:12:21,340
הייתי ממליץ על כתיבת קוד

345
00:12:21,850 --> 00:12:22,960
כדי להפוך מטריצות או כדי לחשב

346
00:12:23,150 --> 00:12:24,490
שורש ריבועי, אני גם

347
00:12:24,660 --> 00:12:26,420
לא ממליץ לכתוב תוכנה

348
00:12:26,560 --> 00:12:27,750
למזער את פונקצית העלות הזו בעצמכם,

349
00:12:28,240 --> 00:12:29,610
אלא במקום זאת כדאי לכם להשתמש

350
00:12:29,780 --> 00:12:31,490
בחבילות תוכנת מדף

351
00:12:31,740 --> 00:12:33,240
שאנשים כבר פיתחו ולכן

352
00:12:33,540 --> 00:12:35,140
חבילות תוכנה אלה כבר מגלמות

353
00:12:35,790 --> 00:12:37,720
את הטריקים האלה של אופטימיזציה נומרית,

354
00:12:39,540 --> 00:12:41,770
אז אתם לא באמת צריכים להתעמק בזה.

355
00:12:41,950 --> 00:12:42,920
אבל דבר אחד

356
00:12:43,180 --> 00:12:45,200
שכן ראוי לדעת עליו הוא זה,

357
00:12:45,350 --> 00:12:46,400
כאשר מפעילים מכונת תמך וקטורי,

358
00:12:46,640 --> 00:12:47,730
איך בוחרים

359
00:12:47,820 --> 00:12:50,220
את הפרמטרים של מכונת התמך הוקטורי?

360
00:12:51,520 --> 00:12:52,300
והדבר האחרון שאני רוצה

361
00:12:52,400 --> 00:12:53,290
לעשות בסרטון הזה הוא לומר

362
00:12:53,450 --> 00:12:54,680
איזו מילה בקשר ליחסי הגומלין

363
00:12:54,840 --> 00:12:57,070
בין ההטיה והשונות בעת שימוש במכונת תמך וקטורי.

364
00:12:57,900 --> 00:12:59,230
כאשר אנחנו משתמשים ב-SVM,

365
00:12:59,390 --> 00:13:00,670
אחד הדברים שצריך לבחור

366
00:13:00,960 --> 00:13:03,850
הוא הפרמטר C

367
00:13:04,090 --> 00:13:05,880
שנמצא במטרת האופטימיזציה,

368
00:13:05,980 --> 00:13:07,690
ואתם זוכרים ש-C שיחק

369
00:13:07,770 --> 00:13:09,800
תפקיד דומה ל-1 חלקי λ,

370
00:13:10,050 --> 00:13:11,750
כש-λ הוא פרמטר ההסדרה

371
00:13:12,520 --> 00:13:13,970
שהיה לנו ברגרסיה לוגיסטית.

372
00:13:15,360 --> 00:13:16,760
זאת אומרת שאם יש לנו

373
00:13:16,930 --> 00:13:18,760
ערך גדול של C, זה מתאים

374
00:13:19,520 --> 00:13:20,560
למצב ברגרסיה לוגיסטית

375
00:13:21,270 --> 00:13:22,260
שבו יש לנו ערך קטן

376
00:13:22,670 --> 00:13:25,080
של λ שמשמעותו הוא שההסדרה משחקת תפקיד שולי.

377
00:13:25,980 --> 00:13:26,960
וכשמשתמשים ב-λ קטנה או ב-C גדול,

378
00:13:27,050 --> 00:13:29,330
בדרך כלל ההשערה תהיה בעלת הטיה נמוכה אבל שונות גבוהה.

379
00:13:30,570 --> 00:13:31,420
בעוד שאם משתמשים בערך קטן יותר

380
00:13:31,630 --> 00:13:33,050
של C זה מתאים

381
00:13:33,240 --> 00:13:34,510
למצב של רגרסיה לוגיסטית

382
00:13:34,660 --> 00:13:36,450
עם ערך גדול

383
00:13:36,620 --> 00:13:38,090
של λ שזה מתאים

384
00:13:38,690 --> 00:13:40,180
להשערה בעלת הטיה גבוהה יותר

385
00:13:40,470 --> 00:13:41,760
ושונות נמוכה יותר.

386
00:13:42,580 --> 00:13:44,520
במילים אחרות, להשערה עם C גדול

387
00:13:45,000 --> 00:13:46,870
יש שונות

388
00:13:47,450 --> 00:13:48,380
גבוהה יותר, ולכן היא נוטה יותר

389
00:13:48,580 --> 00:13:50,290
להתאמת-יתר, ואילו להשערה

390
00:13:50,450 --> 00:13:52,820
עם C קטן יש הטיה גבוהה יותר

391
00:13:52,910 --> 00:13:54,900
ולכן היא נוטה יותר להתאמת-חסר.

392
00:13:56,710 --> 00:13:59,870
אז הפרמטר C הוא אחד מהפרמטרים שאנחנו צריכים לבחור.

393
00:14:00,210 --> 00:14:01,280
הפרמטר השני שאנחנו צריכים לבחור

394
00:14:02,280 --> 00:14:04,580
הוא הפרמטר σ² שהופיע בגרעין הגאוסיאני.

395
00:14:05,760 --> 00:14:07,080
אז אם בגרעין הגאוסיאני

396
00:14:07,750 --> 00:14:09,370
σ² הוא גדול,

397
00:14:09,640 --> 00:14:11,350
אז בפונקציה הדמיון,

398
00:14:11,530 --> 00:14:12,710
שכזכור היא e בחזקת

399
00:14:13,390 --> 00:14:14,710
מינוס הנורמה של x מינוס ציון-הדרך

400
00:14:16,280 --> 00:14:17,950
בריבוע חלקי 2σ².

401
00:14:20,130 --> 00:14:21,290
נסתכל על דוגמא; נניח

402
00:14:21,480 --> 00:14:23,330
שיש לי רק תכונה אחת, x1,

403
00:14:23,570 --> 00:14:25,390
אם יש לי ציון דרך שם

404
00:14:25,490 --> 00:14:27,710
באותו מיקום, אם

405
00:14:27,960 --> 00:14:29,230
σ² הוא גדול, אז

406
00:14:29,480 --> 00:14:30,600
הקרנל הגאוסיאני נוטה

407
00:14:30,690 --> 00:14:32,940
לרדת יחסית לאט

408
00:14:33,960 --> 00:14:34,740
ולכן כך ייראה המאפיין

409
00:14:35,210 --> 00:14:36,690
(f(i, ולכן

410
00:14:36,880 --> 00:14:38,970
זו תהיה פונקציה חלקה יותר,

411
00:14:39,060 --> 00:14:40,640
פונקציה המשתנה בצורה חלקה יותר,

412
00:14:40,760 --> 00:14:42,750
ולכן זה ייתן לנו פונקצית השערה

413
00:14:43,030 --> 00:14:44,170
עם הטיה גבוהה יותר ושונות נמוכה יותר,

414
00:14:44,550 --> 00:14:46,000
כי הקרנל הגאוסיאני יורד בצורה חלקה,

415
00:14:46,840 --> 00:14:48,240
ולכן אנחנו נקבל השערה

416
00:14:48,520 --> 00:14:50,060
שמשתנה לאט, או שמשתנה בצורה חלקה

417
00:14:50,130 --> 00:14:51,860
כשמשנים את

418
00:14:52,050 --> 00:14:53,680
הקלט x. לעומת זאת,

419
00:14:54,030 --> 00:14:55,330
אם σ²

420
00:14:55,660 --> 00:14:57,430
הוא קטן, ואם זהו

421
00:14:57,540 --> 00:14:58,830
ציון הדרך וזו התכונה הראשונה,

422
00:14:58,960 --> 00:15:01,440
הגרעין הגאוסיאני,

423
00:15:01,820 --> 00:15:04,630
אזי פונקציית הדמיון תשתנה בצורה חדה יותר.

424
00:15:05,310 --> 00:15:07,520
ובשני המקרים הפונקציה

425
00:15:07,580 --> 00:15:08,550
מקבלת מקסימום ב-1, ולכן אם סיגמא בריבוע

426
00:15:08,870 --> 00:15:11,730
הוא קטן, אז התכונות משתנות בצורה פחות חלקה.

427
00:15:12,190 --> 00:15:13,740
ואנחנו מקבלים כאן מדרונות גבוהים יותר

428
00:15:14,250 --> 00:15:15,300
או נגזרות גבוהות יותר.

429
00:15:16,020 --> 00:15:17,170
ואם נשתמש ב-σ² קטן,

430
00:15:17,330 --> 00:15:19,620
נקבל השערות עם הטיה נמוכה יותר

431
00:15:19,840 --> 00:15:21,870
וכנראה שונות גבוהה יותר.

432
00:15:23,030 --> 00:15:24,460
וכשתפתרו את

433
00:15:24,680 --> 00:15:26,240
שיעורי הבית של השבוע, אתם בעצם

434
00:15:26,450 --> 00:15:27,230
תקבלו הזדמנות לשחק עם כמה

435
00:15:27,330 --> 00:15:29,480
מהרעיונות האלה בעצמכם ולראות את ההשפעות האלה בעצמכם.

436
00:15:31,590 --> 00:15:34,430
אז זה היה האלגוריתם של מכונת תמך וקטורי עם קרנל.

437
00:15:35,320 --> 00:15:36,450
ואני מקווה שהדיון הזה

438
00:15:37,090 --> 00:15:39,170
על הטיה ושונות ייתן לכם

439
00:15:39,310 --> 00:15:40,380
קצת הרגשה גם בקשר

440
00:15:40,460 --> 00:15:42,600
לאיך אפשר לצפות מהאלגוריתם הזה להתנהג.