1
00:00:00,140 --> 00:00:01,310
עד עכשיו דיברנו על

2
00:00:01,640 --> 00:00:03,290
SVM-ים ברמה די מופשטת.

3
00:00:03,980 --> 00:00:05,030
בסרטון הזה אני רוצה

4
00:00:05,200 --> 00:00:06,460
לדבר על מה שבאמת צריך

5
00:00:06,740 --> 00:00:09,410
לעשות כדי להריץ או להשתמש ב-SVM.

6
00:00:11,320 --> 00:00:12,300
אלגוריתם מכונת התמך הוקטורי

7
00:00:12,850 --> 00:00:14,870
מציב בעיית אופטימיזציה מיוחדת.

8
00:00:15,530 --> 00:00:16,940
אבל כפי שציינתי בקצרה

9
00:00:17,120 --> 00:00:18,150
בוידאו מוקדם יותר, אני

10
00:00:18,380 --> 00:00:20,570
לא ממליץ לכם לכתוב בעצמכם

11
00:00:20,630 --> 00:00:22,810
תוכנה כדי לחשב את וקטור הפרמטרים θ בעצמכם.

12
00:00:23,950 --> 00:00:26,110
בדיוק כמו שבימינו

13
00:00:26,420 --> 00:00:27,730
רק מעטים מאוד מאיתנו,

14
00:00:28,090 --> 00:00:29,400
או בעצם כמעט אף אחד מאיתנו,

15
00:00:29,530 --> 00:00:31,680
לא חושב לכתוב בעצמו קוד להפוך מטריצה

16
00:00:31,950 --> 00:00:33,940
או להוציא שורש ריבועי של מספר, או דברים דומים,

17
00:00:34,190 --> 00:00:36,570
אלא אנחנו פשוט קוראים לפונקצית ספריה כלשהי כדי לעשות זאת.

18
00:00:36,700 --> 00:00:38,090
באותו אופן,

19
00:00:38,850 --> 00:00:40,310
תוכנה לפתרון בעיית האופטימיזציה

20
00:00:40,620 --> 00:00:42,200
של SVM היא מורכבת

21
00:00:42,440 --> 00:00:43,880
מאוד, והיו

22
00:00:43,990 --> 00:00:44,960
חוקרים שעסקו

23
00:00:45,110 --> 00:00:47,560
במחקר המיטבי בתחום הנומרי במשך שנים רבות.

24
00:00:47,850 --> 00:00:48,960
אז כעת יש לנו

25
00:00:49,150 --> 00:00:50,550
ספריות תוכנה טובות וחבילות תוכנה טובות

26
00:00:50,930 --> 00:00:52,270
כדי לעשות את זה.

27
00:00:52,470 --> 00:00:53,480
ולכן אני ממליץ בחום להשתמש

28
00:00:53,860 --> 00:00:55,260
באחת מספריות התוכנה לאופטימיזציה

29
00:00:55,710 --> 00:00:57,780
ולא לנסות וליישם משהו בעצמכם.

30
00:00:58,730 --> 00:01:00,680
ויש הרבה ספריות תוכנה טובות.

31
00:01:00,970 --> 00:01:02,060
השתיים בהן אני

32
00:01:02,210 --> 00:01:03,220
משתמש הכי הרבה הן

33
00:01:03,400 --> 00:01:05,000
liblinear ו-libsvm, אבל יש באמת

34
00:01:05,410 --> 00:01:06,860
הרבה ספריות תוכנה טובות

35
00:01:07,030 --> 00:01:08,430
לעשות את זה, שאפשר

36
00:01:08,600 --> 00:01:10,190
לקרוא להן מהרבה

37
00:01:10,450 --> 00:01:11,860
משפות התכנות הגדולות

38
00:01:11,950 --> 00:01:14,410
שאפשר להשתמש כדי לכתוב אלגוריתם למידה.

39
00:01:15,280 --> 00:01:16,460
אבל, למרות שאתם לא צריכים לכתוב

40
00:01:16,730 --> 00:01:18,330
בעצמכם את התוכנה לעשות אופטימיזציה ב-SVM,

41
00:01:19,120 --> 00:01:20,680
יש בכל זאת כמה דברים שאתם כן צריכים לעשות.

42
00:01:21,420 --> 00:01:23,130
הראשון הוא

43
00:01:23,130 --> 00:01:24,230
לבחור

44
00:01:24,320 --> 00:01:25,640
את הפרמטר C. דיברנו

45
00:01:25,940 --> 00:01:26,930
קצת על מאפייני הטיה ושונות

46
00:01:27,040 --> 00:01:28,850
ב-SVM בסרטון הקודם.

47
00:01:30,290 --> 00:01:31,480
הדבר השני, אתם

48
00:01:31,630 --> 00:01:33,040
צריכים לבחור את הקרנל

49
00:01:33,410 --> 00:01:34,880
או את פונקצית הדמיון שבה אתם רוצים להשתמש.

50
00:01:35,730 --> 00:01:37,080
אפשרות אחת שבאה בחשבון

51
00:01:37,280 --> 00:01:38,980
היא להחליט שלא להשתמש בקרנל בכלל.

52
00:01:40,560 --> 00:01:41,510
הרעיון של אי-שימוש בקרנל

53
00:01:41,910 --> 00:01:43,600
נקרא גם קרנל ליניארי.

54
00:01:44,130 --> 00:01:45,320
אז אם אתם שומעים מישהו אומר

55
00:01:45,530 --> 00:01:46,760
"אני משתמש ב-SVM עם ליבה ליניארית",

56
00:01:47,180 --> 00:01:48,330
מה שזה אומר הוא שהוא משתמש

57
00:01:48,490 --> 00:01:50,690
ב-SVM ללא שימוש

58
00:01:51,020 --> 00:01:52,250
בליבה

59
00:01:52,360 --> 00:01:53,410
והגירסה הזו של SVM

60
00:01:54,120 --> 00:01:55,870
פשוט משתמשת ב-θᵀx, כן,

61
00:01:56,140 --> 00:01:57,620
שעושה ניבוי 1 אם θ0

62
00:01:57,850 --> 00:01:59,420
פלוס θ1 כפול x1

63
00:01:59,740 --> 00:02:01,000
פלוס וכו' פלוס θn

64
00:02:01,690 --> 00:02:04,160
כפול xn גדול או שווה 0.

65
00:02:05,520 --> 00:02:06,830
הקרנל הלינארי,

66
00:02:06,950 --> 00:02:08,250
אפשר לחשוב עליו

67
00:02:08,480 --> 00:02:09,290
כגירסה של SVM

68
00:02:10,340 --> 00:02:12,320
שפשוט נותנת לך מסווג ליניארי סטנדרטי.

69
00:02:13,940 --> 00:02:14,700
זה היא

70
00:02:15,040 --> 00:02:16,160
בחירה סבירה עבור כמה בעיות,

71
00:02:17,130 --> 00:02:18,080
ויש ספריות תוכנה רבות,

72
00:02:18,470 --> 00:02:20,900
liblinear

73
00:02:21,210 --> 00:02:22,320
היא דוגמה אחת מתוך רבות,

74
00:02:22,840 --> 00:02:23,880
דוגמה של ספריית תוכנה

75
00:02:24,560 --> 00:02:25,620
שיכולה לאמן SVM

76
00:02:25,980 --> 00:02:27,410
ללא שימוש בקרנל,

77
00:02:27,760 --> 00:02:29,470
או עם מה שנקרא קרנל או ליבה ליניארית.

78
00:02:29,850 --> 00:02:31,340
אבל למה שנרצה לעשות את זה?

79
00:02:31,410 --> 00:02:32,820
אז אם יש לנו מספר גדול של

80
00:02:33,150 --> 00:02:34,280
תכונות, אם n הוא

81
00:02:34,430 --> 00:02:37,800
גדול, ומספר

82
00:02:37,990 --> 00:02:39,590
דוגמאות האימון m הוא

83
00:02:39,670 --> 00:02:41,050
קטן,

84
00:02:41,230 --> 00:02:42,300
יש מספר עצום של

85
00:02:42,360 --> 00:02:43,630
תכונות וכל וקטור x,

86
00:02:43,710 --> 00:02:45,850
הוא וקטור בעל ממד n או n +1.

87
00:02:46,010 --> 00:02:46,940
אז במקרה שיש לנו

88
00:02:47,080 --> 00:02:48,700
מספר עצום של תכונות אבל

89
00:02:48,800 --> 00:02:50,540
סט אימון קטן, אולי

90
00:02:50,610 --> 00:02:51,430
כדאי להתאים להם גבול החלטה

91
00:02:51,710 --> 00:02:52,890
ליניארי ולא לנסות

92
00:02:53,060 --> 00:02:54,420
להתאים פונקציה לא ליניארית

93
00:02:54,860 --> 00:02:56,980
מאוד מסובכת, כי אולי אין מספיק נתונים

94
00:02:57,560 --> 00:02:59,330
ואנחנו עלולים להסתכן בהתאמת-יתר,

95
00:02:59,470 --> 00:03:00,530
אם ננסה להתאים פונקציה מסובכת מאוד

96
00:03:01,540 --> 00:03:03,220
במרחב תכונות עם ממד גבוה מאוד,

97
00:03:03,980 --> 00:03:04,990
אבל עם סדרת אימון

98
00:03:05,040 --> 00:03:07,120
קטנה. אז זה

99
00:03:07,340 --> 00:03:08,600
יהיה מצב סביר אחד שבו

100
00:03:08,740 --> 00:03:09,950
אנחנו יכולים להחליט פשוט

101
00:03:10,700 --> 00:03:11,960
לא להשתמש בקרנל, או

102
00:03:12,250 --> 00:03:15,580
במילים אחרות להשתמש במה שנקרא ליבה ליניארית.

103
00:03:15,740 --> 00:03:16,740
אופציה שנייה לקרנל

104
00:03:16,820 --> 00:03:18,010
שאפשר לעשות, היא הקרנל הגאוסיאני,

105
00:03:18,370 --> 00:03:19,920
זהו שדיברנו עליו כאן.

106
00:03:21,270 --> 00:03:22,350
ואם מחליטים ללכת על זה,

107
00:03:22,440 --> 00:03:23,130
אז צריך לעשות עוד בחירה

108
00:03:23,420 --> 00:03:25,980
והיא לבחור את הפרמטר σ²

109
00:03:26,850 --> 00:03:29,800
שנוגע גם הוא ביחסים שבין ההטיה והשונות,

110
00:03:30,820 --> 00:03:32,360
כאשר אם σ² הוא

111
00:03:32,600 --> 00:03:33,890
גדול, אז יש סיכוי טוב

112
00:03:34,160 --> 00:03:35,580
להטיה גבוהה יותר

113
00:03:35,770 --> 00:03:37,650
ושונות נמוכה יותר,

114
00:03:37,800 --> 00:03:39,700
ואם σ² הוא קטן,

115
00:03:40,060 --> 00:03:42,360
אז נקבל שונות גבוהה יותר והטייה נמוכה.

116
00:03:43,940 --> 00:03:45,350
אז מתי בוחרים ליבה גאוסיאנית?

117
00:03:46,210 --> 00:03:48,050
ובכן, אם התכונות

118
00:03:48,310 --> 00:03:49,540
המקוריות שלנו, x,

119
00:03:49,820 --> 00:03:51,370
הם ב-Rn, ואם n

120
00:03:51,570 --> 00:03:53,890
הוא קטן, ובאופן אידיאלי,

121
00:03:55,660 --> 00:03:57,110
אם m הוא גדול,

122
00:03:58,470 --> 00:04:00,170
אז לדוגמא אם יש לנו

123
00:04:00,550 --> 00:04:02,340
נניח ערכת אימון דו מימדית,

124
00:04:03,130 --> 00:04:04,880
כמו הדוגמה שציירתי קודם.

125
00:04:05,470 --> 00:04:08,320
שבה n שווה ל-2, אבל יש לנו קבוצת אימון גדולה למדי,

126
00:04:08,680 --> 00:04:09,770
כמו שאני ציירתי שם בגרף,

127
00:04:09,950 --> 00:04:10,890
מספר גדול למדי של דוגמאות אימון,

128
00:04:11,650 --> 00:04:12,410
אז אולי כדאי להשתמש

129
00:04:12,540 --> 00:04:14,400
בליבה כדי להתאים

130
00:04:14,910 --> 00:04:16,260
גבול החלטה לא ליניארי ומורכבת יותר,

131
00:04:16,650 --> 00:04:18,750
ואז ליבה גאוסיאנית תהיה דרך מצוינת לעשות את זה.

132
00:04:19,480 --> 00:04:20,610
לקראת סוף הווידאו,

133
00:04:20,720 --> 00:04:22,570
אני אומר קצת יותר

134
00:04:22,660 --> 00:04:23,760
על מתי כדאי לבחור

135
00:04:23,970 --> 00:04:26,310
ליבה ליניארית, ליבה גאוסיאנית וכן הלאה.

136
00:04:27,860 --> 00:04:29,740
אבל באופן קונקרטי,

137
00:04:30,040 --> 00:04:31,210
אם תחליט להשתמש

138
00:04:31,720 --> 00:04:33,910
בקרנל גאוסיאני, אז הנה מה שאתה צריך לעשות.

139
00:04:35,380 --> 00:04:36,550
בהתאם לחבילת התמיכה של

140
00:04:37,280 --> 00:04:38,990
מכונת התמך הווקטורי שבה אתה משתמש,

141
00:04:39,100 --> 00:04:40,960
היא עשויה לבקש ממך ליישם

142
00:04:41,070 --> 00:04:42,200
פונקצית ליבה, או ליישם

143
00:04:43,060 --> 00:04:43,880
פונקציית דמיון.

144
00:04:45,020 --> 00:04:46,750
אם אתה משתמש

145
00:04:47,010 --> 00:04:49,820
באוקטבה או ביישום MATLAB

146
00:04:50,000 --> 00:04:50,720
של SVM, הוא עשוי לבקש ממך

147
00:04:50,810 --> 00:04:52,560
לספק פונקציה

148
00:04:52,690 --> 00:04:54,680
כדי לחשב תכונה מסוימת של הקרנל.

149
00:04:55,110 --> 00:04:56,480
כאן יש לנו בעצם חישוב של

150
00:04:56,770 --> 00:04:57,890
(f(i עבור

151
00:04:58,220 --> 00:04:59,560
איזשהו ערך של i,

152
00:05:00,570 --> 00:05:02,310
והתוצאה f היא

153
00:05:02,330 --> 00:05:03,570
מספר ממשי, אולי

154
00:05:03,840 --> 00:05:05,060
הייתי צריך לקרוא לו

155
00:05:05,250 --> 00:05:07,230
(f(i, אבל מה שאתם

156
00:05:07,510 --> 00:05:08,130
צריכים לעשות הוא לכתוב פונקציית דמיון,

157
00:05:08,480 --> 00:05:09,530
או פונקצית קרנל, שמקבלת את הקלט הזה,

158
00:05:10,610 --> 00:05:11,910
דוגמה שיכולה להיות דוגמת אימון

159
00:05:12,020 --> 00:05:13,140
או מבחן או אימות,

160
00:05:13,280 --> 00:05:14,640
איזה שהוא וקטור x1,

161
00:05:14,990 --> 00:05:16,220
ועוד קלט

162
00:05:16,370 --> 00:05:18,270
שהוא ציון-דרך,

163
00:05:18,880 --> 00:05:20,750
שכאן קראתי להם פשוט x1

164
00:05:20,950 --> 00:05:21,810
ו-x2, כי

165
00:05:21,900 --> 00:05:23,750
בעצם גם ציוני דרך הם דוגמאות אימון,

166
00:05:24,470 --> 00:05:26,160
אז מה שאתם

167
00:05:26,400 --> 00:05:27,490
צריכים לעשות הוא לכתוב תוכנה

168
00:05:27,670 --> 00:05:28,960
שמקבלת את הקלט זה, x1, x2

169
00:05:29,150 --> 00:05:30,320
ומחשבת את

170
00:05:30,580 --> 00:05:31,950
פונקצית הדמיון ביניהם

171
00:05:32,530 --> 00:05:33,470
ומחזירה מספר ממשי.

172
00:05:36,180 --> 00:05:37,430
אז חבילות מסוימות של מכונת תמך וקטורי

173
00:05:37,580 --> 00:05:39,040
יצפו מכם לספק

174
00:05:39,510 --> 00:05:40,860
את פונקצית הליבה הזו,

175
00:05:41,410 --> 00:05:44,580
שמקבלת את הקלט x1, x2 ומחזירה מספר ממשי.

176
00:05:45,580 --> 00:05:46,460
ומשם והלאה התוכנה תעבוד עצמאית

177
00:05:46,850 --> 00:05:49,070
ותיצור את כל התכונות,

178
00:05:49,410 --> 00:05:51,480
ובצורה אוטומטית היא תקח את x

179
00:05:51,600 --> 00:05:53,370
ותמפה אותו ל-f1,

180
00:05:53,420 --> 00:05:54,420
f2, עד (f(m

181
00:05:54,750 --> 00:05:56,200
באמצעות פונקצית הדמיון שסיפקתם,

182
00:05:56,310 --> 00:05:57,190
והיא תיצור את כל התכונות

183
00:05:57,650 --> 00:05:59,080
ותאמן את מכונת התמך הוקטורי בעצמה.

184
00:05:59,870 --> 00:06:00,800
אבל לפעמים אתם תצטרכו

185
00:06:00,880 --> 00:06:04,710
בעצמכם לספק את הפונקציה הזו.

186
00:06:05,680 --> 00:06:06,770
אם אתה משתמש בקרנל גאוסיאני, חלק מיישומי SVM

187
00:06:06,980 --> 00:06:09,950
כוללים גם את הגרעין הגאוסיאני ועוד

188
00:06:10,040 --> 00:06:10,990
כמה גרעינים אחרים, מכיוון

189
00:06:11,230 --> 00:06:13,580
שהקרנל הגאוסיאני הוא כנראה הקרנל הנפוץ ביותר.

190
00:06:14,880 --> 00:06:16,290
גרעינים גאוסיאנים וליניאריים הם

191
00:06:16,380 --> 00:06:18,210
למעשה שני הגרעינים הפופולריים ביותר הרבה מעל האחרים.

192
00:06:19,130 --> 00:06:20,230
רק נקודה אחד.

193
00:06:20,750 --> 00:06:21,820
אם יש לכם תכונות מקני מידה

194
00:06:22,080 --> 00:06:23,620
שונים מאוד, חשוב

195
00:06:24,700 --> 00:06:26,270
לבצע מישקול - התאמת קנה מידה

196
00:06:26,600 --> 00:06:27,780
לפני השימוש בגרעין הגאוסיאני.

197
00:06:28,580 --> 00:06:29,180
והסיבה היא זו.

198
00:06:30,150 --> 00:06:31,600
תחשבו על חישוב

199
00:06:32,290 --> 00:06:33,570
הנורמה של x-l,

200
00:06:33,790 --> 00:06:34,890
כן, המונח הזה כאן,

201
00:06:35,390 --> 00:06:37,150
המונה של האקספוננט כאן למעלה.

202
00:06:38,300 --> 00:06:39,780
מה שזה עושה, הנורמה

203
00:06:40,070 --> 00:06:40,930
של x-l, בעצם

204
00:06:41,130 --> 00:06:42,140
זה אומר שצריך לחשב וקטור

205
00:06:42,450 --> 00:06:43,290
v, שהוא שווה

206
00:06:43,410 --> 00:06:44,980
x-l. ואז

207
00:06:45,250 --> 00:06:47,940
לחשב את הנורמה

208
00:06:48,130 --> 00:06:49,080
של הוקטור v, שהוא

209
00:06:49,170 --> 00:06:50,510
ההפרש בין x ו-l.

210
00:06:50,580 --> 00:06:51,510
הנורמה של v

211
00:06:53,360 --> 00:06:54,140
מורכבת בעצם מ-v1 בריבוע

212
00:06:54,250 --> 00:06:55,610
פלוס v2 בריבוע

213
00:06:55,830 --> 00:06:58,290
וכולי וכולי, עד פלוס vn בריבוע.

214
00:06:58,900 --> 00:07:00,320
כי כאן x נמצא

215
00:07:01,060 --> 00:07:02,200
ב-Rn, או בעצם

216
00:07:02,290 --> 00:07:05,180
ב-Rn+1, אבל אנחנו כזכור מתעלמים מ-x0.

217
00:07:06,540 --> 00:07:08,420
אז בואו פשוט נאמר ש-x נמצא

218
00:07:08,510 --> 00:07:10,800
ב-Rn, הריבוע

219
00:07:10,950 --> 00:07:12,320
של הביטוי השמאלי הוא מה שעושה את המשוואה הזו נכונה.

220
00:07:12,570 --> 00:07:14,090
זה שווה

221
00:07:14,400 --> 00:07:16,120
לזה, נכון?

222
00:07:17,210 --> 00:07:18,710
אפשר לכתוב את זה אחרת,

223
00:07:18,850 --> 00:07:20,100
x1 מינוס l1

224
00:07:20,290 --> 00:07:22,600
בריבוע, פלוס x2

225
00:07:22,910 --> 00:07:24,590
מינוס l2 בריבוע,

226
00:07:24,910 --> 00:07:26,580
וכולי עד xn מינוס

227
00:07:27,130 --> 00:07:28,540
ln בריבוע,

228
00:07:29,720 --> 00:07:30,790
ועכשיו אם לתכונות

229
00:07:31,850 --> 00:07:33,460
יש טווחים שונים מאוד של ערכים,

230
00:07:33,940 --> 00:07:35,150
ניקח לדוגמא את

231
00:07:35,360 --> 00:07:37,180
חיזוי מחירי הבתים,

232
00:07:38,020 --> 00:07:40,490
אם הנתונים שלנו הוא מספר נתונים בקשר לבתים.

233
00:07:41,420 --> 00:07:43,000
ואם x1 הוא

234
00:07:43,140 --> 00:07:44,660
בטווח של אלפים, לדוגמא הגודל

235
00:07:44,950 --> 00:07:47,190
ברגל מרובעת,

236
00:07:48,010 --> 00:07:48,840
זו התכונה הראשונה, x1.

237
00:07:49,700 --> 00:07:51,630
אבל התכונה השנייה שלנו, x2 היא מספר חדרי השינה.

238
00:07:52,540 --> 00:07:53,610
אז נניח שזה בטווח של

239
00:07:53,730 --> 00:07:56,720
אחד עד חמישה חדרי שינה,

240
00:07:57,810 --> 00:07:59,320
אז x1 מינוס l1 הולך להיות ענק.

241
00:07:59,780 --> 00:08:00,820
זה יכול להיות משהו כמו אלף בריבוע,

242
00:08:01,000 --> 00:08:02,880
ולעומתו x2 מינוס l2

243
00:08:03,200 --> 00:08:04,620
הולך להיות הרבה יותר קטן, ואם

244
00:08:04,750 --> 00:08:06,800
זה המקרה, אז בביטוי הזה,

245
00:08:08,320 --> 00:08:09,660
פונקצית המרחק

246
00:08:10,060 --> 00:08:12,060
תישלט בעיקר על ידי

247
00:08:12,570 --> 00:08:13,280
הגדלים של הבתים,

248
00:08:14,390 --> 00:08:15,760
ומספר החדרים יהיה במידה רבה לא משמעותי.

249
00:08:16,950 --> 00:08:18,060
אז כדי להימנע מזה,

250
00:08:18,230 --> 00:08:19,070
ועל מנת לגרום למכונה

251
00:08:19,360 --> 00:08:21,890
לעבוד היטב, חשוב לעשות מִישְקוּל של התכונות.

252
00:08:23,420 --> 00:08:24,830
וכך להבטיח שה-SVM

253
00:08:25,810 --> 00:08:27,020
נותן תשומת לב דומה

254
00:08:27,950 --> 00:08:28,870
לכל התכונות השונות,

255
00:08:29,190 --> 00:08:30,450
ולא רק כמו

256
00:08:30,600 --> 00:08:31,870
בדוגמה הזו לגודל

257
00:08:32,150 --> 00:08:33,440
של הבתים שבהם התכונות הם במספרים גדולים.

258
00:08:34,700 --> 00:08:35,810
כשמנסים מכונות תמך וקטורי

259
00:08:36,110 --> 00:08:38,760
הסיכויים הם

260
00:08:38,970 --> 00:08:40,000
ששני הגרעינים הנפוצים ביותר

261
00:08:40,460 --> 00:08:41,750
שמשתמשים בהם יהיו

262
00:08:41,850 --> 00:08:43,120
הליבה הליניארית, כלומר

263
00:08:43,320 --> 00:08:45,600
בלי ליבה, או הגרעין הגאוסיאני שדיברנו עליו.

264
00:08:46,520 --> 00:08:47,390
ורק הערה אחת,

265
00:08:47,900 --> 00:08:49,070
שימו לב שלא כל פונקצית דמיון

266
00:08:49,580 --> 00:08:50,590
שאתה מעלה על דעתך

267
00:08:50,770 --> 00:08:52,520
תיתן לך קרנל תקף.

268
00:08:53,450 --> 00:08:54,840
הקרנל הגאוסיאני, הקרנל הליניארי

269
00:08:55,090 --> 00:08:56,410
וכל גרעין אחר

270
00:08:56,710 --> 00:08:57,850
שתשתמש בו לפעמים,

271
00:08:58,030 --> 00:08:59,840
כולם צריכים לעמוד בתנאי הטכני הבא.

272
00:09:00,380 --> 00:09:02,510
הוא נקרא המשפט של מרסר

273
00:09:02,630 --> 00:09:03,560
והסיבה שצריך את זה

274
00:09:03,710 --> 00:09:05,430
היא כי באלגוריתם מכונת

275
00:09:06,380 --> 00:09:08,140
תמך וקטורי או במימושים של

276
00:09:08,480 --> 00:09:09,560
SVM יש הרבה טריקים

277
00:09:10,050 --> 00:09:11,380
נומריים של אופטימיזציה חכמה

278
00:09:12,110 --> 00:09:13,270
שנעשו כדי שיהיה אפשר לחשב

279
00:09:13,340 --> 00:09:15,650
את הפרמטר θ ביעילות,

280
00:09:16,590 --> 00:09:18,840
וכשעשו את התכנון המקורי של SVM,

281
00:09:19,470 --> 00:09:21,010
עשו את ההחלטות האלה להגביל

282
00:09:21,540 --> 00:09:22,900
את תשומת לבנו רק לקרנלים

283
00:09:23,510 --> 00:09:25,860
המספקים את המצב הטכני הזה שקרוי 'משפט מרסר'.

284
00:09:26,280 --> 00:09:27,360
וזה גרם לכך

285
00:09:27,570 --> 00:09:28,540
שאנחנו יודעים בביטחון

286
00:09:28,820 --> 00:09:30,270
שכל חבילות ה-SVM האלה,

287
00:09:30,500 --> 00:09:32,210
כל חבילות התוכנה האלה של SVM

288
00:09:32,310 --> 00:09:34,740
יכולות להשתמש בקבוצה גדולה של אופטימיזציות

289
00:09:35,280 --> 00:09:37,470
ולחשב את הפרמטר θ מהר מאוד.

290
00:09:39,320 --> 00:09:40,340
אז מה שרוב האנשים עושים בסופו של דבר

291
00:09:40,840 --> 00:09:42,470
הוא להשתמש בגרעין

292
00:09:42,610 --> 00:09:44,210
הליניארי או הגאוסיאני, אבל

293
00:09:44,430 --> 00:09:45,610
קיימים עוד כמה גרעינים שגם הם

294
00:09:45,940 --> 00:09:47,460
מספקים את משפט מרסר,

295
00:09:47,560 --> 00:09:48,690
ושאתם עשויים להיפגש בהם,

296
00:09:48,850 --> 00:09:50,050
אם כי אני באופן אישי

297
00:09:50,880 --> 00:09:53,780
משתמש בגרעינים אחרים לעתים רחוקות מאוד מאוד, אם בכלל.

298
00:09:54,160 --> 00:09:56,990
רק להזכיר כמה גרעינים אחרים שאתם עשויים לפגוש.

299
00:09:57,990 --> 00:10:00,300
האחד הוא הקרנל הפולינומי.

300
00:10:01,570 --> 00:10:03,350
ועבורו פונקצית הדמיון בין

301
00:10:03,800 --> 00:10:05,520
x ו-l

302
00:10:05,730 --> 00:10:06,760
מוגדר כך, יש

303
00:10:06,830 --> 00:10:07,880
הרבה אפשרויות, אתה יכול

304
00:10:08,640 --> 00:10:10,370
להשתמש ב-xᵀl)²).

305
00:10:10,960 --> 00:10:13,410
אז הנה מדד אחד של כמה x ו-l דומים.

306
00:10:13,610 --> 00:10:14,930
אם x ו-l קרובים מאוד זה לזה,

307
00:10:15,500 --> 00:10:18,260
אזי המכפלה הפנימית נוטה להיות גדולה.

308
00:10:20,200 --> 00:10:21,870
אז כפי שאתם מבינים, זוהי ליבה

309
00:10:23,080 --> 00:10:23,520
חריגה במקצת.

310
00:10:24,000 --> 00:10:25,130
לא משתמשים בה לעתים קרובות, אבל

311
00:10:26,490 --> 00:10:29,190
אפשר למצוא כמה אנשים שכן משתמשים בה.

312
00:10:30,050 --> 00:10:31,810
זוהי גרסה אחת של ליבה פולינומית.

313
00:10:32,330 --> 00:10:35,090
גרסה אחרת היא xᵀl)³).

314
00:10:36,690 --> 00:10:38,780
כל הדברים האלה על השקופית הם דוגמאות של קרנל פולינומי.

315
00:10:39,040 --> 00:10:41,270
xᵀl+1)³)

316
00:10:42,560 --> 00:10:43,620
xᵀl פלוס

317
00:10:43,910 --> 00:10:44,930
מספר שונה מ-1, אולי 5,

318
00:10:44,970 --> 00:10:46,680
ובחזקת 4,

319
00:10:47,700 --> 00:10:49,840
אז לקרנל פולינומי יש למעשה שני פרמטרים.

320
00:10:50,610 --> 00:10:53,020
האחד הוא, איזה מספר להוסיף?

321
00:10:53,520 --> 00:10:53,920
זה יכול להיות 0.

322
00:10:54,430 --> 00:10:58,660
בדוגמה הזו זה באמת פלוס 0, והפרמטר השני הוא דרגת הפולינום.

323
00:10:58,680 --> 00:11:01,670
אז הדרגה, המספרים האלה,

324
00:11:02,250 --> 00:11:04,140
והצורה הכללית יותר של

325
00:11:04,280 --> 00:11:05,530
הקרנל הפולינומי היא

326
00:11:05,720 --> 00:11:07,620
x משוחלף כפול l, פלוס

327
00:11:07,940 --> 00:11:11,510
איזה קבוע

328
00:11:11,800 --> 00:11:14,850
מועלה בחזקה מסוימת,

329
00:11:15,060 --> 00:11:16,720
אז שני אלה

330
00:11:16,940 --> 00:11:19,650
הם הפרמטרים של הקרנל הפולינומי.

331
00:11:20,510 --> 00:11:22,820
לקרנל הפולינומי בדרך כלל

332
00:11:23,350 --> 00:11:24,440
או כמעט תמיד יש ביצועים גרועים יותר

333
00:11:24,820 --> 00:11:25,950
מאשר לקרנל הגאוסיאני ולא משתמשים

334
00:11:26,270 --> 00:11:28,370
בו הרבה, אבל זה משהו שאתם עשויים להיתקל בו.

335
00:11:29,320 --> 00:11:30,480
בדרך כלל משתמשים בו רק עבור

336
00:11:30,750 --> 00:11:31,710
נתונים בהם x ו-l

337
00:11:32,000 --> 00:11:33,180
הם לגמרי לא שליליים,

338
00:11:33,740 --> 00:11:34,720
וזה מבטיח כי

339
00:11:34,910 --> 00:11:36,710
המכפלות הפנימיות האלה לעולם לא יהיו שליליות.

340
00:11:37,850 --> 00:11:40,010
וזה מתאים לאינטואיציה

341
00:11:40,390 --> 00:11:41,340
כי כאשר x ו-l מאוד דומים

342
00:11:41,540 --> 00:11:44,110
זה לזה, אז אולי המכפלה בין שניהם תהיה גדולה.

343
00:11:44,420 --> 00:11:45,590
יש לו עוד תכונות,

344
00:11:46,260 --> 00:11:48,080
אבל בכל אופן אנשים נוטים לא להשתמש בו הרבה.

345
00:11:49,130 --> 00:11:50,150
ואז, תלוי במה שאתה עושה,

346
00:11:50,260 --> 00:11:51,210
יש עוד כמה

347
00:11:52,330 --> 00:11:54,950
גרעינים איזוטריים אחרים, שאתה עלול להיתקל בהם.

348
00:11:55,670 --> 00:11:57,180
יש ליבת מחרוזת, זה

349
00:11:57,340 --> 00:11:58,430
דבר שמשתמשים בו לפעמים אם

350
00:11:58,550 --> 00:12:01,350
נתוני הקלט הם מחרוזות טקסט או סוגים אחרים של מחרוזות.

351
00:12:02,270 --> 00:12:02,940
יש דברים כמו

352
00:12:03,260 --> 00:12:06,000
ליבת חִי בריבוע, ליבת מפגש היסטוגרמה, וכן הלאה.

353
00:12:06,690 --> 00:12:08,420
אלה סוגים של גרעינים אזוטריים נוספים

354
00:12:08,660 --> 00:12:09,840
שבהם ניתן להשתמש כדי למדוד דמיון

355
00:12:10,760 --> 00:12:12,030
בין דברים מסוגים שונים.

356
00:12:12,660 --> 00:12:13,800
אז לדוגמה, אם אתה מנסה

357
00:12:14,380 --> 00:12:15,840
לפתור איזושהי בעיה של

358
00:12:16,170 --> 00:12:17,060
סיווג טקסט, כאשר הקלט

359
00:12:17,200 --> 00:12:19,300
x הוא מחרוזת אז

360
00:12:19,490 --> 00:12:20,490
אולי אנחנו רוצים למצוא

361
00:12:20,550 --> 00:12:22,050
את הדמיון בין שתי מחרוזות

362
00:12:22,430 --> 00:12:24,240
באמצעות ליבת מחרוזת,

363
00:12:24,520 --> 00:12:26,440
אבל אני אישית רק באופן נדיר מאוד,

364
00:12:26,990 --> 00:12:29,340
אם בכלל, משתמש בגרעינים היותר איזוטריים.

365
00:12:29,880 --> 00:12:30,970
אני חושב שיצא לי להשתמש בקרנל חי בריבוע

366
00:12:31,170 --> 00:12:32,270
אולי פעם אחת

367
00:12:32,340 --> 00:12:33,670
בחיים שלי, ובליבת ההיסטוגרמה,

368
00:12:34,240 --> 00:12:35,580
יכול להיות פעם או פעמיים בחיי. אני עצמי

369
00:12:35,630 --> 00:12:38,500
אף פעם לא השתמשתי בקרנל מחרוזת בעצמי. אבל

370
00:12:39,350 --> 00:12:41,560
אם במקרה נתקלתם בזה ביישומים אחרים,

371
00:12:42,700 --> 00:12:43,640
אם תעשו חיפוש מהיר

372
00:12:43,860 --> 00:12:44,850
באינטרנט בגוגל

373
00:12:45,040 --> 00:12:46,000
או בבינג

374
00:12:46,590 --> 00:12:48,240
אתם בוודאי תמצאו הגדרות של הגרעינים האלה גם כן.

375
00:12:51,480 --> 00:12:55,680
אז רק שני פרטים אחרונים שאני רוצה לדבר עליהם בוידאו הזה. אחד הוא סיווג רב-מחלקתי.

376
00:12:56,370 --> 00:12:59,510
אז נניח שיש לכם ארבע מחלקות, או באופן יותר כללי k מחלקות,

377
00:12:59,800 --> 00:13:01,880
ואתם רוצים שה-SVM יוציא

378
00:13:02,530 --> 00:13:06,860
גבול החלטה מתאים בין המחלקות הרבות. לרוב ה-SVM, לחבילות SVM רבות

379
00:13:07,220 --> 00:13:08,750
כבר יש פונקציונליות מובנית

380
00:13:09,030 --> 00:13:10,430
לסיווג רב-מחלקתי. אז

381
00:13:11,100 --> 00:13:12,060
אם אתם משתמשים בחבילה כזו,

382
00:13:12,270 --> 00:13:13,320
אתם פשוט צריכים להשתמש

383
00:13:13,540 --> 00:13:15,370
בפונקציונליות המובנית וזה צריך

384
00:13:15,490 --> 00:13:16,940
לעבוד בסדר. אחרת,

385
00:13:17,790 --> 00:13:18,790
דרך אחת לעשות זאת

386
00:13:19,000 --> 00:13:19,880
היא להשתמש בשיטת

387
00:13:20,000 --> 00:13:21,280
האחד-מול-השאר

388
00:13:21,370 --> 00:13:23,690
עליה דיברנו כאשר עסקנו ברגרסיה לוגיסטית.

389
00:13:24,680 --> 00:13:25,410
אז מה שעושים הוא לאמן

390
00:13:26,160 --> 00:13:27,550
k מכונות SVM נפרדות

391
00:13:27,700 --> 00:13:29,190
עבור k המחלקות, כל אחת

392
00:13:29,900 --> 00:13:31,060
מבדילה מחלקה אחת משאר המחלקות.

393
00:13:31,850 --> 00:13:32,930
וזה ייתן לכם k וקטורי

394
00:13:33,520 --> 00:13:34,530
פרמטרים, אז

395
00:13:34,680 --> 00:13:36,210
הראשון ייתן לכם את θ1

396
00:13:36,530 --> 00:13:38,170
שמנסה להבחין בין המחלקה y שווה

397
00:13:38,630 --> 00:13:39,980
אחת לבין

398
00:13:40,130 --> 00:13:41,340
שאר המחלקות,

399
00:13:41,420 --> 00:13:42,910
והפרמטר השני, הוקטור

400
00:13:42,970 --> 00:13:43,910
θ2, זה מה

401
00:13:44,020 --> 00:13:45,420
שאתה מקבל כדי להבחין

402
00:13:45,720 --> 00:13:47,080
בין y שווה 2 כמחלקה החיובית

403
00:13:47,460 --> 00:13:48,680
וכל השאר כמחלקות שליליות

404
00:13:49,260 --> 00:13:50,550
וכן הלאה, עד

405
00:13:50,800 --> 00:13:52,400
וקטור הפרמטרים θk,

406
00:13:52,750 --> 00:13:54,520
שהוא וקטור פרמטרים

407
00:13:54,600 --> 00:13:56,770
המבדיל בין המחלקה האחרונה

408
00:13:57,360 --> 00:13:59,380
ובין השאר.

409
00:13:59,490 --> 00:14:00,590
ואז בעצם יש לנו בדיוק

410
00:14:01,270 --> 00:14:02,040
אותו דבר כמו בשיטת האחד-מול-השאר

411
00:14:02,420 --> 00:14:04,230
שהשתמשנו בה ברגרסיה לוגיסטית,

412
00:14:04,760 --> 00:14:05,910
שבה פשוט ניבאנו את המחלקה i

413
00:14:06,390 --> 00:14:07,690
שבה θᵀx

414
00:14:08,030 --> 00:14:11,840
היה המספר הגדול ביותר. אז זהו הסיווג הרב-מחלקתי במקרה שלנו.

415
00:14:12,440 --> 00:14:13,750
עבור המקרים הנפוצים יותר,

416
00:14:14,300 --> 00:14:15,090
יש סיכוי טוב

417
00:14:15,180 --> 00:14:16,460
שכל חבילת תוכנה

418
00:14:16,780 --> 00:14:18,010
בה תשתמש, יש

419
00:14:18,340 --> 00:14:19,650
סיכוי סביר שיש בה

420
00:14:19,920 --> 00:14:21,740
פונקציונליות מובנה לסיווג רב-מחלקתי,

421
00:14:21,920 --> 00:14:24,410
ולכן אתה לא צריך לדאוג בקשר לזה.

422
00:14:25,280 --> 00:14:27,010
עוד דבר אחרון, פיתחנו את מכונת התמך הוקטורי

423
00:14:27,210 --> 00:14:28,650
על ידי שהתחלנו עם רגרסיה לוגיסטית

424
00:14:29,090 --> 00:14:31,500
ואז שינינו קצת את פונקציית העלות.

425
00:14:31,910 --> 00:14:34,900
אז הדבר האחרון שאנחנו רוצים לעשות בוידאו הזה, הוא לדבר קצת על

426
00:14:35,550 --> 00:14:36,570
מתי תשתמש בכל אחד

427
00:14:36,660 --> 00:14:38,840
משני האלגוריתמים האלה. אז בואו

428
00:14:39,080 --> 00:14:40,000
נניח ש-n הוא מספר התכונות

429
00:14:40,160 --> 00:14:42,000
ו-m הוא מספר דוגמאות האימון.

430
00:14:43,190 --> 00:14:45,250
אז מתי אנחנו צריכים להשתמש באלגוריתם אחד ומתי בשני?

431
00:14:47,130 --> 00:14:48,430
אז אם n הוא גדול

432
00:14:48,980 --> 00:14:50,140
יחסית לגודל של סדרת האימון,

433
00:14:50,360 --> 00:14:51,390
למשל

434
00:14:52,810 --> 00:14:53,990
אם יש לך מצב

435
00:14:54,250 --> 00:14:55,180
של מספר תכונות

436
00:14:55,330 --> 00:14:56,870
הרבה יותר גדול מ-m,

437
00:14:57,120 --> 00:14:58,210
וזה יכול להיות, למשל,

438
00:14:58,320 --> 00:15:00,590
אם יש לך בעית סיווג טקסט,

439
00:15:01,550 --> 00:15:02,430
שבה המאפיין של וקטור התכונות

440
00:15:02,700 --> 00:15:04,160
יכול אולי להיות 10,000.

441
00:15:05,370 --> 00:15:06,350
וגודל סדרת האימון

442
00:15:06,720 --> 00:15:08,290
הוא אולי 10

443
00:15:08,510 --> 00:15:10,250
או אולי עד 1000.

444
00:15:10,500 --> 00:15:12,140
דמיינו בעיה של סיווג

445
00:15:12,320 --> 00:15:14,250
דואר זבל, דואר זבל

446
00:15:14,510 --> 00:15:15,840
בתוך הדוא"ל, שבו יש נניח 10,000

447
00:15:16,150 --> 00:15:18,010
תכונות שזה מקביל ל-10,000 מלים

448
00:15:18,190 --> 00:15:19,550
אבל מצד שני יש אולי 10

449
00:15:19,780 --> 00:15:21,150
דוגמאות הכשרה או אולי עד 1,000 דוגמאות.

450
00:15:22,450 --> 00:15:23,750
אז אם n הוא גדול בהרבה יחסית

451
00:15:23,890 --> 00:15:25,090
ל-m, אז מה שאני הייתי

452
00:15:25,250 --> 00:15:26,480
עושה באופן נורמלי הוא להשתמש

453
00:15:26,850 --> 00:15:27,990
ברגרסיה לוגיסטית או להשתמש

454
00:15:28,100 --> 00:15:29,030
ב-SVM בלי גרעין

455
00:15:29,460 --> 00:15:30,790
או עם ליבה ליניארית.

456
00:15:31,620 --> 00:15:32,430
כי אם יש לך כל כך הרבה תכונות

457
00:15:32,580 --> 00:15:33,830
עם ערכת אימון קטנה יותר,

458
00:15:34,530 --> 00:15:35,870
אז פונקציה ליניארית תהיה כנראה

459
00:15:36,330 --> 00:15:37,380
בסדר גמור, וממילא אין לך

460
00:15:37,640 --> 00:15:38,790
מספיק נתונים

461
00:15:38,910 --> 00:15:40,760
כדי להתאים פונקציה לא ליניארית מסובכת מאוד.

462
00:15:41,340 --> 00:15:42,410
עכשיו אם n הוא

463
00:15:42,520 --> 00:15:44,020
קטן ו-m הוא

464
00:15:44,350 --> 00:15:45,890
בינוני, ומה שאני מתכוון

465
00:15:45,940 --> 00:15:47,450
בזה הוא ש-n

466
00:15:48,040 --> 00:15:50,350
הוא אולי איפשהו בין 1-1000,

467
00:15:50,530 --> 00:15:51,470
1 זה קטן

468
00:15:51,700 --> 00:15:54,270
מאוד. אבל אולי עד 1000 תכונות, ואם

469
00:15:54,590 --> 00:15:56,180
מספר דוגמאות

470
00:15:56,330 --> 00:15:57,700
האימון הוא אולי איפשהו

471
00:15:58,210 --> 00:16:00,750
בין 10, נניח 10 עד אולי 10,000 דוגמאות.

472
00:16:01,350 --> 00:16:03,160
אולי אפילו עד 50,000 דוגמאות.

473
00:16:03,630 --> 00:16:06,490
אם m הוא די גדול, בסביבות 10,000 אבל לא מיליון.

474
00:16:06,760 --> 00:16:08,100
בסדר? אז אם m הוא

475
00:16:08,300 --> 00:16:09,950
בגודל בינוני אז

476
00:16:10,790 --> 00:16:12,980
SVM עם ליבה ליניארית יעבוד לעתים קרובות טוב.

477
00:16:13,530 --> 00:16:14,580
דיברנו על זה גם יותר מוקדם,

478
00:16:14,710 --> 00:16:15,800
עם דוגמה קונקרטית אחת,

479
00:16:16,350 --> 00:16:17,100
כאשר היתה לנו

480
00:16:17,520 --> 00:16:19,720
ערכת אימון דו מימדית. n

481
00:16:19,900 --> 00:16:21,010
היה שווה ל-2

482
00:16:21,320 --> 00:16:23,710
והיה לנו שם תרשים עם מספר לא מבוטל של דוגמאות הכשרה.

483
00:16:24,710 --> 00:16:25,860
אז הגרעין הגאוסיאני יעשה

484
00:16:26,130 --> 00:16:28,160
עבודה די טובה להפריד בין דוגמאות חיוביות ושליליות.

485
00:16:29,770 --> 00:16:30,890
מצב שלישי מעניין הוא

486
00:16:30,980 --> 00:16:32,420
אם n הוא קטן

487
00:16:32,520 --> 00:16:34,270
אבל m הוא גדול.

488
00:16:34,890 --> 00:16:36,560
אם גם כאן n הוא אולי

489
00:16:37,390 --> 00:16:39,280
מ-1 עד 1000, או אולי יכול להיות גדול יותר.

490
00:16:40,200 --> 00:16:42,750
אבל m הוא אולי

491
00:16:43,320 --> 00:16:46,400
בין 50,000 ויותר ועד מיליונים.

492
00:16:47,520 --> 00:16:50,270
50,000, 100,000, מיליון, שני מיליון.

493
00:16:51,290 --> 00:16:54,020
יש לנו סדרת אימון מאוד מאוד גדולה, כן.

494
00:16:55,240 --> 00:16:56,160
אז אם זה המקרה,

495
00:16:56,380 --> 00:16:57,630
אז SVM

496
00:16:57,900 --> 00:16:59,850
עם ליבה גאוסיאנית ירוץ בצורה קצת איטית.

497
00:17:00,160 --> 00:17:02,300
חבילות SVM של היום, אם

498
00:17:02,410 --> 00:17:04,900
נשתמש בקרנל גאוסיאני, יצטרכו להתאמץ קצת.

499
00:17:05,050 --> 00:17:06,250
אם יש לך אולי 50

500
00:17:06,590 --> 00:17:07,530
אלף זה עוד בסדר, אבל אם

501
00:17:07,620 --> 00:17:10,250
יש לך מיליון דוגמאות הכשרה, אולי

502
00:17:10,450 --> 00:17:11,950
אפילו 100,000. עם

503
00:17:12,170 --> 00:17:13,730
ערך מסיבי של m.

504
00:17:14,180 --> 00:17:15,590
חבילות SVM של היום הן טובות מאוד,

505
00:17:15,870 --> 00:17:17,100
אבל הן עדיין עלולות להיתקל בקושי

506
00:17:17,600 --> 00:17:18,400
כאשר הן צריכות

507
00:17:19,010 --> 00:17:20,940
לעבוד על גדלים מסיביים של ערכות אימון כאשר משתמשים בקרנל גאוסיאני.

508
00:17:22,050 --> 00:17:23,150
אז במקרה זה, מה שאני

509
00:17:23,350 --> 00:17:24,960
הייתי בוחר לעשות הוא לנסות

510
00:17:25,330 --> 00:17:26,660
ליצור באופן ידני

511
00:17:26,800 --> 00:17:28,600
תכונות נוספות ואז להשתמש

512
00:17:28,930 --> 00:17:30,340
ברגרסיה לוגיסטית או ב-SVM

513
00:17:30,630 --> 00:17:32,060
בלי קרנל.

514
00:17:33,140 --> 00:17:34,030
ואם אתה מסתכל על השקופית הזאת

515
00:17:34,230 --> 00:17:35,900
ואתה רואה שרגרסיה לוגיסטית

516
00:17:36,460 --> 00:17:37,750
ו-SVM בלי ליבה נמצאים ביחד,

517
00:17:38,510 --> 00:17:39,890
בשני המקומות האלה

518
00:17:39,980 --> 00:17:41,750
קיבצתי אותם ביחד.

519
00:17:42,060 --> 00:17:43,050
ויש סיבה לכך,

520
00:17:43,900 --> 00:17:45,640
רגרסיה לוגיסטית ו-SVM בלי קרנל

521
00:17:46,000 --> 00:17:47,130
הם בעצם אלגוריתמים די דומים,

522
00:17:47,350 --> 00:17:49,450
גם רגרסיה לוגיסטית

523
00:17:49,680 --> 00:17:51,170
וגם SVM בלי קרנל

524
00:17:51,500 --> 00:17:53,230
בדרך כלל עושים

525
00:17:53,380 --> 00:17:54,780
דברים דומים למדי,

526
00:17:54,900 --> 00:17:56,690
ויש להם ביצועים דומים למדי, אבל בהתאם

527
00:17:57,060 --> 00:18:00,340
לפרטי היישום שלך, אחד מהם עשוי להיות יותר יעיל מאשר האחר.

528
00:18:00,930 --> 00:18:02,220
אבל כאשר אחד

529
00:18:02,310 --> 00:18:03,530
האלגוריתמים הללו מתאים,

530
00:18:03,740 --> 00:18:05,190
רגרסיה לוגיסטית או SVM ללא ליבה,

531
00:18:05,420 --> 00:18:05,840
השני גם הוא

532
00:18:06,650 --> 00:18:07,600
צפוי לעבוד די טוב.

533
00:18:08,540 --> 00:18:09,660
אבל הרבה מהעוצמה

534
00:18:09,720 --> 00:18:11,610
של SVM הוא כאשר

535
00:18:11,810 --> 00:18:14,100
אנחנו משתמשים בגרעינים שונים

536
00:18:14,430 --> 00:18:15,860
כדי ללמוד פונקציות לא לינאריות מורכבות.

537
00:18:16,680 --> 00:18:20,300
באזור הזה, כשיש לך

538
00:18:20,550 --> 00:18:22,530
אולי עד 10,000 דוגמאות, אולי עד 50,000.

539
00:18:22,610 --> 00:18:25,010
ומספר התכונות שלך

540
00:18:26,580 --> 00:18:27,540
גדול למדי.

541
00:18:27,840 --> 00:18:29,230
זה אזור נפוץ מאוד

542
00:18:29,670 --> 00:18:30,910
ואולי זה האזור

543
00:18:31,430 --> 00:18:33,830
שבו מכונת תמך וקטורי עם קרנל גאוסיאני תהיה הכוכב.

544
00:18:34,320 --> 00:18:35,640
אפשר לעשות דברים

545
00:18:35,860 --> 00:18:39,850
שהרבה יותר קשה לעשות בעזרת רגרסיה לוגיסטית.

546
00:18:40,100 --> 00:18:40,930
ולבסוף, היכן נכנסות כאן רשתות עצביות?

547
00:18:41,120 --> 00:18:42,230
אז עבור כל

548
00:18:42,440 --> 00:18:43,890
הבעיות הללו, עבור כל

549
00:18:43,960 --> 00:18:46,310
האזורים השונים האלה,

550
00:18:46,630 --> 00:18:49,110
רשת עצבית מתוכננת היטב גם היא עשויה לעבוד היטב.

551
00:18:50,320 --> 00:18:51,700
החיסרון היחיד, או

552
00:18:51,830 --> 00:18:52,980
הסיבה היחידה שאולי אני לא משתמש לפעמים

553
00:18:53,220 --> 00:18:54,690
ברשת העצבים, היא

554
00:18:54,920 --> 00:18:56,080
שבכמה מהבעיות האלה,

555
00:18:56,180 --> 00:18:57,640
הרשת העצבית עלולה ללמוד בצורה איטית.

556
00:18:58,250 --> 00:18:59,080
ולעומתה אם יש לך חבילת יישום

557
00:18:59,350 --> 00:19:01,190
טובה מאוד של SVM,

558
00:19:01,400 --> 00:19:04,120
היא יכולה לרוץ מהר יותר, ודי הרבה מהר יותר, מאשר הרשת העצבית שלך.

559
00:19:05,130 --> 00:19:06,130
ולמרות שלא הראינו את זה

560
00:19:06,350 --> 00:19:07,520
מקודם, מתברר כי

561
00:19:07,630 --> 00:19:09,800
בעיית האופטימיזציה של

562
00:19:10,070 --> 00:19:11,120
SVM היא בעיית

563
00:19:12,320 --> 00:19:13,830
אופטימיזציה קמורה ולכן

564
00:19:14,410 --> 00:19:15,800
חבילות התוכנה הטובות

565
00:19:16,160 --> 00:19:17,870
לאופטימיזציה של SVM ימצאו תמיד

566
00:19:18,240 --> 00:19:21,370
את המינימום הגלובלי או משהו קרוב אליו.

567
00:19:21,720 --> 00:19:24,100
ולכן עבור SVM אתה לא צריך לדאוג שהיא תמצא אופטימום מקומי.

568
00:19:25,280 --> 00:19:26,440
בפועל אופטימום מקומי הוא לא

569
00:19:26,580 --> 00:19:27,920
בעיה גדולה מדי גם עבור רשתות עצביות

570
00:19:28,090 --> 00:19:29,120
אבל הן כולם פחות אופטימליות,

571
00:19:29,310 --> 00:19:31,520
אז זה דבר אחד פחות לדאוג אם אתה משתמש ב-SVM.

572
00:19:33,350 --> 00:19:34,560
ובהתאם לבעיה שלך,

573
00:19:34,910 --> 00:19:37,050
הרשת העצבית עשויה להיות,

574
00:19:37,580 --> 00:19:41,020
במיוחד בסוג הזה האמצעי של אזור, איטית יותר מאשר SVM.

575
00:19:41,420 --> 00:19:42,200
במקרה שההנחיות שנתנו כאן

576
00:19:42,520 --> 00:19:43,500
נראות קצת מעורפלות,

577
00:19:43,860 --> 00:19:44,600
ואם אתה מסתכל על קצת בעיות,

578
00:19:46,930 --> 00:19:48,050
ההנחיות קצת מעורפלות,

579
00:19:48,170 --> 00:19:49,190
ואתה חושב, אני עדיין לא

580
00:19:49,570 --> 00:19:50,730
בטוח לגמרי, האם אני צריך

581
00:19:50,780 --> 00:19:52,690
להשתמש באלגוריתם זה או באלגוריתם ההוא, זה ממש בסדר.

582
00:19:52,950 --> 00:19:54,100
כאשר אני נתקל בבעיה של למידת מכונה,

583
00:19:54,330 --> 00:19:55,570
לפעמים זה פשוט לא ברור

584
00:19:55,730 --> 00:19:57,010
איזה אלגוריתם הוא

585
00:19:57,150 --> 00:19:58,700
הטוב ביותר לשימוש, אבל

586
00:19:59,540 --> 00:20:00,590
כפי שראית בקטעי הוידאו הקודמים,

587
00:20:01,200 --> 00:20:02,470
אתה יודע בעצם, שלמרות

588
00:20:02,700 --> 00:20:03,920
שהאלגוריתם אכן משנה, אבל מה שלעתים קרובות

589
00:20:04,250 --> 00:20:06,400
עוד יותר חשוב הוא דברים כמו, כמה נתונים יש לך,

590
00:20:07,090 --> 00:20:08,280
כמה אתה מיומן,

591
00:20:08,450 --> 00:20:09,500
כמה טוב אתה בניתוח שגיאות

592
00:20:09,750 --> 00:20:11,450
וניפוי של אלגוריתמי למידה,

593
00:20:11,660 --> 00:20:13,090
כמה אתה מבין איך לעצב

594
00:20:13,220 --> 00:20:15,120
תכונות חדשות,

595
00:20:15,280 --> 00:20:17,540
אתה מבין אילו תכונות נוספות לתת לאלגוריתם הלמידה שלך וכן הלאה.

596
00:20:17,960 --> 00:20:19,110
ולעתים קרובות הדברים האלה חשובים

597
00:20:19,660 --> 00:20:20,700
יותר מאשר האם אתה

598
00:20:20,840 --> 00:20:22,370
משתמש ברגרסיה לוגיסטית או SVM.

599
00:20:23,280 --> 00:20:24,650
אבל לאחר שאמרנו את זה,

600
00:20:25,010 --> 00:20:26,180
SVM עדיין באופן נרחב

601
00:20:26,630 --> 00:20:27,890
נתפס כאחד

602
00:20:27,950 --> 00:20:29,600
מאלגוריתמי הלמידה החזקים ביותר,

603
00:20:29,740 --> 00:20:31,570
ויש טווחי גדלים שבהם

604
00:20:31,790 --> 00:20:34,340
הוא דרך יעילה מאוד ללמוד פונקציות מורכבות לא ליניאריות.

605
00:20:35,150 --> 00:20:36,840
אז בעצם, עם

606
00:20:37,040 --> 00:20:38,930
רגרסיות לוגיסטיות, רשתות עצביות, SVM,

607
00:20:39,090 --> 00:20:40,630
כאשר תשתמש באלגוריתמים האלה

608
00:20:40,760 --> 00:20:42,170
כדי לזרז את הלמידה, אני מאמין

609
00:20:42,440 --> 00:20:43,610
שאתה ממוקם היטב כדי לבנות

610
00:20:44,120 --> 00:20:45,120
מערכות למידת מכונה

611
00:20:45,310 --> 00:20:46,710
שנמצאות בפסגת הטכנולוגיה

612
00:20:46,960 --> 00:20:49,110
עבור תחום יישומים רחב

613
00:20:49,330 --> 00:20:52,460
וזהו עוד כלי חזק מאוד שיש לך בארגז הכלים.

614
00:20:53,160 --> 00:20:54,270
כלי הנמצא בשימוש

615
00:20:54,460 --> 00:20:55,850
בכל מקום בעמק הסיליקון,

616
00:20:56,390 --> 00:20:58,030
כמו גם בתעשייה

617
00:20:58,310 --> 00:20:59,860
ובאקדמיה, והמשמש לבנות

618
00:21:00,120 --> 00:21:01,680
מערכות למידת מכונה בעלות ביצועים גבוהים.