רשתות עצביות הן אחד מאלגוריתמי הלמידה החזקים ביותר שיש לנו כיום. בסרטון זה ובסרטונים הבאים, אני רוצה להתחיל לדבר על אלגוריתם למידה עבור התאמת הפרמטרים של רשת עצבית בהינתן קבוצת אימון. כמו בדיון של רוב אלגוריתמי הלמידה שלנו, אנחנו נתחיל בדיון על פונקציית העלות עבור התאמת הפרמטרים של הרשת. אני אתמקד ביישום של רשתות עצביות בבעיות סיווג. אז נניח שיש לנו רשת כזאת כמו שמוצגת משמאל. ונניח שיש לנו קבוצת אימון כמו זה של זוגות ⁽x⁽ⁱ ⁽y⁽ⁱ ויש לנו m דוגמאות אימון. אני הולך להשתמש ב-L גדולה כדי לציין את המספר הכולל של שכבות ברשת זו. אז עבור הרשת המוצגת בצד שמאל יש לנו L גדולה שווה 4. ואני אשתמש ב-sₗ דהיינו s עם אינדקס l, לציין את מספר היחידות, כלומר מספר הנוירונים, חוץ מיחידת ההטיה, בשכבה l של הרשת. כך, למשל, יהיה לנו s₁, שהוא שווה כאן, שווה ל-3, ו-S₂ בדוגמה שלנו הוא חמש יחידות. ושכבת הפלט s₄, שהיא גם שווה ל-s עם אינדקס L גדולה כי L גדולה שווה ל-4, בשכבת הפלט בדוגמה שלנו כאן יש ארבע יחידות. אנחנו נדון בשני סוגים של בעיות סיווג. הראשון הוא סיווג בינארי, שבו התוויות y הן 0 או 1. במקרה זה, תהיה לנו יחידת פלט אחת, אז ברשת העצבית הזו יש 4 יחידות פלט, אבל כשיש לנו סיווג בינארי, יש לנו רק יחידת פלט אחת שמחשבת את (h(x. והפלט של הרשת העצבית הוא (h(x שיהיה מספר ממשי. ובמקרה זה מספר יחידות הפלט, s אינדקס L, כי שוב L הוא האינדקס של השכבה האחרונה. כי זה מספר השכבות שיש לנו ברשת אז מספר היחידות שיש לנו בשכבת הפלט יהיה 1. במקרה שלנו כדי לפשט את הסימון מאוחר יותר, אני גם אגדיר ש-K=1, אתם יכולים לחשוב על K כעוד סימון של מספר היחידות בשכבת הפלט. הסוג השני של בעיית סיווג שנדון בו יהיה בעיית סיווג רב מחלקתית, שבה יש לנו K מחלקות שונות. אז לדוגמה הייצוג בדוגמא הראשונה שלנו היה כזה עבור y אם יש לנו 4 מחלקות, ובמקרה זה יהיו לנו K יחידות פלט והפלט של פונקציית ההשערה שלנו הוא וקטורים בעלי ממד K. ומספר יחידות הפלט יהיה שווה ל-K. ובדרך כלל יש לנו K גדול שווה 3 במקרה כזה, כי אם היו לנו רק שתי מחלקות, אז אנחנו לא צריכים להשתמש בשיטת אחד-מול-השאר. אנו משתמשים בשיטת אחד-מול-השאר רק אם יש לנו K גדול או שווה 3 מחלקות, וכשיש לנו רק שתי מחלקות אנחנו פשוט משתמשים ביחידת פלט אחת. עכשיו בואו נגדיר את פונקציית העלות עבור הרשת העצבית שלנו. פונקציית העלות שבה אנו משתמשים עבור הרשת העצבית תהיה הכללה של הפונקציה בה אנו משתמשים עבור רגרסיה לוגיסטית. עבור רגרסיה לוגיסטית מזערנו את פונקצית העלות (J(θ, שהיתה מינוס 1 חלקי m כפול ביטוי העלות הזה, והוספנו את ביטוי ההסדרה כאן, וזה היה סכום מ-J=1 עד n, כי אנחנו לא מסדירים את מונח ההטיה θ₀. עבור רשת עצבית, פונקציית העלות שלנו תהיה הכללה של זה. כאשר במקום שיש לנו רק ערך אחד של הפלט של הרגרסיה הלוגיסטית, יש לנו במקום זה K כאלה. אז הנה פונקציית העלות שלנו. הרשת העצבית שלנו מוציאה עכשיו קלטים שהם וקטורים ב-Rᴷ כאשר K יכול להיות שווה 1 אם יש לנו בעיה סיווג בינארית. אני אשתמש בסימון (h(x אינדקס i כדי לציין את הפלט ה-i. כלומר, (h(x הוא וקטור k-מימדי והאינדקס i פשוט בוחר את האלמנט ה-i של וקטור הפלט של הרשת העצבית. פונקצית העלות שלנו (J(Θ עכשיו תהיה הדבר הבא. 1- חלקי m כפול הסכום של המונח הזה שהוא דומה למה שהיה לנו ברגרסיה לוגיסטית, אלא שיש לנו כאן הסכום מ-k=1 עד K. סיכום זה הוא בעצם סכום על K יחידות הפלט שלנו. אז אם יש לנו ארבע יחידות פלט, כלומר אם בשכבה האחרונה של הרשת העצבית יש ארבע יחידות פלט, אז זה סכום מ-k=1 עד 4 של בעצם הפונקציה של העלות של אלגוריתם הרגרסיה הלוגיסטית אבל מסכמים את פונקצית העלות על כל אחד מארבע יחידות הפלט. אז אתם יכולים לראות בפרט שזה חל על yₖ hₖ, כי אנחנו בעצם לוקחים את K יחידות הפלט, ומשווים אותם לערך של yₖ שהוא אחד מאותם וקטורים שלפיהם אנחנו מחשבים את המחיר. ולבסוף, המונח השני כאן הוא מונח ההסדרה, בדומה למה שהיה לנו ברגרסיה לוגיסטית. מונח הסיכום הזה נראה באמת מסובך, אבל כל מה שהוא עושה זה סיכום על הביטויים האלה ⁽Θⱼᵢ⁽ˡ עבור כל הערכים של i, j ו-l. חוץ מזה שאנחנו לא מסכמים את המונחים המקבילים לערכי ההטיה האלה, כמו ברגרסיה לוגיסטית. מעשית אנחנו לא מסכמים את הביטויים שמתאימים למקום שבו i שווה 0. מפני שכאשר אנחנו מחשבים את ההפעלה של נוירון, יש לנו מונחים כאלה. Θᵢ₀x₀ ועוד Θᵢ₁x₁ וכו' ואני משער שנשים כאן 2, זה הראשון שם. אז הערכים עם אפס שם, שמתאימים למשהו שמכפילים אותו ב-x0 או a0. אז זה די דומה ליחידת הטיה ובאנלוגיה למה שעשינו עבור רגרסיה לוגיסטית, לא נסכם את המונחים האלה במונח ההסדרה שלנו, כי אנחנו לא רוצים להסדיר אותם ולהוריד את ערכיהם לאפס. אבל זו רק קונוונציה אפשרית אחת, וגם לו סיכמנו על i=0 עד sl, זה יעבוד בערך אותו דבר ולא ישנה הרבה. אבל אולי המוסכמה הזו של לא להסדיר את מונח ההטייה היא פשוט קצת יותר נפוצה. אז זוהי פונקציית העלות שבה אנחנו נשתמש עבור הרשת העצבית שלנו. בסרטון הבא נתחיל לדבר על אלגוריתם שינסה לבצע אופטימיזציה של פונקציית העלות.