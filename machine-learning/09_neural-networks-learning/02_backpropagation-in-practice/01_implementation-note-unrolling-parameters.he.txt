בסרטון הקודם, דיברנו על אופן השימוש במסירה אחורה כדי לחשב את הנגזרות של פונקציית העלות. בסרטון זה, ברצוני לספר לכם במהירות על פרט יישום אחד של תרגום או שיטוח או פרישת הפרמטרים ממטריצות לוקטורים, להם אנו זקוקים כדי להשתמש בשגרות האופטימיזציה המתקדמות. באופן קונקרטי, נניח שבניתם פונקצייה שלוקחת את הקלט הזה, הפרמטרים תטא ומחזירה את פונקציית העלות ומחזירה נגזרות. אז עכשיו אפשר להעביר את הפונקציה הזו לאלגוריתמי אופטימיזציה מתקדמים על ידי fminunc, ו-fminunc היא לא האפשרות היחידה דרך אגב. יש גם אלגוריתמים מתקדמים אחרים לאופטימיזציה. אבל מה שכולם עושים הוא לקבל כקלט, מצביע לפונקצית העלות, ואיזשהו ערך ראשוני של תטא. והפונקציות האלה מניחות שתטא והערך הראשוני של תטא, שהם פרמטרים וקטורים, אולי ב-Rn או ב-Rn+1. בכל אופן אלו וקטורים, והפונקציה מניחה גם שפונקציה העלות מחזירה כערך שני את השיפוע וגם הוא ב-Rn או ב-Rn+1. אז גם הוא וקטור. זה עבד בסדר כאשר השתמשנו ברגרסיה לוגיסטית, אבל עכשיו כשאנחנו משתמשים ברשת עצבית הפרמטרים שלנו הם כבר לא וקטורים, אלא במקום זה הם מטריצות כי ברשת עצבית יש לנו פרמטרים Θ1, Θ2, Θ3 שהם מטריצות ושאנו עשויים לייצג אותם באוקטבה כמטריצות תטא1, תטא2, תטא3. ובאותו אופן גם הביטויים של השיפועים שצפויים לחזור מהפונקציה שלנו. ובכן, בסרטון הקודם הראינו כיצד לחשב את מטריצות הגרדיינטים האלו, D1, D2, D3, שאותם אנחנו יכולים לייצג באוקטבה לדוגמא כמטריצות D1, D2, D3. בסרטון הזה אני רוצה לספר לכם בקיצור על הרעיון של איך לקחת את המטריצות האלה ולפרוש אותם לתוך וקטורים. כך שהם נהיות בפורמט מתאים להיות מועברים כתטא כאן או לצאת כפלט של השיפוע שם. באופן קונקרטי, נניח שיש לנו רשת עצבית עם שכבת קלט אחת עם 10 יחידות, שכבה נסתרת עם עשר יחידות ושכבת פלט אחת עם יחידה אחת בלבד, אז s1 הוא מספר היחידות בשכבה אחת ו-s2 הוא מספר היחידות בשכבה השניה, ו-s3 הוא מספר יחידות בשכבה השלישית. במקרה הזה, הממד של המטריצות Θ ו-D יהיו נתונים על ידי הביטויים האלה. לדוגמה, Θ1 תהיה מטריצה 10 על 11 וכן הלאה. אז באוקטבה, אם אתה רוצה להמיר בין המטריצות האלה לבין וקטורים מה שאתה יכול לעשות זה לקחת את תטא1, תטא2, תטא3, ולכתוב את פיסת הקוד הזו שתיקח את כל האלמנטים של שלוש המטריצות שלך תטא, שתיקח את כל האלמנטים של תטא1, כל האלמנטים של תטא2, כל האלמנטים של תטא3, ותפרוש אותם ותשים את כל האלמנטים בתוך וקטור אחד ארוך. שייקרא thetaVec וכן הפקודה השנייה תיקח את כל המטריצות שלך D ותפרוש אותם לתוך וקטור אחד גדול שייקרא DVec. ובסוף, כשתרצה לחזור מהייצוג הוקטורי לייצוג המטריציוני. מה שתעשה כדי לחזור נניח לתטא1 הוא לקחת את thetaVec ולמשוך החוצה את 110 האיברים הראשונים. בתטא1 יש 110 איברים כי היא מטריצה 10 על 11, אז זה ימשוך את 110 האיברים הראשונים ולאחר מכן השתמש בפקודה reshape כדי לעצב אותם מחדש בחזרה לתוך תטא1. ואז כדי להחזיר את תטא2 אתה שולף את 110 האלמנטים הבאים ומעצב מחדש גם אותם. וגם עבור תטא3, אתה שולף את אחד עשר האלמנטים האחרונים, ומפעיל reshape כדי להחזיר את תטא3. הנה הדגמה מהירה באוקטבה של התהליך הזה. אז עבור הדוגמה הזו בואו נגדיר את Theta1 להיות מטריצת אחדות של 10 על 11, אז זו מטריצה שכולה 1-ים. ופשוט כדי שיהיה קל לראות, בואו נגדיר את Theta2 להיות 2 כפול מטריצת אחדות של 10 על 11 וכן נגדיר את Theta3 שווה 3 כפול מטריצת 1-ים של 1 על 11. אז זה 3 מטריצות נפרדות: Theta1, Theta2 ו-Theta3. עכשיו אנחנו רוצים לשים את כל אלה בתור וקטור. thetaVec שווה Theta1(:) ; Theta2(:) ; Theta3(:). נכון, זה נקודתיים באינדקסים של המטריצות וכך עכשיו thetaVec הולך להיות וקטור ארוך מאוד. יש בו 231 אלמנטים. כשמציגים אותו, רואים שזה וקטור ארוך מאוד עם כל האלמנטים של המטריצה הראשונה, כל האלמנטים של המטריצה השנייה, ובסוף כל האלמנטים של המטריצה השלישית. ואם אני רוצה להחזיר את המטריצות המקוריות שלי, אני יכול לעצב מחדש את התטאות בעזרת הפקודה reshape. בואו נשלוף את 110 האלמנטים הראשונים ונעצב אותם מחדש למטריצה של 10 על 11. זה מחזיר לי את Theta1. ואם אני אז מושך את 110 האלמנטים הבאים. האינדקסים 111 עד 220. אני מקבל בחזרה את כל Theta2. ואם אני הולך מ-221 עד האלמנט האחרון, שהוא האלמנט ה-231, ומעצב אותו מחדש כמטריצה 1 על 11, אני מקבל בחזרה את Theta3. כדי להפוך את התהליך הזה לבאמת ספציפי, הנה האופן שבו אנו משתמשים ברעיון הפרישה כדי ליישם את אלגוריתם הלמידה שלנו. נניח שיש לך ערך ראשוני של הפרמטרים Θ1, Θ2, Θ3. מה שאנחנו הולכים לעשות כאן, הוא לקחת אותם ולפרוש אותם לתוך וקטור ארוך, שלו אנחנו נקרא initialTheta ואותו נשלח ל-fminunc כהגדרה הראשונית של הפרמטרים Θ. הדבר השני שאנחנו צריכים לעשות הוא ליישם את פונקציית העלות. הנה היישום של פונקציית העלות. פונקצית עלות מקבלת כקלט את thetaVec, שהולך להיות שרשור של כל וקטורי הפרמטרים שנפרשו לתוך וקטור אחד. אז הדבר הראשון שאני צריך לעשות הוא להשתמש ב-thetaVec ואני אשתמש בפונקצית reshape. אז אני שולף את האלמנטים מ-thetaVec ומשתמש ב-reshape כדי להחזיר את מטריצות הפרמטרים המקוריים, Θ1, Θ2, ו-Θ3. אז אנחנו מקבלים כאן מטריצות. זה נותן לנו צורה נוחה יותר לשימוש במטריצות האלה, כך שעכשיו אפשר להריץ את המסירה לפנים והמסירה לאחור כדי לחשב את הנגזרות שלי, ולחשב את פונקצית העלות (J(Θ. ואחרי החישובים אנחנו לוקחים את מטריצות הנגזרות ופורשים אותם, ושומרים שהאיברים ישארו באותו סדר כמו שעשינו כאשר פרשנו את תטא. עכשיו אני עומד לפרוש את המטריצות D1, D2, D3 ולקבל מהן את gradientVec שזהו מה שפונקצית העלות יכולה להחזיר. היא יכולה להחזיר וקטור של הנגזרות האלה. אז אני מקווה שעכשיו קיבלתם תחושה טובה לגבי איך להמיר הלוך וחזור בין ייצוג מטריציוני של פרמטרים ובין ייצוג וקטורי של הפרמטרים. היתרון של ייצוג מטריצה הוא שכאשר הפרמטרים שלך מאוחסנים כמטריצות, זה יותר נוח לחשב כשאתה עושה מסירה קדימה ומסירה לאחור וזה קל יותר כאשר הפרמטרים שלך מאוחסנים כמטריצות לנצל את היישומים הוקטוריים של השפה. בעוד לעומת זאת היתרון של ייצוג וקטורי, כאשר יש לך דברים כמו thetaVec או DVec זה מאפשר להשתמש באלגוריתמים מתקדמים של אופטימיזציה. האלגוריתמים האלה נוטים להניח שיש לך את כל הפרמטרים שלך פרושים לתוך וקטור אחד ארוך. וכך עם מה שכרגע למדנו, אני מקווה שאתם יכולים עכשיו להמיר במהירות בין שני הייצוגים לפי הצורך.