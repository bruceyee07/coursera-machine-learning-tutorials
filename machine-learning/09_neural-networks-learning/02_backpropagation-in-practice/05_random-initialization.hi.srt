1
00:00:00,560 --> 00:00:05,200
पिछले पिछले  विडि हमनेइकट्ठेकियेहैंलगभगसभीपीसजोआपकोचाहिए करनेक

2
00:00:05,200 --> 00:00:07,240
इम्प्लमेंट एंड ट्रेन आपका नेटवर्क.

3
00:00:07,240 --> 00:00:10,010
एक सिर्फ़ अंतिम सुझाव जो मुझे आपको बताना है,

4
00:00:10,010 --> 00:00:12,180
जो है देना रैंडम प्रारंभिक वैल्यूज़.

5
00:00:13,260 --> 00:00:15,480
जब आप चला रहे हैं एक अल्गोरिद्म ग्रेडीयंट डिसेंट या

6
00:00:15,480 --> 00:00:19,900
एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म्स भी, हमें ज़रूरत है लेने की कुछ प्रारम्भिक वैल्यू

7
00:00:19,900 --> 00:00:21,620
पेरमिटर्स थीटा की.

8
00:00:21,620 --> 00:00:23,840
तो एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म के लिए,

9
00:00:23,840 --> 00:00:27,880
यह मान कर चलता है कि आप देंगे इसे कुछ प्रारम्भिक वैल्यू पेरमिटर्स थीटा की.

10
00:00:29,060 --> 00:00:31,280
चलो देखते हैं ग्रेडीयंट डिसेंट को.

11
00:00:31,280 --> 00:00:34,690
उसके लिए, हमें आवश्यकता है थीटा को कुछ आरम्भिक वेल्यु देने की, और

12
00:00:34,690 --> 00:00:38,910
फिर हम धीरे-धीरे ले सकते हैं स्टेप्स नीचे की ओर जाने के लिए इस्तेमाल करके ग्रेडीयंट डिसेंट.

13
00:00:38,910 --> 00:00:41,980
नीचे जाने के लिए, न्यूनतम / मिनमायज़ करने के लिए कॉस्ट फ़ंक्शन जे ऑफ़ थीटा को.

14
00:00:41,980 --> 00:00:45,490
तो हम क्या सेट करें थीटा की प्रारंभिक वैल्यूज़?

15
00:00:45,490 --> 00:00:51,900
क्या यह सम्भव है थीटा की आरम्भिक वैल्यू सेट करना ज़ीरोज़ के वेक्टर पर?

16
00:00:51,900 --> 00:00:55,660
जबकि यह सही काम करेगा जब हम कर रहे थे लॉजिस्टिक रेग्रेशन,

17
00:00:55,660 --> 00:00:59,210
आपके सारे पेरमिटर्स को शुरू में ज़ीरो करना वास्तव में नहीं काम करता

18
00:00:59,210 --> 00:01:01,390
जब आप ट्रेन कर रहे हैं आपका न्यूरल नेटवर्क.

19
00:01:01,390 --> 00:01:03,820
मान लो आप ट्रेन कर रहे हैं निम्न न्यूरल नेटवर्क, और

20
00:01:03,820 --> 00:01:07,580
और मान लो आप रखते हो सारे पेरमिटर्स नेटवर्क के 0 पर शुरू में.

21
00:01:07,580 --> 00:01:12,940
और यदि आप वह करते हैं, तब आप क्या, उसका क्या मतलब है कि शुरू में

22
00:01:12,940 --> 00:01:18,620
यह नीला वेट, रंग किया नीले से होगा बराबर उस वेट के, तो ये दोनो 0 हैं.

23
00:01:18,620 --> 00:01:21,040
और यह वेट जो मैं रंग कर रहा हूँ लाल से,

24
00:01:21,040 --> 00:01:25,640
बराबर है उस वेट के, रंग किया है लाल से, और यह वेट भी,

25
00:01:25,640 --> 00:01:30,030
जो मैं रंग कर रहा हूँ हरे से, बराबर होगा उस वेट की वैल्यू से.

26
00:01:30,030 --> 00:01:32,770
उसका क्या मतलब है कि दोनो आपके हिडन यूनिट्स, A1 और A2,

27
00:01:32,770 --> 00:01:37,830
कम्प्यूट करेंगे समान फ़ंक्शन आपकी इन्पुट्स का.

28
00:01:37,830 --> 00:01:42,744
और इसलिए आपको मिलेगा आपके प्रत्येक ट्रेनिंग इग्ज़ाम्पल्ज़ के लिए,

29
00:01:42,744 --> 00:01:45,480
आपको मिलेगा A2 1 बराबर A 2 2.

30
00:01:46,940 --> 00:01:50,860
और इसके अलावा, क्योंकि मैं बहुत अधिक विस्तार में यह दिखाने के लिए नहीं जा रहा हूँ, लेकिन

31
00:01:50,860 --> 00:01:54,360
क्योंकि ये बाहर जाने वाले वेट हैं समान आप दिखा भी सकते हैं

32
00:01:54,360 --> 00:01:56,770
डेल्टा वैल्यूज़ भी समान ही होंगी.

33
00:01:56,770 --> 00:02:02,536
तो वस्तुत: आपको मिलता है डेल्टा 1 1, डेल्टा 2 1 बराबर डेल्टा 2 2,

34
00:02:02,536 --> 00:02:08,582
और यदि आप मैप में और आगे जाते है, आप क्या दिखा सकते हैं कि पर्शियल

35
00:02:08,582 --> 00:02:14,538
डेरिवेटिव विद रिस्पेक्ट टु आपके पेरमिटर्स संतुष्ट करेंगे निम्न,

36
00:02:14,538 --> 00:02:19,831
कि पर्शियल डेरिवेटिव कॉस्ट फ़ंक्शन के विद रिस्पेक्ट टु

37
00:02:19,831 --> 00:02:26,103
अलग कर रहा हूँ डेरिवेटिव्स विद रिस्पेक्ट टु ये दो नीली लाइन आपके नेटवर्क में.

38
00:02:26,103 --> 00:02:29,911
आपको मिलेगा कि ये दो पर्शियल डेरिवेटिव्स होंगे बराबर

39
00:02:29,911 --> 00:02:30,660
एक दूसरे के.

40
00:02:31,930 --> 00:02:35,906
और उसका क्या मतलब है कि ग्रेडीयंट डिसेंट के एक अप्डेट के बाद भी,

41
00:02:35,906 --> 00:02:40,469
आप करेंगे अप्डेट, मान लो, यह पहला नीला वेट जो था लर्निंग रेट गुणा यह,

42
00:02:40,469 --> 00:02:44,990
और आप करेंगे अप्डेट दूसरा नीला वेट जो था लर्निंग रेट गुणा यह.

43
00:02:44,990 --> 00:02:50,386
और उसका क्या मतलब है कि ग्रेडीयंट डिसेंट के एक अप्डेट के बाद भी, वे दोनो नीले

44
00:02:50,386 --> 00:02:55,183
वेट, वे नीले पेरमिटर्स रहेंगे समान एक दूसरे के.

45
00:02:55,183 --> 00:03:00,550
तो वहाँ कोई नॉन-ज़ीरो वैल्यू, लेकिन यह वैल्यू होगी बराबर उस वैल्यू के.

46
00:03:00,550 --> 00:03:01,420
और इसी प्रकार,

47
00:03:01,420 --> 00:03:06,150
ग्रेडीयंट डिसेंट के एक अप्डेट के बाद भी, यह वैल्यू होगी बराबर उस वैल्यू के.

48
00:03:06,150 --> 00:03:07,818
अभी भी होंगी कुछ नॉन-ज़ीरो वैल्यूज़,

49
00:03:07,818 --> 00:03:10,230
केवल यह कि दो लाल वैल्यूज़ हैं बराबर एक दूसरे के.

50
00:03:10,230 --> 00:03:12,500
और इसी प्रकार, दो हरे वेट्स.

51
00:03:12,500 --> 00:03:14,010
ठीक, दोनो की वैल्यूज़ बदल जाएँगी, लेकिन

52
00:03:14,010 --> 00:03:17,590
वे होंगे समान के दूसरे के.

53
00:03:17,590 --> 00:03:21,447
तो प्रत्येक अप्डेट के बाद, पेरमिटर्स कॉरेस्पॉंडिंग तो इन्पुट्स जो जा रही हैं

54
00:03:21,447 --> 00:03:23,656
दोनो हिडन यूनिट्स में हैं समान.

55
00:03:23,656 --> 00:03:27,101
उसका मतलब है कि दोनो हरे वेट्स हैं अभी भी वही, दो लाल

56
00:03:27,101 --> 00:03:30,758
वेट्स हैं अभी भी वही, डॉन नीले वेट्स हैं अभी भी वही, और उसका क्या

57
00:03:30,758 --> 00:03:34,270
मतलब है कि एक इटरेशन के बाद भी, मान लो ग्रेडीयंट डिसेंट की

58
00:03:34,270 --> 00:03:39,114
आपको मिलेगा कि आपकी दोनो हिडन यूनिट्स अभी भी कम्प्यूट कर रही हैं बिल्कुल एक जैसे

59
00:03:39,114 --> 00:03:40,897
फ़ंक्शन इनपुट के.

60
00:03:40,897 --> 00:03:44,092
आपके पास अभी भी हैं a1(2) = a2(2).

61
00:03:44,092 --> 00:03:45,729
और आप वापिस वही स्थिति में हैं.

62
00:03:45,729 --> 00:03:49,634
और जैसे आप चलाते रहते हैं ग्रेडीयंट डिसेंट को, दोनो नीले वेट्स,

63
00:03:49,634 --> 00:03:51,470
फिर भी रहेंगे समान एक दूसरे के.

64
00:03:51,470 --> 00:03:53,410
दोनो लाल वेट्स रहेंगे समान एक दूसरे के और

65
00:03:53,410 --> 00:03:54,889
दोनो हरे वेट्स रहेंगे समान एक दूसरे के.

66
00:03:56,030 --> 00:03:59,220
और उसका क्या मतलब है कि आपका न्यूरल नेटवर्क वास्तव में कम्प्यूट कर सकता है

67
00:03:59,220 --> 00:04:00,740
बहुत दिलचस्प फ़ंक्शन्स, ठीक है?

68
00:04:00,740 --> 00:04:04,960
कल्पना करें कि आपके पास सिर्फ़ दो हिडन यूनिट्स नहीं थी, लेकिन

69
00:04:04,960 --> 00:04:08,070
कल्पना करें कि आपके पास होती बहुत सी हिडन यूनिट्स.

70
00:04:08,070 --> 00:04:11,670
तब इसका क्या मतलब हैं कि सारी आपकी हिडन यूनिट्स कम्प्यूट कर रही हैं

71
00:04:11,670 --> 00:04:13,150
बिल्कुल एक सा फ़ंक्शन.

72
00:04:13,150 --> 00:04:17,060
सारी आपकी हिडन यूनिट्स कम्प्यूट कर रही हैं एक समान फ़ंक्शन इन्पुट्स का.

73
00:04:17,060 --> 00:04:20,190
और यह है एक अत्यधिक व्यर्थ रेप्रेज़ेंटेशन

74
00:04:20,190 --> 00:04:22,620
क्योंकि आप पाते हैं लॉजिस्टिक रेग्रेशन यूनिट.

75
00:04:22,620 --> 00:04:26,320
इसको वास्तव में देखने की ज़रूरत है केवल एक फ़ंक्शन क्योंकि सारे ये हैं समान.

76
00:04:26,320 --> 00:04:29,190
और यह रोकता है आपको और आपके नेटवर्क को करने से कुछ दिलचस्प.

77
00:04:31,640 --> 00:04:35,350
इस समस्या से बचने के लिए, जिस तरह हम देते हैं प्रारम्भिक वैल्यूज़ पेरमिटर्स को

78
00:04:35,350 --> 00:04:38,449
एक न्यूरल नेटवर्क के इसलिए है देना रैंडम प्रारम्भिक वैल्यूज़.

79
00:04:41,264 --> 00:04:45,370
वस्तुतः, समस्या जो हमने देखी पिछली स्लाइड पर है कुछ

80
00:04:45,370 --> 00:04:49,990
जिसे कहते हैं समस्या सिमेट्रिक वेट्स की, कि वेट्स हैं समान.

81
00:04:49,990 --> 00:04:55,510
तो यह रैंडम प्रारम्भिक वैल्यूज़ देना है जिससे हम तोड़ते हैं सिमट्री.

82
00:04:55,510 --> 00:05:00,313
तो हम क्या करते हैं हम देते हैं शुरू की प्रत्येक वैल्यू थीटा की एक रैंडम नम्बर

83
00:05:00,313 --> 00:05:02,177
माइनस एप्सिलोन और एप्सिलोन के बीच.

84
00:05:02,177 --> 00:05:06,290
तो यह है नोटेशन नम्बर्ज़ का माइनस एप्सिलोन और प्लस एप्सिलोन के बीच.

85
00:05:06,290 --> 00:05:08,794
तो मेरे वेट्स मेरे पेरमिटर्स के लिए होंगे

86
00:05:08,794 --> 00:05:12,183
रैंडम ढंग से दी हुई वैल्यूज़ माइनस एप्सिलोन और प्लस एप्सिलोन के बीच.

87
00:05:12,183 --> 00:05:16,782
जिस तरह मैं लिखता हूँ कोड इसे करने के लिए ओकटेव में, मैं कहता हूँ थीटा 1 होना चाहिए बराबर

88
00:05:16,782 --> 00:05:17,369
इसके.

89
00:05:17,369 --> 00:05:19,749
तो यह है रैंड 10 बाई 11,

90
00:05:19,749 --> 00:05:26,750
इस तरह आप कम्प्यूट करते हैं एक रैंडम 10 बाई 11 डिमेन्शनल मेट्रिक्स.

91
00:05:26,750 --> 00:05:31,740
सारी वैल्यूज़ हैं 0 और 1 के बीच, तो ये होंगे

92
00:05:31,740 --> 00:05:35,460
रैंडम नम्बर्ज़ जो लेते हैं कोई भी कोंटिनयूस वैल्यू 0 और 1 के बीच.

93
00:05:35,460 --> 00:05:37,140
और इसलिए यदि आप लेते है एक नम्बर ज़ीरो और

94
00:05:37,140 --> 00:05:40,940
एक के बीच, गुणा करते हैं दो गुणा INIT_EPSILON तब माइनस INITI_EPSILON,

95
00:05:40,940 --> 00:05:44,530
तब आपको मिलता है एक नम्बर जो है माइनस एप्सिलोन और प्लस एप्सिलोन के बीच.

96
00:05:45,640 --> 00:05:48,490
और उससे एक और बात कि, इस एप्सिलोन का यहाँ कुछ लेना देना नहीं है

97
00:05:48,490 --> 00:05:52,590
उस एप्सिलोन से जो हम इस्तेमाल कर रहे थे जब हम कर रहे थे ग्रेडीयंट चेकिंग.

98
00:05:52,590 --> 00:05:54,870
जब कर रहे थे नूमेरिकल ग्रेडीयंट चेकिंग

99
00:05:54,870 --> 00:05:57,420
तब हम जोड़ रहे थे कुछ वैल्यूज़ एप्सिलोन और थीटा की.

100
00:05:57,420 --> 00:05:59,860
यह है आपकी कोई अन्य वैल्यू एप्सिलोन की.

101
00:05:59,860 --> 00:06:02,940
हम सिर्फ़ चाहते थे नोटेट करना init_epsilon सिर्फ़ भेद करने के लिए इसे

102
00:06:02,940 --> 00:06:06,490
उस एप्सिलोन की वैल्यू से जो हम इस्तेमाल कर रहे थे ग्रेडीयंट चेकिंग में.

103
00:06:06,490 --> 00:06:11,240
और इसी प्रकार यदि आप चाहते हैं देना प्रारम्भिक वैल्यू थीटा 2 को एक रैंडम 1 बाई 11 की

104
00:06:11,240 --> 00:06:13,650
मेट्रिक्स आप वैसा कर सकते हैं इस कोड से यहाँ.

105
00:06:16,120 --> 00:06:19,625
तो संक्षेप में, बनाने के लिए एक न्यूरल नेटवर्क आपको क्या चाहिए

106
00:06:19,625 --> 00:06:23,552
करना कि रैंडम ढंग से दें शुरू के वेट्स छोटी वैल्यूज़ जो ज़ीरो के आसपास की हैं,

107
00:06:23,552 --> 00:06:25,879
मान लो -एप्सिलोन और +एप्सिलोन के बीच.

108
00:06:25,879 --> 00:06:29,699
और फिर इम्प्लमेंट करें बैक प्रॉपगेशन, करें ग्रेडीयंट चेकिंग,

109
00:06:29,699 --> 00:06:34,694
और इस्तेमाल करें ग्रेडीयंट चेकिंग या कोई एक एडवांसड ऑप्टिमायज़ेशन अल्गोरिद्म करने के लिए

110
00:06:34,694 --> 00:06:39,470
मिनमायज़ जे(थीटा) जो है एक फ़ंक्शन पेरमिटर्स थीटा का शुरू करते हुए केवल

111
00:06:39,470 --> 00:06:42,716
रैंडम ढंग से ली हुई प्रारंभिक वैल्यूज़ से पेरमिटर्स की.

112
00:06:42,716 --> 00:06:44,377
और तोड़ने से सिमट्री,

113
00:06:44,377 --> 00:06:47,403
जो है यह प्रक्रिया, उम्मीद है ग्रेडीयंट डिसेंट या

114
00:06:47,403 --> 00:06:51,452
एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म ढूँढ पाएगा एक अच्छी वैल्यू थीटा के लिए.