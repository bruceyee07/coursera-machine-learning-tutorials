1
00:00:00,500 --> 00:00:01,550
בסרטון זה ובווידאו הבא,

2
00:00:02,040 --> 00:00:03,470
ברצוני לספר לכם על

3
00:00:03,760 --> 00:00:05,880
הרחבה אפשרית אחת

4
00:00:06,140 --> 00:00:08,270
לאלגוריתם זיהוי החריגים שפיתחנו עד כה.

5
00:00:09,020 --> 00:00:11,970
ההרחבה הזו משתמשת במשהו שנקרא ההתפלגות הגאוסיאנית

6
00:00:12,100 --> 00:00:13,480
הרב-משתנית, ויש לה

7
00:00:13,770 --> 00:00:14,970
כמה יתרונות

8
00:00:15,160 --> 00:00:16,790
וכמה חסרונות, והיא יכולה

9
00:00:17,070 --> 00:00:20,610
לפעמים לתפוס כמה חריגים שהאלגוריתם הקודם לא תופס.

10
00:00:21,740 --> 00:00:23,730
כדי להתניע את זה, נתחיל בדוגמה.

11
00:00:25,620 --> 00:00:28,410
נניח שככה נראים הנתונים הלא מתויגים, כמו מה שציירתי כאן.

12
00:00:29,060 --> 00:00:30,190
ואני אשתמש

13
00:00:30,340 --> 00:00:32,320
בדוגמה של ניטור מכונות

14
00:00:32,890 --> 00:00:34,890
במרכז נתונים, ניטור של מחשבים במרכז הנתונים.

15
00:00:35,290 --> 00:00:36,170
שתי התכונות שלי

16
00:00:36,220 --> 00:00:37,070
הן x1

17
00:00:37,250 --> 00:00:39,280
שהוא העומס על ה-CPU ו-x2 שהוא כמות הזיכרון בשימוש.

18
00:00:41,160 --> 00:00:42,160
אז אם אני לוקח

19
00:00:42,340 --> 00:00:43,330
את שתי התכונות שלי, x1 ו-x2,

20
00:00:43,580 --> 00:00:45,960
ואני ממדל אותן כגאוסיאנים אז

21
00:00:46,200 --> 00:00:47,430
הנה גרף של

22
00:00:47,610 --> 00:00:49,040
תכונה x1 והנה

23
00:00:49,210 --> 00:00:50,370
הגרף של תכונה x2,

24
00:00:50,980 --> 00:00:51,880
ואם אני מתאים

25
00:00:51,910 --> 00:00:52,640
גאוסיאן לזה, אני אקבל

26
00:00:52,760 --> 00:00:56,050
אולי גאוסיאן כזה, אז

27
00:00:56,730 --> 00:00:57,750
הנה p של x1,

28
00:00:57,860 --> 00:01:00,350
שתלוי

29
00:01:00,690 --> 00:01:02,130
בפרמטרים μ1

30
00:01:02,440 --> 00:01:04,740
ו-σ²1,

31
00:01:04,880 --> 00:01:06,120
והנה כמות הזיכרון בשימוש,

32
00:01:06,240 --> 00:01:07,020
ואולי אני אקבל גאוסיאן

33
00:01:07,560 --> 00:01:09,910
שנראה ככה, וזהו p של x2,

34
00:01:10,760 --> 00:01:12,500
שתלוי ב-μ2 ו-σ²2.

35
00:01:12,590 --> 00:01:14,660
אז כך

36
00:01:14,870 --> 00:01:16,340
ממדל אלגוריתם זיהוי החריגים

37
00:01:16,790 --> 00:01:17,850
את x1 ו-x2.

38
00:01:19,900 --> 00:01:21,160
עכשיו נניח

39
00:01:21,260 --> 00:01:22,330
שבסדרת הבדיקה יש לי

40
00:01:22,410 --> 00:01:24,010
דוגמה שנראית כך.

41
00:01:25,540 --> 00:01:26,600
במיקומו של הצלב

42
00:01:27,310 --> 00:01:29,160
הירוק כאן, הערך של

43
00:01:29,360 --> 00:01:31,220
x1 הוא בערך 0.4, והערך של x2 הוא בערך 1.5.

44
00:01:31,300 --> 00:01:34,430
אם נסתכל על

45
00:01:34,660 --> 00:01:35,780
הנתונים, זה נראה כאילו

46
00:01:35,960 --> 00:01:36,780
רוב הנתונים

47
00:01:37,140 --> 00:01:38,800
נמצאים באזור הזה,

48
00:01:38,940 --> 00:01:40,400
והצלב הירוק

49
00:01:41,110 --> 00:01:43,510
הוא די רחוק מכל הנתונים שראינו.

50
00:01:43,840 --> 00:01:44,870
נראה שיש לסמן אותו

51
00:01:45,210 --> 00:01:46,790
כאנומליה. אז

52
00:01:46,970 --> 00:01:48,660
בנתונים

53
00:01:48,790 --> 00:01:49,930
של הדוגמאות הטובות שלנו,

54
00:01:50,320 --> 00:01:51,430
זה נראה כאילו

55
00:01:51,510 --> 00:01:52,680
העומס על המעבד

56
00:01:52,770 --> 00:01:54,330
והשימוש בזיכרון

57
00:01:54,680 --> 00:01:56,100
גדלים בערך באופן ליניארי זה עם זה.

58
00:01:56,560 --> 00:01:57,720
אז אם יש לנו

59
00:01:57,940 --> 00:01:59,000
מחשב עם עומס CPU גבוה,

60
00:01:59,150 --> 00:02:00,460
אנחנו מצפים שגם השימוש בזיכרון

61
00:02:00,830 --> 00:02:02,930
יהיה גבוה, ואילו

62
00:02:03,320 --> 00:02:05,910
בדוגמה הזו, הדוגמה הירוקה זה נראה

63
00:02:06,040 --> 00:02:07,140
שכאן העומס על ה-CPU

64
00:02:07,280 --> 00:02:08,280
הוא נמוך מאוד, אבל השימוש בזיכרון

65
00:02:08,490 --> 00:02:09,310
הוא גבוה מאוד, ואנחנו פשוט

66
00:02:09,430 --> 00:02:10,820
טרם ראינו כזה מקרה בנתוני האימון שלנו.

67
00:02:10,980 --> 00:02:12,150
נראה כאילו שזה צריך להיות חריג.

68
00:02:13,190 --> 00:02:15,300
אבל בואו נראה מה יעשה אלגוריתם זיהוי החריגים.

69
00:02:15,570 --> 00:02:16,750
אז לגבי העומס על המעבד,

70
00:02:16,850 --> 00:02:17,990
הוא שם אותו בסביבות

71
00:02:18,280 --> 00:02:20,700
0.5 וההסתברות הגבוהה הזו

72
00:02:20,900 --> 00:02:21,910
אינה רחוקה

73
00:02:22,120 --> 00:02:23,350
מדוגמאות אחרות שאולי כבר ראינו,

74
00:02:23,650 --> 00:02:25,230
בעוד שלגבי

75
00:02:26,160 --> 00:02:28,320
השימוש בזיכרון,

76
00:02:29,030 --> 00:02:29,900
...

77
00:02:30,030 --> 00:02:32,340
הוא נמצא בערך ב-1.5, כאן מימין.

78
00:02:32,680 --> 00:02:34,600
אז זה

79
00:02:34,730 --> 00:02:35,850
בתוך הגאוסיאן,

80
00:02:35,980 --> 00:02:37,310
הערך כאן והערך

81
00:02:37,550 --> 00:02:38,830
כאן אינם שונים מהרבה

82
00:02:39,210 --> 00:02:41,180
דוגמאות אחרות שראינו,

83
00:02:41,430 --> 00:02:43,020
אז p של

84
00:02:43,210 --> 00:02:44,530
x1 יהיה גבוה למדי,

85
00:02:45,550 --> 00:02:46,030
גבוה בצורה סבירה.

86
00:02:46,290 --> 00:02:47,730
וגם p של x2 גבוה באופן סביר.

87
00:02:47,980 --> 00:02:49,030
זאת אומרת, אם תסתכלו על

88
00:02:49,910 --> 00:02:51,230
התרשים הזה, הנקודה הזאת כאן

89
00:02:51,410 --> 00:02:52,530
לא נראית כל כך רע,

90
00:02:52,830 --> 00:02:54,440
ואם תסתכלו על התרשים הזה,

91
00:02:54,720 --> 00:02:56,690
אז גם זה לא נראה כל כך רע.

92
00:02:57,050 --> 00:02:58,780
הרי היו לנו דוגמאות

93
00:02:58,980 --> 00:03:00,730
עם צריכת זיכרון אפילו יותר גבוהה,

94
00:03:01,030 --> 00:03:02,270
והיו דוגמאות אפילו עם פחות צריכת מעבד,

95
00:03:02,860 --> 00:03:04,780
ולכן זאת לא נראית דוגמה חריגה.

96
00:03:05,940 --> 00:03:07,380
ולכן אלגוריתם זיהוי חריגים

97
00:03:07,680 --> 00:03:10,090
לא יצליח לסמן את הנקודה הזו כאנומליה.

98
00:03:10,550 --> 00:03:12,220
ומתברר

99
00:03:12,360 --> 00:03:13,610
שהאלגוריתם שלנו

100
00:03:13,880 --> 00:03:15,070
לאיתור חריגים

101
00:03:15,200 --> 00:03:16,700
לא קולט שהאליפסה

102
00:03:16,900 --> 00:03:18,060
הכחולה הזאת מראה את האזור

103
00:03:18,210 --> 00:03:19,380
בעל ההסתברות הגבוהה,

104
00:03:19,490 --> 00:03:21,290
הדברים האלה, הדוגמאות כאן,

105
00:03:21,720 --> 00:03:23,430
יש להן הסתברות גבוהה

106
00:03:23,680 --> 00:03:24,980
והדוגמאות במעגל השני

107
00:03:26,170 --> 00:03:27,280
בהסתברות נמוכה יותר,

108
00:03:27,370 --> 00:03:28,950
והדוגמאות כאן הם אפילו

109
00:03:29,220 --> 00:03:31,040
עם הסתברות עוד יותר נמוכה, ואיכשהו,

110
00:03:31,150 --> 00:03:32,070
לדברים כאן, הצלב הירוק

111
00:03:32,420 --> 00:03:33,430
כאן, יש סבירות גבוהה למדי.

112
00:03:34,490 --> 00:03:35,510
ובפרט, הוא חושב

113
00:03:35,990 --> 00:03:37,740
שלכל דבר באזור

114
00:03:38,000 --> 00:03:40,400
הזה, לכל מה

115
00:03:40,580 --> 00:03:43,390
שבתוך העיגול הזה, יש הסתברות שווה,

116
00:03:44,160 --> 00:03:45,810
והוא לא מבין שלמשהו

117
00:03:46,790 --> 00:03:50,910
שנמצא כאן יש למעשה

118
00:03:51,080 --> 00:03:53,130
הסתברות נמוכה בהרבה מאשר משהו שנמצא שם.

119
00:03:55,060 --> 00:03:56,080
אז כדי לתקן

120
00:03:56,270 --> 00:03:57,300
את זה, אנחנו

121
00:03:57,580 --> 00:03:58,930
נפתח גרסה שונה של

122
00:03:58,990 --> 00:04:01,030
אלגוריתם לזיהוי חריגים, באמצעות

123
00:04:01,430 --> 00:04:02,520
משהו שנקרא התפלגות גאוסיאנית

124
00:04:02,580 --> 00:04:05,880
מרובת-משתנים או התפלגות נורמלית מרובת-משתנים.

125
00:04:07,330 --> 00:04:08,120
הנה מה שנעשה.

126
00:04:08,810 --> 00:04:10,270
יש לנו תכונות x

127
00:04:10,470 --> 00:04:11,680
ב-Rn ובמקום

128
00:04:11,910 --> 00:04:14,180
לחשב בנפרד את p של x1, ואת p של x2,

129
00:04:14,570 --> 00:04:15,630
אנחנו נמדל את p של x

130
00:04:15,800 --> 00:04:16,840
בבת אחת,

131
00:04:17,010 --> 00:04:18,970
ניצור מודל של p של x, הכל בבת אחת.

132
00:04:20,300 --> 00:04:21,550
אז הפרמטרים של

133
00:04:21,830 --> 00:04:24,140
ההתפלגות הגאוסיאנית הרב-משתנית הם μ

134
00:04:24,630 --> 00:04:25,770
שהוא וקטור ו-Σ (סיגמא, האות הגדולה)

135
00:04:26,490 --> 00:04:28,450
שהיא מטריצה n על n, הנקראת מטריצת שונות משותפת,

136
00:04:29,640 --> 00:04:30,870
והיא דומה

137
00:04:31,010 --> 00:04:32,220
למטריצת השונות המשותפת

138
00:04:32,430 --> 00:04:33,560
שראינו כשעבדנו

139
00:04:34,080 --> 00:04:35,200
עם אלגוריתם PCA -

140
00:04:35,280 --> 00:04:36,700
ניתוח מרכיבים עיקריים.

141
00:04:37,860 --> 00:04:38,970
למען השלמות, תנו

142
00:04:39,070 --> 00:04:39,880
לי רק לכתוב את הנוסחה

143
00:04:40,930 --> 00:04:42,390
עבור התפלגות גאוסיאנית מרובת משתנים.

144
00:04:42,820 --> 00:04:44,030
אז אנחנו אומרים שההסתברות

145
00:04:44,140 --> 00:04:45,100
של x, שהפרמטרים שלו

146
00:04:46,090 --> 00:04:47,500
הם μ

147
00:04:47,640 --> 00:04:49,280
ו-Σ,

148
00:04:49,360 --> 00:04:50,100
שההסתברות של x שווה,

149
00:04:50,430 --> 00:04:52,260
ואני מדגיש,

150
00:04:52,580 --> 00:04:54,810
אין שום צורך לזכור את הנוסחה הזו.

151
00:04:56,030 --> 00:04:56,780
אפשר למצוא אותה באינטרנט

152
00:04:57,010 --> 00:04:58,160
כל פעם שצריך להשתמש בה,

153
00:04:58,340 --> 00:04:59,130
אבל כך

154
00:04:59,690 --> 00:05:01,230
נראית ההסתברות של x.

155
00:05:03,000 --> 00:05:04,680
e בחזקת מינוס חצי x מינוס μᵀ

156
00:05:05,220 --> 00:05:06,300
כפול ההופכית של מטריצת השונות כפול x מינוס μ.

157
00:05:07,400 --> 00:05:08,850
והדבר הזה כאן,

158
00:05:10,390 --> 00:05:11,510
הערך המוחלט של Σ,

159
00:05:11,680 --> 00:05:13,140
הדבר הזה כאן כשכותבים

160
00:05:13,410 --> 00:05:14,430
את הסמל הזה על מטריצות, זה נקרא

161
00:05:14,600 --> 00:05:17,220
הדטרמיננטה של המטריצה Σ

162
00:05:18,150 --> 00:05:19,620
וזו פונקציה מתמטית

163
00:05:20,210 --> 00:05:21,740
על מטריצות שבאמת

164
00:05:21,960 --> 00:05:22,820
אין שום צורך לדעת

165
00:05:23,240 --> 00:05:24,250
מה זה הדטרמיננטה של מטריצה,

166
00:05:24,780 --> 00:05:25,770
ובעצם כל מה שצריך

167
00:05:25,860 --> 00:05:27,180
לדעת הוא שאפשר

168
00:05:27,320 --> 00:05:29,380
לחשב את זה באוקטבה באמצעות

169
00:05:29,760 --> 00:05:31,820
הפקודה (det(sigma.

170
00:05:33,570 --> 00:05:33,570
...

171
00:05:34,010 --> 00:05:36,210
אוקיי, ושוב רק לשם הבהירות,

172
00:05:36,300 --> 00:05:38,240
בביטוי הזה, הסיגמות (Σ) האלה

173
00:05:38,730 --> 00:05:41,250
כאן, הן פשוט מטריצות n על n.

174
00:05:41,850 --> 00:05:43,150
זה לא הסימן של סיכום,

175
00:05:43,260 --> 00:05:45,680
הן פשוט מטריצות n על n.

176
00:05:46,710 --> 00:05:47,780
אז זו הנוסחה של p

177
00:05:48,010 --> 00:05:50,500
של x, אבל מה

178
00:05:50,820 --> 00:05:52,030
שיותר מעניין או יותר חשוב,

179
00:05:53,940 --> 00:05:55,610
איך נראית בעצם p של x?

180
00:05:56,190 --> 00:05:57,450
בואו נסתכל על כמה דוגמאות

181
00:05:58,020 --> 00:06:00,690
של התפלגויות גאוסיאניות מרובות משתנים.

182
00:06:02,350 --> 00:06:03,380
בואו ניקח

183
00:06:03,500 --> 00:06:04,700
דוגמא דו-מימדית, נניח

184
00:06:04,820 --> 00:06:06,550
אם n שווה 2,

185
00:06:06,710 --> 00:06:08,160
יש לנו שתי תכונות, x1 ו-x2.

186
00:06:09,250 --> 00:06:10,540
נניח שאני מגדיר את μ

187
00:06:10,650 --> 00:06:11,800
להיות שווה ל-0 ואת Σ

188
00:06:12,330 --> 00:06:14,030
להיות המטריצה הזו כאן.

189
00:06:14,200 --> 00:06:16,710
עם 1-ים על האלכסונים ואפסים בשאר המקומות,

190
00:06:17,600 --> 00:06:19,980
המטריצה הזו מכונה לעתים גם מטריצת הזהות.

191
00:06:21,350 --> 00:06:22,470
במקרה הזה, p

192
00:06:22,590 --> 00:06:24,950
של x ייראה

193
00:06:25,240 --> 00:06:27,430
כך, ומה

194
00:06:27,600 --> 00:06:29,380
שאני מראה בתרשים הזה הוא

195
00:06:29,500 --> 00:06:30,900
עבור ערכים ספציפיים

196
00:06:31,240 --> 00:06:32,860
של x1

197
00:06:32,970 --> 00:06:34,680
ו-x2, גובה

198
00:06:34,810 --> 00:06:36,470
המשטח הוא הערך

199
00:06:36,970 --> 00:06:38,330
של p של x.

200
00:06:38,470 --> 00:06:39,520
אז במצב הזה הערך של

201
00:06:40,610 --> 00:06:42,100
p של x הוא גבוה ביותר כאשר

202
00:06:42,300 --> 00:06:43,620
x1 ו-x2 שניהם שווים אפס,

203
00:06:44,010 --> 00:06:45,710
זה השיא של ההסתברות בהתפלגות הזו,

204
00:06:46,950 --> 00:06:48,760
וההסתברות יורדת עם

205
00:06:48,970 --> 00:06:51,330
הפעמון

206
00:06:51,510 --> 00:06:53,590
או הגאוסיאן הדו מימדי הזה.

207
00:06:55,080 --> 00:06:56,400
הגרף התחתון מראה

208
00:06:56,610 --> 00:06:58,230
אותה תמונה אבל עם גרף

209
00:06:58,330 --> 00:07:00,970
קווי מתאר, או באמצעות צבעים שונים,

210
00:07:01,150 --> 00:07:02,020
אז האדום

211
00:07:02,530 --> 00:07:04,210
החזק והכבד

212
00:07:04,280 --> 00:07:06,260
באמצע מתאים לערכים הגבוהים ביותר,

213
00:07:06,850 --> 00:07:08,230
וערכים נמוכים יותר

214
00:07:08,790 --> 00:07:10,470
בצהוב,

215
00:07:10,700 --> 00:07:11,830
עוד יותר נמוכים בתכול,

216
00:07:12,060 --> 00:07:13,230
והערכים הנמוכים ביותר

217
00:07:14,000 --> 00:07:15,440
בכחול עמוק,

218
00:07:15,450 --> 00:07:17,010
ולכן זה באמת אותו גרף

219
00:07:17,240 --> 00:07:19,410
אבל במבט על בעזרת צבעים במקום זה.

220
00:07:21,390 --> 00:07:22,510
אז עם ההתפלגות הזו,

221
00:07:23,830 --> 00:07:25,010
אפשר לראות שרוב

222
00:07:25,300 --> 00:07:27,440
ההסתברות נמצאת באזור 0,0

223
00:07:27,600 --> 00:07:28,630
וכשיוצאים החוצה

224
00:07:28,710 --> 00:07:32,450
מ-0,0 ההסתברות של x1 ו-x2 יורדת.

225
00:07:36,000 --> 00:07:37,220
עכשיו בואו וננסה לשנות

226
00:07:37,310 --> 00:07:38,630
כמה פרמטרים ולראות

227
00:07:38,770 --> 00:07:40,150
מה קורה. אז בואו

228
00:07:40,940 --> 00:07:42,420
ניקח את Σ ונשנה אותה,

229
00:07:42,590 --> 00:07:44,720
נניח נקטין אותה

230
00:07:44,870 --> 00:07:46,350
קצת. Σ היא

231
00:07:46,580 --> 00:07:47,710
מטריצת שונות ולכן היא

232
00:07:47,820 --> 00:07:49,030
מודדת את השונות

233
00:07:49,120 --> 00:07:50,640
של התכונות x1 ו-x2.

234
00:07:50,720 --> 00:07:52,080
אז אם נכווץ

235
00:07:52,400 --> 00:07:53,430
את Σ מה שיקרה הוא

236
00:07:53,780 --> 00:07:54,290
שהרוחב

237
00:07:54,400 --> 00:07:56,320
של הבליטה הזאת פוחת

238
00:07:57,760 --> 00:07:59,310
והגובה

239
00:07:59,550 --> 00:08:00,620
יגדל קצת, כי

240
00:08:01,090 --> 00:08:03,080
הנפח מתחת לעקומה שווה 1.

241
00:08:03,130 --> 00:08:04,400
האינטגרל של

242
00:08:04,950 --> 00:08:06,230
הנפח מתחת למשטח

243
00:08:06,580 --> 00:08:08,000
שווה 1, כי סכום

244
00:08:08,690 --> 00:08:10,080
ההסתברויות חייב להסתכם ב-1.

245
00:08:10,800 --> 00:08:11,650
אבל כשמכווצים את השונות,

246
00:08:12,660 --> 00:08:14,290
זה קצת כמו לכווץ

247
00:08:14,810 --> 00:08:15,870
את σ²,

248
00:08:16,740 --> 00:08:20,080
ומקבלים התפלגות קצת יותר צרה וגבוהה.

249
00:08:20,860 --> 00:08:22,150
וכפי שאפשר לראות כאן גם

250
00:08:22,580 --> 00:08:27,200
האליפסות הקונצנטריות התכווצו במקצת.

251
00:08:27,340 --> 00:08:28,730
ולעומת זאת לו הגדלנו את Σ

252
00:08:29,770 --> 00:08:31,000
ל-2 על

253
00:08:31,110 --> 00:08:32,020
האלכסונים, דהיינו

254
00:08:32,220 --> 00:08:34,370
מטריצת הזהות כפול שתיים, היינו מקבלים

255
00:08:34,510 --> 00:08:35,880
גאוסיאן הרבה יותר רחב ושטוח.

256
00:08:36,150 --> 00:08:38,190
ואתם רואים שזה אכן הרבה יותר רחב.

257
00:08:38,930 --> 00:08:39,800
קשה לראות אבל זה

258
00:08:40,020 --> 00:08:41,090
עדיין בצורת פעמון,

259
00:08:41,210 --> 00:08:42,540
פשוט זה נהיה הרבה יותר שטוח

260
00:08:42,620 --> 00:08:44,470
והרבה יותר רחב

261
00:08:44,590 --> 00:08:45,720
ולכן השונות

262
00:08:45,830 --> 00:08:48,690
של x1 ו-x2 פשוט נהיית רחבה יותר.

263
00:08:50,520 --> 00:08:50,980
הנה כמה דוגמאות נוספות.

264
00:08:51,670 --> 00:08:53,930
בואו עכשיו ננסה לשנות

265
00:08:54,070 --> 00:08:55,490
את האלמנטים של Σ אחד אחד.

266
00:08:55,840 --> 00:08:58,080
נניח ש-Σ הוא עכשיו

267
00:08:58,140 --> 00:09:00,020
0.6 כאן, ו-1 שם.

268
00:09:01,340 --> 00:09:02,380
מה שזה עושה

269
00:09:02,610 --> 00:09:04,240
הוא להפחית את השונות

270
00:09:05,780 --> 00:09:06,960
של התכונה הראשונה, x1, תוך

271
00:09:07,770 --> 00:09:08,890
שמירה על השונות של

272
00:09:08,960 --> 00:09:11,530
התכונה השנייה x2.

273
00:09:12,160 --> 00:09:15,150
אז עם הגדרה כזו של פרמטרים, אפשר למדל דברים כאלה.

274
00:09:15,670 --> 00:09:16,910
ל-x1 יש שונות קטנה יותר,

275
00:09:17,580 --> 00:09:19,120
ול-x2 יש שונות גדולה יותר.

276
00:09:20,080 --> 00:09:20,800
ואם אני עושה ההפך,

277
00:09:21,120 --> 00:09:22,900
אני קובע את המטריצה

278
00:09:23,090 --> 00:09:24,390
להיות 1 ,2

279
00:09:24,560 --> 00:09:25,900
אז אפשר גם למדל

280
00:09:26,230 --> 00:09:27,470
דוגמאות שבהם

281
00:09:28,850 --> 00:09:30,590
x1 מקבל

282
00:09:30,830 --> 00:09:31,930
מגוון רחב של ערכים

283
00:09:32,220 --> 00:09:34,870
ואילו x2 מקבל טווח יחסית צר של ערכים.

284
00:09:35,070 --> 00:09:37,060
וזה בא לידי ביטוי

285
00:09:37,270 --> 00:09:38,040
גם בגרף הזה, שבו

286
00:09:38,750 --> 00:09:40,530
ההתפלגות יורדת

287
00:09:40,830 --> 00:09:42,670
לאט יותר כש-x1

288
00:09:42,820 --> 00:09:43,940
מתרחק מ-0,

289
00:09:44,180 --> 00:09:45,380
ונופל במהירות רבה

290
00:09:45,640 --> 00:09:48,080
כש-x2 מתרחק מ-0.

291
00:09:49,190 --> 00:09:50,710
ואם

292
00:09:50,800 --> 00:09:52,320
נשנה את

293
00:09:53,010 --> 00:09:54,490
האלמנט הזה של

294
00:09:54,660 --> 00:09:55,570
המטריצה במקום זה, אז בדומה

295
00:09:57,390 --> 00:09:58,860
לשקופית הקודמת, אלא שכאן

296
00:09:59,450 --> 00:10:00,900
כשאנחנו משחקים בערכים

297
00:10:01,240 --> 00:10:03,010
נראה ש-x2 יכול לקבל

298
00:10:03,170 --> 00:10:04,460
מגוון קטן מאוד של ערכים

299
00:10:05,190 --> 00:10:06,840
כאן כשהערך הוא 0.6,

300
00:10:07,200 --> 00:10:08,740
אנו רואים עכשיו ש-x2

301
00:10:09,810 --> 00:10:10,610
נוטה לקבל מגוון

302
00:10:10,760 --> 00:10:12,930
קטן בהרבה של ערכים מאשר בדוגמה המקורית,

303
00:10:14,010 --> 00:10:15,310
ואילו אם

304
00:10:15,680 --> 00:10:17,320
נגדיר Σ להיות שווה ל-2

305
00:10:17,410 --> 00:10:20,580
אז זה כמו לומר ש-x2 יכול לקבל מגוון רחב בהרבה של ערכים.

306
00:10:22,780 --> 00:10:23,570
עכשיו, אחד הדברים

307
00:10:23,880 --> 00:10:24,950
המגניבים בקשר להתפלגות

308
00:10:25,190 --> 00:10:26,690
מרובת-משתנים הוא

309
00:10:26,880 --> 00:10:28,050
שאפשר להשתמש בה

310
00:10:28,330 --> 00:10:30,230
גם כדי למדל קשר בין הנתונים.

311
00:10:30,410 --> 00:10:31,930
אנחנו יכולים להשתמש בה

312
00:10:32,060 --> 00:10:33,510
כדי להדגים את העובדה

313
00:10:33,610 --> 00:10:34,940
ש-x1 ו-x2 נוטים להיות

314
00:10:35,070 --> 00:10:36,760
מתואמים מאוד זה עם זה למשל.

315
00:10:37,640 --> 00:10:38,880
בפרט אם אנחנו מתחילים

316
00:10:39,540 --> 00:10:40,720
לשנות את ערכי המטריצה

317
00:10:41,340 --> 00:10:42,390
שמחוץ לאלכסונים

318
00:10:42,950 --> 00:10:45,250
נקבל סוג אחר של התפלגות גאוסיאנית.

319
00:10:46,610 --> 00:10:48,250
אז כשאני

320
00:10:48,340 --> 00:10:49,590
מגדיל את הערכים מחוץ לאלכסון

321
00:10:50,090 --> 00:10:51,300
מ-0.5 ל-0.8,

322
00:10:51,580 --> 00:10:53,080
אנחנו מקבלים התפלגות

323
00:10:53,380 --> 00:10:54,590
שהיא יותר ויותר מחודדת

324
00:10:55,100 --> 00:10:57,480
ובעלת פסגה לאורך הקו הזה של x שווה y.

325
00:10:57,700 --> 00:10:59,100
רואים

326
00:10:59,160 --> 00:11:00,610
במפת המתאר - קווי הגובה - ש-x

327
00:11:00,730 --> 00:11:03,010
ו-y נוטים לגדול יחד

328
00:11:03,290 --> 00:11:04,500
והדברים שיש להם

329
00:11:04,640 --> 00:11:06,550
הסתברות גדולה הם

330
00:11:06,790 --> 00:11:08,140
אם גם x1 הוא גדול

331
00:11:08,260 --> 00:11:09,560
וגם x2 הוא גדול או גם x1

332
00:11:09,890 --> 00:11:11,160
הוא קטן וגם x2 הוא קטן.

333
00:11:11,490 --> 00:11:12,480
או איפשהו בין לבין.

334
00:11:13,110 --> 00:11:14,700
וכשהערך הזה,

335
00:11:15,130 --> 00:11:16,280
0.8, גדל, מקבלים

336
00:11:16,490 --> 00:11:18,410
התפלגות גאוסיאנית שבה

337
00:11:18,660 --> 00:11:20,570
כל ההסתברות נמצאת על

338
00:11:20,770 --> 00:11:22,870
האזור הצר,

339
00:11:24,350 --> 00:11:26,200
שבו x1 שווה בערך

340
00:11:26,420 --> 00:11:27,530
ל-x2. זו

341
00:11:28,020 --> 00:11:30,290
התפלגות מאוד גבוהה ורזה

342
00:11:30,670 --> 00:11:32,570
בעיקר לאורך הקו הזה

343
00:11:33,860 --> 00:11:34,940
באזור המרכזי שבו x1

344
00:11:35,010 --> 00:11:36,860
קרוב ל-x2. זה

345
00:11:37,130 --> 00:11:38,350
מה שקורה אם אנחנו

346
00:11:38,810 --> 00:11:40,360
מגדירים את הערכים האלה להיות ערכים חיוביים.

347
00:11:40,970 --> 00:11:42,120
לעומת זאת, אם נגדיר

348
00:11:42,460 --> 00:11:43,530
אותם להיות ערכים שליליים,

349
00:11:44,350 --> 00:11:46,340
כשאני מקטין את הערך כאן מ-0.5-

350
00:11:46,380 --> 00:11:47,920
ל-0.8-,

351
00:11:48,060 --> 00:11:49,360
מה שאנחנו מקבלים הוא מודל

352
00:11:49,870 --> 00:11:50,930
שבו רוב ההסתברות

353
00:11:51,620 --> 00:11:53,930
על מין אזור של מתאם שלילי

354
00:11:54,010 --> 00:11:55,420
בין x1 לבין x2.

355
00:11:55,710 --> 00:11:57,330
אז רוב ההסתברות

356
00:11:57,480 --> 00:11:58,420
נמצאת כעת באזור הזה,

357
00:11:58,810 --> 00:11:59,910
כאשר x1 שווה בערך

358
00:12:00,190 --> 00:12:01,700
למינוס x2, ולא באזור של

359
00:12:01,890 --> 00:12:03,370
x1 שווה ל-x2.

360
00:12:04,180 --> 00:12:05,460
אז זה לוכד מעין

361
00:12:05,610 --> 00:12:08,050
מתאם שלילי בין x1

362
00:12:10,300 --> 00:12:10,650
ו-x2.

363
00:12:11,010 --> 00:12:12,550
אז אני

364
00:12:12,750 --> 00:12:13,640
מקווה שזה נותן לכם תחושה

365
00:12:13,750 --> 00:12:15,230
של ההתפלגויות השונות

366
00:12:15,650 --> 00:12:17,400
שהתפלגות גאוסיאנית מרובת-משתנים יכולה ללכוד.

367
00:12:18,680 --> 00:12:20,430
עד עכשיו שינינו

368
00:12:20,730 --> 00:12:22,200
את מטריצת השונות Σ,

369
00:12:22,910 --> 00:12:23,880
הדבר האחר שאפשר לעשות הוא

370
00:12:24,030 --> 00:12:26,090
לשנות את פרמטר

371
00:12:26,300 --> 00:12:27,730
הממוצע μ, אז

372
00:12:28,370 --> 00:12:29,740
במקור, היה לנו μ

373
00:12:30,270 --> 00:12:31,190
שווה 0, 0, ולכן

374
00:12:31,250 --> 00:12:32,820
ההתפלגות היתה מרוכזת סביב

375
00:12:33,270 --> 00:12:34,650
x1 שווה 0, x2 שווה ל-0,

376
00:12:35,050 --> 00:12:35,980
והשיא של

377
00:12:36,070 --> 00:12:38,530
ההתפלגות נמצא כאן בראשית הצירים, ואילו

378
00:12:38,950 --> 00:12:40,430
אם נשנה את הערכים

379
00:12:40,610 --> 00:12:42,120
של μ, זה ישנה

380
00:12:42,360 --> 00:12:43,700
את שיא ההתפלגות ולכן,

381
00:12:43,910 --> 00:12:45,770
אם μ שווה 0.5, 0

382
00:12:45,920 --> 00:12:47,100
השיא יהיה

383
00:12:47,270 --> 00:12:49,470
ב-x1 שווה אפס ו-x2

384
00:12:49,810 --> 00:12:51,430
שווה ל -0.5,

385
00:12:51,980 --> 00:12:53,400
השיא או מרכז

386
00:12:53,710 --> 00:12:55,260
ההתפלגות השתנה,

387
00:12:56,470 --> 00:12:57,770
ואם μ היה 1.5,

388
00:12:58,340 --> 00:13:00,050
מינוס 0.5 אז

389
00:13:01,170 --> 00:13:03,350
בדומה לכך השיא

390
00:13:03,890 --> 00:13:05,490
או הפסגה עובר

391
00:13:05,620 --> 00:13:06,750
עכשיו למקום אחר,

392
00:13:07,670 --> 00:13:09,710
המקביל למקום

393
00:13:09,910 --> 00:13:11,020
שבו x1 הוא 1.5 ו-x2

394
00:13:11,350 --> 00:13:12,710
הוא 0.5-, אז

395
00:13:13,290 --> 00:13:15,180
פרמטר הממוצע μ פשוט מזיז

396
00:13:15,730 --> 00:13:17,840
את מרכז ההתפלגות.

397
00:13:18,450 --> 00:13:19,670
אז אני מקווה שכשאתם רואים

398
00:13:19,780 --> 00:13:21,270
את כל התמונות השונות האלה אתם מקבלים

399
00:13:21,410 --> 00:13:22,440
תחושה של סוגי

400
00:13:22,700 --> 00:13:24,850
התפלגויות ההסתברות

401
00:13:25,070 --> 00:13:28,000
שהתפלגות גאוס מרובת-משתנים מאפשרת לנו ללכוד.

402
00:13:28,800 --> 00:13:29,800
והיתרון העיקרי של זה

403
00:13:29,990 --> 00:13:30,930
הוא שהיא מאפשרת לנו

404
00:13:31,130 --> 00:13:32,240
ללכוד את המצב כאשר אנחנו חושדים

405
00:13:32,750 --> 00:13:33,840
ששתי תכונות שונות

406
00:13:33,970 --> 00:13:36,560
מתואמות חיובית או אולי שלילית.

407
00:13:37,790 --> 00:13:39,030
בסרטון הבא ניקח

408
00:13:39,260 --> 00:13:40,760
את ההתפלגות הגאוסיאנית מרובת-המשתנים הזו

409
00:13:41,670 --> 00:13:43,290
ונפעיל אותה בזיהוי חריגים.