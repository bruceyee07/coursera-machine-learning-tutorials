בסרטון האחרון דיברנו על ההתפלגות הגאוסיאנית הרב-משתנית וראינו כמה דוגמאות לסוגי ההתפלגויות שאפשר למדל כאשר משנים את הפרמטרים μ ו-Σ. בסרטון הזה, ניקח את הרעיונות האלה, ונממש אותם על מנת לפתח אלגוריתם אחר לאיתור חריגים. סיכום קצר של התפלגות גאוסיאנית או נורמלית מרובת-משתנים, יש לה שני פרמטרים, μ ו-Σ. כש-μ הוא וקטור n-ממדי ו-Σ היא מטריצת שונות שהיא n על n. והנה הנוסחה של ההסתברות של x, לפי הפרמטרים ידי μ ו-Σ, וכאשר משנים את μ ו-Σ, אפשר לקבל מגוון של התפלגויות שונות, כמו שלוש הדוגמאות האלה שראינו בסרטון הקודם. אז בואו נדבר על התאמת הפרמטרים או על בעיית הערכת הפרמטרים. השאלה, כרגיל, היא זו, יש לנו קבוצה של דוגמאות x1 עד xm וכאן כל אחת מהדוגמאות האלה היא וקטור n-ממדי ואנחנו מאמינים שהדוגמאות מתפלגות גאוסיאנית רב-משתנית. כיצד ננסה להעריך את הפרמטרים μ ו-Σ? ובכן, נוסחאות סטנדרטיות להערכה שלהם הם להגדיר את μ להיות פשוט הממוצע של דוגמאות האימון. ומגדירים את Σ להיות שווה לזה. וזה בדיוק כמו ה-σ שהגדרנו בעבר כאשר עסקנו ב-PCA או אלגוריתם ניתוח מרכיבים ראשיים. אז פשוט מחברים את שתי הנוסחאות וזה נותן לנו גם את הפרמטר μ משוער וגם את הפרמטר Σ משוערת. אז בהינתן ערכת נתונים, כך מעריכים את μ ו-Σ. בואו ניקח את השיטה הזאת ופשוט נציב אותה באלגוריתם זיהוי חריגים. איך מחברים את כל זה ביחד כדי לפתח אלגוריתם לזיהוי חריגים? הנה מה שעושים. בהתחלה אנחנו לוקחים את מערך ההדרכה שלנו, ואנחנו מתאימים את המודל, אנחנו מתאימים את p של x על ידי הגדרת μ ו-Σ כפי שתואר בשקופית הקודמת. אחר כך, כאשר מקבלים דוגמה חדשה x. אז אם מקבלים דוגמת מבחן, בואו לא ניקח דוגמה מהישנות אלא ניקח דוגמה חדשה כאן. זוהי דוגמת המבחן שלי. בהינתן הדוגמה החדשה x, אנחנו נחשב את (p(x באמצעות הנוסחה הזו עבור התפלגות גאוסית מרובת-משתנים. ואז, אם (p(x הוא קטן מאוד, אז נסמן אותה כחריגה, ואם p של x גדול מהפרמטר ε, אז לא נסמן אותה כחריגה. אז מתברר שלו התאמנו התפלגות גאוסית רב-משתנית למערך הנתונים הזה, רק לצלבים האדומים, ולא לדוגמאות הירוקות, היינו מקבלים התפלגות גאוסית שממקמת את רוב ההסתברות באזור המרכזי כאן, קצת פחות הסתברות כאן, ועוד קצת פחות הסתברות כאן, ועוד קצת פחות הסתברות כאן, והסתברות נמוכה מאוד בנקודה הרחוקה כאן. אז אם תיישמו התפלגות גאוסית רב-משתנית על הדוגמה הזו, היא אכן תסמן נכונה את הדוגמה כחריגה. לבסוף, כדאי לומר כמה מילים על הקשר בין מודל ההתפלגות הגאוסי הרב-משתני, לבין המודל המקורי, שבו מידלנו את (p(x כמכפלה של (p(x1 כפול (p(x2 וכו' עד (p(xn. מתברר שאפשר להוכיח מתמטית, אני לא מתכוון להוכיח את זה כאן, אבל אפשר להוכיח מתמטית שהקשר הזה, בין המודל הגאוסי מרובה-המשתנים ובין זה המקורי, בפרט מתברר שהמודל המקורי תואם לגאוסיאנים רב-משתנים שבהם קווי המתאר של הגאוסיאן הם תמיד מיושרים לצירים. אז כל שלוש הדוגמאות האלה הן דוגמאות של התפלגויות גאוס שאפשר להתאים באמצעות המודל המקורי. מסתבר שזה תואם לגאוסיאן רב-משתנים, שבו האליפסות כאן, קווי המתאר של ההתפלגות הזו, מתברר שהמודל הזה למעשה מתאים למקרה ספציפי של התפלגות גאוסית רב משתנית. ובפרט, המקרה המיוחד הזה מוגדר על ידי הגבלה של ההתפלגות (p(x, התפלגות גאוסית רב-משתנית של (p(x, כך שקווי המתאר של פונקצית צפיפות ההסתברות מיושרים לצירים. ולכן אפשר לקבל (p(x עם גאוסיאן רב משתני שנראה ככה, או ככה, או ככה. ושימו לב שבכל 3 הדוגמאות האלה, האליפסות האלה שאני מצייר, הצירים שלהם מיושרים עם צירי x1 ו-x2. ומה שאנחנו לא רואים הם קווי מתאר בזווית, נכון? וזה מתאים לדוגמאות שבהן Σ שווה ל-1,1 ו-0.8, 0.8 עם אברים שאינם 0 מחוץ לאלכסון. אז כאמור מתברר שאפשר להראות מתמטית שהמודל הזה הוא זהה להתפלגות גאוסית רב-משתנית, אבל עם האילוץ הזה. והאילוץ הוא שמטריצת השונות המשותפת חייבת להיות עם 0 בכל האלמנטים שאינם על האלכסון. בפרט, Σ מטריצת השונות המשותפת, הדבר הזה כאן, הערכים כאן יהיו σ²1, σ²2, וכו' עד σ²n, וכל הערכים שאינם באלכסון, כל האלמנטים האלה מעל ומתחת לאלכסון של המטריצה, כל אלה הם 0. ולמעשה אם תקחו את הערכים האלה של Σ, σ²1, σ²2, וכו' עד σ²n, ותציבו אותם כאן, בתוך המטריצה הזו, אז שני המודלים זהים. כלומר, המודל החדש זה, המשתמש בהתפלגות גאוסית רב-משתנית, מתאים בדיוק למודל הישן, אם במטריצת Σ, יש רק 0-ים מחוץ לאלכסון, ואכן בתמונות שמראות התפלגויות נורמליות כאלה, רואים שקווי המתאר של פונקצית ההתפלגות הזו מיושרים לצירים. אז אי אפשר למדל מתאמים או קורלציות בין התכונות השונות. אז במובן הזה המודל המקורי הוא למעשה מקרה מיוחד של מודל גאוס רב-המשתנים הזה. אז מתי כדאי להשתמש בכל אחד משני המודלים האלה? מתי כדאי להשתמש במודל המקורי ומתי יותר כדאי להשתמש במודל הגאוסי מרובה-המשתנים? המודל המקורי הוא כנראה בשימוש יותר נפוץ, ואילו ההתפלגות הגאוסית מרובת המשתנים נמצאת קצת פחות בשימוש אבל יש לה היתרון של היכולת ללכוד קורלציות בין תכונות. אז נניח שאתה רוצה ללכוד חריגים במקרה שיש תכונות שונות, לדוגמא התכונות x1, x2 שמקבלות צירופים יוצאי דופן של ערכים אז בדוגמה הקודמת, היתה לנו דוגמה שבה האנומליה היתה שעומס ה-CPU וכמות הזיכרון בשימוש קיבלו שילוב יוצאי דופן של ערכים, אם רוצים להשתמש במודל המקורי כדי לתפוש את זה, אז מה שצריך לעשות הוא ליצור תכונה נוספת, כגון x3 שווה x1/x2 דהיינו עומס ה-CPU חלקי כמות הזיכרון בשימוש, או משהו דומה, וצריך ליצור תכונות נוספות בכל מקרה של שילובים יוצאי דופן של ערכים בהם x1 ו-x2 מקבלים שילוב יוצא דופן של ערכים למרות ש-x1 בפני עצמו ו-x2 כשלעצמו נראים כאילו הם מקבלים ערכים נורמלים לחלוטין. אבל אם אנחנו מוכנים להשקיע זמן כדי ליצור באופן ידני תכונות נוספות כמו זו, אז המודל המקורי יעבוד בסדר. לעומת זאת, המודל הגאוסי מרובה המשתנים יכול באופן אוטומטי ללכוד מתאם בין תכונות שונות. אבל למודל המקורי יש כמה יתרונות משמעותיים יותר, אחד היתרונות הגדולים של המודל המקורי הוא שהוא זול יותר מבחינה חישובית, ועוד נקודת מבט על אותו עניין הוא שניתן לעבוד בו טוב יותר גם בערכים גדולים מאוד של n ומספר גדול מאוד של תכונות, ולכן גם אם n הוא עשרת אלפים, או אפילו אם n הוא מאה אלף, המודל המקורי יהיה בדרך כלל בסדר גמור. בניגוד לכך במודל הגאוסי רב-המשתנים, אז כאן למשל, אנו צריכים לחשב הופכי של המטריצה Σ כש-Σ היא מטריצה n על n, ולכן חישוב ההופכי של Σ אם Σ היא מטריצה של מאה אלף על מאה אלף יהיה יקר מאוד מבחינה חישובית. אז המודל הגאוסי הרב-משתני גדל פחות טוב לערכים גדולים של n. ולבסוף מתברר שהמודל המקורי עובד בסדר גם אם יש לנו סדרת אימון קטנה יחסית, מספר קטן של דוגמאות ללא תוויות שבהם אנחנו משתמשים כדי למדל את p של x, וזה עובד בסדר גם אם הוא אולי 50 או 100, זה עובד בסדר. לעומת זאת, בגאוס מרובה משתנים, זו תכונה מתמטית של האלגוריתם ש-m חייב להיות גדול מ-n, מספר הדוגמאות חייב להיות גדול ממספר התכונות. ויש תכונה מתמטית של האופן שבו אנו מעריכים את הפרמטרים שאם זה לא נכון, אם m הוא קטן או שווה ל-n, אז המטריצה אפילו לא הפיכה, המטריצה היא סינגולרית, ולכן בכלל אי-אפשר להשתמש במודל גאוס מרובה-משתנים, אלא אם כן עושים בו כמה שינויים. אבל כלל אצבע אופייני שבו אני משתמש הוא שאני אשתמש במודל גאוסי מרובה משתנים רק אם m הוא הרבה יותר גדול מ-n, אז זה מרחיב את הדרישה המתמטית הצרה, אבל בפועל, הייתי משתמש במודל גאוס מרובה משתנים, רק אם m הוא די הרבה יותר גדול מ-n. אם m גדול או שווה ל-10 כפול n, נניח, זה יכול להיות כלל אצבע סביר, ואם זה לא מספק את זה, אז תחשבו על כך שבמודל גאוס מרובה משתנים יש המון פרמטרים, המטריצה Σ היא מטריצה n על n, אז יש לנו בערך n בריבוע פרמטרים, אבל מכיוון שמדובר במטריצה סימטרית, המספר למעשה קרוב יותר ל-n בריבוע חלקי 2, אבל זה בכל אופן הרבה פרמטרים, אז אתה צריך לוודא שיש לך ערך מספיק גדול עבור m, לוודא שיש לך מספיק נתונים כדי להתאים את כל הפרמטרים האלה. ו-m גדול או שווה ל 10*n יהיה כלל אצבע סביר כדי לוודא שאפשר להעריך את מטריצת השונות Σ באופן סביר. אז בפועל המודל המקורי משמאל יותר נפוץ. ואם אתם חושדים שצריך ללכוד קורלציות בין תכונות, מה שנעשה בדרך כלל הוא לבנות ידנית תכונות נוספות כמו אלה כדי ללכוד שילובים יוצאי דופן ספציפיים של ערכים. אבל בבעיות שבהן יש לנו קבוצת אימון גדולה מאוד, m הוא גדול מאוד ו-n הוא לא גדול מדי, אז כדאי לשקול את המודל הגאוסי הרב-משתני, והוא עשוי לעבוד טוב יותר וגם לחסוך זמן על יצירה ידנית של תכונות נוספות אם החריגים הם צירופים יוצאי דופן של ערכים של תכונות. לבסוף אני רוצה להזכיר בקצרה תכונה קצת טכנית, והיא שאם מתאימים מודל גאוסי רב משתני ומגלים שמטריצת השונות המשותפת Σ היא סינגולרית או בלתי הפיכה, יש בדרך כלל 2 מקרים שבהם זה קורה. האחד הוא שהתנאי הזה ש-m גדול מ-n איננו מתקיים, והמקרה השני הוא שיש לנו תכונות מיותרות. אז בתכונות מיותרות, אני מתכוון לדוגמא אם יש לנו 2 תכונות זהות. איכשהו בטעות יצרנו שני עותקים של אותה תכונה, כך ש-x1 שווה בדיוק ל-x2. או תכונות מיותרות יכולות להיות אם לדוגמא התכונה x3 שווה לערך של x4 + x5. אוקיי, אז אם יש לנו תכונות ממש מיותרות כמו אלה, אם x3 שווה x4 + x5, אז x3 אינו מכיל שום מידע חדש. ברור? פשוט לקחנו 2 תכונות וחיברנו אותן. ואם יש לנו סוג כזה של תכונות מיותרות, תכונות משוכפלות, או סוג כזה של תכונות תלויות לינארית, אז Σ עשויה להיות בלתי הפיכה. אז יש שלב של ניפוי שגיאות - זה צריך לקרות לעתים רחוקות מאוד, אז כנראה לא תתקלו בזה, זה מאוד לא סביר שתצטרכו לדאוג לזה - אבל אם אתם מיישמים מודל גאוס מרובה משתנים ומגלים ש-Σ אינה הפיכה, הדבר הראשון שהייתי עושה הוא לוודא ש-m הוא גדול בהרבה מ-n, ואם כן, אז הדבר השני שהייתי עושה הוא פשוט לבדוק אם יש תכונות מיותרות. אז אם יש 2 תכונות שוות, פשוט צריך להיפטר מאחת מהם, או אם יש דברים כמו אלה, x3 שווה x4 + x5, פשוט תיפטרו מאחת מהן, ואז זה צריך שוב לעבוד בסדר. כהערת אגב עבור אלה מכם המומחים באלגברה ליניארית, כשאני אומר תכונות מיותרות, מה שאני מתכוון, המונח הרשמי הוא, תכונות תלויות ליניארית. אבל בפועל מה שזה באמת אומר הוא, אם אחת הבעיות האלה מפילה את האלגוריתם, אם פשוט תגרמו לתכונות להיות לא מיותרות, וזה צריך לפתור את הבעיה של Σ בלתי הפיכה. אבל כאמור הסיכויים שלכם להיתקל בבעיה הזו בכלל הם די נמוכים, רוב הסיכויים הם שתצליחו פשוט ליישם את המודל הגאוסי מרובה המשתנים, בלי לדאוג בקשר ל-Σ בלתי הפיכה, כל עוד m מספיק גדול מ-n. אז זהו זה בקשר לזיהוי חריגים עם התפלגות גאוסית מרובת משתנים. וכשמשתמשים בשיטה הזו אפשר לקבל אלגוריתם זיהוי חריגים שלוכד באופן אוטומטי מתאמים חיוביים ושליליים בין תכונות שונות ומסמן חריגים אם הוא רואה שילוב יוצא דופן של ערכי התכונות.