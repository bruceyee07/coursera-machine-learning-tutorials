1
00:00:00,280 --> 00:00:04,540
בסרטון זה אני רוצה לדבר על התפלגות גאוסיאנית

2
00:00:04,540 --> 00:00:07,440
שנקראת גם התפלגות נורמלית.

3
00:00:07,440 --> 00:00:11,417
אם אתם כבר מכירים היטב את ההתפלגות הגאוסיאנית,

4
00:00:11,417 --> 00:00:14,678
זה בסדר גמור לדלג על הסרטון הזה, אבל אם אתם לא בטוחים

5
00:00:14,678 --> 00:00:18,475
או אם עבר זמן מה מאז שעבדתם עם התפלגות גאוסיאנית או

6
00:00:18,475 --> 00:00:22,950
התפלגות נורמלית אז בבקשה צפו בסרטון הזה עד הסוף.

7
00:00:22,950 --> 00:00:26,970
ובווידאו שאחרי זה נתחיל ליישם את ההתפלגות הגאוסיאנית

8
00:00:26,970 --> 00:00:29,250
כדי לפתח אלגוריתם זיהוי חריגים או זיהוי אנומליה.

9
00:00:32,040 --> 00:00:37,450
נניח ש-x הוא משתנה אקראי עם ערך ממשי, אז x הוא מספר ממשי.

10
00:00:37,450 --> 00:00:42,840
אם הסתברות ההתפלגות של x היא גאוסיאנית עם ממוצע μ (מיו)

11
00:00:42,840 --> 00:00:44,710
ושונות σ² (סיגמא בריבוע),

12
00:00:44,710 --> 00:00:49,280
אז נכתוב זאת כ- x, המשתנה האקראי.

13
00:00:49,280 --> 00:00:54,517
טילדה, ~ , הטילדה הקטנה הזו, המשמעות של זה היא "מתפלג כ".

14
00:00:59,174 --> 00:01:02,278
ואז כדי לציין התפלגות גאוסיאנית,

15
00:01:02,278 --> 00:01:07,440
לפעמים אני אכתוב N מסוגננת, ובסוגריים - (μ,σ²) - מיו פסיק סיגמא בריבוע.

16
00:01:07,440 --> 00:01:10,960
ה-N המסולסלת מציינת "נורמלי" מכיוון שגאוסיאני

17
00:01:10,960 --> 00:01:14,390
ונורמלי הן מילים בעלות משמעות זהה, מילים נרדפות.

18
00:01:14,390 --> 00:01:18,924
ולהתפלגות הגאוסיאנית יש שני פרמטרים,

19
00:01:18,924 --> 00:01:21,581
פרמטר הממוצע שאותו אנו מציינים ב-μ,

20
00:01:21,581 --> 00:01:26,160
ופרמטר השונות שאותו אנו מציינים ב-σ².

21
00:01:26,160 --> 00:01:30,120
אם נשרטט התפלגות גאוסיאנית או את צפיפות ההסתברות הגאוסיאנית,

22
00:01:30,120 --> 00:01:36,230
זה ייראה כמו פעמון, צורת פעמון שייתכן שראיתם בעבר.

23
00:01:36,230 --> 00:01:36,870
וכך

24
00:01:36,870 --> 00:01:41,300
עקומת הפעמון הזו מקבלת שני פרמטרים, μ ו-σ.

25
00:01:41,300 --> 00:01:46,520
המיקום של מרכז הפעמון הוא הממוצע, μ.

26
00:01:46,520 --> 00:01:51,060
ורוחב עקומת הפעמון, בערך בגובה הזה,

27
00:01:51,060 --> 00:01:56,550
זה הפרמטר σ, והוא נקרא גם סטיית תקן אחת,

28
00:01:56,550 --> 00:02:00,820
והוא מציין את ההסתברות ש-x מקבל ערכים שונים.

29
00:02:00,820 --> 00:02:04,060
x מקבל ערכים שנמצאים כאן באמצע העקומה בהסתברות גבוהה,

30
00:02:04,060 --> 00:02:08,490
כי הצפיפות הגאוסיאנית כאן היא די גבוהה, ואילו ההסתברות ש-x מקבל ערכים

31
00:02:08,490 --> 00:02:12,140
רחוק יותר מהאמצע יורדת והולכת.

32
00:02:12,140 --> 00:02:14,990
רק למען הַשְלֵמוּת תנו לי לכתוב את הנוסחה של

33
00:02:14,990 --> 00:02:16,990
התפלגות גאוסיאנית.

34
00:02:16,990 --> 00:02:21,490
ההסתברות של x, ולפעמים במקום לכתוב את זה כ-(p(x

35
00:02:21,490 --> 00:02:26,380
אני אכתוב את זה כ-(P(x; μ, σ², מה שמציין

36
00:02:26,380 --> 00:02:31,920
שההסתברות של x יש לה שני הפרמטרים μ וσ².

37
00:02:31,920 --> 00:02:38,508
אז הנוסחה של צפיפות גאוסיאנית היא 1 חלקי שורש 2π כפול σ

38
00:02:38,508 --> 00:02:44,250
כפול e בחזקת מינוס (x-μ) בריבוע חלקי 2σ².

39
00:02:44,250 --> 00:02:47,220
אין צורך לזכור את הנוסחה הזו.

40
00:02:47,220 --> 00:02:52,010
זוהי הנוסחה של עקומת הפעמון כאן משמאל.

41
00:02:52,010 --> 00:02:53,230
אין צורך לזכור אותה,

42
00:02:53,230 --> 00:02:56,490
וכשתצטרכו להשתמש בה, תמיד תוכלו למצוא אותה.

43
00:02:56,490 --> 00:03:00,720
אז הגרף משמאל, זה מה שתקבל אם תיקח ערך קבוע של μ

44
00:03:00,720 --> 00:03:07,490
וערך קבוע של σ, ותשרטט את הגרף של (p(x, אז תקבל את העקומה הזו.

45
00:03:07,490 --> 00:03:11,940
זה בעצם (p(x משורטט כפונקציה של x

46
00:03:11,940 --> 00:03:14,820
עבור ערכים קבועים של μ ו-σ².

47
00:03:14,820 --> 00:03:18,530
ודרך אגב, לפעמים קל יותר לחשוב במונחים של σ²,

48
00:03:18,530 --> 00:03:19,940
מה שנקרא השונות.

49
00:03:19,940 --> 00:03:22,880
ולפעמים קל יותר לחשוב במונחים של σ.

50
00:03:22,880 --> 00:03:28,040
σ נקראת סטיית תקן,

51
00:03:28,040 --> 00:03:32,374
והיא מציינת את רוחב צפיפות ההתפלגות הגאוסיאנית הזו,

52
00:03:32,374 --> 00:03:35,630
וכאמור σ² נקראת שונות.

53
00:03:36,630 --> 00:03:41,070
בואו נראה כמה דוגמאות של איך נראית התפלגות גאוסיאנית.

54
00:03:41,070 --> 00:03:43,660
אם μ שווה לאפס ו-σ שווה לאחת,

55
00:03:43,660 --> 00:03:47,410
אז יש לנו התפלגות גאוסיאנית שממורכזת סביב האפס,

56
00:03:47,410 --> 00:03:48,940
כי μ הוא אפס,

57
00:03:48,940 --> 00:03:53,880
והרוחב של הגאוסיאן הזה, דהיינו סטיית תקן אחת היא σ כאן.

58
00:03:55,210 --> 00:03:58,330
בואו נראה כמה דוגמאות של גאוסיאנים.

59
00:03:58,330 --> 00:04:00,900
אם μ שווה לאפס ו-σ שווה לאחת,

60
00:04:00,900 --> 00:04:05,380
זה מתאים להתפלגות גאוסיאנית הממוקדת באפס,

61
00:04:05,380 --> 00:04:08,920
שכן μ הוא אפס, ורוחב הגאוסיאן הזה

62
00:04:10,860 --> 00:04:15,880
נשלט על ידי הפרמטר σ.

63
00:04:16,880 --> 00:04:17,830
הנה עוד דוגמה.

64
00:04:20,530 --> 00:04:24,690
אותו μ עדיין שווה ל-0 ו-σ שווה ל-0.5,

65
00:04:24,690 --> 00:04:29,740
אז סטיית התקן היא 0.5 והשונות, σ², היא

66
00:04:29,740 --> 00:04:34,970
הריבוע של 0.5 דהיינו 0.25 ובמקרה הזה ההתפלגות הגאוסיאנית,

67
00:04:34,970 --> 00:04:37,599
צפיפות ההסתברות הגאוסיאנית דומה לזֶה.

68
00:04:38,620 --> 00:04:40,430
וגם היא ממורכזת באפס.

69
00:04:40,430 --> 00:04:45,160
אבל עכשיו הרוחב הזה הוא הרבה יותר קטן, כי השונות קטנה יותר,

70
00:04:45,160 --> 00:04:50,600
הרוחב של הצפיפות הגאוסיאנית היא בערך חצי מהרוחב.

71
00:04:50,600 --> 00:04:54,490
אבל מכיוון שזו היא התפלגות של הסתברות, לכן השטח מתחת לעקומה,

72
00:04:54,490 --> 00:04:56,550
האזור המוצלל כאן,

73
00:04:56,550 --> 00:05:01,770
לאזור הזה יש שטח שווה לאחת, זה מאפיין של כל התפלגויות ההסתברויות.

74
00:05:01,770 --> 00:05:06,220
ולכן הצפיפות כאן חייבת להיות הרבה יותר גבוהה, כי הרוחב שלה הוא חצי,

75
00:05:06,220 --> 00:05:09,140
חצי רוחב של סטיית תקן ולכן הוא גבוה כפליים.

76
00:05:09,140 --> 00:05:14,060
עוד דוגמה היא עם σ שווה 2 אז מקבלים צפיפות גאוסיאנית הרבה יותר

77
00:05:14,060 --> 00:05:16,300
שמנה ורחבה,

78
00:05:16,300 --> 00:05:21,920
הפרמטר σ שולט בכך שלהתפלגות הגאוסיאנית יש רוחב גדול יותר.

79
00:05:21,920 --> 00:05:26,240
ושוב, האזור מתחת לעקומה, האזור המקווקו, תמיד

80
00:05:26,240 --> 00:05:30,580
יהיה בעל שטח 1, זהו מאפיין של התפלגויות הסתברותיות, וומכיוון

81
00:05:30,580 --> 00:05:34,220
שהוא רחב יותר, הוא גם יותר נמוך כך שהאינטגרל הוא עדיין אותו דבר.

82
00:05:35,780 --> 00:05:40,340
ולבסוף, עוד דוגמה אחת, נניח שאנחנו עכשיו משנים גם את הפרמטר μ.

83
00:05:40,340 --> 00:05:45,090
אז במקום להיות מרוכזים מסביב ל-0 עכשיו תהיה לנו התפלגות גאוסיאנית

84
00:05:45,090 --> 00:05:50,150
מסביב ל-3 כי זה מזיז את כל פעמון ההתפלגות הגאוסיאנית.

85
00:05:51,240 --> 00:05:55,100
עכשיו, בואו נדבר על בעיית אומדן הפרמטרים.

86
00:05:55,100 --> 00:05:57,560
מהי בעיית אומדן הפרמטרים?

87
00:05:57,560 --> 00:06:01,014
נניח שיש לנו מערך נתונים של m דוגמאות x1 עד xm

88
00:06:01,014 --> 00:06:04,210
ונניח שכל דוגמא היא מספר ממשי.

89
00:06:04,210 --> 00:06:07,214
כאן בתרשים התוויתי דוגמה של נתונים כאלה,

90
00:06:07,214 --> 00:06:11,117
הציר האופקי הוא ציר x ויש לנו מגוון של דוגמאות x,

91
00:06:11,117 --> 00:06:14,580
ואני פשוט שרטטתי אותם על הגרף הזה כאן.

92
00:06:14,580 --> 00:06:17,290
בעיית אומדן הפרמטרים היא זו,

93
00:06:17,290 --> 00:06:21,150
נניח שאני חושד שהדוגמאות האלה מתפלגות גאוסיאנית.

94
00:06:21,150 --> 00:06:25,340
אז נניח שאני חושד שכל אחת מהדוגמאות xi, מתפלגת,

95
00:06:25,340 --> 00:06:27,640
זה מה שמסמן הטילדה הזה,

96
00:06:27,640 --> 00:06:31,050
אני חושד שכל הדוגמאות הללו מתפלגות

97
00:06:31,050 --> 00:06:35,400
בהתפלגות נורמלית, או התפלגות גאוסיאנית, עם איזשהו פרמטר μ

98
00:06:35,400 --> 00:06:37,590
ואיזשהו פרמטר σ².

99
00:06:37,590 --> 00:06:40,840
אבל אני לא יודע מה הערכים של הפרמטרים האלה.

100
00:06:40,840 --> 00:06:44,990
הבעיה של אומדן או הערכת הפרמטרים היא,
כאשר אנחנו מקבלים ערכת נתונים כזו, אנחנו רוצים לנסות

101
00:06:44,990 --> 00:06:49,678
להבין, אנחנו רוצים להעריך מה הם הערכים של μ ו-σ².

102
00:06:49,678 --> 00:06:51,620
אז אם אנחנו מקבלים ערכת נתונים שנראית כך,

103
00:06:51,620 --> 00:06:58,070
זה נראה כאילו שאם נעריך את ההתפלגות הגאוסיאנית ממנה הגיעו הנתונים,

104
00:06:58,070 --> 00:07:03,440
אולי היא תיראה בערך כך.

105
00:07:03,440 --> 00:07:09,000
עם μ באמצע הפיזור, וסיגמה סטיית התקן

106
00:07:09,000 --> 00:07:12,510
מגדירה את הרוחב של ההתפלגות הגאוסיאנית הזו.

107
00:07:12,510 --> 00:07:14,500
זה נראה כמו התאמה סבירה לנתונים.

108
00:07:14,500 --> 00:07:18,970
כי נראה שלנתונים יש סבירות גבוהה מאוד

109
00:07:18,970 --> 00:07:22,870
להיות באזור המרכזי, והסתברות יותר נמוכה להיות רחוקים יותר,

110
00:07:22,870 --> 00:07:25,060
ועוד יותר נמוכה לעוד יותר רחוק וכן הלאה.

111
00:07:25,060 --> 00:07:30,470
אז אולי זה אומדן סביר של μ ו-σ².

112
00:07:30,470 --> 00:07:33,510
כלומר, אם ההתפלגות היא אכן נורמלית,

113
00:07:33,510 --> 00:07:34,280
אז פונקצית ההתפלגות נראית ככה.

114
00:07:35,680 --> 00:07:40,010
אז אני פשוט אכתוב את הנוסחאות הסטנדרטיות

115
00:07:40,010 --> 00:07:43,160
להערכת הפרמטרים μ ו-σ².

116
00:07:43,160 --> 00:07:46,890
ההערכה שלנו לגבי μ

117
00:07:46,890 --> 00:07:51,190
תהיה פשוט הממוצע של כל הדוגמאות.

118
00:07:51,190 --> 00:07:52,770
μ הוא הפרמטר של ממוצע ההתפלגות.

119
00:07:52,770 --> 00:07:56,220
פשוט ניקח את ערכת האימון, ניקח את m הדוגמאות שלנו ונמצא את הממוצע שלהם.

120
00:07:56,220 --> 00:07:58,710
זה פשוט נותן את מרכז ההתפלגות הזאת.

121
00:08:01,160 --> 00:08:02,060
מה בקשר ל-σ²?

122
00:08:02,060 --> 00:08:05,320
ובכן, השונות, אני פשוט שוב אכתוב את הנוסחה הרגילה,

123
00:08:05,320 --> 00:08:12,260
אני מעריך את השונות כסכום מ-1 עד m של xi פחות μ בריבוע.

124
00:08:12,260 --> 00:08:15,370
ו-μ כאן הוא למעשה אותו μ שחישבנו לפני רגע

125
00:08:15,370 --> 00:08:16,780
באמצעות הנוסחה הזו.

126
00:08:16,780 --> 00:08:18,060
והמשמעות של השונות,

127
00:08:18,060 --> 00:08:21,130
או יותר נכון פרשנות אחת למשמעות של השונות היא שכשמסתכלים על המונח הזה,

128
00:08:21,130 --> 00:08:26,260
הוא ריבוע ההפרש בין ערך הדוגמא והממוצע,

129
00:08:26,260 --> 00:08:28,890
דהיינו פחות האמצע, פחות אמצע ההתפלגות,

130
00:08:28,890 --> 00:08:31,730
אז אנחנו מעריכים את השונות

131
00:08:31,730 --> 00:08:36,160
כממוצע ריבועי ההפרשים בין הדוגמאות ובין הממוצע.

132
00:08:37,280 --> 00:08:41,450
והערת אגב, רק לאלו מכם המומחים בסטטיסטיקה.

133
00:08:41,450 --> 00:08:44,660
אם אתה מומחה לסטטיסטיקה, ואם שמעת

134
00:08:44,660 --> 00:08:48,800
על אומדן סבירות מקסימלית, אז ההערכות האלה

135
00:08:48,800 --> 00:08:52,320
הן למעשה אומדני הסבירות המקסימלית של הפרמטרים μ

136
00:08:52,320 --> 00:08:55,480
ו-σ², אבל מי שלא מכיר את הנושא, אין לכם מה לדאוג,

137
00:08:55,480 --> 00:08:59,360
כל מה שאתם צריכים לדעת הוא שאלה הן שתי הנוסחאות הסטנדרטיות

138
00:08:59,360 --> 00:09:05,090
כדי להעריך את μ ו-σ² לגבי ערכת נתונים נתונה.

139
00:09:05,090 --> 00:09:09,210
לבסוף עוד הערה צדדית

140
00:09:09,210 --> 00:09:13,240
לאלה מכם שלמדו סטטיסטיקה.

141
00:09:13,240 --> 00:09:18,581
חלק מכם אולי ראו את הנוסחה כאן אבל במקום m היה כאן m-1

142
00:09:18,581 --> 00:09:22,480
אז הכופל הראשון כאן הוא 1 חלקי m-1 במקום 1 חלקי m.

143
00:09:22,480 --> 00:09:27,698
בלמידת מכונה אנחנו נוטים להשתמש בנוסחה 1 חלקי m, אבל למעשה אם זה

144
00:09:27,698 --> 00:09:33,100
1 חלקי m או 1 חלקי m-1 זה לא ממש משנה בהנחה ש-m הוא לא ממש קטן.

145
00:09:33,100 --> 00:09:35,340
אם יש סדרת אימון גדולה במידה סבירה.

146
00:09:35,340 --> 00:09:38,360
אז אם במקרה ראיתם את הגרסה השונה מקודם,

147
00:09:38,360 --> 00:09:42,240
בשתי הגרסאות זה עובד כמעט במידה שווה, אבל בלמידת מכונה

148
00:09:42,240 --> 00:09:46,770
רובנו נוטים להשתמש ב-1 חלקי m בנוסחה הזו. ולשתי הגירסאות יש

149
00:09:46,770 --> 00:09:50,440
מאפיינים תיאורטיים מעט שונים זה מזה, תכונות מתמטיות שונות במעט.

150
00:09:50,440 --> 00:09:54,361
אבל למעשה באמת יש הבדל קטן מאוד, אם בכלל.

151
00:09:56,486 --> 00:10:01,264
אז אני מקווה שעכשיו יש לכם תחושה טובה של איך נראית התפלגות גאוסיאנית,

152
00:10:01,264 --> 00:10:03,817
כמו גם כיצד להעריך את הפרמטרים μ

153
00:10:03,817 --> 00:10:07,875
ו-σ² של התפלגות גאוסיאנית אם אתם מקבלים ערכת אימון,

154
00:10:07,875 --> 00:10:11,932
כלומר אם אתם מקבלים קבוצת נתונים שאתה חושב שהיא מתפלגת גאוסיאנית

155
00:10:11,932 --> 00:10:16,260
עם פרמטרים לא ידועים, μ ו-σ².

156
00:10:16,260 --> 00:10:18,723
בסרטון הבא, נתחיל לקחת את הדברים האלה ולהשתמש

157
00:10:18,723 --> 00:10:21,507
בה כדי לפתח אלגוריתם לאיתור אנומליה.