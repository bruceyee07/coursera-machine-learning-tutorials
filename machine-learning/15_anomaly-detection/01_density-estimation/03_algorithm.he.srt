1
00:00:00,090 --> 00:00:01,240
בהרצאה הקודמת דיברנו

2
00:00:01,560 --> 00:00:03,660
על התפלגות גאוסיאנית.

3
00:00:03,810 --> 00:00:05,350
בסרטון הזה נשתמש בזה

4
00:00:05,440 --> 00:00:07,300
כדי לפתח אלגוריתם זיהוי חריגים או אנומליות.

5
00:00:10,360 --> 00:00:11,690
נניח שיש לנו

6
00:00:11,840 --> 00:00:13,390
סדרת אימון לא מתויגת של

7
00:00:13,650 --> 00:00:15,410
m דוגמאות, והדוגמאות

8
00:00:15,470 --> 00:00:16,730
הן

9
00:00:16,760 --> 00:00:18,350
וקטורי תכונות ב-Rⁿ,

10
00:00:18,440 --> 00:00:19,420
לדוגמא סדרת האימון יכולה להיות,

11
00:00:20,540 --> 00:00:21,860
וקטורים של תכונות

12
00:00:22,730 --> 00:00:24,150
של m המטוסים האחרונים שיוצרו,

13
00:00:24,960 --> 00:00:26,730
או m תכונות

14
00:00:27,070 --> 00:00:28,290
של משתמשים או כל דבר אחר.

15
00:00:29,320 --> 00:00:30,460
הדרך בה אנחנו נטפל

16
00:00:30,840 --> 00:00:32,310
בזיהוי אנומליה היא

17
00:00:32,350 --> 00:00:33,480
לבנות מודל p של x

18
00:00:33,860 --> 00:00:35,640
מתוך הנתונים.

19
00:00:36,240 --> 00:00:38,530
אנחנו ננסה להבין לאילו תכונות יש הסתברות גבוהה,

20
00:00:38,860 --> 00:00:40,620
ולאילו סוגי תכונות יש הסתברות נמוכה יותר.

21
00:00:41,350 --> 00:00:42,810
אז x הוא

22
00:00:43,090 --> 00:00:44,900
וקטור ואנחנו

23
00:00:45,320 --> 00:00:46,580
נבנה מודל p של x,

24
00:00:47,020 --> 00:00:48,870
כמכפלה של ההסתברות של x1,

25
00:00:49,440 --> 00:00:50,390
כלומר של המרכיב הראשון

26
00:00:50,950 --> 00:00:53,180
של x, כפול ההסתברות

27
00:00:53,990 --> 00:00:54,960
של x2, כלומר ההסתברות

28
00:00:55,510 --> 00:00:57,350
של התכונה השנייה, כפול

29
00:00:57,450 --> 00:00:58,860
ההסתברות של התכונה השלישית,

30
00:00:59,090 --> 00:01:01,230
וכן הלאה עד

31
00:01:01,410 --> 00:01:03,290
ההסתברות של התכונה האחרונה

32
00:01:03,760 --> 00:01:03,930
xn.

33
00:01:04,200 --> 00:01:06,320
אני משאיר כאן מקום כי אני תיכף אמלא פה משהו.

34
00:01:08,780 --> 00:01:09,720
אבל איך

35
00:01:09,830 --> 00:01:10,960
נבנה מודל של ההסתברות של כל תכונה,

36
00:01:11,460 --> 00:01:13,020
p של x1, ו-p של x2, וכן הלאה?

37
00:01:14,080 --> 00:01:15,380
מה שנעשה הוא

38
00:01:15,680 --> 00:01:16,860
להניח שהתכונה

39
00:01:17,480 --> 00:01:19,830
x1 מתפלגת

40
00:01:20,340 --> 00:01:22,950
גאוסיאנית עם

41
00:01:23,160 --> 00:01:25,140
איזה שהוא פרמטר ממוצע

42
00:01:25,340 --> 00:01:25,850
שנקרא לו μ₁

43
00:01:25,920 --> 00:01:26,900
ואיזו שונות, שנקרא לה

44
00:01:26,990 --> 00:01:28,560
σ²₁,

45
00:01:29,890 --> 00:01:30,690
אז p של x1

46
00:01:30,820 --> 00:01:32,020
הוא התפלגות

47
00:01:32,350 --> 00:01:34,410
גאוסיאנית עם ממוצע

48
00:01:34,610 --> 00:01:37,580
μ₁ ושונות σ²₁.

49
00:01:38,230 --> 00:01:39,660
ונניח שוב

50
00:01:39,720 --> 00:01:40,570
שגם x2

51
00:01:40,760 --> 00:01:42,220
מתפלג גאוסיאנית,

52
00:01:42,870 --> 00:01:44,620
זה מה שמציינת הטילדה הקטנה כאן,

53
00:01:44,800 --> 00:01:47,220
כלומר התפלגות גאוסיאנית

54
00:01:47,740 --> 00:01:49,490
עם ממוצע μ₂ ושונות σ²₂

55
00:01:49,830 --> 00:01:51,780
ההתפלגות הגאוסיאנית

56
00:01:52,170 --> 00:01:54,230
כאן שונה, כי יש לה

57
00:01:54,460 --> 00:01:58,010
פרמטרים שונים, μ₂ ו-σ²₂.

58
00:01:58,120 --> 00:02:00,160
ובדומה לכך, אתם יודעים,

59
00:02:00,360 --> 00:02:04,020
x3 גם הוא

60
00:02:04,480 --> 00:02:06,590
גאוסיאני

61
00:02:06,780 --> 00:02:09,100
עם הממוצע שלו

62
00:02:09,300 --> 00:02:11,630
וסטיית התקן שלו,

63
00:02:11,830 --> 00:02:15,370
וכן הלאה, עד xn.

64
00:02:17,000 --> 00:02:17,740
אז זה המודל שלי.

65
00:02:19,010 --> 00:02:20,230
כהערת אגב

66
00:02:20,370 --> 00:02:21,490
לאלה מכם המומחים

67
00:02:21,890 --> 00:02:22,770
בסטטיסטיקה, מתברר

68
00:02:22,990 --> 00:02:23,850
שהמשוואה הזו

69
00:02:24,250 --> 00:02:25,590
שכתבתי בעצם מתאימה

70
00:02:25,750 --> 00:02:27,490
להנחה של אי-תלות

71
00:02:28,060 --> 00:02:29,550
בין ערכי התכונות x1 עד xn.

72
00:02:30,290 --> 00:02:31,520
אבל בפועל מתברר

73
00:02:32,040 --> 00:02:34,010
שהקטע הזה באלגוריתם עובד בסדר גמור,

74
00:02:34,410 --> 00:02:36,330
בין אם התכונות אינן תלויות

75
00:02:36,610 --> 00:02:37,780
ובין אם הן רק קרובות להיות בלתי-תלויות,

76
00:02:38,280 --> 00:02:39,810
ואפילו אם הנחת האי-תלות אינה נכונה,

77
00:02:40,240 --> 00:02:41,830
האלגוריתם הזה עובד בסדר גמור.

78
00:02:42,650 --> 00:02:45,870
אבל למי שלא מכיר את המונחים

79
00:02:45,970 --> 00:02:47,380
ולא הבין מה שאמרתי,

80
00:02:47,830 --> 00:02:48,460
אל תדאגו,

81
00:02:49,170 --> 00:02:50,840
תוכלו להבין

82
00:02:51,360 --> 00:02:52,690
ולבנות את האלגוריתם הזה בלי בעיות,

83
00:02:53,250 --> 00:02:55,310
ההערה באמת נועדה רק למומחים בסטטיסטיקה.

84
00:02:57,790 --> 00:02:58,880
לבסוף,

85
00:02:59,210 --> 00:03:00,320
לסיכום, תנו לי

86
00:03:00,590 --> 00:03:04,680
לקחת את הביטוי הזה ולכתוב אותו בצורה קצת יותר קומפקטית.

87
00:03:05,120 --> 00:03:06,200
אנחנו

88
00:03:06,310 --> 00:03:07,500
כותבים את זה כך: המכפלה

89
00:03:07,740 --> 00:03:09,520
מ-j שווה 1

90
00:03:10,230 --> 00:03:11,840
עד n, של p

91
00:03:12,140 --> 00:03:15,350
של xj עם הפרמטרים

92
00:03:16,020 --> 00:03:17,930
μj ו-σ²j.

93
00:03:19,500 --> 00:03:21,500
הסימן הזה Π,

94
00:03:21,790 --> 00:03:23,330
האות היוונית

95
00:03:23,780 --> 00:03:25,220
הגדולה פיי (Π),

96
00:03:25,490 --> 00:03:27,600
הוא סימון שמשתמשים בו

97
00:03:28,190 --> 00:03:29,980
כדי לציין מכפלה של קבוצת ערכים.

98
00:03:30,590 --> 00:03:32,290
כמו שאתם מכירים

99
00:03:32,400 --> 00:03:33,930
את הסימן סיגמא - Σ, שמסמן סיכום,

100
00:03:34,520 --> 00:03:36,460
כמו הסכום של i שווה 1 עד

101
00:03:36,930 --> 00:03:39,070
n של i.

102
00:03:39,960 --> 00:03:41,820
דהיינו 1 + 2 + 3

103
00:03:42,230 --> 00:03:43,730
ועוד וכו' וכו'

104
00:03:43,910 --> 00:03:45,350
עד n. אז כאן

105
00:03:45,660 --> 00:03:46,910
האות הזו היא סימן

106
00:03:47,390 --> 00:03:48,630
של מכפלה, לדוגמא מכפלה של i

107
00:03:48,840 --> 00:03:50,310
שווה 1 עד n

108
00:03:50,620 --> 00:03:52,210
של i. שזה

109
00:03:52,520 --> 00:03:54,530
בדיוק כמו סיכום, אבל עכשיו אנחנו מכפילים.

110
00:03:55,200 --> 00:03:56,680
ומקבלים 1 כפול

111
00:03:56,880 --> 00:03:58,700
2 כפול 3 כפול וכו'

112
00:03:59,910 --> 00:04:01,330
עד n. אז כשמשתמשים

113
00:04:01,860 --> 00:04:03,430
בסימון הזה של כפל,

114
00:04:03,570 --> 00:04:05,880
כפל מ-j שווה 1 עד n של הביטוי הזה.

115
00:04:06,620 --> 00:04:08,440
זה קומפקטי יותר,

116
00:04:08,820 --> 00:04:09,960
זו דרך יותר קצרה לכתוב

117
00:04:10,330 --> 00:04:12,810
את המכפלה הזו

118
00:04:13,120 --> 00:04:14,400
של כל הביטויים האלה,

119
00:04:15,200 --> 00:04:16,200
כי אנחנו לוקחים את כל הביטויים האלה

120
00:04:16,430 --> 00:04:17,510
p של x j בהנחת μj

121
00:04:17,730 --> 00:04:18,740
ו-σ²j

122
00:04:19,130 --> 00:04:20,290
ומכפילים אותם זה בזה.

123
00:04:21,540 --> 00:04:22,830
ודרך אגב, הבעיה הזו

124
00:04:23,250 --> 00:04:25,370
של אומדן של ההתפלגות

125
00:04:25,990 --> 00:04:27,130
p של x נקראת לפעמים

126
00:04:28,280 --> 00:04:29,540
בעיית אומדן הצפיפות.

127
00:04:30,420 --> 00:04:31,270
ומכאן הכותרת של השקופית.

128
00:04:33,800 --> 00:04:35,310
אז בואו ונחבר את כל החלקים,

129
00:04:35,500 --> 00:04:36,920
הנה האלגוריתם שלנו לזיהוי חריגים.

130
00:04:38,120 --> 00:04:40,290
הצעד הראשון הוא לבחור

131
00:04:40,650 --> 00:04:41,600
תכונות, או למצוא

132
00:04:41,700 --> 00:04:42,740
תכונות xi שאנחנו חושבים

133
00:04:43,040 --> 00:04:45,340
שיכולות להצביע על דוגמאות חריגות.

134
00:04:46,050 --> 00:04:47,020
מה שאני מתכוון

135
00:04:47,240 --> 00:04:48,490
הוא לנסות למצוא

136
00:04:48,680 --> 00:04:49,990
את התכונות כך שכאשר יש

137
00:04:50,280 --> 00:04:51,630
משתמש יוצא דופן במערכת

138
00:04:52,190 --> 00:04:53,000
שעשוי לנסות

139
00:04:53,190 --> 00:04:54,790
הונאה, או כאשר

140
00:04:55,020 --> 00:04:56,670
המנוע מתנהג כך אפשר להבין

141
00:04:56,760 --> 00:04:59,500
שמשהו לא בסדר, שמשהו מוזר באחד ממנועי המטוסים.

142
00:05:00,280 --> 00:05:01,230
לבחור את התכונות xi,

143
00:05:02,000 --> 00:05:03,330
שלדעתך עשויות לקבל ערכים

144
00:05:04,410 --> 00:05:05,860
גדולים במיוחד, או קטנים

145
00:05:06,020 --> 00:05:08,750
במיוחד,

146
00:05:08,880 --> 00:05:10,160
בדוגמאות חריגות.

147
00:05:10,910 --> 00:05:12,440
אבל באופן כללי יותר, פשוט לנסות

148
00:05:12,690 --> 00:05:14,340
לבחור תכונות המתארות תכונות כלליות

149
00:05:16,160 --> 00:05:19,380
של הדברים שעליהם אנחנו אוספים נתונים.

150
00:05:20,030 --> 00:05:21,360
אחר כך, לגבי מערך האימון

151
00:05:22,020 --> 00:05:23,980
של m דוגמאות לא מתויגות,

152
00:05:25,000 --> 00:05:26,980
x1 עד xm, אנו

153
00:05:27,170 --> 00:05:28,580
מחשבים את הפרמטרים

154
00:05:29,090 --> 00:05:30,170
μ1 עד μn,

155
00:05:30,340 --> 00:05:31,480
ו-σ²1 עד σ²n

156
00:05:31,690 --> 00:05:33,460
שהן

157
00:05:33,840 --> 00:05:34,810
נוסחאות כמו

158
00:05:34,840 --> 00:05:36,420
הנוסחאות שבנינו

159
00:05:36,680 --> 00:05:37,610
בסרטון הקודם,

160
00:05:37,740 --> 00:05:39,180
אנחנו משתמשים באומדן

161
00:05:39,310 --> 00:05:41,120
של כל אחד מהפרמטרים האלה, ופשוט

162
00:05:42,030 --> 00:05:43,670
כדי להבין את זה, μj

163
00:05:44,060 --> 00:05:47,830
הוא הערך הממוצע של התכונה ה-j,

164
00:05:48,720 --> 00:05:51,580
μj הוא מה שנמצא כאן בנוסחה p של xj,

165
00:05:52,440 --> 00:05:53,870
שהפרמטרים שלה הם μj

166
00:05:54,220 --> 00:05:55,590
ו-σ²j.

167
00:05:55,920 --> 00:05:57,890
מה שזה אומר

168
00:05:58,360 --> 00:05:59,620
הוא ש-μj הוא פשוט

169
00:05:59,700 --> 00:06:00,720
הממוצע על סדרת האימון

170
00:06:01,070 --> 00:06:02,930
של הערכים של תכונה j.

171
00:06:03,860 --> 00:06:05,100
ורק להזכיר,

172
00:06:05,220 --> 00:06:07,410
עושים את זה, מחשבים

173
00:06:07,620 --> 00:06:08,830
את הנוסחאות האלה עבור j שווה

174
00:06:09,420 --> 00:06:10,360
1 עד n. אז משתמשים

175
00:06:10,700 --> 00:06:11,960
בנוסחאות האלה כדי להעריך את

176
00:06:12,230 --> 00:06:14,020
μ1, ואת μ2,

177
00:06:14,070 --> 00:06:15,620
וכן הלאה עד

178
00:06:16,170 --> 00:06:17,460
μn, ובאופן דומה עבור

179
00:06:17,770 --> 00:06:19,060
σ², ואפשר גם

180
00:06:19,390 --> 00:06:21,530
לבנות גירסאות וקטוריות של הנוסחאות האלה.

181
00:06:21,830 --> 00:06:22,900
אם נחשוב על

182
00:06:23,000 --> 00:06:25,220
μ כעל וקטור, אז

183
00:06:25,920 --> 00:06:27,430
יש לו אברים μ1,

184
00:06:27,760 --> 00:06:29,230
μ2 וכו' עד

185
00:06:29,570 --> 00:06:31,180
μn, אז גירסה

186
00:06:31,660 --> 00:06:33,510
וקטורית של קבוצת

187
00:06:33,910 --> 00:06:35,530
הפרמטרים הזו ניתנת לכתיבה

188
00:06:36,440 --> 00:06:37,830
כסכום של i

189
00:06:37,880 --> 00:06:39,610
מ-1 עד n של xi.

190
00:06:40,290 --> 00:06:41,290
אז הנוסחה הזו

191
00:06:41,410 --> 00:06:43,530
שכתבתי מעריכה

192
00:06:43,990 --> 00:06:45,160
את μ על פי וקטורי התכונות xi

193
00:06:45,660 --> 00:06:48,140
עבור כל n הערכים של μ בו-זמנית.

194
00:06:49,140 --> 00:06:50,070
ואפשר גם לבנות

195
00:06:50,430 --> 00:06:52,130
נוסחה וקטורית

196
00:06:52,290 --> 00:06:55,110
להערכת σ²j. לבסוף,

197
00:06:56,500 --> 00:06:57,890
כאשר אנחנו מקבלים דוגמה חדשה,

198
00:06:58,100 --> 00:06:59,270
לדוגמא מקבלים מנוע חדש של מטוס

199
00:06:59,740 --> 00:07:01,420
ואנחנו רוצים לדעת אם המנוע הזה חריג,

200
00:07:02,470 --> 00:07:03,430
מה שאנחנו צריכים לעשות הוא

201
00:07:03,570 --> 00:07:05,610
לחשב את p של x, מה ההסתברות של הדוגמה החדשה זו?

202
00:07:06,790 --> 00:07:07,670
אז p של x שווה

203
00:07:07,990 --> 00:07:09,990
למכפלה הזו,

204
00:07:10,100 --> 00:07:11,140
ומה שאתם מיישמים, מה שאתם מחשבים,

205
00:07:11,750 --> 00:07:14,040
הוא הנוסחה הזו,

206
00:07:15,000 --> 00:07:16,610
וכאן, הדבר הזה

207
00:07:16,840 --> 00:07:17,900
הוא פשוט

208
00:07:18,260 --> 00:07:19,250
הנוסחה של ההסתברות

209
00:07:19,800 --> 00:07:21,000
הגאוסיאנית, אז אתם מחשבים

210
00:07:21,240 --> 00:07:22,880
את הדבר הזה, ואם

211
00:07:22,940 --> 00:07:24,420
ההסתברות הזאת קטנה מאוד,

212
00:07:24,860 --> 00:07:26,370
אז אתם מסמנים את הדוגמה החדשה הזו כחריגה.

213
00:07:27,570 --> 00:07:29,380
הנה דוגמה ליישום של שיטה זו.

214
00:07:30,870 --> 00:07:31,860
נניח שיש לנו קבוצת נתונים

215
00:07:32,210 --> 00:07:35,430
שמוצגת בגרף בפינה השמאלית העליונה של השקופית הזו.

216
00:07:36,670 --> 00:07:38,860
אם נסתכל על זה, בואו נסתכל על התכונה x1.

217
00:07:39,610 --> 00:07:40,640
אם נסתכל על סדרת הנתונים,

218
00:07:40,750 --> 00:07:42,600
נראה כאילו בממוצע, לתכונה

219
00:07:42,950 --> 00:07:44,330
x1 יש ממוצע של כ-5

220
00:07:45,540 --> 00:07:47,420
וסטיית תקן, אם

221
00:07:47,590 --> 00:07:48,660
מסתכלים רק על ערכי x1

222
00:07:49,010 --> 00:07:50,030
של הנתונים,

223
00:07:50,310 --> 00:07:51,720
יש להם סטיית תקן של אולי 2.

224
00:07:52,370 --> 00:07:55,110
אז זה σ1,

225
00:07:55,460 --> 00:07:57,380
ונראה כאילו שלגבי x2,

226
00:07:57,670 --> 00:07:59,070
הערכים של התכונות

227
00:07:59,250 --> 00:08:00,370
כפי שאנו מודדים על הציר האנכי,

228
00:08:00,840 --> 00:08:01,730
נראה שהממוצע

229
00:08:02,010 --> 00:08:03,110
הוא כ-3,

230
00:08:03,380 --> 00:08:05,750
וסטיית התקן שלו היא בערך 1.

231
00:08:05,880 --> 00:08:06,940
אז אם ניקח את סדרת הנתונים

232
00:08:07,010 --> 00:08:08,690
ונעריך את μ1, μ2, σ1

233
00:08:09,030 --> 00:08:11,410
ו-σ2, זה מה שנקבל.

234
00:08:11,610 --> 00:08:12,930
ושוב, אני כותב כאן σ,

235
00:08:13,140 --> 00:08:14,620
ואני חושב על סטיות תקן, אבל

236
00:08:15,100 --> 00:08:16,240
הנוסחה בשקופית הקודמת

237
00:08:16,280 --> 00:08:17,640
בעצם נתנה את האומדנים של הריבועים

238
00:08:18,120 --> 00:08:20,670
של הדברים האלה, σ²1 ו-σ²2.

239
00:08:20,940 --> 00:08:21,920
צריך להיות זהירים

240
00:08:22,090 --> 00:08:23,260
בשימוש ב-σ1 ו-σ2

241
00:08:23,380 --> 00:08:25,490
או ב-σ²1 או σ²2.

242
00:08:25,960 --> 00:08:26,700
σ²1 בריבוע כמובן

243
00:08:26,820 --> 00:08:28,500
שווה ל-4,

244
00:08:31,130 --> 00:08:32,260
הריבוע של 2.

245
00:08:32,310 --> 00:08:34,010
ובתמונות אנחנו רואים את p

246
00:08:34,180 --> 00:08:35,550
של x1 עם הפרמטרים μ1

247
00:08:35,660 --> 00:08:36,830
ו-σ²1 בריבוע ואת p

248
00:08:37,120 --> 00:08:38,130
של x2 עם הפרמטרים

249
00:08:38,230 --> 00:08:39,050
μ2 ו-σ²2 בריבוע,

250
00:08:39,190 --> 00:08:41,360
זה נראה כמו שתי ההתפלגויות כאן.

251
00:08:42,650 --> 00:08:44,280
ומסתבר

252
00:08:44,480 --> 00:08:45,960
שאם נעשה גרף של

253
00:08:46,210 --> 00:08:47,540
p של x, שהוא

254
00:08:47,710 --> 00:08:49,000
המכפלה של שני

255
00:08:49,210 --> 00:08:50,450
הדברים האלה, נקבל למעשה

256
00:08:50,800 --> 00:08:52,770
גרף תלת-ממדי שנראה ככה.

257
00:08:53,360 --> 00:08:54,370
זה הגרף של p

258
00:08:54,640 --> 00:08:55,920
של x, שבו הגובה

259
00:08:56,390 --> 00:08:57,730
מעל המישור,

260
00:08:57,830 --> 00:08:58,950
הגובה של המשטח הזה

261
00:08:58,990 --> 00:09:01,360
בנקודה מסוימת, אם נתונים

262
00:09:01,470 --> 00:09:03,670
x1 ו-x2,

263
00:09:03,930 --> 00:09:05,640
ערכים מסוימים שלהם,

264
00:09:05,800 --> 00:09:07,830
אם נניח x1 שווה 2 ו-x2 שווה 2, בנקודה הזאת.

265
00:09:08,510 --> 00:09:09,450
אז הגובה התלת-ממדי

266
00:09:09,710 --> 00:09:11,280
כאן, זה p

267
00:09:13,020 --> 00:09:14,420
של x. אז p של x, זה גובה הגרף

268
00:09:14,710 --> 00:09:16,220
בנקודה הזו, הוא

269
00:09:16,340 --> 00:09:17,520
פשוט p של x1

270
00:09:18,640 --> 00:09:20,010
עם פרמטרים μ1 ו-σ²₁,

271
00:09:20,290 --> 00:09:22,540
כפול p

272
00:09:23,200 --> 00:09:25,050
של x2 עם פרמטרים

273
00:09:25,120 --> 00:09:27,530
μ2 ו-σ²2.

274
00:09:27,720 --> 00:09:29,180
אז כך

275
00:09:29,320 --> 00:09:31,400
אנחנו מחשבים או מתאימים את הפרמטרים לנתונים האלה.

276
00:09:31,930 --> 00:09:32,950
בואו נראה מה קורה כשיש לנו דוגמאות חדשות.

277
00:09:33,530 --> 00:09:35,090
אולי יש לנו דוגמא חדשה כאן.

278
00:09:36,700 --> 00:09:38,340
האם היא אנומליה או לא?

279
00:09:38,550 --> 00:09:39,220
או אולי יש לנו דוגמה

280
00:09:39,570 --> 00:09:41,860
אחרת, אולי דוגמה אחרת שם.

281
00:09:42,140 --> 00:09:43,400
האם היא אנומליה או לא?

282
00:09:44,360 --> 00:09:47,050
אנחנו עושים את זה על ידי

283
00:09:47,190 --> 00:09:48,470
הגדרת ערך כלשהו

284
00:09:48,620 --> 00:09:49,490
עבור ε (אפסילון), נניח שנבחר

285
00:09:50,020 --> 00:09:51,220
ε שווה 0.02.

286
00:09:51,980 --> 00:09:54,110
אני אדבר יותר מאוחר על איך בוחרים ε.

287
00:09:55,180 --> 00:09:56,110
אבל בואו ניקח את הדוגמה

288
00:09:56,540 --> 00:09:57,360
הראשונה, תנו לי לקרוא לה

289
00:09:57,500 --> 00:09:59,500
דוגמת מבחן x1.

290
00:10:00,200 --> 00:10:01,010
ותנו לי לקרוא לדוגמה השנייה

291
00:10:02,800 --> 00:10:03,900
דוגמת מבחן x2.

292
00:10:04,780 --> 00:10:05,670
מה שאנחנו עושים הוא

293
00:10:05,820 --> 00:10:07,380
לחשב את p

294
00:10:07,540 --> 00:10:08,740
של דוגמת מבחן x1, אנחנו משתמשים

295
00:10:08,990 --> 00:10:10,400
בנוסחה הזו כדי לחשב את זה

296
00:10:11,140 --> 00:10:12,760
וזה נראה כמו ערך גדול למדי.

297
00:10:13,250 --> 00:10:15,560
בפרט, זה גדול,

298
00:10:15,920 --> 00:10:18,480
או גדול שווה ל-ε.

299
00:10:18,670 --> 00:10:19,670
ולכן יש לדוגמה

300
00:10:19,810 --> 00:10:21,290
הסתברות גבוהה למדי, לפחות גדולה

301
00:10:21,490 --> 00:10:22,510
מ-ε, ולכן אנו מחליטים

302
00:10:22,970 --> 00:10:24,490
שדוגמת מבחן x1 איננה חריגה.

303
00:10:25,650 --> 00:10:27,370
ולעומת זאת, אם נחשב את p של

304
00:10:27,440 --> 00:10:29,810
דוגמת מבחן x2, נקבל ערך הרבה יותר קטן.

305
00:10:30,170 --> 00:10:31,340
ערך קטן

306
00:10:31,490 --> 00:10:32,490
מ-ε ולכן נאמר

307
00:10:32,720 --> 00:10:34,400
שהיא אכן אנומליה,

308
00:10:34,860 --> 00:10:37,350
כי קיבלנו מספר הרבה יותר קטן מ-ε עליו החלטנו.

309
00:10:38,450 --> 00:10:39,950
ולמעשה, לא הוכחתי את זה,

310
00:10:40,460 --> 00:10:43,340
אבל מה שזה באמת אומר היא שאם נסתכל על הגרף התלת-ממדי הזה,

311
00:10:44,660 --> 00:10:46,270
זה אומר שכל

312
00:10:46,350 --> 00:10:47,940
הערכים של x1 ו-x2

313
00:10:48,210 --> 00:10:50,570
שנמצאים בגובה גבוה

314
00:10:50,810 --> 00:10:52,770
מעל פני השטח, מתאימים

315
00:10:52,910 --> 00:10:55,160
לדוגמה לא חריגה של דגימה טובה ורגילה.

316
00:10:55,970 --> 00:10:57,450
בעוד שכל הנקודות הרחוקות

317
00:10:57,640 --> 00:10:58,940
כאן, כל הנקודות

318
00:10:59,150 --> 00:11:00,460
כאן, לכל

319
00:11:00,580 --> 00:11:01,740
הנקודות האלה יש סבירות

320
00:11:01,910 --> 00:11:02,940
נמוכה מאוד, אז אנחנו

321
00:11:03,020 --> 00:11:04,310
נסמן את הנקודות האלה

322
00:11:04,620 --> 00:11:06,350
כחריגות, וזה מגדיר

323
00:11:06,760 --> 00:11:07,790
אזור מסוים, שאולי נראה

324
00:11:08,000 --> 00:11:09,480
כך, כך שכל דבר

325
00:11:09,810 --> 00:11:12,160
מחוץ לו אנחנו מסמנים

326
00:11:12,380 --> 00:11:12,580
כחריג,

327
00:11:14,940 --> 00:11:16,260
ואילו כל הדברים בתוך

328
00:11:16,770 --> 00:11:18,340
האליפסה הזאת שציירתי,

329
00:11:18,570 --> 00:11:21,320
נראים בסדר, או לא חריגים, דוגמאות לא חריגות.

330
00:11:22,110 --> 00:11:24,040
אז דוגמת מבחן x2

331
00:11:24,250 --> 00:11:26,260
נמצאת מחוץ

332
00:11:26,650 --> 00:11:27,510
לאזור הזה, ולכן

333
00:11:27,620 --> 00:11:30,280
יש לה הסתברות קטנה מאוד, ולכן אנו רואים בה דוגמה חריגה.

334
00:11:31,400 --> 00:11:32,990
בסרטון הזה דיברנו על איך

335
00:11:33,460 --> 00:11:35,440
אומדים את p של x, ההסתברות

336
00:11:35,590 --> 00:11:36,840
של x, לצורך

337
00:11:36,930 --> 00:11:38,740
פיתוח אלגוריתם זיהוי חריגים.

338
00:11:39,880 --> 00:11:40,890
ועוד בסרטון הזה

339
00:11:41,260 --> 00:11:42,970
עברנו על תהליך

340
00:11:43,830 --> 00:11:45,090
שבו כשאנחנו מקבלים ערכת נתונים,

341
00:11:45,340 --> 00:11:47,740
בנינו חישובים והערכות של הפרמטרים,

342
00:11:48,370 --> 00:11:50,570
חישבנו את הפרמטרים μ ו-σ,

343
00:11:50,700 --> 00:11:52,180
ואז קיבלנו דוגמאות חדשות והחלטנו

344
00:11:52,740 --> 00:11:54,110
אם הדוגמאות החדשות הן חריגות או לא.

345
00:11:55,490 --> 00:11:56,800
בכמה קטעי הוידאו הבאים

346
00:11:56,880 --> 00:11:58,580
אנו נצלול עמוק לתוך האלגוריתם הזה,

347
00:11:58,980 --> 00:11:59,930
ונדבר קצת יותר

348
00:12:00,230 --> 00:12:02,310
על איך באמת לגרום לו לעבוד היטב.