در ویدئوی قبل تعریف ریاضیاتی
تابع هزینه را بیان کردیم. در این ویدئو، چند مثال می‌زنیم تا بهتر متوجه شوید که تابع هزینه چه می‌کند و
چرا از آن استفاده می‌کنیم. برای خلاصه، مطالب ویدئوی قبل را مرور کنیم.
می‌خواهیم خطی راست برای داده‌هایمان رسم کنیم بنابراین تابع هزینه را بر حسب تتا صفر و تتا یک نوشتیم و گفتیم که با انتخاب پارامترهای مختلف به
خطوط راست مختلفی می‌رسیم. و تابع هزینه به این شکل است و این هم هدف بهینه‌سازی است.
در این ویدئو، برای تصویرسازی بهتر تابع هزینه،
می‌خواهم با تابع فرضیه ساده‌تری کار کنم، تابعی که در سمت راست نشان داده شده است.
پس می‌خواهم از فرضیه ساده‌تری که فقط برابر است با تتا یک ضرب‌در x استفاده کنم.
یعنی می‌توان فرض کرد که تتا صفر برابر صفر است.
پس فقط پارامتر تتا یک وجود دارد و تابع هزینه مثل قبل است با این تفاوت
که h برحسب x برابر با تتا یک ضرب‌در x است.
پس فقط پارامتر تتا یک را دارم و هدف بهینه‌سازی مینیمم کردن J بر حسب تتا یک است.
بر روی شکل، اگر تتا صفر برابر تتا یک باشد
یعنی تابع فرضیه‌ای را باید انتخاب کنیم که از مبدأ یعنی نقطه صفر و صفر می‌گذرد. استفاده از تعریف ساده‌تر تابع هزینه فرضیه
اجازه می‌دهد مفهوم تابع هزینه را بهتر بفهمیم.
دو تابع کلیدی است که باید بشناسیم. اول، تابع فرضیه است و
دوم تابع هزینه. توجه کنید که فرضیه یعنی h بر حسب x
برای مقدار ثابت تتا یک تابعی از x است. یعنی تابع فرضیه
برحسب بزرگی خانه (x) است. در مقابل، تابع هزینه J تابعی است که برحسب پارامتر تتا یک قرار دارد،
که شیب خط راست را تعیین می‌کند. این تابع‌ها را رسم می‌کنیم و سعی می‌کنیم بهتر درکشان کنیم.
بیایید با تابع فرضیه در سمت چپ آغاز کنیم. فرض کنید این مجموعه آموزشی من است
با سه نقطه یک و یک، دو و دو، و سه و سه. بیایید مقداری برای تتا یک انتخاب کنیم
مثلا بگوییم تتا یک برابر یک است. و اگر این مقدار را انتخاب کنم، تابع فرضیه خطی راست شبیه این می‌شود. و اشاره کنم که زمانی که تابع فرضیه را رسم می‌کنم محور x یعنی محور افقی با x نام‌گذاری شده،
یعنی اندازه خانه. حالا که تتا یک را برابر یک قرار دادم باید ببینم J بر حسب تتا یک زمانی که تتا یک
برابر با یک است چه مقداری دارد؟ پس بیایید محاسبه کنیم که تابع هزینه چه مقداری
برای تتا یک برابر با یک دارد. خب تعریف تابع هزینه به این شکل است:
مجموع مجموعه آموزشی و این هم از عبارت خطای مجذور.
و بنابراین برابر است با این: یک روی 2m ضرب‌در سیگما از یک تا m
ضرب‌در مجذور h برحسب xi منهای yi. که برابر است با صفر به توان دو به اضافه صفر به توان دو
به اضافه صفر به توان دو که برابر است با صفر. در این تابع هزینه، هرکدام از عبارت‌ها برابر صفر است، چون برای مجموعه آموزشی سه نقطه‌ای‌مان که برابر است با
نقاط یک و یک، و دو دو، و سه و سه، اگر تتا یک برابر یک باشد، آنگاه h برحسب x دقیقا برابر yi است. پس h بر حسب x منهای yi
برابر صفر است و به همین دلیل J بر حسب 1 برابر است با صفر. بیایید رسمش کنیم.
می‌خواهم در سمت راست تابع هزینه J را رسم کنم. و توجه کنید که چون تابع هزینه
برحسب پارامتر تتا یک است، زمانی که تابع هزینه را رسم می‌کنم
نام محور افقی تتا یک است. داریم J برحسب یک برابر است با صفر.
پس رسمش می‌کنیم. همین ضرب‌در روی یک.
مثالی دیگر بزنیم. تتا یک می‌تواند مقادیر متفاوتی داشته باشد. می‌تواند مقادیری مثبت یا منفی داشته باشد. پس اگر تتا یک برابر 0.5 باشد چه؟
بیایید رسمش کنیم. تتا یک را برابر 0.5 قرار می‌دهم و بدین ترتیب فرضیه شبیه این می‌شود، خطی که شیبش 0.5 است.
پس J را بر حسب 0.5 محاسبه می‌کنیم. پس می‌شود یک روی 2m و
همان تابع هزینه همیشگی. تابع هزینه برابر می‌شود با مجموع مجذورات طول این خط، به اضافه مجموع مجذور طول این خط، به اضافه مجموع مجذور طول این خط،
چون این فاصله‌ی عمودی همان اختلاف میان yi و
مقدار پیش‌بینی h برحسب xi است. پس اولین نمونه برابر است با
مجذور 0.5 منهای یک چون فرضیه 0.5 را پیش‌بینی کرده
و مقدار واقعی یک بوده. برای مثال دوم داریم
مجذور یک منهای دو چون فرضیه یک را پیش‌بینی کرده اما قیمت واقعی ۲ است
و سرانجام داریم مجذور 1.5 منهای سه. و این برابر است با
یک روی دو ضرب‌در سه، چون m اندازه مجموعه است
و در اینجا سه مثال آموزشی داریم. پرانتز را اگر ساده کنیم می‌شود 3.5
پس داریم 3.5 روی شش که حدود 0.68 است. اکنون می‌دانیم که J برحسب 0.5 برابر است با 0.68.
بیایید ترسیمش کنیم. ببخشید، اشتباه ریاضی، در واقع برابر 0.58 است
که حدودا می‌شود اینجا. یکی دیگر هم انجام دهیم.
اگر تتا یک برابر صفر باشد چه؟ یعنی J برحسب صفر چه می‌شود.
اگر تتا یک برابر صفر باشد آنگاه h بر حسب x یک خط راست است
که کاملا افقی است. و خب با اندازه‌گیری خطاها داریم که
J برحسب صفر برابر است با یک روی 2m ضرب‌در مجذور یک به اضافه مجذور دو
به اضافه مجذور سه که برابر است با یک ششم ضرب‌در چهار
که برابر 2.3 است. این نقطه را هم رسم کنیم. 2.3 حدودا اینجا است.
می‌توانیم این کار را برای مقادیر دیگری برای تتا یک ادامه دهیم.
می‌توانید مقادیر منفی هم برای تتا یک داشته باشید، اگر تتا یک منفی باشد
آنگاه h برحسب x برابر خواهد بود با مثلا 0.5x- پس تتا یک برابر منفی 0.5 است، و این یعنی شیب h برابر منفی 0.5 است، و می‌توانید این خطاها را محاسبه کنید و
مثلا برای منفی 0.5 خطای زیادی دارید که حدود 5.25 است، و الی آخر. برای مقادیر متفاوت تتا یک
می‌توانید محاسبه کنید، و برای این مقادیر به چیزی شبیه به این می‌رسید. و کم کم می‌توانید این را رسم کنید. خب این معنای تابع J برحسب تتا است
و کاری که می‌کند. به طور خلاصه، هر مقدار تتا یک برابر است با تابع فرضیه متفاوت یا خط مستقیم متفاوت
و برای هر مقدار تتا یک به مقدار متفاوتی برای تابع J برحسب تتا می‌رسیم، و مثلا برای تتا یک مساوی 1
این خط مستقیم را داریم، و برای تتا یک مساوی 0.5
این خط صورتی را داریم، و برای تتا یک مساوی 0
این خط آبی را داریم که کاملا افقی است.
پس برای هر مقدار تتا یک به مقدار متفاوتی برای J برحسب تتا یک می‌رسیم
و در نهایت شکل سمت راست به دست می‌آید. اگر یادتان باشد هدف بهینه‌سازی
برای الگوریتم یادگیری این است که می‌خواهیم مقداری را
برای تتا یک انتخاب کنیم که تابع J را مینیمم کند. این تابع هدف برای رگرسیون خطی بود. با نگاه به این منحنی می‌بینیم
مقدار تتا یک که J در آن مینیمم است برابر 1 است
و می‌بینید که واقعا هم بهترین خط راست ممکن با تتا یک برابر 1 به دست می‌آید.
و برای این مجموعه آموزشی به خطی کاملا متناسب دست یافتیم.
و به همین خاطر مینیمم کردن J برحسب تتا یک ارتباط دارد با پیدا کردن خط مستقیمی که
تناسب خوبی با داده‌ها داشته باشد. خلاصه این درس اینکه
چند نقطه رسم کردیم، تا تابع هزینه را درک کنیم.
برای این کار الگوریتم را ساده‌سازی کردیم، به طوری که فقط تتا یک را در نظر گرفتیم
و تتا صفر را برابر 0 قرار دادیم. در ویدئوی بعد به فرمول مسأله اصلی برمی‌گردیم و به تابعی که هم تتا یک و تتا صفر داشته باشد نگاه می‌کنیم. یعنی تتا صفر را برابر 0 قرار نمی‌دهیم.
و امیدوارم که این کار درک بهتری به شما از کارکرد تابع هزینه J در فرمول رگرسیون خطی بدهد.