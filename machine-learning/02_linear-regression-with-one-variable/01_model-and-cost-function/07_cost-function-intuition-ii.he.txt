בסרטון הזה, נעמיק ונקבל אינטואיציה אפילו יותר טובה על תפקידה של פונקצית העלות. וידאו זה מבוסס על ההנחה שאתה מכיר תרשימי קווי גובה. אם אתה לא מכיר את זה, ייתכן שחלק מהאיורים בוידאו הזה לא ייראו לכם הגיוניים אבל זה בסדר ואם בסופו של דבר תדלג על הוידאו או על חלק ממנו שלא מובן לך, כי אתה לא מכיר את סוג התרשימים הזה, אז זה עדיין בסדר, ועדיין תצליח להבין את שאר הקורס הזה בלי החלקים האלה. הנה הניסוח הרגיל של הבעיה שלנו, עם הפרמטרים של פונקצית ההשערה, פונקצית העלות, ומטרת האופטימיזציה שלנו. שלא כמו בווידאו שעבר, הפעם נשתמש בשני הפרמטרים θ₀ ו-θ₁, ביצירת הויזואליזציה של פונקציית העלות. אז בדיוק כמו בפעם שעברה, אנו רוצים לחקור את פונקצית ההשערה h ופונקצית העלות J. הנה סדרת האימון של מחירי הבתים ובואו נבנה איזו השערה, כמו זו, היא לא השערה טובה במיוחד. אבל אם אני מגדיר θ₀ = 50 ו-θ₁ = 0.06, אז אני מקבל את ההשערה הזו כאן שמתאימה לישר הזה. עכשיו בהינתן ערכים אלה של θ₀ ו-θ₁, אנחנו רוצים לשרטט את פונקצית העלות המתאימה מימין, כמו שעשינו בפעם הקודמת כשהיתה לנו רק θ₁. במילים אחרות, נצייר גרפים שנראים כמו זה שהוא פונקציה של θ₁. אבל עכשיו יש לנו שני פרמטרים, θ₀ ו-θ₁, וכך העלילה מסתבכת. כשהיה לנו פרמטר אחד בלבד, הגרף שציירנו היה מין פונקציה כזו בצורת קערה. ועכשיו כשיש לנו שני פרמטרים, מתברר שפונקצית העלות גם הפעם דומה לצורת קערה. ואכן, בהתאם לסדרת האימון שלך, אתה עשוי לקבל פונקציית עלות שאולי נראית משהו כזה. אז זהו גרף שהוא משטח במרחב תלת-ממדי, שבו הצירים הם θ₀ ו-θ₁. כשמשנים את שני הפרמטרים, θ₀ וב-θ₁, מקבלים ערכים שונים של פונקצית העלות (J(θ₀, θ₁ שהם גובה המשטח הזה מעל כל נקודה מסוימת (θ₀, θ₁). זה הציר האנכי. גובה המשטח מעל הנקודה נותן את הערך של הפונקציה (J(θ₀, θ₁. ואתם יכולים לראות שיש לזה מין צורת קערה. הרשו לי להראות את אותו הגרף בשלשה ממדים. אז הנה אותה תמונה בתלת-ממד, הציר האופקי θ₁ והציר האנכי (J(θ₀, θ₁, ואם אני מסובב את התרשים, אתם יכולים, אני מקווה, לראות מין צורה קעורה כזו וכך אכן נראית פונקצית העלות J. עכשיו לצורך ההמחשה בשאר הסרטון הזה אני לא מתכוון להשתמש במשטחים התלת-ממדיים האלה כדי להראות לכם את פונקצית העלות J, ובמקומם אני אשתמש בתרשימי קווי-גובה.או מה שאני קורא גם תמונות קווי גובה. אני מניח שזה אותו דבר. כדי להראות לכם כאלה משטחים, הנה דוגמא אחת בצד ימין. הצירים הם θ₀ ו-θ₁. וכל אחת מהאליפסות האלה, מה שכל אליפסה מראה הן קבוצה של נקודות שמקבלת אותו ערך עבור (J(θ₀, θ₁. אז באופן קונקרטי, למשל, תוכל לקחת את הנקודה הזו, הזו והזו. לכל שלוש הנקודות הללו שכרגע צבעתי במגנטה יש אותו ערך של (J(θ₀, θ₁, בסדר.הצירים הם θ₀ ו-θ₁ אבל לשלוש הנקודות יש אותו ערך של (J(θ₀, θ₁. ואם לא ראיתם מפות קווי גובה קודם, תחשבו או תדמיינו פונקציה בצורת קערה שיוצאת מהמסך שלי. אז זה המינימום, כך התחתית של הקערה היא בנקודה הזו שם, כן? המרכז הזה, המרכז של האליפסות הקונצנטריות האלה. ותדמיינו לעצמכם מין צורת קערה כזו בולטת מתוך המסך שלי ככה, כך שכל אחת מהאליפסות האלה נמצאת בגובה אחיד מעל המסך שלי. ואת המינימום כאן בקערה, כאן. אז תרשימי קווי גובה הם אולי דרך נוחה יותר כדי להמחיש את הפונקציה J. אז בואו נסתכל על כמה דוגמאות. הנה, יש לי נקודה מסוימת, נכון? בנקודה הזו θ₀ שווה אולי כ-800, θ₁ שווה אולי 0.15-. אז הנקודה הזו באדום מציינת זוג ערכים, θ₀, θ₁ והיא מקבילה למעשה להשערה הזו, θ₀ הוא כ-800, כלומר, הוא מצטלב עם הציר האנכי בכ-800, והשיפוע הוא של כ-0.15-. עכשיו הקו הזה הוא ממש לא כל כך מתאים טוב לנתונים. ההשערה הזו, (h(x, עם הערכים האלו של θ₀ ו-θ₁, ממש לא מתאימה מאוד לנתונים. ולכן אנו רואים שהעלות, הערך הזה של הפונקציה כאן, הוא די רחוק מהמינימום, וזאת אומרת שהמחיר גבוה למדי כי ההתאמה לנתונים פשוט לא כל כך טובה. בואו נסתכל על עוד כמה דוגמאות. עכשיו הנה השערה שונה שעדיין לא מתאימה כל כך טוב לנתונים אבל יכול להיות שהיא מעט טובה יותר, אז הנה, זאת הנקודה שלי, אלה הם הפרמטרים שלי θ₀ ו-θ₁, ערכו של θ₀ כאן הוא בערך 360 והערך של θ₁ הוא אפס. אז בואו ננתח את זה. בואו ניקח θ₀ שווה 360 ו-θ₁ שווה אפס. הזוג הזה של פרמטרים תואם להשערה הזו, לקו השטוח, (h(x שווה 360 פלוס אפס כפול x. אז זו ההשערה. ויש לה עלות, והעלות מובעת כגובה של הפונקציה J בנקודה זו. בואו נראה עוד כמה דוגמאות. הנה עוד אחת, בערכים האלה של θ₀ ו-θ₁ אנחנו מגיעים להשערה הזו, (h(x ושוב לא בהתאמה טובה לנתונים, והיא אפילו יותר רחוקה מהמינימום. ודוגמה אחרונה, בעצם לא ממש מינימום אבל די קרובה למינימום. התאמה לא רעה לנתונים, עבור הערכים האלה של θ₀ ו-θ₁ אנחנו מקבלים (h(x שהוא לא ממש המינימלי אבל די קרוב. הסכום של ריבועי השגיאות, הסכום של ריבועי המרחקים בין דגימות האימון ובין ההשערה. זה סכום של ריבועי מרחקים, נכון? מכל סכומי השגיאות הללו. זה די קרוב למינימום למרות שזה לא ממש המינימום. אז עם הגרפים האלה אני מקווה שקיבלתם הבנה יותר טובה של מהם ערכי פונקצית העלות J ואיך הם מתאימים להשערות שונות ואיך השערות יותר טובות עשויות להיות תואמות לנקודות יותר קרובות למינימום של פונקצית העלות הזו J. עכשיו כמובן מה שאנחנו באמת רוצים הוא אלגוריתם יעיל, תוכנה יעילה למציאה אוטומטית של הערכים של θ₀ ו-θ₁ שימזערו את פונקצית העלות, נכון? ואנחנו לא רוצים לכתוב תוכנה שתשרטט את הגרף הזה ואז תנסה לראות את הגרף ולהוציא ממנו את המספרים, כי זו לא דרך טובה לעשות את זה. נראה מאוחר יותר גם שכאשר נתבונן בדוגמות מסובכות יותר, תהיינה לנו תמונות רב-ממדיות עם עוד פרמטרים, ונראה בהמשך הקורס הזה, דוגמאות בהן לא כל כך אפשרי בכלל לצייר את הגרף והרבה יותר קשה לדמיין אותו. אז מה שאנחנו רוצים זה תוכנה שתמצא את הערכים של θ₀ ו-θ₁ שממזערים את הפונקציה הזו. בסרטון הבא נתחיל לדבר על אלגוריתם למציאה אוטומטית של ערכי θ כך שימזערו את פונקצית העלות J.