1
00:00:00,620 --> 00:00:03,800
در این ویدئو تابع هزینه را تعریف می‌کنم.

2
00:00:03,800 --> 00:00:07,480
با این تابع می‌توانیم بهترین خط مستقیم را
برای داده‌هایمان به دست آوریم.

3
00:00:10,310 --> 00:00:13,820
در رگرسیون خطی،
مجموعه داده‌هایمان همانند این است،

4
00:00:13,820 --> 00:00:18,870
و یادتان است که حرف m بیانگر
تعداد مثال‌های آموزشی است، مثلا شاید m برابر ۴۷ باشد.

5
00:00:18,870 --> 00:00:20,989
و شکل تابع فرضیه،

6
00:00:22,210 --> 00:00:25,360
که از آن برای پیش‌بینی استفاده می‌کنیم،
این تابع خطی است.

7
00:00:26,430 --> 00:00:31,240
اصطلاحات تخصصی بیشتری را تعریف می‌کنیم
و می‌گوییم این تتا صفر

8
00:00:31,240 --> 00:00:37,260
و تتا یک، آنچه را پارامترهای مدل
نامیده می‌شود تثبیت می‌کنند.

9
00:00:37,260 --> 00:00:42,560
و در این ویدئو می‌گوییم چگونه

10
00:00:42,560 --> 00:00:47,550
این دو پارامتر یعنی تتا صفر و تتا یک را انتخاب کنیم.

11
00:00:47,550 --> 00:00:51,100
با انتخاب متفاوت پارامترهای تتا صفر و تتا یک

12
00:00:51,100 --> 00:00:55,250
فرضیه‌های متفاوت،
یعنی تابع‌های فرضیه متفاوت به دست می‌آوریم.

13
00:00:55,250 --> 00:00:58,170
می‌دانم بعضی از شما آشنا هستید با

14
00:00:58,170 --> 00:01:02,110
مطالبی که می‌خواهم بگویم
ولی برای مرور چند مثال می‌زنم.

15
00:01:02,110 --> 00:01:05,990
اگر تتا صفر برابر 1.5 و تتا یک برابر 0 باشد

16
00:01:05,990 --> 00:01:08,870
تابع هزینه شبیه این است.

17
00:01:10,070 --> 00:01:17,610
چون تابع فرضیه برابر است با
h برحسب x مساوی است با 1.5 به اضافه صفر ضرب در

18
00:01:17,610 --> 00:01:22,533
x که در این تابع مقدار ثابت است
که در نقطه 1.5 ثابت است.

19
00:01:22,533 --> 00:01:26,600
اگر تتا صفر برابر 0 و تتا یک برابر 0.5 باشد

20
00:01:26,600 --> 00:01:31,420
بنابراین فرضیه شبیه این است و از

21
00:01:31,420 --> 00:01:34,850
نقطه (1 ,2) می‌گذرد و این
h بر حسب x است.

22
00:01:34,850 --> 00:01:40,150
یا در واقع h تتا بر حسب x است
ولی گاهی برای اختصار تتا را حذف می‌کنم.

23
00:01:40,150 --> 00:01:45,570
پس h برحسب x مساوی است با
0.5 ضرب در x که شبیه این است.

24
00:01:45,570 --> 00:01:49,830
و در آخر اگر تتا صفر برابر 1 و تتا یک برابر 0.5 باشد،

25
00:01:49,830 --> 00:01:53,280
پس تابع فرضیه شبیه این است.

26
00:01:53,280 --> 00:01:59,670
از نقطه 2 و 2 می‌گذرد.

27
00:01:59,670 --> 00:02:04,640
این تابع جدید h بر حسب x
یا دقیق‌تر تابع h اندیس تتا بر حسب x است.

28
00:02:04,640 --> 00:02:08,618
الان نوشتن h اندیس تتا بر حسب x اما

29
00:02:08,618 --> 00:02:12,095
گاهی برای اختصار فقط می‌نویسم
h بر حسب x.

30
00:02:13,917 --> 00:02:19,330
در رگرسیون خطی، مجموعه آموزشی‌ای داریم،
مانند چیزی که اینجا رسم کردم.

31
00:02:19,330 --> 00:02:24,880
و می‌خواهیم مقادیری برای
دو نقطه تتا صفر و تتا یک به دست آوریم

32
00:02:24,880 --> 00:02:29,960
به طوری که خط راستی که رسم می‌کنیم

33
00:02:29,960 --> 00:02:33,500
بهترین تطابق را با داده‌هایمان داشته باشد.

34
00:02:34,590 --> 00:02:37,190
خب چگونه مقادیری برای

35
00:02:37,190 --> 00:02:40,650
تتا صفر و تتا یک به دست آوریم
که تطابق خوبی برای داده‌هایمان داشته باشد؟

36
00:02:42,540 --> 00:02:46,460
هدف این است که پارامترهای تتا صفر
و تتا یک را به گونه‌ای انتخاب کنیم

37
00:02:46,460 --> 00:02:51,190
که h برحسب x، یعنی مقداری که
بر حسب x پیش‌بینی می‌کنیم

38
00:02:51,190 --> 00:02:55,730
تا جای ممکن به مقادیر y در

39
00:02:55,730 --> 00:02:59,908
مثال‌های مجموعه آموزشی نزدیک باشد.

40
00:02:59,908 --> 00:03:04,000
در مجموعه آموزشی چند نمونه داریم که می‌دانیم

41
00:03:04,000 --> 00:03:07,350
x تصمیم‌گیرنده اصلی است
و همچنین قیمت‌های واقعی فروش خانه‌ها را هم می‌دانیم.

42
00:03:07,350 --> 00:03:11,100
خب مقادیری برای پارامترها
انتخاب می‌کنیم به طوری که

43
00:03:11,100 --> 00:03:13,830
حداقل در مجموعه آموزشی
با توجه به xهای مجموعه آموزشی

44
00:03:13,830 --> 00:03:19,040
پیش‌بینی‌های واقعی برای مقادیر y انجام شود.

45
00:03:19,040 --> 00:03:20,980
خب فرمولش را بنویسیم.

46
00:03:20,980 --> 00:03:23,700
در رگرسیون خطی کاری که می‌کنیم این است که

47
00:03:23,700 --> 00:03:27,430
مسأله مینیمم کردن را باید حل کنیم
(مترجم: مینیمم کردن اختلاف بین مقادیر واقعی و مقادیر پیش‌بینی)

48
00:03:27,430 --> 00:03:34,319
پس می‌نویسم مینیمم کردن تتا صفر و تتا یک.

49
00:03:34,319 --> 00:03:39,620
و می‌خواهم این عبارت مینیمم باشد.

50
00:03:39,620 --> 00:03:42,960
می‌خواهم تفاضل میان h برحسب x
و y کوچک باشد.

51
00:03:42,960 --> 00:03:47,770
و کاری که می‌کنم مجذور تفاضلِ

52
00:03:47,770 --> 00:03:51,226
خروجی تابع فرضیه
و قیمت واقعی خانه‌ها را مینیمم می‌کنم.

53
00:03:51,226 --> 00:03:54,600
خب، به جزئیات بپردازیم.

54
00:03:54,600 --> 00:03:59,328
یادتان هست که از عبارت
((x(i),y(i) استفاده کردم

55
00:03:59,328 --> 00:04:02,380
تا iامین مثال آموزشی را نشان دهم.

56
00:04:02,380 --> 00:04:07,480
پس در واقع می‌خواهم برای مجموعه آموزشی

57
00:04:07,480 --> 00:04:10,666
یعنی از i = 1 تا m

58
00:04:10,666 --> 00:04:16,040
مجموع مجذور تفاضل میان پیش‌بینی

59
00:04:16,040 --> 00:04:21,261
تابع فرضیه که ورودی‌اش اندازه خانه است،

60
00:04:22,560 --> 00:04:25,530
منهای قیمت واقعی خانه را

61
00:04:25,530 --> 00:04:29,630
که به فروش رفته است مشخص کنم.
و من می‌خواهم مجموع مجموعه آموزشی را مینیمم کنم.

62
00:04:29,630 --> 00:04:34,240
مجموعه i از یک تا m،
برای تفاضل میان این خطای مجذور.

63
00:04:34,240 --> 00:04:37,160
مجذور اختلاف میان قیمت پیش‌بینی یک خانه

64
00:04:37,160 --> 00:04:40,550
و قیمتی که خانه در واقع فروخته شده است.

65
00:04:40,550 --> 00:04:46,950
و یادآوری می‌کتم که این علامت m
تعداد مجموعه آموزشی بود.

66
00:04:46,950 --> 00:04:50,570
پس این m بیانگر تعداد نمونه‌های آموزشی است.

67
00:04:50,570 --> 00:04:57,750
این هش تگ مخفف تعداد نمونه‌های آموزشی است.

68
00:04:57,750 --> 00:05:01,270
و برای اینکه بعضی از
فرمول‌های ریاضی آسان‌تر شود،

69
00:05:01,270 --> 00:05:05,950
می‌خواهم عبارت یک روی m را بنویسم،

70
00:05:05,950 --> 00:05:09,380
بنابراین این عبارت را
ضرب‌در یک روی 2m می‌کنم و مینیمم می‌کنم.

71
00:05:09,380 --> 00:05:14,450
قرار دادن ۲ در اینجا یعنی عبارت را نصف می‌کنیم

72
00:05:14,450 --> 00:05:18,730
و اینگونه کار ریاضی آسان‌تر می‌شود،
چون می‌دانیم که مینیمم کردن نصف چیزی

73
00:05:18,730 --> 00:05:23,130
همانند مینیمم کردن همان چیز است
و تتا صفر و تتا یک در تابع مینیمم به دست می‌آیند.

74
00:05:24,300 --> 00:05:27,640
و برای اطمینان معادله را توضیح می‌دهیم.

75
00:05:27,640 --> 00:05:31,452
این عبارت در اینجا،

76
00:05:31,452 --> 00:05:36,560
h تتا برحسب ایکس

77
00:05:37,890 --> 00:05:42,668
برابر است با
تتا صفر به اضافه تتا یک ضرب‌در xi.

78
00:05:42,668 --> 00:05:48,050
و این عبارت،
مینیمم کردن تتا صفر و تتا یک،

79
00:05:48,050 --> 00:05:53,140
یعنی باید مقادیری برای تتا صفر و تتا یک
که این معادله را تشکیل داده‌اند پیدا کنید.

80
00:05:53,140 --> 00:05:57,620
یعنی مینیمم کردن این عبارت بستگی به
تتا صفر و تتا یک دارد.

81
00:05:57,620 --> 00:05:58,710
پس خلاصه کنیم.

82
00:05:58,710 --> 00:06:03,380
این مسأله را تغییر دادیم به
پیداکردن مقادیری برای تتا صفر و تتا یک

83
00:06:03,380 --> 00:06:07,210
به طوری که میانگین عبارت
یک روی 2m

84
00:06:07,210 --> 00:06:11,240
ضرب‌در مجموع مجذور
پیش‌بینی‌های مجموعه آموزشی

85
00:06:11,240 --> 00:06:15,250
منهای قیمت واقعی خانه‌ها در مجموعه آموزشی
مینیمم باشد.

86
00:06:15,250 --> 00:06:20,709
پس هدف نهایی تابع رگرسیون خطی این است.

87
00:06:22,080 --> 00:06:27,250
و به شکلی ساده‌تر اگر بنویسیم،

88
00:06:27,250 --> 00:06:29,790
بنا به قرارداد، تابع هزینه‌ای را تعریف می‌کنیم

89
00:06:31,240 --> 00:06:35,930
که دقیقا این فرمول اینجا است.

90
00:06:37,040 --> 00:06:45,289
و هدف من مینیمم کردن تتا صفر و تتا یک

91
00:06:45,289 --> 00:06:51,770
در تابع J برحسب تتا صفر و تتا یک است.

92
00:06:51,770 --> 00:06:52,430
نوشتیمش.

93
00:06:53,730 --> 00:06:56,540
این تابع هزینه است.

94
00:06:59,380 --> 00:07:04,960
این تابع هزینه
تابع خطای مجذور نیز نامیده می‌شود.

95
00:07:06,850 --> 00:07:11,190
و گاهی اوقات به آن تابع هزینه خطای مجذور هم می‌گویند.

96
00:07:11,190 --> 00:07:15,730
دلیل اینکه مجذور خطاها را
محاسبه می‌کنیم این است که

97
00:07:15,730 --> 00:07:19,660
مشخص شده که این تابع هزینه خطای مجذور
انتخابی منطقی است

98
00:07:19,660 --> 00:07:22,990
و برای بیشتر مسائل رگرسیون مناسب است.

99
00:07:22,990 --> 00:07:25,740
توابع هزینه‌ی دیگری هم وجود دارند که مناسبند،

100
00:07:25,740 --> 00:07:29,860
اما تابع هزینه مجذور
احتمالا رایج‌ترین تابع

101
00:07:29,860 --> 00:07:30,935
برای مسائل رگرسیون است.

102
00:07:30,935 --> 00:07:34,980
بعدتر در مورد دیگر توابع هزینه هم صحبت می‌کنیم،

103
00:07:34,980 --> 00:07:39,085
اما این تابع که الان انتخاب کردیم
تابع بسیار خوبی

104
00:07:39,085 --> 00:07:41,030
برای بیشتر مسائل رگرسیون است.

105
00:07:42,340 --> 00:07:43,030
بسیار خب.

106
00:07:43,030 --> 00:07:44,280
این تابع هزینه است.

107
00:07:45,340 --> 00:07:50,840
تا اینجا فقط تعریف ریاضی این تابع هزینه را دیدیم.

108
00:07:50,840 --> 00:07:54,310
اگر تابع J برحسب تتا صفر و تتا یک،

109
00:07:54,310 --> 00:07:56,260
کمی انتزاعی به نظر می‌رسد،

110
00:07:56,260 --> 00:07:58,885
و به طور کامل متوجه نشدید چه کاری انجام می‌دهد

111
00:07:58,885 --> 00:08:03,210
در چند ویدئوی بعدی می‌خواهم

112
00:08:03,210 --> 00:08:07,930
به صورت جزئی‌تر نشان دهم
که تابع هزینه J چه می‌کند و تلاش کنم تا

113
00:08:07,930 --> 00:08:11,730
بهتر متوجه شوید که چه چیزی را محاسبه می‌کند
و چرا می‌خواهیم از این تابع استفاده کنیم.