در ویدئوی قبل
 تابع هزینه J را تعریف کردیم. این ویدیو در مورد الگوریتم
گرادیان نزولی برای مینیمم کردن تابع هزینه J است. گرادیان نزولی یک الگوریتم کلی تر است، و تنها در رگرسیون خطی کاربرد ندارد. در واقع در کل یادگیری ماشین استفاده می شود. و درادامه کلاس، ازگرادیان نزولی برای به حداقل رساندن توابع دیگر نیزاستفاده می کنیم.
نه فقط برای تابع هزینه J در رگرسیون خطی. دراین ویدیو، در مورد گرادیان نزولی
صحبت می‌کنیم برای به حداقل رساندن چند تابع دلخواه J و سپس درویدیو بعد، این الگوریتم را به طور خاص استفاده می‌کنیم
برای تابع هزینه J که تعریف کردیم برای رگرسیون خطی. صورت مسأله این است. فرض می کنیم که تابع J ( تتا صفر و تتا یک) راداریم
که ممکن است تابع هزینه رگرسیون خطی باشد
یا هرتابع دیگری که می خواهیم به حداقل برسانیم. و می خواهیم الگوریتمی برای حداقل رسانی تابع J (تتا صفر و تتا یک) بدست آوریم. در حاشیه بگویم
که گرادیان نزولی در واقع برای تابع‌های عمومی‌تر استفاده می‌شود. بنابراین تصور کنید، تابع J را ،
به صورت تابعی برای تتا صفر، تتا یک، تتا دو تا تتا n و
می خواهید برای تتا صفر به حداقل برسانید. یعنی می‌خواهید در تابع J برای تتا صفر تا تتا n
مقادیر تتا صفر تا تتا n را مینیمم کنید. گرادیان نزولی الگوریتمی است برای حل این مسأله‌ی کلی‌تر. اما به خاطر اختصار و استفاده کمتر از نمادها، وانمود می کنم که در بقیه این ویدیو، فقط دو پارامتردارم. گرادیان نزولی به این شکل کار می‌کند. آنچه که قصد انجامش را داریم این است
که با برخی از حدس های اولیه برای تتا صفر و تتا یک شروع می کنیم. واقعا مهم نیست که آنها چه هستند،
اما یک انتخاب معمول این خواهد بود که تتا صفرو تتا یک را صفر در نظر می گیریم،
مقدار دهی اولیه صفر. چیزی که ما در گرادیان نزولی انجام خواهیم داد، تغییر تتا 0 و تتا یک به میزان جزیی است تا تابع هزینه J(تتا صفر و تتا یک) کاهش یابد تا زمانی که 
به مینیمم و یا مینیمم محلی برسیم. اجازه دهید در نمودار ببینیم
که گرادیان نزولی چه می کند. فرض کنیم می‌خواهید این تابع را
مینیمم کنید. به محورها دقت کنید، این تتا صفر، و تتا یک در محور افقی و
تابع هزینه J در محور عمودی است. بنابراین ارتفاع ازسطح، تابع هزینه J را نشان می دهد و
می خواهیم این تابع را مینیمم کنیم. پس باید با تتا 0، تتا 1 درنقطه ای شروع کنیم. مقادیری برای تتا صفر و تتا یک فرض می کنیم و آن نقطه جایی در این تابع
قرار می‌گیرد. به ازای هر مقدار برای تتا صفر و تتا یک
مقداری به دست خواهید آورد. من مقادیر اولیه‌ی صفر و صفر
را در نظر گرفتم اما می‌توانید از مقادیر دیگر هم
شروع کنید. می‌خواهم تصور کنید که این تصویر
مانند چشم‌انداز است. تصور کنید که چشم‌انداز پارکی سرسبز است. که دو تپه هم دارد.
و می‌خواهم تصور کنید که خودتان روی این نقطه،
روی تپه قرمزرنگ در پارک ایستاده‌اید. در گرادیان نزولی،
در تمامی جهت‌ها می‌چرخیم اطرافمان را نگاه می‌کنیم
و فرض می‌کنیم می‌خواهیم قدمی کوچک به یک جهت برداریم و
در سریع‌ترین زمان به پایین برسیم. به کدام جهت باید حرکت کنم اگر بخواهم پایین بروم؟ یعنی اگر بخواهم به سرعت
به پایین تپه برسم؟ اگر آن بالای تپه ایستاده باشید،
و به اطراف نگاه کنید، می‌بینید که بهترین مسیر برای پایین رفتن تقریبا این مسیر است. حالا در این نقطه جدید تپه هستید. دوباره به اطراف نگاه می کنید و می‌گویید در کدام جهت با قدمی کوچک
به سمت پایین می‌روم؟ و اگر این کار را بکنید و قدمی دیگر بردارید
در این مسیر خواهد بود. و ادامه می‌دهید. از این نقطه جدید نگاه می‌کنید تصمیم می‌گیرید کدام جهت
شما را سریع‌تر به پایین می‌رساند. قدمی دیگر برمی‌دارید، و قدمی دیگر و الی آخر تا به این مینیمم موضعی
در اینجا می‌رسید. گرادیان نزولی ویژگی جالبی دارد. اولین زمانی که گرادیان نزولی را شروع کردیم
از اینجا شروع کردیم. صحیح؟ از اینجا شروع کردیم. اکنون تصور کنید گرادیان نزولی را
کمی مایل به راست شروع کرده بودیم. تصور کنید گرادیان نزولی را
از این نقطه راست و بالاتر شروع کرده بودیم. اگر می‌خواستید این فرایند را تکرار کنید،
به اطراف نگاه کنید، قدمی کوچک بردارید تا سریع‌تر
به پایین برسید، این کار را می‌کردید. بعد نگاه می‌کردید و قدم برمی‌داشتید،
الی آخر. اگر فقط کمی از سمت راست شروع می‌کردید
گرادیان نزولی شما را به دومین مینیمم موضعی
در سمت راست می‌برد. اگر از نقطه اول شروع می‌کردید
به این نقطه بهینه موضعی می‌رسیدید، اما اگر از مکانی کمی راست‌تر شروع می‌کردید به نقطه بهینه‌ی موضعی
کاملا متفاوتی می‌رسیدید. و این ویژگی گرادیان نزولی است که کمی بعد بیشتر در موردش می‌گوییم. پس در تصویر موضوع را فهمیدیم. اکنون بیایید ریاضیاتش را ببینیم. این تعریف الگوریتم گرادیان نزولی است. قرار است به صورت مکرر
این کار را انجام دهیم تا به مینیمم برسیم. مقدار پارامتر تتا j را تغییر می‌دهیم،
به این صورت که مقدار تتا j را با کسر این عبارت ضرب‌در آلفا
تغییر می‌دهیم. جزئیات زیادی در این معادله وجود دارد
که در مورد بعضی‌شان صحبت می‌کنیم. اول در مورد علامت =: صحبت کنیم.
از =: برای نسبت دادن استفاده می‌کنیم.
پس عملگر منسوب کننده است. به طور خلاصه، اگر بنویسم
a := b
به این معنی است که کامپیوتر مقدار b را می‌گیرد
و آن را با مقدار قبلی a جایگزین می‌کند. پس یعنی مقدار a را برابر
مقدار b قرار می‌دهیم که این منسوب کردن است. همچنین می‌شود نوشت:
a := a + 1 این یعنی مقدار a را به اضافه یک کن. در مقابل، اگر از علامت مساوی استفاده کنم می‌نویسم a برابر است با b
و این عبارتی خبری است. پس اگر بنویسم a برابر است با b، می‌گویم که
مقدار a با مقدار b برابر است. پس قسمت چپ
عملگر کامپیوتری است که مقدار a را به مقداری جدید
تغییر می‌دهیم. قسمت سمت راست، عبارت خبری است،
فقط دارم بیان می‌کنم که مقادیر a و b برابرند، پس اگر بنویسم
a := a + 1
یعنی a را یکی افزایش می‌دهیم. پس نباید بنویسم
a = a + 1
چون غلط است. a و a + 1 هرگز نمی‌توانند
با هم برابر باشند. خب. خب این اولین قسمت تعریف بود. این آلفا در اینجا
عددی است که «نرخ یادگیری» نامیده می‌شود. و کاری که آلفا می‌کند، در واقع کنترل کردن این است که قدم‌مان به سمت پایین
چقدر بزرگ باشد. پس اگر آلفا خیلی بزرگ باشد،
گرادیان نزولی خیلی بزرگ خواهد بود
و یعنی قدم بزرگی به سمت پایین برمی‌داریم، و اگر آلفا خیلی کوچک باشد
یعنی قدم‌های کوچکی برمی‌داریم. بعدا برمی‌گردم و بیشتر توضیح می‌دهم
که چطور آلفا را تعیین کنیم. و در نهایت عبارت اینجا،
عبارت مشتق است. اکنون نمی‌خواهم در موردش صحبت کنم
ولی بعدا مشتق این عبارت را می‌گیرم و می‌گویم که دقیقا چیست. بعضی از شما احتمالا آشنایی بیشتری
با حسابان داریم، اما اگر با حسابان آشنا نیستید
نگران نباشید. به شما می‌گویم که در مورد این عبارت
چه چیزهایی باید بدانید. ظرافت دیگری هم در مورد
گرادیان نزولی وجود دارد که در گرادیان نزولی باید
مقادیر تتا صفر و تتا یک را پیوسته تغییر دهیم. پس این تغییر برای j = 0
و j = 1 صورت می‌گیرد. پس قرار است تتا صفر و تتا یک تغییر کنند. و ظرافت اعمال گرادیان نزولی این است،
که در این عبارت، این عبارت تغییرکننده، به طور پیوسته باید تتا صفر و تتا یک را تغییر دهید. منظورم این است که در این معادله
مقدار تتا صفر را به تتا صفر منهای یک مقداری،
و تتا یک را به تتا یک منهای یک مقداری تغییر می‌دهیم. و روش انجام کار این است که
سمت راست را حساب کنید یعنی این قسمت را برای تتا صفر
و تتا یک محاسبه کنید و بعد به صورت همزمان
تتا صفر و تتا یک را تغییر دهید. اجازه دهید توضیح دهم. این روش درست گرادیان نزولی است،
منظورم تغییر همزمان است. این روش درست گرادیان نزولی است،
منظورم تغییر همزمان است. پس در اینجا temp0 را برابر این،
و temp1 را برابر این قرار می‌دهم،
یعنی قسمت‌های راست را محاسبه می‌کنم و با انجام این کار و ذخیره کردنشان در متغیرهای temp0 و temp1 تتا صفر و تتا یک را به صورت همزمان تغییر می‌دهم
و این روشِ درست است. در مقابل، در روش نادرست تغییر همزمان نیست. در این روش نادرست تتا صفر را تغییر می‌دهیم
و بعد temp1 را محاسبه می‌کنیم و تتا یک را تغییر می‌دهیم. و تفاوت میان روش سمت راست و سمت چپ این است
اگر به پایین نگاه کنید در این مرحله،
اگر اول تتا صفر را تغییر دهید، بعد مقدار جدید تتا صفر را
برای محاسبه این مشتق استفاده می‌کنید. و این مقدار متفاوتی نسبت به
سمت چپ برای temp1 به شما می‌دهد. چون اکنون مقدار جدید تتا صفر
را در معادله به کار برده‌اید. بنابراین سمت راست روش درست گرادیان نزولی نیست. نمی‌گویم چرا باید
به صورت همزمان تغییر دهید. فقط بدانید در روش استفاده از
گرادیان نزولی، که بعدا بیشتر در موردش می‌گویم، طبیعی‌تر این است که
به صورت همزمان تغییر دهیم. و زمانی که صحبت از گرادیان نزولی است، همیشه منظور تغییر همزمان است. اگر از تغییر غیرهمزمان استفاده کنید، احتمالا به پاسخ می‌رسید، اما این الگوریتم درستی نیست. منظور از گرادیان نزولی این نیست. و این الگوریتم دیگری است
با ویژگی‌های متفاوت. به دلایل مختلف این کار می‌تواند
نتایج عجیبی داشته باشد، و کاری که باید بکنید این است که
در گرادیان نزولی به صورت همزمان تغییر دهید. خب، این هم از کلیات الگوریتم گرادیان نزولی. در ویدئوی بعدی به جزئیات
عبارت مشتق می‌پردازیم، عبارتی که در این ویدئو نوشتم
اما تعریف نکردم. و اگر قبلا حسابان را گذرانده باشید
و با مشتق جزئی و مشتق آشنا باشید،
این عبارت هم دقیقا همان‌طور است، اما در صورتی که با حسابان آشنا نیستید،
نگران نباشید. ویدئوی بعدی هر آنچه را باید بدانید بهتان می‌گوید
تا این عبارت مشتق را حساب کنید، حتی اگر قبلا حسابان و مشتق جزئی را ندیده باشید. و امیدوارم که در ویدئوی بعدی بتوانیم مطالب لازم را برای
استفاده از گرادیان نزولی بگوییم.