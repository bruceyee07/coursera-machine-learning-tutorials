בסרטון הזה נתחיל לדבר על גרסה חדשה וחזקה יותר של רגרסיה ליניארית. גרסה שעובדת עם משתנים מרובים או עם תכונות מרובות. אסביר את כוונתי. בגרסה המקורית של רגרסיה ליניארית שפיתחנו, יש לנו תכונה x אחת, הגודל של הבית, ובה השתמשנו כדי לחזות את המחיר של הבית, וזו היתה הצורה של ההשערה שלנו. אבל עכשיו תחשבו מה אם יש לנו לא רק את גודל הבית כתכונה או משתנה שבעזרתו אנו מנסים לחזות את המחיר, אלא אנחנו יודעים גם את מספר חדרי השינה, מספר הקומות ואת הגיל של הבית בשנים. נראה שזה נותן לנו הרבה יותר מידע שימושי כדי לחזות בעזרתו את המחיר. נוסיף קצת סימונים, אנחנו התחלנו לדבר על זה קצת עוד קודם, אני מתכוון להשתמש במשתנים x אינדקס 1, x אינדקס 2 או x₁,x₂ וכן הלאה לציון, במקרה הזה, של ארבע תכונות ואני אמשיך להשתמש ב-y כדי לציין את המשתנה, המחיר, שהוא משתנה הפלט שאנחנו מנסים לחזות. בואו נוסיף עוד קצת סימונים. עכשיו כשיש לנו ארבע תכונות אני אשתמש באות קטנה "n" כדי לציין את מספר התכונות. בדוגמא זו יש לנו n=4 כי יש לנו, אתם רואים, אחת, שתיים, שלוש, ארבע תכונות. ו-"n" עכשיו שונה מהסימונים הקודמים שלנו שבהם השתמשנו ב-"m" כדי לציין את מספר הדוגמאות. אז אם יש לנו 47 שורות אז "m" הוא מספר השורות או מספר דוגמאות האימון בטבלה הזו. אני גם אשתמש ב-x ציון עילי "i" -או ⁽x⁽ⁱ - כדי לציין את תכונות הקלט של דוגמת האימון "i". כדוגמה קונקרטית, x ציון עילי 2 - ⁽x⁽² - למשל הוא וקטור התכונות של האיבר השני בסדרת האימון. אז x2 כאן הוא הוקטור 1416, 3, 2, 40 מאחר ואלה הן ארבע התכונות לפיהן אני עומד לנסות ולחזות את המחיר של הבית השני. אז, לפי השיטה הזו, ה-2 העילי כאן הוא אינדקס בסדרת האימון. זה לא x בחזקת 2. אלא הוא אינדקס שאומר לנו להסתכל על השורה השנייה של הטבלה. זה מתייחס לדוגמת האימון השנייה. בסימון הזה ⁽x⁽² הוא וקטור ארבעה-מימדי. ולמעשה, באופן כללי יותר, הוא וקטור n-ממדי של תכונות. בסימון הזה ⁽x⁽² הוא עכשיו וקטור, אני גם אשתמש ב-⁽xⱼ⁽ⁱ כדי לציין את הערך של התכונה מספר j של דוגמת האימון מספר i. דוגמא קונקרטית, ⁽x₃⁽², מתייחס לתכונה מספר שלוש בוקטור ⁽x⁽², ברור? שם זה היה 3, צריך לתקן את כתב היד שלי. אז ⁽x₃⁽² שווה ל-2. עכשיו כשיש לנו תכונות מרובות, בואו נדבר על איך צריכה ההשערה שלנו להיראות. מקודם זו היתה הצורה של ההשערה שלנו, כאשר x היה התכונה האחת שלנו, אבל עכשיו כשיש לנו תכונות רבות, אנחנו לא יכולים להמשיך ולהשתמש בייצוג הפשוט הזה. במקום זאת, צורת ההשערה ברגרסיה ליניארית תהיה או יכולה להיות θ₀ ועוד θ₁x₁ ועוד θ₂x₂ ועוד θ₃x₃ ועוד θ₄x₄. ואם יש לנו n תכונות אז במקום סיכום על ארבע התכונות שלנו, היינו צריכים לסכום מעל n התכונות. לדוגמא עבור סדרה מסוימת של פרמטרים אנו עשויים להגדיר את פונקצית ההשערה (h(x שווה 80 + 0.1x1 + 0.01x2 + 3x3 - 2x4. זו דוגמא אחת של השערה ותזכרו שההשערה מנסה לחזות את מחיר הבית באלפי דולרים, אז זה אומר, אתם מבינים, שמחיר הבסיס של בית הוא אולי 80,000 ועוד 0.1, זאת אומרת תוספת של כמה, מאה דולרים לכל רגל מרובעת, כן, ועוד קצת כי המחיר עולה קצת לכל קומה נוספת שיש בבית. ה-x השני הוא מספר הקומות, והמחיר עולה עוד בגלל כל חדר שינה נוסף בבית, כי x3 הוא מספר חדרי השינה, והמחיר יורד קצת בגלל הגיל של הבית. עם כל שנה נוספת של גיל הבית. הנה ההשערה בצורתה הכתובה מחדש בשקופית. ומה שאני עומד לעשות הוא להוסיף קצת סימונים כדי לפשט את המשוואה הזאת. כדי לעשות את הסימון נוח, הרשו לי להגדיר את x₀ להיות שווה לאחד. באופן מעשי, משמעות הדבר היא כי עבור כל דוגמה i יש לנו וקטור x ציון עליון i - או ⁽x⁽ⁱ של תכונות ו-⁽x⁽ⁱ ציון תחתון 0 - או ⁽x₀⁽ⁱ - שווה ל-1. אתם יכולים לחשוב על זה כעל הגדרה תכונה נוספת מספר אפס. אז בעוד שבעבר היו לנו n תכונות מ-x2, x1 ועד xn, עכשיו הגדרתי איזו תכונה מספר אפס שערכה הוא תמיד אחת. אז עכשיו וקטור התכונות שלי x הופך להיות וקטור של n+1 ממדים שמתחיל מאינדקס אפס. אז עכשיו זהו וקטור תכונות n+1-ממדי, אבל אנחנו מתחילים בו מ-0 ואני גם מתכוון לחשוב על הפרמטרים כוקטור. אז הפרמטרים שלנו כאן, נכון, זה יהיה θ0, θ1, θ2, וכן הלאה עד θn, אנחנו נסדר אותם בתוך וקטור של פרמטרים, הבה נכתוב θ0, θ1, θ2, וכן הלאה, עד θn. גם הוא וקטור המתחיל באפס. האינדקס שלו מתחיל באפס. גם הוא וקטור n + 1 ממדי. אז עכשו ניתן לכתוב את פונקצית ההשערה כ-θ0x0 ועוד θ1x1 ... עד θnxn. והמשוואה הזו זהה לזו למעלה, אתם מבינים, כי x0 שווה אחת. ומה שמדליק פה הוא שעכשיו אני יכול לקחת את הצורה הזו של השערה ולכתוב אותה כ-θᵀx, תלוי כמה אתם מכירים מכפלה פנימית של וקטורים, אם תכתוב מה יוצא בחישוב של θᵀx, מה זה θᵀ, זה θ0, θ1, עד θn. הדבר הזה כאן הוא θᵀ וזו בעצם מטריצה של n+1 על אחת. זה נקרא גם וקטור שורה ואתה לוקח אותו ומכפיל אותו בוקטור x שהוא x0, x1 וכן הלאה עד xn. אז המכפלה הפנימית של θᵀ ב-x היא פשוט שווה לזה. זה נותן לנו דרך נוחה לכתוב את פונקצית ההשערה בצורה של מכפלה פנימית של וקטור הפרמטרים שלנו תטא ובין x. הסימון הקטן הזה, הפיסה הקטנה של סימון מוסכם שמאפשרת לנו לכתוב את זה בצורה הקומפקטית הזו. אז זו הצורה של השערה כאשר יש לנו תכונות מרובות. ורק כדי לתת לזה עוד שם, זה נקרא גם רגרסיה ליניארית מרובת משתנים. והמונח מרובת משתנים הוא אולי פשוט מונח יותר עילאי כדי לומר שיש לנו תכונות מרובות, או משתנים מרובים, שבעזרתם נוכל לנסות לחזות את הערך של y.