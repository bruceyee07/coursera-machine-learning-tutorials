U ovome videu i onome posle ovoga, želeo bih da vam kažem nešto o praktičnim trikovima da bi algoritam
 opadajućeg gradijenta dobro radio. U ovom video rekao bih vam nešto o
 ideji zvanoj skaliranje osobina. Ovo je ideja. Ako imate problem gde imate više osobina, ako ste sigurni da su osobine na sličnoj skali, mislim, ako ste sigurni da različite osobine zauzimaju slične opsege vrednosti, tada opadajući gradijent brže konvergira. Konkretno, recimo da imate problem sa dve osobine gde je x1 veličina kuće i uzima vrednosti između 0 i 2.000 a druga je broj spavaćih soba, i može da uzme vrednosti između 1 i 5. Ako iscrtate konture funkcije koštanja J od teta, one bi mogle da izgledaju ovako, gde, recimo, J od teta je funkcija parametara teta0, teta1 i teta2. Ignorisaću teta0, dakle, zaboravimo teta0 i pravimo se kao da je funkcija samo od teta1 i teta2, ali ako x1 može da uzme mnogo veći rang vrednosti od x2 ispada da konture funkcije koštanja J od teta mogu da dobiju ovaj veoma nakošen eliptični oblik, izuzev ako koristimo odnos 2000 prema 5, mogle bi biti više skalirane. Dakle, ovo su veoma visoke i tanke elipse, ili veoma visoki tanki ovali, i mogu da formiraju konture funkcije 
koštanja J od teta. Ako pokrenete opadajući gradijent na ovoj funkciji koštanja, vaši gradijenti bi mogli da uzmu mnogo vremena i mogli bi da osciliraju napred, nazad i potrajalo bi dok bi konačno našli globalni minimum. U stvari, zamislite da su te konture preuveličane čak iako crtate neverovatno tanke, visoke tanke konture, moglo bi da bude i ekstremnije tad opadajući gradijent treba više vremena da nađe svoj put, krivudajući okolo, može da potraje dok ne pronađe 
svoj put do globalnog minimuma. U takvim postavkama, korisna stvar je da se osobine skaliraju. Konkretno, ako umesto da definišete osobinu x1 da bude veličina kuće podeljena sa 2000, a x2 da bude možda broj spavaćih soba podeljen sa 5, tada, konture funkcije koštanja J bi postale mnogo manje nakrivljene tako da 
bi više ličile na krugove. I ako pokrenete opadajući gradijent na funkciji koštanja kao što je ova, tada bi opadajući gradijent, možete pokazati matematički, možete naći mnogo direktniji put ka globalnom minimumu 
nego uzimajući mnogo komplikovaniji put gde ste nekako pokušavali da pratite mnogo komplikovaniju putanju do globalnog minimuma. Znači, skaliranjem osobina se dobijaju slični rangovi vrednosti. U ovom primeru dobili smo obe osobine, x1 i x2, između 0 i 1. Možete se igrati sa implementacijama 
opadajućeg gradijenta. Oni mogu da konvergiraju mnogo brže. Uopšteno, kada radimo skaliranje osobina, ono što često želimo da uradimo jeste da svaku osobinu smestimo približno u opseg -1 do +1 i konkretno, vaša osobina x0 je uvek 1. Dakle, to je već u tom opsegu, ali može da se desi da i ostale osobine u različitim opsezima da treba da dobijete u ovom rangu. Brojevi -1 i +1 nisu toliko važni. Tako da, ako imate osobinu x1 koja ima vrednosti između 0 i 3, to nije problem. Ako se desi da imate različite osobine koje imaju vrednosti između -2 i +0.5, ponovo, to je dovoljno blizu -1 i +1 to je u redu. Jedino ako imate drugačiju osobinu, recimo x3, koja je između -100 i +100 tad su to veoma različite vrednosti od -1 i +1. Dakle, to bi mogla da bude slabije skalirana osobina i slično, ako vaše osobine upadaju u opseg veoma malih vrednosti, recimo x4 uzima vrednosti između -0.0001 i +0.0001, tad opet pada u rang veoma malih vrednosti od -1 do +1 opsega. I opet, i ovu osobinu bih 
smatrao slabo skaliranom. Znači, vaš raspon vrednosti može da bude veći od +1 ili manji od +1, ali ne mnogo veći, kao što je +100 ovde, ili mnogo manji kao što je 0.001 ovde. Različiti ljudi imaju različite mere. Ali ona koju ja koristim je da, ako osobina uzima vrednosti u rasponu od recimo -3 do +3 što bi trebalo smatrati ispravnim, ali možda uzimaju mnogo veće vrednosti od +3 ili -3 ne treba da brinete i ako uzima vrednosti između -1/3 i 1/3. Mislim da je to u redu od 0 do 1/3 ili -1/3 do 0. Pretpostavljam da je to 
tipičan uredan rang vrednosti. Ali ako uzima mnogo tanji raspon vrednosti kao x4 ovde tad opet 
ne treba da brinete. Dakle, poruka je ne brinite ako vaše osobine nisu baš u istoj skali ili u 
istom rasponu vrednosti. Dokle god su sve dovoljno blizu ovom opadajućem 
gradijentu, trebalo bi biti u redu. Dodatno, kada se deli nekom maksimalnom vrednošću prilikom izvođenja skaliranja osobina, ponekad se takođe radi takozvana 
normalizacija srednje vrednosti. Šta mislim pod time je da želite da uzmete osobinu xi i zamenite je sa xi - mui da dobijete vaše osobine 
sa srednjom vrednosti 0. Očigledno ne želimo da to primenimo na osobinu x0 jer osobina x0 je uvek jednaka 1 tako da ona ne može da ima srednju vrednost 0. A, konkretno za ostale osobine, ako raspon veličina kuća uzima vrednost između 0 i 2000 i ako srednja vrednost veličine kuće je jednaka 1000 tad biste mogli da koristite ovu formulu. Veličina, postavite osobinu x1 na veličina minus srednja vrednost podeljeno sa 2000 i slično tome, ako vaše kuće imaju od jedne do pet soba i ako je srednja vrednost soba u kućama dva, tad biste mogli da koristite ovu 
formulu da normalizujete vašu drugu osobinu x2. U oba ova slučaja dobijete osobine x1 i x2. Oba mogu da dobiju vrednosti otprilike između -0.5 i +0.5. Nije baš tačno, x2 može malo da bude veće 
od 0.5 ali, vrlo blizu. Opštije pravilo je da možete da uzmete osobinu x1 i da je zamenite sa x1 - mu1 preko S1 gde ćemo definisati mu1 kao srednju vrednost od x1 u trening skupu a S1 je opseg vrednosti te osobine a pod time mislim vrednost maksimuma minus minimalna vrednost ili za vas koji razumete devijaciju varijable, S1 bi bila standardna devijacija varijable. Ali i maks minus min bi bilo u redu. I slično tome, za drugu osobinu, x2, menjate x2 sa razlikom srednje vrednosti osobine i delite je opsegom vrednosti, znači maks minus min. A ta vrsta formule će vašu osobinu da stavi, možda ne tačno, ali otprilike u te opsege i, usput, za vas koji ste tehnički pedantni, ako uzmemo opseg kao maks minus min, ovo 5 ovde će da bude 4. Dakle, ako je maks 5 minus 1 tad je opseg njihovih vrednosti u stvari jednak 4, ali sve to je približno i bilo koja vrednost koja stavlja osobinu u bilo šta blizu tim 
opsezima će da odgovara. A skaliranje osobine ne mora da bude precizno, da biste dobili opadajući gradijent da radi brže. Dakle, sada znate o skaliranju osobina i ako primenite ovaj jednostavan trik, možete da ubrzate rad 
opadajućeg gradijenta i da konvergirate u 
manjem broju iteracija. To je bilo skaliranje osobina. U sledećem videu, govoriću vam o još jednom triku da opadajući gradijent u praksi radi dobro.