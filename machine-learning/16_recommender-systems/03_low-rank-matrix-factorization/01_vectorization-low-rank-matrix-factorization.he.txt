בסרטונים האחרונים דיברנו על אלגוריתם סינון שיתופי. בסרטון הזה אני עומד לדבר קצת על היישום הווקטורי של האלגוריתם הזה. וגם לדבר קצת על דברים אחרים שאפשר לעשות עם האלגוריתם הזה. לדוגמה, אחד הדברים שאפשר לעשות הוא, כשנתון מוצר אחד אפשר למצוא מוצרים אחרים הקשורים אליו, למשל, אם משתמש הסתכל לאחרונה על מוצר אחד. האם יש מוצרים אחרים הקשורים אליו עליהם אפשר להמליץ למשתמש הזה? בואו נראה מה נוכל לעשות בקשר לזה. מה שאני רוצה לעשות הוא למצוא דרך חלופית לכתוב את התחזיות של אלגוריתם הסינון השיתופי. בתור התחלה, הנה מערכת הנתונים שלנו עם חמישה הסרטים ומה שאני אעשה הוא לקחת את כל הדירוגים שנעשו על ידי כל המשתמשים ולקבץ אותם למטריצה. אז כאן יש לנו חמישה סרטים וארבעה משתמשים, ולכן המטריצה y שלנו תהיה מטריצה 5 על 4. זה פשוט מקבץ את כל האיברים, את כל הנתונים. כולל סימני השאלה, ואוסף אותם לתוך המטריצה הזו. וכמובן האלמנטים של המטריצה הזו, האלמנט במקום ה-(i, j) של המטריצה הזו הוא בעצם מה שקראנו לו בעבר (y(i, j. ... זהו הדירוג שניתן לסרט i על ידי המשתמש j. בהינתן המטריצה הזו של כל הדירוגים שיש לנו, קיימת דרך חלופית לכתוב את כל הדירוגים החזויים של האלגוריתם. ובפרט אם נסתכל על מה התחזית של משתמש מסוים לגבי סרט מסוים, מה צופה המשתמש j על הסרט i נתון על ידי הנוסחה הזו. אז אם יש לנו מטריצה של תחזיות של דירוגים, מה שיש לנו זו המטריצה הבאה שבה המקום ה-i,j מתאים לדירוג שאנחנו צופים שהצופה j ייתן לסרט i וזה בדיוק שווה ל-⁽θ⁽ʲ⁾ᵀx⁽ⁱ אז זו מטריצה שבה האלמנט הראשון, אלמנט במקום 1,1, הוא הניבוי שלנו לדירוג שמשתמש 1 ייתן לסרט 1, והאיבר הזה, איבר 1,2, הוא הדירוג החזוי של משתמש 2 על סרט 1, וכן הלאה, וזה הדירוג החזוי של משתמש 1 על הסרט האחרון ואם אתם רוצים, הדירוג הזה הוא מה שהיינו מנבאים עבור הערך כאן והדירוג הזה הוא מה שהיינו מנבאים עבור הערך כאן, וכן הלאה. עכשיו, בהינתן מטריצה כזו של דירוגים חזויים ישנה דרך פשוטה יותר, או וקטורית, לכתוב את זה. בפרט אם אנחנו מגדירים את המטריצה X, שתהייה בדיוק כמו המטריצה שהיתה לנו מקודם עבור רגרסיה ליניארית להיות מין x1ᵀ, x2ᵀ, וכו' עד x(nₘ)ᵀ. בעצם אנחנו לוקחים את כל התכונות עבור הסרטים ומשכיבים אותם בשורות. אז אם נחשוב על כל סרט כדוגמה אחת, ונשכיב את כל התכונות של סרטים שונים בשורות. ואם גם נמצא מטריצה Θ (באות גדולה), ומה שאני הולך לעשות הוא לקחת כל אחד מווקטורי הפרמטרים של המשתמשים, ולהשכיב גם אותם בשורות, כך. אז זהו θ1, שהוא וקטור הפרמטרים עבור המשתמש הראשון. והנה θ2, אז צריך לערום אותם בשורות כאלה כדי להגדיר את המטריצה Θ גדולה אז יש לנו nᵤ וקטורי פרמטרים שוכבים בשורות ככה. עכשיו בהינתן ההגדרה הזו עבור המטריצה x וההגדרה הזו עבור המטריצה Θ, על מנת להריץ דרך וקטורית לחישוב המטריצה של כל התחזיות אפשר פשוט לחשב x כפול המטריצה Θᵀ, וזה נותן לנו דרך וקטורית לחישוב המטריצה הזו שבכאן. כדי לקרוא לאלגוריתם הסינון השיתופי שבו השתמשנו בשם אחר האלגוריתם שבו אנו משתמשים נקרא גם פירוק לגורמים של מטריצה מדרגה נמוכה. אז אם תשמעו מישהו מדבר על פירוק לגורמים של מטריצה מדרגה נמוכה, אז זה בעצם האלגוריתם שעליו אנחנו מדברים. והמונח הזה מקורו במאפיין שלמטריצה xΘᵀ יש תכונה מתמטית באלגברה ליניארית שאומרת שהמטריצה הזו היא מדרגה נמוכה ומכאן מגיע השם פירוק לגורמים של מטריצה מדרגה נמוכה עבור האלגוריתמים האלה, בגלל התכונה של דרגה נמוכה של המטריצה הזו xΘᵀ. ולמי שלא יודע מה פירוש דרגה נמוכה או מי שלא יודע מה זו מטריצה מדרגה נמוכה, זה לא חשוב. לא באמת צריך לדעת את זה כדי להשתמש באלגוריתם הזה. אבל למי שכן מומחה באלגברה ליניארית, זה מה שנותן לאלגוריתם הזה את השם החדש של פירוק לגורמים של מטריצה מדרגה נמוכה. ולבסוף, לאחר שהפעלנו אלגוריתם סינון שיתופי הנה עוד משהו שאפשר לעשות, והוא להשתמש בתכונות שהוא למד על מנת למצוא סרטים קשורים. בפרט עבור כל מוצר i, בעצם עבור כל סרט i, למדנו וקטור תכונות (x(i. אז כאשר לומדים תכונות מסוימות אנחנו לא יודעים מראש באמת מה המשמעות של התכונות, אבל אם מפעילים את האלגוריתם אז התכונות בדרך כלל נוטות ללכוד את ההיבטים החשובים של הסרטים השונים האלה או המוצרים השונים או מה שיש. מהם ההיבטים החשובים שגורמים למשתמשים מסוימים לאהוב סרטים מסוימים ולגרום למשתמשים מסוימים אחרים לאהוב קבוצות שונות של סרטים. אז אולי אנחנו מצאנו וקטור תכונות שבו x1 שווה רומנטיקה, x2 שווה פעולה כמו בסרטים הקודמים שלנו ואולי למדנו עוד תכונה x3 שמתארת עד כמה הסרט הוא קומדיה. או איזה תכונה x4 שהיא עוד משהו. ובסך הכל יש לנו n תכונות ואחרי שמצאנו את התכונות האלה, זה בעצם לעתים קרובות די קשה להגדיר לתכונות שמצאנו ולתת להם פרשנות אנושית של מה בעצם אומרות התכונות האלה. אבל בפועל, למרות שהתכונות האלה יכולות להיות קשות להגדיר בדיוק. יכול להיות קשה להבין בדיוק מה הן התכונות האלו. בדרך כלל, האלגוריתם שלנו ילמד תכונות שהן משמעותיות מאוד ללכידת המאפיינים החשובים ביותר או הבולטים ביותר של הסרט שגורמים לאדם לאהוב או לא לאהוב אותו, אז עכשיו נניח שאנחנו רוצים לטפל בבעיה הבאה. נניח שיש לנו סרט מסוים i ואנחנו רוצים למצוא סרטים אחרים j שקשורים לסרט הזה. אז למה שנרצה לעשות את זה? אז ברור, לדוגמא אם יש לנו משתמש שכרגע גולש בסרטים, והוא כרגע צופה בסרט j, אז איזה סרט סביר להמליץ לו לראות אחרי שהוא יסיים עם הסרט j? או אם מישהו רכש לאחרונה את סרט j, אז איזה סרט אחר יהיה סביר לנו להמליץ לו שישקול לרכוש. אז עכשיו, אחרי שלמדנו את התכונות הללו, זה נותן לנו דרך נוחה מאוד למדוד עד כמה דומים שני סרטים. בפרט, יש לנו וקטור תכונות (x(i של הסרט i. אז אם אפשר למצוא סרט אחר, j, כך שהמרחק בין (x(i לבין (x(j הוא קטן, אז זה סימן חזק למדי שהסרטים j ו-i דומים איכשהו. לפחות במובן הזה שאם כמה מהצופים אוהבים את הסרט i, אולי יותר סביר שיאהבו גם את הסרט j. אז, רק לסכם, אם המשתמש שלנו מסתכל על איזה סרט i ואנחנו רוצים למצוא את 5 הסרטים הדומים ביותר לסרט הזה על מנת להמליץ לו על 5 סרטים חדשים, אנחנו נמצא את חמשת הסרטים j עם המרחק הקטן ביותר בין וקטורי התכונות של הסרטים השונים. וזה יכול לתת לנו כמה סרטים שונים להמליץ עליהם למשתמש שלנו. אז עכשיו, אני מקווה, עכשיו אתם יודעים איך להשתמש ביישום הוקטורי הזה כדי לחשב בו-זמנית את כל הדירוגים החזויים של כל המשתמשים ושל כל הסרטים, וגם איך לעשות דברים כמו להשתמש בתכונות שנלמדו כדי למצוא אילו סרטים אחרים ואילו מוצרים אחרים יכולים להיות קשורים אילו לאילו.