1
00:00:00,000 --> 00:00:01,980
在上一段影片中, 您可以看到

2
00:00:01,980 --> 00:00:05,047
序列模型可以廣泛用在許多應用上

3
00:00:05,047 --> 00:00:10,470
我們從定義建立序列模型時會用到的符號開始

4
00:00:10,470 --> 00:00:12,360
讓我們看個例子

5
00:00:12,360 --> 00:00:16,290
假設你想建立一個序列模型來輸入這樣的句子

6
00:00:16,290 --> 00:00:19,361
「哈利波特和妙麗格蘭傑發明了新的咒語」
(Harry Potter and Hermione Granger invented a new spell.)

7
00:00:19,361 --> 00:00:21,210
用單字組成

8
00:00:21,210 --> 00:00:25,595
從JK 羅琳所著之《哈利波特》系列小說中節錄

9
00:00:25,595 --> 00:00:29,220
假設你想要一個可以自動告訴你

10
00:00:29,220 --> 00:00:34,120
人名出現在句子中何處的序列模型

11
00:00:34,120 --> 00:00:36,760
這是個叫做「命名實體辨識」(Named-entity recognition) 的問題

12
00:00:36,760 --> 00:00:40,125
常用於搜尋引擎當中

13
00:00:40,125 --> 00:00:43,800
例如, 標示出過去一天出現在新聞文章中的人名

14
00:00:43,800 --> 00:00:49,245
並適當予以索引

15
00:00:49,245 --> 00:00:52,050
這個辨識系統可以運用於

16
00:00:52,050 --> 00:00:54,765
找出文本中的人名, 公司名稱,

17
00:00:54,765 --> 00:00:57,210
時間, 地點, 國家名稱,

18
00:00:57,210 --> 00:01:01,370
貨幣名稱等等

19
00:01:01,370 --> 00:01:04,650
現在, 給定這個輸入 x, 假設你想要一個模型

20
00:01:04,650 --> 00:01:08,250
來輸出 y, 且一個輸入對應一個輸出

21
00:01:08,250 --> 00:01:11,355
而目標輸出 y

22
00:01:11,355 --> 00:01:17,130
會告訴你每個輸入單字是否為人名的一部分

23
00:01:17,130 --> 00:01:21,030
從技術上來說
這也許不是最好的輸出表示方法

24
00:01:21,030 --> 00:01:23,520
有一些更複雜的輸出表示法不只能告訴你

25
00:01:23,520 --> 00:01:26,558
那個字是否為人名的一部分

26
00:01:26,558 --> 00:01:30,775
也能告訴你各個人名在句子當中開頭和結尾的位置

27
00:01:30,775 --> 00:01:33,297
像是知道哈利波特從這裡開始

28
00:01:33,297 --> 00:01:35,550
並在這裡結束, 開始於此並結束於此

29
00:01:35,550 --> 00:01:37,990
但在這個例子中

30
00:01:37,990 --> 00:01:41,900
我會使用這個較為簡要的表示法

31
00:01:41,900 --> 00:01:44,790
現在, 輸入是九個單字的序列

32
00:01:44,790 --> 00:01:51,345
因此, 最終我們將有九組特徵來表示這九個單字

33
00:01:51,345 --> 00:01:53,858
而位置和序列的索引

34
00:01:53,858 --> 00:01:59,797
我將會用 X, 上標角括號中1到9

35
00:01:59,797 --> 00:02:06,955
來表示他們的位置

36
00:02:06,955 --> 00:02:13,180
X^<t>中的t就是位置索引

37
00:02:13,180 --> 00:02:15,270
標示在句子中的位置

38
00:02:15,270 --> 00:02:17,400
索引 t 指的是無論這些序列

39
00:02:17,400 --> 00:02:21,735
是否為暫時 (temporal) 的序列

40
00:02:21,735 --> 00:02:27,805
我都會用 t 來表示序列的索引

41
00:02:27,805 --> 00:02:29,895
同樣的對於輸出

42
00:02:29,895 --> 00:02:34,040
我們以 y 來表示, 索引為1,

43
00:02:34,040 --> 00:02:39,725
2, 3, 到9

44
00:02:39,725 --> 00:02:44,553
我們同樣用T_x來表示輸入序列的長度

45
00:02:44,553 --> 00:02:46,540
在這個例子中有 9 個單字

46
00:02:46,540 --> 00:02:53,025
T_x等於9, 而T_y表示輸出序列的長度

47
00:02:53,025 --> 00:02:56,130
在本例中, T_x 等於 T_y, 但

48
00:02:56,130 --> 00:02:59,410
在上一段影片中的 T_x 和 T_y 可以是不同的。

49
00:02:59,410 --> 00:03:03,690
我們過去一直在使用的符號中

50
00:03:03,690 --> 00:03:09,080
X^(i)是用來表示這是第i個訓練例子

51
00:03:09,080 --> 00:03:10,710
所以,

52
00:03:10,710 --> 00:03:17,160
第 i 個訓練例中第 t 個元素我們將用 X^(i)<t> 來表示

53
00:03:17,160 --> 00:03:21,870
而Tx為序列長度

54
00:03:21,870 --> 00:03:26,700
且訓練集中的不同例子可以有不一樣的序列長度

55
00:03:26,700 --> 00:03:33,368
所以Tx^(i)表示第 i 個訓練例子的序列長度

56
00:03:33,368 --> 00:03:40,930
同樣的, y^(i)<t>表示第 i 個訓練例中第 t 個輸出

57
00:03:40,930 --> 00:03:49,842
Ty^(i)表示第 i 個訓練例子輸出序列的長度

58
00:03:49,842 --> 00:03:51,570
在這個例子中

59
00:03:51,570 --> 00:03:57,015
Tx^(i)為9, 但若是在另一個含有15個單字的訓練例子中

60
00:03:57,015 --> 00:04:03,370
Tx^(i)就等於15

61
00:04:03,370 --> 00:04:09,645
現在, 我們將開始實踐 NLP 或稱之為自然語言處理

62
00:04:09,645 --> 00:04:16,410
這是我們第一次認真的見識這個程序

63
00:04:16,410 --> 00:04:18,915
我們需要決定的一件事是

64
00:04:18,915 --> 00:04:22,470
如何表示序列中的各個單字

65
00:04:22,470 --> 00:04:25,195
像是你如何代表一個像「哈利」(Harry) 這樣的單字

66
00:04:25,195 --> 00:04:30,330
還有X^<1>應該是甚麼

67
00:04:30,330 --> 00:04:35,580
接下來我們將討論如何在一個句子中表示單獨的單字

68
00:04:35,580 --> 00:04:38,530
用來表示一個單字在句子中，首要做的事是

69
00:04:38,530 --> 00:04:42,075
取得一個字彙集

70
00:04:42,075 --> 00:04:46,090
或稱之為字典, 意思是

71
00:04:46,090 --> 00:04:50,740
一份你會用到的單字的清單

72
00:04:50,740 --> 00:04:53,160
字彙集中第一個單字是"a"

73
00:04:53,160 --> 00:04:55,270
是字典中第一個單字

74
00:04:55,270 --> 00:05:00,805
第二個單字是"Aaron", 之後會有"and"

75
00:05:00,805 --> 00:05:08,035
然後會有"Harry"和"Potter"

76
00:05:08,035 --> 00:05:16,895
也許最後一個單字是"Zulu"

77
00:05:16,895 --> 00:05:19,415
所以"a"是第一字

78
00:05:19,415 --> 00:05:21,302
"Aaron"是第二字

79
00:05:21,302 --> 00:05:29,385
"and"出現在字典中的位置為367

80
00:05:29,385 --> 00:05:34,925
「哈利」出現在位置4075

81
00:05:34,925 --> 00:05:37,775
「波特」在位置6830

82
00:05:37,775 --> 00:05:44,690
而「祖魯」(Zulu) 是詞典的最後一個單字, 也許是位置10,000

83
00:05:44,690 --> 00:05:46,295
在這個例子中

84
00:05:46,295 --> 00:05:51,380
我要用一萬字大小的字典

85
00:05:51,380 --> 00:05:55,880
對於現代 NLP 應用來說這是相當小的

86
00:05:55,880 --> 00:06:00,460
對於商業應用, 對於視覺商業應用,

87
00:06:00,460 --> 00:06:07,485
字典的大小為三到五萬更常見, 十萬也並不少見。

88
00:06:07,485 --> 00:06:09,920
然後一些大型網際網路公司會用

89
00:06:09,920 --> 00:06:14,310
可能是一百萬字甚至更大的字典

90
00:06:14,310 --> 00:06:17,695
但你可以看到很多商業應用使用字典的大小

91
00:06:17,695 --> 00:06:21,660
大約在三到五萬

92
00:06:21,660 --> 00:06:27,790
但我要用一萬作為例子, 因為它是個整數。

93
00:06:27,790 --> 00:06:33,520
所以, 如果你選擇了一萬個單字的字典, 建構

94
00:06:33,520 --> 00:06:35,630
這個字典的方法可以是

95
00:06:35,630 --> 00:06:40,115
從你的訓練集中選取最常用的一萬字

96
00:06:40,115 --> 00:06:43,940
或是查看一些線上字典會告訴你

97
00:06:43,940 --> 00:06:48,099
最常被存用的一萬個英文單字為何

98
00:06:48,099 --> 00:06:54,320
然後用one-hot表示法來表達這些單字

99
00:06:54,320 --> 00:07:02,960
例如, x^<1> 代表的詞為"Harry", 將是一個位置4075為1, 其他為0的向量

100
00:07:02,960 --> 00:07:12,080
因為那個位置是"Harry"在字典中的位置

101
00:07:12,080 --> 00:07:18,110
同樣的, x^<2>是一個只有在位置6830為1

102
00:07:18,110 --> 00:07:24,757
其他位置為0的向量

103
00:07:24,757 --> 00:07:30,620
"and"在位置367, 所以x^<3>

104
00:07:30,620 --> 00:07:38,000
是只有在位置367為1其他為0的向量

105
00:07:38,000 --> 00:07:40,835
每一個向量的維度都是10,000

106
00:07:40,835 --> 00:07:45,830
因為字彙集中有一萬字

107
00:07:45,830 --> 00:07:50,570
而這個"a"是字典中的首字

108
00:07:50,570 --> 00:07:54,258
所以代表了"a"的x^<7>

109
00:07:54,258 --> 00:07:57,625
會是第一位置為1其他位置為0的向量

110
00:07:57,625 --> 00:08:03,060
因為它是字典中的首字

111
00:08:03,060 --> 00:08:07,760
在這個表示法中

112
00:08:07,760 --> 00:08:12,800
x^<t>對於不同 t 值都是個one-hot向量

113
00:08:12,800 --> 00:08:16,760
one-hot 因為它只有一個1, 其他位置都是0

114
00:08:16,760 --> 00:08:22,075
而你會有九個這樣的向量來表示句子當中的九個單字

115
00:08:22,075 --> 00:08:25,995
我們目標就是輸入以這種方法表示的x

116
00:08:25,995 --> 00:08:31,325
用一個序列模型去學習映射至目標輸出y

117
00:08:31,325 --> 00:08:33,875
我會把它當做一個監督式學習問題,

118
00:08:33,875 --> 00:08:37,460
需要輸入有標籤過資料x與y

119
00:08:37,460 --> 00:08:39,137
最後一個細節,

120
00:08:39,137 --> 00:08:42,665
也是之後影片會提到更多

121
00:08:42,665 --> 00:08:46,545
如果你遇到一個不在你的詞彙集中的單字該怎麼辦？

122
00:08:46,545 --> 00:08:52,400
可以做的事是創建一個新標記或假字詞
稱為『未知』(unkown) 單字

123
00:08:52,400 --> 00:08:58,391
我用<UNK>來表示沒有出現在字彙集中的所有單字

124
00:08:58,391 --> 00:09:00,985
我們之後會回頭講這件事

125
00:09:00,985 --> 00:09:02,660
總結這段影片

126
00:09:02,660 --> 00:09:05,570
我們描述了一個符號方法來描述

127
00:09:05,570 --> 00:09:09,205
序列資料訓練集中的x和y

128
00:09:09,205 --> 00:09:11,390
在下一影片中, 我們會開始描述

129
00:09:11,390 --> 00:09:15,420
將 X 對應至 Y 的遞迴神經網路