在我们训练了一个序列模型以后， 我们可以通过采样新的序列非正式地
了解它学到了什么 让我们看看应该怎么做 记住，一个序列模型模拟 在任何序列模型中的词出现的机会如下，
我们现在想 在这个分布中采样，以生成新词序列 以上结构训练了这个网络 但是采样方法略有不同 首先为你希望模型生成的第一个字采样 为此你输入x1=0，a0=0 现在你的第一个时间标记 有一些可能输出的最大概率 然后根据softmax的分布随机采样 softmax 分布会告诉你第一个词指向a的概率 指向Aaron的概率 指向Zulu的概率 第一个单词是未知单词标记的几率是什么。 也许这是一个句子标记的结束。 然后你用这个向量使其比如运行numpy指令 np.random.choice以采样 通过这个向量概率定义的分布，
然后你就可以为这些首先出现的词采样了 然后你继续，前进到第二步时间点 记住第二步时间需要输入是这个y1 现在你用刚刚采样过的y1 在这里传递它到下一步时间点 不管什么方式，管用就行 你只是选择第一步，把这个输入传递到第二个位置 然后softwax会预测y^2 例如,,假设在你对第一个单词进行取样后, 第一个词恰好是 z, 这个词作为第一个词很常见。 然后你传递 v 作为 x2, x2现在等于 y^1。 现在你正在试图找出 当第一个词是d时，第二词的几率 会是y^2 然后你用同样的采样方法为y^2采样 然后在下一个时间标记 你把你有的选择当成硬编码 然后传给下一个时间步骤 然后你为第三个词取样，不管你选了什么 你一直继续直到最后一个时间标记 那你怎么知道序列结束了呢 那么, 你可以一直采样直到你取得EOS标记 如果标记的结尾是词汇的一部分 这会告诉你句子结束了，你可以停止了 或者，如果你的词汇里没有EOS标记 你也可以只是去采20词或100词的样 然后一直继续直到你时间步骤的上限 这个特定的过程有时会产生一个未知词标记。 如果要确保算法从不生成此标记, 你可以做的一件事就是拒绝所有 未知词标记样本，只从剩余词汇重新取样 直到没有未知词为止 或者你可以将其放入输出项中 如果你不介意有个未知词输出 这是如何生成一个随机选择的句子 从你的 RNN 语言模型里。 到目前为止,我们已经建立了一个字级 RNN, 词汇来自英语。 根据你的应用, 你也可以建立一个字符级别 RNN。 在这种情况下,你的词汇将只是字母。 到 z, 也许还有空格 标点符号,如果你需要的话,数字0到9。 如果你想区分大写和小写, 也可以包括大写字母以及 你可以看看你的训练集和 里面的字符,并使用它来定义词汇表。 如果你建立字符级语言模型而不是词汇级的 那么你的序列 y1, y2, y3, 将是您的训练数据中的单个字符, 而不是训练数据中的个别单词。 像我们之前的例子一样,
句子“猫平均每天睡15小时”。 在这个例子中, c 会是 y1, a 会是 y2, t 会是 y3, 空格会是 y4 等等。 使用字符级语言模型有一些利弊。 你不必担心未知的单词标记。 字符级语言模型 能够分配一个像mau一样的非零概率的序列。 而如果mau不在你的词汇水平语言模型中 您只需将它标为未知的单词标记。 但字符级语言模型的主要缺点 是你最终会有更长的序列。 很多英语句子有10到20字， 但可能有非常多的字符。 因此,，字符语言模型不如词级语言模型好 在找出句首对句尾的 长距离的关系上 字符级模型在计算训练上也更加复杂。 所以我在自然语言处理中看到的趋势是, 大多数情况下,还在使用字级语言模型 但是随着计算机速度的加快,人们的应用越来越多, 至少在某些特殊情况下,是字符级别模型。 但它们往往需要大量的硬件和更复杂的计算训练, 因此今天还没有被广泛使用。 除非你可能需要特殊处理 很多未知单词或其他词汇词的程序。 或者,它们也被用于更专业的应用程序中 这些程序需要更专业词汇。 因此,有了这些方法, 你现在能做的就是建立一个RNN
来观察英文文本 构建单词级别和字符级别的模型 在你培训的语言模型中采样。 下面是一个语言模型中的文本示例, 这是一个有文化级别的语言模型。 你可以在练习中实现这样的东西。 如果这个模型是在新闻文章上受训的, 它会生成左边的文本。 这看起来有点像新闻文本,
不是语法层面上来讲 但也许听起来有点像新闻里的东西, 比如这句
“concussion epidemic to be 
examined.” 如果在莎士比亚的文本上训练 然后它会写出像莎士比亚写出的东西。 像是这句“终有一死的月亮
陷入爱河的月食”。 “And subject of this thou
art another this fold.” “When besser be my love 
to me see sabl's.” "For whose are ruse of mine eyes 
heaves." 这是基本的 RNN, 
如何用它建立一个语言模型, 以及你所训练的语言模型中的样本。 在接下来的几个视频中, 
我想进一步讨论一些训练RNN的挑战。 以及如何应对这些挑战,尤其是 通过建立更强大的 RNN 模型
使梯度消失 所以在接下来的视频中
让我们来谈谈梯度消失的问题 我们将继续谈论 GRU, 
门复发单元以及 LSTM 模型。