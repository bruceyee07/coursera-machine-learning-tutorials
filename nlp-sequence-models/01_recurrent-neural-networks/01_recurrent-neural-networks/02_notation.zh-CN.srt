1
00:00:00,000 --> 00:00:01,980
上一讲说过

2
00:00:01,980 --> 00:00:05,047
序列模型有很广泛的应用.

3
00:00:05,047 --> 00:00:10,470
现在,我们来说一说这些以后建模会用到的符号

4
00:00:10,470 --> 00:00:12,360
比如说

5
00:00:12,360 --> 00:00:16,290
比如用下列句子,作为序列模型的输入数据

6
00:00:16,290 --> 00:00:19,361
Harry Potter and Hermione Granger invented a new spell.
（哈利波特和赫敏格兰杰发明了中新的咒语）

7
00:00:19,361 --> 00:00:21,210
句子里这些角色来自

8
00:00:21,210 --> 00:00:25,595
J·K·罗琳写的系列小说<哈利·波特>

9
00:00:25,595 --> 00:00:29,220
假设你想让序列模型自动识别出

10
00:00:29,220 --> 00:00:34,120
句子中哪些单词是人名

11
00:00:34,120 --> 00:00:36,760
这是个名字识别的例子

12
00:00:36,760 --> 00:00:40,125
常用在搜索引擎中

13
00:00:40,125 --> 00:00:43,800
比如，过去24小时的新闻报道中

14
00:00:43,800 --> 00:00:49,245
提到的人名进行恰当的索引

15
00:00:49,245 --> 00:00:52,050
除此以外,识别系统也能通过名称查找信息

16
00:00:52,050 --> 00:00:54,765
比如人名,企业名称

17
00:00:54,765 --> 00:00:57,210
时间,地点,国家名称

18
00:00:57,210 --> 00:01:01,370
货币名称等等

19
00:01:01,370 --> 00:01:04,650
假设,通过输入变量 x ,你想让这个模型

20
00:01:04,650 --> 00:01:08,250
的输出变量 y 对应每一个

21
00:01:08,250 --> 00:01:11,355
输入的单词,目标输出

22
00:01:11,355 --> 00:01:17,130
 y 的值标出那些输入单词是人名

23
00:01:17,130 --> 00:01:21,030
当然,这种输出方式并非最佳

24
00:01:21,030 --> 00:01:23,520
还有一些更复杂的输出形式不仅

25
00:01:23,520 --> 00:01:26,558
告诉你哪个词是人名

26
00:01:26,558 --> 00:01:30,775
还能够指出人名在句子中的起始位置

27
00:01:30,775 --> 00:01:33,297
比如,Harry Potter 这个名字从这里开始

28
00:01:33,297 --> 00:01:35,550
到这里结束，从这里开始，到这里结束

29
00:01:35,550 --> 00:01:37,990
不过在这个例子里

30
00:01:37,990 --> 00:01:41,900
我们只关注这种简单输出方式

31
00:01:41,900 --> 00:01:44,790
那么，作为输入的序列数据只有9个单词

32
00:01:44,790 --> 00:01:51,345
所以,我们最终会有9组特征来代表9个单词

33
00:01:51,345 --> 00:01:53,858
并指出位置和序列

34
00:01:53,858 --> 00:01:59,797
我用 x 和上标 <1> <2>

35
00:01:59,797 --> 00:02:06,955
<3>...<9> 表示句子中单词的位置

36
00:02:06,955 --> 00:02:13,180
我们使用X^<t>来指示位置

37
00:02:13,180 --> 00:02:15,270
在序列当中

38
00:02:15,270 --> 00:02:17,400
其中的t表明X^<t>所在的序列为时间序列，

39
00:02:17,400 --> 00:02:21,735
而不论(所代表的)序列是否是时间序列

40
00:02:21,735 --> 00:02:27,805
我将使用索引t来指示序列中的位置

41
00:02:27,805 --> 00:02:29,895
输出也一样

42
00:02:29,895 --> 00:02:34,040
y 表示输出,上标 <1>

43
00:02:34,040 --> 00:02:39,725
<2>...<9> 表示位置

44
00:02:39,725 --> 00:02:44,553
用 Tx 表示输入数据的长度

45
00:02:44,553 --> 00:02:46,540
这个例子中共9个词

46
00:02:46,540 --> 00:02:53,025
所以,Tx 等于9，然后我们用Ty表示输出序列的长度

47
00:02:53,025 --> 00:02:56,130
这个例子中 Tx 等于 Ty 

48
00:02:56,130 --> 00:02:59,410
但是,在上一个视频中,我们看到 Tx 不等于 Ty 

49
00:02:59,410 --> 00:03:03,690
也许，你还记得这个符号

50
00:03:03,690 --> 00:03:09,080
x(i) ,它表示第 i 个训练样本

51
00:03:09,080 --> 00:03:10,710
所以，为了表示

52
00:03:10,710 --> 00:03:17,160
第t个元素，或者是训练样本， i 的序列中的
第t个元素，我会使用X^(i)<t>这个符号

53
00:03:17,160 --> 00:03:21,870
而如果 T_x 表示序列的长度

54
00:03:21,870 --> 00:03:26,700
那么，你的训练集中不同的例子的长度可能不同

55
00:03:26,700 --> 00:03:33,368
所以，T_x^(i) 就代表第i个训练样例的输入序列长度

56
00:03:33,368 --> 00:03:40,930
类似的，y^(i)<t> 代表第i个
训练样例的输出序列的第t个元素

57
00:03:40,930 --> 00:03:49,842
T_y^(i) 则是第 i 训练样例的输出序列的长度

58
00:03:49,842 --> 00:03:51,570
所以，这个例子中

59
00:03:51,570 --> 00:03:57,015
T_x^(i) 等于9, 如果你有另外一个练习例子

60
00:03:57,015 --> 00:04:03,370
由15个单词组成的句子，
对于不同的例子, T_x^(i) 则为 15

61
00:04:03,370 --> 00:04:09,645
现在,我们开始讲自然语言处理(NLP)

62
00:04:09,645 --> 00:04:16,410
这是我们第一次正式接触到NLP或者说自然语言处理

63
00:04:16,410 --> 00:04:18,915
我们需要决定

64
00:04:18,915 --> 00:04:22,470
在一个序列中如何表示一个单词？

65
00:04:22,470 --> 00:04:25,195
比方说,如何表示 Harry 这个词

66
00:04:25,195 --> 00:04:30,330
X<1>的值应该是什么呢？

67
00:04:30,330 --> 00:04:35,580
我们先讲一讲怎么表示句子中的某个单词

68
00:04:35,580 --> 00:04:38,530
首先我们要

69
00:04:38,530 --> 00:04:42,075
准备好一个词汇表

70
00:04:42,075 --> 00:04:46,090
有时也称为字典

71
00:04:46,090 --> 00:04:50,740
其实就是将你要用到的单词放到一起做一个清单

72
00:04:50,740 --> 00:04:53,160
比如,这个词汇表中的

73
00:04:53,160 --> 00:04:55,270
第一个词是 a，就是字典里的第一个单词

74
00:04:55,270 --> 00:05:00,805
第二个是 Aaron, 再下面就是 and

75
00:05:00,805 --> 00:05:08,035
再往下就是 Harry 然后是 Potter

76
00:05:08,035 --> 00:05:16,895
最后一个单词是 Zulu

77
00:05:16,895 --> 00:05:19,415
也就是说, a 是单词1

78
00:05:19,415 --> 00:05:21,302
Aaron 是单词2

79
00:05:21,302 --> 00:05:29,385
在我做的词典里, and 这个词的位置索引是 367

80
00:05:29,385 --> 00:05:34,925
Harry 则是 4075

81
00:05:34,925 --> 00:05:37,775
Potter 是 6830

82
00:05:37,775 --> 00:05:44,690
Zulu 这个词排在最后,它的位置索引是 10,000

83
00:05:44,690 --> 00:05:46,295
在这个例子里

84
00:05:46,295 --> 00:05:51,380
我用的是词汇量为 10,000 的字典

85
00:05:51,380 --> 00:05:55,880
对于现代的自然语言处理应用而言, 
这种规模属于非常小的了

86
00:05:55,880 --> 00:06:00,460
对于商业级的应用，一般的这种商业级应用

87
00:06:00,460 --> 00:06:07,485
常用的字典规模一般为3到5万词汇。
 10万级词汇的字典也比较常见。

88
00:06:07,485 --> 00:06:09,920
有些大型互联网公司会使用

89
00:06:09,920 --> 00:06:14,310
词汇量达到百万量级甚至更大的字典

90
00:06:14,310 --> 00:06:17,695
不过也有很多商业应用使用字典的

91
00:06:17,695 --> 00:06:21,660
词汇规模大概在3万到5万

92
00:06:21,660 --> 00:06:27,790
我们使用词汇为1万的字典，
因为1万是个比较整的数

93
00:06:27,790 --> 00:06:33,520
所以,如果你打算使用大小为1万的字典，其中一种构建

94
00:06:33,520 --> 00:06:35,630
这个字典的方法就是去你的

95
00:06:35,630 --> 00:06:40,115
训练集中查找，找到出现频率最高的1万个词

96
00:06:40,115 --> 00:06:43,940
另一种方式是查找一些网上的字典，

97
00:06:43,940 --> 00:06:48,099
将其中包含的英语中最常见的1万词作为拟构建的字典

98
00:06:48,099 --> 00:06:54,320
我们可以将这些词汇中的每个
都表示成为一位热键(one-hot)的表示(representation)

99
00:06:54,320 --> 00:07:02,960
例如，X^<1>代表的单词Harry，
就被表示为一个向量：向量的其余位全为0，除了

100
00:07:02,960 --> 00:07:12,080
在第4075位上有一个1表示。因为，
Harry这个单词就在词汇表中的第4075位上。

101
00:07:12,080 --> 00:07:18,110
同理对于x^<2>，也是一个向量，

102
00:07:18,110 --> 00:07:24,757
除了在第6830位有个1，其余位均为0。

103
00:07:24,757 --> 00:07:30,620
单词“and”，在词汇表中在第367位，所以x^<3>向量

104
00:07:30,620 --> 00:07:38,000
除了在第367位有个1，其余位也均为0。

105
00:07:38,000 --> 00:07:40,835
假如你的词汇表中存在1万个词汇，

106
00:07:40,835 --> 00:07:45,830
那么每一个词也就表示成为一个维数为1万的向量。

107
00:07:45,830 --> 00:07:50,570
这里有个有个词“a”，
我猜在任何一部英文词典中它都是第一个，

108
00:07:50,570 --> 00:07:54,258
在句子单词“a”对应于x^<7>，

109
00:07:54,258 --> 00:07:57,625
用向量表示就是向量[1;0;...;0]，

110
00:07:57,625 --> 00:08:03,060
也就是说将字典中的第一个元素用1表示了，其余全0。

111
00:08:03,060 --> 00:08:07,760
所以，这种表示方法中，

112
00:08:07,760 --> 00:08:12,800
句子里的任意一个词t，设为x^<t>，
都将表示为一个one-hot（一位热码）向量，

113
00:08:12,800 --> 00:08:16,760
one-hot的意思指只有一位为1其余位全是0。

114
00:08:16,760 --> 00:08:22,075
例子中这句话有9个单词，
也就需要9个one-hot向量来表示

115
00:08:22,075 --> 00:08:25,995
这样做的目的是，先学习

116
00:08:25,995 --> 00:08:31,325
使用序列模型到目标输出的方法表示x。

117
00:08:31,325 --> 00:08:33,875
作为监督式学习问题，

118
00:08:33,875 --> 00:08:37,460
用到的数据表中包括X和Y。

119
00:08:37,460 --> 00:08:39,137
最后还有注意，

120
00:08:39,137 --> 00:08:42,665
们在之后的章节中会深入探讨，那就是

121
00:08:42,665 --> 00:08:46,545
当你遇到不再词汇表中的单词怎么办？

122
00:08:46,545 --> 00:08:52,400
解决办法是, 创建一个新的标记, 
或者说是一个伪词, 称其为Unknown Word,

123
00:08:52,400 --> 00:08:58,391
并使用尖括号加UNK(<UNK>)
来表示这些不在词汇表中的词。

124
00:08:58,391 --> 00:09:00,985
在后面的章节中我们会详细讲解。

125
00:09:00,985 --> 00:09:02,660
好，来总结这一讲的内容：

126
00:09:02,660 --> 00:09:05,570
我们构建起了一套符号来描述

127
00:09:05,570 --> 00:09:09,205
训练集中的序列数据X和Y。

128
00:09:09,205 --> 00:09:11,390
在下一讲中，我们将开始讲述

129
00:09:11,390 --> 00:09:15,420
循环神经网络用于构建从X到Y的映射