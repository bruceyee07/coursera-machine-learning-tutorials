語言建模是最基本也是 最重要的自然語言處理任務之一 是可以充分運用RNN的領域 在這段影片, 你會學到如何建構一個RNN語言模型 這會帶領你進入這周有趣的程式練習 你會建構一個語言模型 並用來產生一段莎士比亞式的文本, 或者其他風格 讓我們開始吧 那甚麼是語言模型呢 假設我們要建構一個語音辨識系統 當你聽到以下句子: 「蘋果和梨子沙拉很好吃」 所以你聽到了甚麼 我是說「蘋果和一對沙拉很好吃」還是「蘋果和梨子沙拉很好吃」(注: 英文中一對(pair)和梨子(pear)同音) 你應該會認為第二句較為可能 而這就是一個好的語音辨識系統能做到的事 即使聽起來相同, 卻能幫我們判斷出是哪一句 而語音辨識系統挑出第二句的方法 是透過語言模型 來告訴我們這兩句子各自的機率為何 例如, 一個語言模型可能會說第一句的 機率是3.2乘以10的-13次方 第二句的機率是5.7乘以10的-10次方 有了這些機率, 第二句是更為可能的 因為和第一句相比10的指數多3 所以系統會挑出第二句 語言模型做的事是給定特定句子 它能告訴你特定句子的機率為何 我說的機率是指, 如果你想拿起隨機一份報紙, 隨機打開一個電子郵件或一個網頁或 聽你的朋友說的下一件事 此特定句子, 比如說剛提到的蘋果和梨子沙拉 在這世界中被使用到機率為何 這是以下兩者的基礎要件: 剛提到的語音辨識系統 和機器翻譯系統 我們會期望它輸出最有可能出現的句子 因此, 語言模型的基礎工作是輸入一個 我會將其寫成y^<1>, y^<2> 到 y^<Ty>的句子 語言模型做的是 將句子表示為 y 而不是 x 但語言模型做的事是預測 該特定字詞序列的機率 那該如何建構語言模型呢 用RNN建構模型 你會需要一個包含許多英文文本語料庫(corpus)的訓練資料 或其他任何你想套用你的語言模型的語言上 而「語料庫(corpus)」是自然語言分析領域的術語,
代表非常大的文體 或是一套包含非常多英文句子的文本 假設你從訓練集裡得到了以下句子 「貓平均一天睡十五小時」 你要做的第一件事是解析標記(tokenize)該句子 這代表你要組成一個像是先前影片中看過的字典 並對應每個單字至, 例如說one-hot向量 或是在你字典中的索引值 有一件你可能也想做的事是
建構句子何時結束的模型 因此, 加入一個稱為EOS的標記(token)是很常見的 那代表「句子結束」(End of Sentence), 
幫助你找出句子何時結束 我們之後會再回頭講這件事 如果你希望你的模型可以判斷句子何時結束 你可以把EOS標記加到你訓練集當中每一個句子的最後 這周末的程式作業中, 我們並不會使用EOS標記 但在某些應用中你可能會想使用它 稍後我們會看到它在哪裡發揮效用 在這個例子當中, 我們有y^<1>到y^<9>九個輸入 如果你把EOS標記加到每一個句子最後 並進行標記解析, 你可以決定 是否把句末當作標記 在這個例子當中, 我會直接忽略標點符號 所以「天(day)」是一個標記 然後忽略句號, 但如果你把句號(或其他標點符號)當作 標記, 那你也可以把句號加到你的字典中 現在, 另一個細節是如果有一些訓練集中字詞 並不在你的字典裏面 假設你的字典包含一萬字, 也許是最常見的一萬個 英文字, 那麼「埃及貓(Mau)」這個字 可能不在這一萬字當中 在這情況下, 你可以把「埃及貓(Mau)」這個字 用一個獨特的標記<UNK>來代替,
代表著不存於字典的字詞 模型當中就把所有字典裡沒有的字詞統一當作一個字詞來處理 進行標記步驟基本上意味著 輸入句子並將其映射到各個獨立標記, 或者說 你字典當中的獨立字詞 接下來, 讓我們建立一個 RNN 以模擬這些不同的序列的機率 我們將在下一張投影片看到的是 你會設定 x^<t><t> 為 y^<t-1><t-1> 那我們將繼續建立 RNN 模型, 我會繼續用這個貓的句子當作範例 這會是RNN架構 在時間0, 你會計算一些啟動函數值 a^<1> 是輸入數值 x^<1> 的函數 而且 x^<1> 會初始為全為零的向量 前面的 a^<0> 習慣上來說也會設定成零向量 但是 a^<1> 做的事情是softmax預測 試著找出第一個單詞的概率 y 所以會寫成 y^<1> 所以這步驟做的其實是嘗試用softmax以預測 字典中字詞的機率為何 第一字是 "a" 或第二字 "Aaron" 的機率是多少 然後句子裡第一字是「貓(Cat)」的機率是多少 或第一字是「祖魯(Zulu)」的機率是多少 或第一字是個未知字詞的機率是多少 或第一字是代表句子結尾的EOS標記的機率是多少 但這應該不太可能會出現, 對吧 y_hat^<1> 是softmax的輸出 他預測了第一字出現特定字詞的機率 在我們的例子中, 出現「貓(Cat)」這個字 所以這是個一萬個softmax輸出, 因為字典還有一萬字 或者說10,002個輸出, 因為把未知字詞和 句子結尾當作標記 然後, RNN前進到下一步 而且a^<1>也傳到下一步 而在這一步, 要嘗試找出第二個字詞為何 但是我們會給他實際的第一個字詞 我們要告訴他 第一個字是「貓(Cat)」 這裡是 y^<1> 用 y^<1> 等於 x^<2> 來告訴它這是「貓」 第二步中同樣使用softmax輸出預測值 RNN的工作是, 不管在句子何處, 無論先前輸入了甚麼 它會估計不同字詞在該處出現的機率 預測是否為"a", "Aaron", "Cats", "Zulu", 未知字詞標記還是句尾標記 那麼這樣的話 在這裡的答案應該是「平均(average)」, 因為句子的開頭是「貓平均」 然後, 你會繼續做RNN下一步 計算出 a^<3> 但要預測第三字詞, 「15」 我們要輸入前面兩個字詞 我們要告訴它「貓(Cats)」和「平均(Average)」是前面兩字詞 所以這裡的輸入 x^<3> 等於代表「平均(average)」的 y^<2> 然後嘗試預測接下來出現甚麼字 換句話說, 當已經出現「貓平均 (Cat average)」, 我們要找出字典中字詞 在那之後出現的機率 這個例子下是「15」機率最大, 接下來也是同樣做法 直到最後的 我猜是在第九步的時間9, 你會需要輸入 x^<9> 它等於 y^<8>, 代表著「天(day)」 然後這裡是 a^<9>, 他的工作是輸出 y_hat^<9> 它代表著 EOS 標記 (句尾標記) 不論句子前面出現了哪些字 我們會預期它將預測EOS在這裡會有最高出現機率 代表著句尾標記 RNN當中的每一步會看看前面出現過的單詞, 例如說 給定三個字, 下一個出現字詞的機率為何? 所以這個RNN模型是從左至右, 一字一字做預測 我們訓練到一個網路之後, 我們將定義成本函數(cost function)。 所以, 在特定的時間 t, 如果真正的字 y^<t> 然後神經網路的softmax函數輸出預測值 y_hat 那這個就是softmax損失函數(loss function), 
你可能已經對它很熟悉 然後總損失函數就是加總在每一步當中 獨立預測單詞的損失函數 當你用一個很大的訓練集來訓練這個RNN 你可以做的是, 給定任何一組字詞, 像是"Cats average 15 hours", 它會預測特定字詞在接下來出現的機率 例如說, 簡單起見, 給定一個含有 y^<1>, y^<2> 和 y^<3>三個詞的例句 找出這整個句子的機率是什麼的方法是 第一個 softmax 函數告訴你 y^<1>的機率 這是第一個輸出 第二個 softmax 告訴你給定 y^<1> 情況之下, y^<2> 機率為何 第三個 softmax 表示給定 y^<1> 和 y^<2>, y^<3> 機率為何 然後將這些機率相乘 你會在前面的程式練習當中見到更多細節 將這三個機率相乘, 你會得到整個句子 這個包含三個單字句子的機率 那這就是一個用RNN訓練語言模型的基礎結構 如果有些地方對你來說很抽象, 請不要擔心 你會在程式作業當中獲得更多練習 但接下來你可以用語言模型做的一個很有趣的事是 是從模型當中取樣序列 讓我們在下一段影片看看它