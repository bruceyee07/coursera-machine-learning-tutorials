到目前为止, 你已经了解了 RNNs 的大部分组成部分。 但是, 还有两个想法
 可以让你建立更强大的模型。 一个是双向 RNNs, 这让你在一个时间点获得 序列中前部分的和后部分的信息, 所以我们将在这个视频中讨论这部分内容。 第二, 是深度 RNNs, 你将会在下一个视频中看到。 因此, 让我们从双向 RNNs 开始。 为了激发双向 RNNs, 看一下这个网络,
 在之前识别人名的上下文识别中 已经看到过几次。 这个网络的一个问题是, 为了弄清第三个单词
“泰迪“是否是人名的一部分, 仅仅考虑句子的前半部分是不够的。 所以为了判断 Y ^<3>是 0 还是 1, 你需要更多的信息 不只是前三个单词, 因为
前三个单词不足以告诉你, 比如他们会 谈论泰迪熊或者前美国总统泰迪. 罗斯福。 因此, 这是单向或正向 RNN。 我刚才说的都成立， 无论这些部分是 标准 RNN单位，GRU 单位,
 还是 LSTM 单位。 所有这些单位都是单向且朝前的。 相对而言，一个双向 RNN（BRNN） 可以解决此问题。 双向 RNN 的工作原理如下： 我将用一个简化的四维输入,
 或者说是一个四个单词的句子。 所以我们有四个输入矢量。 x1 到 x4 因此, 这个网络的头部层将有一个前向递归的部分。 所以我们要叫这个 A1, A2, A3，A4， 然后我会画一个右箭头 去表示这是前向递归的组成, 因此, 它们将连接如下。 因此, 这四个单位
每次都输入当前的 X, 然后喂入数据 去帮助预测 Y^1, Y^2, Y^3 和 Y^4 所以，到目前为止我还什么都没做。 基本上, 我们绘制了上张幻灯片中的 RNN, 但箭头放置在了有趣的位置。 我把箭头的位置 做了调整, 因为我们还要 添加一个后向递归层。 所以我们有 A1, 左箭头表示这是一个后向连接, A2，向后， A3, 向后， A4，向后, 因此左箭头
表示它是后向连接的。 因此, 我们将网络连接成如下。 而这后向的连接将连接彼此，
向后传播。 因此, 请注意, 
此网络定义了一个无循环图。 因此, 给定一个输入序列, x1到 x4, 前向序列将
首先计算A(前向）^1， 然后用它计算A(前向）^2, 然后 A(前向)^3, A(前向)^4, 相反, 向后序列
将从计算A(后向)^ 4开始, 然后向后计算A(向后)^3, 然后当计算到激活层时, 注意这整个过程不是反向传播, 而是前向传播。 前向传播的关系图中有一部分 计算是从左向右， 有一部分是从右向左。 计算了A(向后)^3以后, 您可以使用这些激活部分
来计算A(向后)^2, 然后 A(向后)^1 ,
然后计算所有的激活部分, 然后你就可以做出预测了。 比如 为了做出预测, 你的网络在时间 t ，
将得到 Y ^t，这是个对于W(y)来说的激活函数 在时间 t，有前向激活函数, 也有后向激活函数 一起被喂入，来做预测。 所以，举例一下
假设在时间设为3的位置上, 然后从 X 得到的信息可以流到这里, 从前向 1 到 2 ， 激活函数中都有考虑,
再由前向 3 得到 Y ^3。 所以 x ^1, x ^2, x ^3中的信息都被考虑了进去，
并且 x ^4中的信息能通过 A(反向)^4 到 A(反向)^3 传入 因此, 这允许在 t3 时刻的预测将 过去的信息作为输入, 以及目前的通过前向作为输入，以及 后项的信息 以及来自未来的信息同样作为输入。 所以, 如果给出一个类似的短语, 
"他说, 泰迪. 罗斯福...”来预测 ‘泰迪’是否是人名字的一部分, 你会考虑过去和未来的信息。 这就是双向递归神经网络（BRNN） 这里可以不只是标准的 RNN 块, 也可以是 GRU 块或 LSTM 块。 事实上, 对于许多 NLP 问题, 对于处理NLP问题的大量文本, 带有 LSTM 的双向 RNN 
是非常常用的。 所以, 我们有 NLP 问题, 你有完整的句子, 你试着把句子里的东西标注出来, 具有 LSTM 块的双向 RNN 既向前又向后，这值得首先尝试。 所以, 这是双向 RNN, 这是 对基本的 RNN 结构
或 GRU 或 LSTM 进行的修改, 通过做这个改变, 你可以用 使用RNN 或 GRU 或 LSTM的模型 预测任何地方, 甚至在一个序列的中间, 利用来自整个序列的信息。 双向 RNN 的缺点是 需要整个数据序列, 然后才能在任何地方进行预测。 例如, 如果要构建语音识别系统, 然后 BRNN 会让你考虑 整个演讲的内容,
 但如果你使用简单的前向实现, 你需要等待人停止说话, 得到 整个话语, 你才可以 实际处理它，并进行语音识别预测。 所以对于一个实时类型的语音识别应用程序, 他们有更复杂的模块, 而不是仅仅 使用标准的双向 RNN, 正如在这里看到的。 但对于许多自然语言处理应用, 其中 你可以同时得到整个句子, 标准 BRNN 算法实际上是非常有效的。 所以, 这是 BRNNs ，
在下一个也是本周最后的视频中, 让我们来谈谈
如何利用 RNNs, LSTMs GRUs 和双向版本, 去构建它们的深层版本。