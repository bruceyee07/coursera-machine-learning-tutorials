到目前为止你所见过的 RNNs 的不同版本 已经可以很好的解决问题了。 但对于学习非常复杂的函数，有时候 把多层 RNNs 堆在一起形成更深层的这些模型的版本会很有帮助。 在本视频中, 你将看到如何构建这些更深层的 RNNs。让我们来看看。 所以你记得，对于一个标准的神经网络, 你将有一个输入 x。 然后, 这是堆积到一些隐藏的层, 所以可能有激活 a1 来自于第一个隐藏层, 然后将其堆叠到下一层,并且激活 a2, 然后也许还有一层, 激活 a3 然后你做一个预测ŷ。 所以一个深层 RNN 有点像这样, 通过采用这个我刚刚手画的神经网络并且 按时间展开。让我们来看看。 这是你所看到过的标准 RNN。 但我改变了一点点符号, 改变的是, 我并没有把时刻0的激活写为 a0 , 我添加了这个正方形括号1
表示这是来自于第一层的。 所以我们将要使用a[l]来表示它是 对应第l层上面的激活，
并且用<t>来表示它对应时间t 所以这会在a[1]<1>上激活, 这是(a[1]<2>) (a[1]<3>) (a[1]<4>)。 然后我们可以把这些叠在上面 这将会是一个包含三个隐藏层的新网络。 让我们来看一个如何计算这个数值的例子。 a[2]<3>有两个输入。 它有一个来自底部的输入, 另外还有一个来自左边的输入。 这里计算机会把一个激活函数g代入到一个矩阵上。 也就是Wa,因为要计算a的值，还有一个激活后的值。 对于第二层, 我要给它a[2]<2>的值， 也就是这个，逗号a[1]<3>，也就是这个值 加上第二层相应的ba 这就是你计算激活值的方式。 因此相同的参数Wa[2]以及 ba[2]会在这一层的每一次计算中被使用。 与之相反，第一层会有它自己的参数Wa[1]和ba[1]。 但是对于像左边这样的标准RNN， 我们见过非常深的神经网络， 甚至可能超过100层。 对于RNN来说，有三层已经算很多了。 由于时间这一维度的存在, 即使只有很少的层数这些网络也已经变得很大。 你很少会看见这样的神经网络堆叠到100层。 你有时会看到的是 有一些互相堆叠的循环层。 但是你可能取的是这里的输出，我们先不说这个， 然后有一些没有水平连接的深层 但是在这里有一个深度网络最后会预测y<1>。 然后这里也可以有同样的深度网络用来预测y<2>。 这就是我们比较多的时候会见到的一种网络结构当你 有三个以时间连接的循环单元， 然后跟着一个网络， 后面跟着另一个网络， 就像我们看到的y<3>和y<4>。 这里有一个深度神经网络，但没有水平的连接。 这是一种我们经常看见的结构。 并且很经常的，这些模块不一定要是标准RNN， 简单RNN模型。 它们也可以是GRU模块或者LSTM模块。 最后，你也可以建立一个双向RNN的深层版本。 因为深层RNN在训练时计算力花费很大， 经常有很大的时间范围, 虽然你不会看到那么多深度循环层， 这有三个在时间上相连接的深度循环层。 你不会看到那么多深度循环层， 不会像在一个传统的深层神经网络中那么多层。 所以这就是深层 RNNs的所有内容。 这周你所看到的 从基本的 RNN, 基本的循环单位, 到 GRU,到 LSTM, 到双向 RNN, 以及你刚才看到的这些深层的版本, 你现在有一个非常丰富的工具箱来构建 非常强大的模型学习序列模型。 我希望你喜欢这周的视频。 祝你编程练习好运, 我期待下周见到你。