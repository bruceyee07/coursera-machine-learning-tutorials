嗨，欢迎学习这门课最后一周的内容 同时也是深度学习系列 最后一周的课程内容 你们即将到达终点线 这周你将学习Seq2Seq模型 该模型对实施机器翻译和语言识别很有帮助 现在我们先引入基本模型，在之后的课程中 你将会学到集束搜索（Beam Search）、 注意力模型（Attention model） 最后讨论如何对语音数据建模作为收尾 如何对数据进行运算 假如你现在输入一句法语
如：Jane visite l'Afrique en septembre 然后你想把这句法语翻译成英文 简9月份正在访问非洲
(Jane is visiting Africa in September.) 像之前那样，我们用x<1>到x<5> 来表示作为输入的这句法语句子里面 的每个单词 然后我们用y<1>到y<6>来表达输出句子里每个单词 现在你该如何构造一个神经网络，
使得输入是序列X，输出是序列y呢？ 对于这个问题，你可以这么做： 顺便一提，我接下去要说的这个方法主要由Sutskever Oriol Vinyals和Quoc Le的一篇论文提供 另一篇是由Kyunghyun Cho、 Bart van Merrienboer, Caglar Gulcehre, 
Dzmitry Bahdanau, Fethi Bougares Hogler Schwen和Yoshua Bengio提供 首先我们先定义一个神经网络 该网络使用RNN模型来搭建一个编码器网络 这部分可能是GRU或者LSTM 每次向模型喂入一个法语单词 然后通过理解输入序列的内容 随后RNN将输出一个向量来表示输入序列 在此之后，需要再建立一个解码器网络 该网络将编码器的输出作为输入 也就是图中黑色部分画出的部分 而这些输入将通过神经网络进行训练 并且按一次一个单词的顺序 将翻译结果输出 而当解码器停止时，也就意味着句子翻译结束 像之前一样，我们可以将每一次产生的输出 作为后一个产生单词的RNN模型的输入 就像我们之前在序列中用语言模型合成文本一样 在深度学习中应用证明这个方法是有效的 当给到你足够多的，且一一对应的法语和英语句子 如果你训练一个模型，输入一句法语句子 然后输出一个相应的英语翻译 这个方法目前看来确实是行之有效的 并且这个模型仅仅用了一个编码器网络 它的作用是将输入的法语句子先编码 再然后用解码器将来产生相应的英语翻译 同样相似的结构也可以用在图像标注 比如给出这样一张照片 也许希望可以自动辨识出这张图里，一只猫坐在椅子上 那么你该如何构建一个神经网络，通过输入一张图片 再输出一段辨识文字：
a cat sitting on a chair(一只猫坐在椅子上) 你可以这样做：在之前讲卷积网络时 你学会了如何输入一张图片到卷积网络中去 也许是预训练好的AlexNet 并且AlexNet能够学习输入图片的编码结果或一系列特征 所以 这是AlexNet模型，如果我们不要这最后的Softmax部分 预训练好的AlexNet模型最后可以得到 一个4096维的特征向量来表达这张关于猫的图像 现在这个预训练好的网络可以作为该图片的编码器网路部分 而你将有一个4096维的向量来表示这张图 你可以将这个向量喂入RNN模型 其作用是每次产生一个说明文字 类似于我们看到的机器翻译，从法语到英语的翻译 你现在可以输入一个特征向量来描述输入 随后产生一个输出集，或者说一个文字输出序列
并且是每次一个单词 这个方法对图像标识而言，效果不错 尤其是当产生的说明文字不长的时候 据我所知 这个模型一开始是由 Junhua Mao, Wei Xu, Yi Yang, 
Jiang Wang, Zhiheng Huang, 和Alan Yuille提出 尽管有很多研究组互相独立， 同时独立提出了相似的模型 另外两个研究组在同一时间做了相似的工作 他们是Oriol Vinyals Alexander Toshev, Samy Bengio Dumitru Erhan, Andrej Karpathy, 李菲菲 现在你已经看到一个基本的Seq2seq模型是如何运行的 以及基本的图像-序列（图像标识）模型是如何建立的 但在你跑这样一个模型来产生一个序列 和用语言模型合成文本相比， 仍然有很大的区别 关键区别之一是： 你不希望输出一个随意的翻译 你希望输出一个你想要的翻译结果 或者说你不希望输出一个随意的图片标识 你希望输出一个最好，或者说最符合的标识 下节课我将告诉你，你该如何获得你想要的结果
GTC字幕组翻译