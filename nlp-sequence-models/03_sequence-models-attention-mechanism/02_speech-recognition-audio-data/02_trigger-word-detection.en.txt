You've now learned so much about deep learning, and sequence models, that we can actually describe a trigger word system quite simply, just on one slide as you see in this video. But, with the rise of speech recognition, there have been more and more devices. You can wake up with your voice, and those are sometimes called trigger word detection systems. So, let's see how you can build a trigger word system. Examples of trigger word systems include; Amazon Echo, which is broken out with the word Alexa, the Baidu DuerOS power devices, broken out with the phrase Xiadunihao, Apple Siri broken up with Hey Siri, and Google Home broken up with Okay Google. So, [inaudible] trigger word detection, that if you have say an Amazon echo in your living room, you can walk through the living room and just say, "Alexa, what time is it", and have it wake up, or be triggered by the voice Alexa, and answer your voice query. So, if you can build a trigger word detection system; maybe you can make your computer do something by telling your computer, "activate." One of my friends also works on turning on and off a particular lamp, using a trigger word, as a fun project. But, what I want to show you is how you can build a trigger word detection system. The literature on triggered detection algorithm is still evolving, so there isn't wide consensus yet, on what's the best algorithm for trigger word detection. So, I'm just going to show you one example of an algorithm you can use. Now, you've seen RNNs like this, and what we really do, is to take an audio clip, maybe compute spectrogram features, and that generates audio features X-1 X-2 X-3, that you pass through an RNN. So, all that remains to be done, is to define the target labels y. So, this point in the audio clip, is when someone just finished saying the trigger word, such as Alexa or Xiadunihao, or Hey Siri, or okay Google. Then, in the training set, you can set the target labels to be zero for everything before that point, and right after that, to set the target label of one. Then, if a little bit later on, the trigger word was said again at this point, then you can again set the target label to be one, right after that. Now, this type of labeling scheme for an RNN could work. Actually it just won't actually work reasonably well. One slight disadvantage of this is, it creates a very imbalanced training set, so we have a lot more zeros than we want. So, one other thing you could do, that it's little bit of a hack, but could make the model a little bit easier to train, is instead of setting only a single time step to operate one, you could actually make it to operate a few ones for several times. So, for a fixed period of time, before reverting back to zero. So that slightly evens out the ratio of one's to zero's, but there's this little bit of a hack. But, if this is when in the audio clip, the trigger word was said, then right after that, you can set the target label to one, and if this is the trigger word said again, then right after that, is when you want the RNN to output one. So, you get to play more off this as well, in the programming exercise, but I think you should feel quite proud of yourself. We've learned enough about deep learning, that it just takes one picture; one slide, to describe something as complicated as trigger word detection. Based on this, I hope you'll implement something that works, and allows you to detect trigger words. Well, you see more of this in the programming exercise. So, that's it for trigger words. I hope you feel quite proud of yourself, for how much you've learned about deep learning, that you can now describe trigger words in just one slide in a few minutes, and that you prepare hopefully to implemented it, and get it to work. Maybe even make it do something fun in your house even, like turn on or turn off, or you could do something on your computer, when you or when someone else says the trigger words. This is the last technical video of this course, and to wrap up in discourse on sequence models, you learned about RNNs, including both GR use and LSTMs. Then in the second week, you've learned a lot about word embeddings, and also learned representations of words. Then in this week, you learned about the attention model, as well as how to use it to process audio theater. I hope you have fun implementing all of these ideas in this peace-pro exercise. Let's go on to the last video.