1
00:00:00,000 --> 00:00:04,530
情感分类的任务是分析一段文本

2
00:00:04,530 --> 00:00:07,170
告诉人们某个人是不是

3
00:00:07,170 --> 00:00:09,125
喜欢他们正在谈论的东西

4
00:00:09,125 --> 00:00:14,135
它是自然语言处理最重要的组成部分<br />在很多应用中使用

5
00:00:14,135 --> 00:00:15,980
情感分类的挑战之一是

6
00:00:15,980 --> 00:00:19,223
你可能缺乏一个特别大的<br />标签训练集

7
00:00:19,223 --> 00:00:20,340
不过 使用词嵌入（word embedding）后

8
00:00:20,340 --> 00:00:22,972
依靠一个中等大小的标签训练集

9
00:00:22,972 --> 00:00:25,870
你也可以构建出一个很好的情感分类器

10
00:00:25,870 --> 00:00:27,255
让我们看看该怎么做

11
00:00:27,255 --> 00:00:31,720
有这样一个情感分类问题

12
00:00:31,720 --> 00:00:34,860
输入X是一段文本 输出Y

13
00:00:34,860 --> 00:00:38,864
是你想预测出的情感

14
00:00:38,864 --> 00:00:40,983
比如酒店的

15
00:00:40,983 --> 00:00:43,025
星级评分

16
00:00:43,025 --> 00:00:47,025
如果有人说 甜点很棒 并且在评论中给了四颗星

17
00:00:47,025 --> 00:00:49,090
服务很慢 两颗星

18
00:00:49,090 --> 00:00:51,178
简单吃一顿还行 但没特色 三颗星还行

19
00:00:51,178 --> 00:00:53,120
还有段比较严厉的批评

20
00:00:53,120 --> 00:00:54,090
完全没品味 服务差 环境不好

21
00:00:54,090 --> 00:00:56,090
评价只有一颗星

22
00:00:56,090 --> 00:01:02,835
所以如果你要根据类似这样的标签数据集<br />训练实现从X到Y映射的系统

23
00:01:02,835 --> 00:01:05,880
然后你可以用它来监控

24
00:01:05,880 --> 00:01:08,925
人们对你开的餐厅的评论

25
00:01:08,925 --> 00:01:13,335
人们也可能会在社交媒体上发些<br />与你的餐厅有关的信息

26
00:01:13,335 --> 00:01:14,895
比如在Twitter Facebook

27
00:01:14,895 --> 00:01:17,510
Instagram或其他社交媒体上

28
00:01:17,510 --> 00:01:20,605
如果你有一个情感分析器

29
00:01:20,605 --> 00:01:23,730
它可以看一段文字 然后猜出

30
00:01:23,730 --> 00:01:27,540
对你酒店的评论帖子的情感是正面还是负面的

31
00:01:27,540 --> 00:01:30,750
然后你可以跟踪餐厅是否有问题

32
00:01:30,750 --> 00:01:35,475
或者你的餐厅随时间变得更好还是更差

33
00:01:35,475 --> 00:01:38,310
其中 情感分类的一个挑战是

34
00:01:38,310 --> 00:01:43,250
你的标签数据集可能不是特别大

35
00:01:43,250 --> 00:01:45,400
那么 对情感分类任务而言

36
00:01:45,400 --> 00:01:47,910
训练集的数据可能在

37
00:01:47,910 --> 00:01:52,410
10,000到100,000个词之间 这个都很常见

38
00:01:52,410 --> 00:01:57,285
有时候甚至少于10,000个词<br />词嵌入可以

39
00:01:57,285 --> 00:02:00,020
帮你更好地

40
00:02:00,020 --> 00:02:03,680
了解训练集小的时候的情况

41
00:02:03,680 --> 00:02:04,980
你可以这样做

42
00:02:04,980 --> 00:02:08,120
在这个视频中 我们看一些不同的算法

43
00:02:08,120 --> 00:02:11,150
有这样一个情感分类模型

44
00:02:11,150 --> 00:02:13,490
你可以接收一个类似“甜点极好”的句子

45
00:02:13,490 --> 00:02:16,070
然后在你的词典里面查这些词

46
00:02:16,070 --> 00:02:18,465
我们像往常一样使用1万字的词典

47
00:02:18,465 --> 00:02:24,140
我们现在构建一个分类器 把它映射到四星级的输出Y上。

48
00:02:24,140 --> 00:02:27,080
给定这四个词 同之前一样

49
00:02:27,080 --> 00:02:33,620
我们可以输入这四个词 查找one-hot向量

50
00:02:33,620 --> 00:02:38,882
可以得出0 8 9 2 8 它是一个one-hot向量与嵌入矩阵E的乘积

51
00:02:38,882 --> 00:02:41,920
它可以从更大的文本向量中学习

52
00:02:41,920 --> 00:02:43,550
例如 它可以从

53
00:02:43,550 --> 00:02:45,440
十亿词的向量或千亿词的向量学习

54
00:02:45,440 --> 00:02:50,745
使用该向量抽取出"the"这个词的嵌入向量

55
00:02:50,745 --> 00:02:52,965
然后对"dessert"执行相同的操作。

56
00:02:52,965 --> 00:02:57,545
然后对"is" 然后对"excellent"执行相同的操作

57
00:02:57,545 --> 00:03:02,530
如果利用非常大的数据集训练

58
00:03:02,530 --> 00:03:04,218
例如几千亿个词

59
00:03:04,218 --> 00:03:06,980
那么你可以甚至可以从不常见的词

60
00:03:06,980 --> 00:03:10,250
中获取很多知识<br />然后把它们用到你的问题上

61
00:03:10,250 --> 00:03:15,455
即使那些不在标注了的训练集中的词语也能用

62
00:03:15,455 --> 00:03:17,709
现在我们有一个方法来构建分类器

63
00:03:17,709 --> 00:03:19,570
你可以用这些向量

64
00:03:19,570 --> 00:03:22,505
例如说有300维的向量

65
00:03:22,505 --> 00:03:26,220
然后你可以对它们求和或求平均数

66
00:03:26,220 --> 00:03:34,380
现在我在这儿放一个更大的求平均数符号<br />你可以用它来求和或求平均数

67
00:03:34,380 --> 00:03:38,430
它会给你一个300维的向量

68
00:03:38,430 --> 00:03:44,260
然后你可以把它传给一个softmax分类器<br />由它来输出Y-hat

69
00:03:44,260 --> 00:03:47,250
然后softmax可以输出

70
00:03:47,250 --> 00:03:50,935
一星到五星这五个结果的概率

71
00:03:50,935 --> 00:03:57,285
这会有五个可能的结果来预测Y是什么

72
00:03:57,285 --> 00:04:01,070
大家注意 这儿我们通过使用求平均的操作

73
00:04:01,070 --> 00:04:04,680
这个特别的算法对短的或长的评论都有效果

74
00:04:04,680 --> 00:04:08,550
即使评论只有100个单词长也有效果

75
00:04:08,550 --> 00:04:11,390
你可以简单地对这一百个单词的所有特征向量求和或求平均

76
00:04:11,390 --> 00:04:15,645
所以给你一个表示

77
00:04:15,645 --> 00:04:18,095
一个300维的特征表示

78
00:04:18,095 --> 00:04:21,745
然后你可以把它传到你的情感分类器

79
00:04:21,745 --> 00:04:23,890
平均数的方法会有相当好的效果

80
00:04:23,890 --> 00:04:27,030
它实际做的是求你的例子中所有单词的意思

81
00:04:27,030 --> 00:04:33,045
平均数或求和

82
00:04:33,045 --> 00:04:35,180
这对...（难以听清）情况也适用

83
00:04:35,180 --> 00:04:38,575
这个算法的问题之一是它忽视了单词的顺序

84
00:04:38,575 --> 00:04:41,935
特别是 以下面这个特别负面的评论为例

85
00:04:41,935 --> 00:04:43,080
品味完全不佳

86
00:04:43,080 --> 00:04:44,378
服务不好 环境不好

87
00:04:44,378 --> 00:04:46,725
但是好这个词出现很多次

88
00:04:46,725 --> 00:04:47,440
有很多

89
00:04:47,440 --> 00:04:48,420
好 好 好

90
00:04:48,420 --> 00:04:52,557
所以如果你使用类似这种忽视词语顺序的算法

91
00:04:52,557 --> 00:04:56,870
仅仅对不同词语的所有向量求和或求平均数

92
00:04:56,870 --> 00:05:01,445
那么最后在你最终的特征向量中<br />会有很多好的表示

93
00:05:01,445 --> 00:05:04,231
你的分类起可能会

94
00:05:04,231 --> 00:05:07,335
认为这个评论不错<br />即使这实际上是一个非常严厉的评论

95
00:05:07,335 --> 00:05:08,460
这是个一星级的评论

96
00:05:08,460 --> 00:05:11,625
现在有一个更复杂的模型

97
00:05:11,625 --> 00:05:14,880
它不仅仅对你所有的词嵌入求和

98
00:05:14,880 --> 00:05:20,550
你可以使用RNN进行情感分类

99
00:05:20,550 --> 00:05:23,220
你可以这样做<br />你可以输入那则评论

100
00:05:23,220 --> 00:05:24,645
品味完全不佳

101
00:05:24,645 --> 00:05:26,231
服务不好 环境不好

102
00:05:26,231 --> 00:05:29,840
然后为它们每一个都找出one-hot向量

103
00:05:29,840 --> 00:05:31,575
所以我想只跳过

104
00:05:31,575 --> 00:05:34,999
单个one-hot向量表示<br />但是利用多个one-hot向量

105
00:05:34,999 --> 00:05:38,805
跟通常一样<br />把它与词嵌入矩阵E相乘

106
00:05:38,805 --> 00:05:48,005
然后你可以得到多个词嵌入向量<br /> 接着你可以把它们输入到RNN

107
00:05:48,005 --> 00:05:52,575
接下来RNN的任务是在最后一步计算

108
00:05:52,575 --> 00:05:57,550
该表示 让你预测出Y-hat

109
00:05:57,550 --> 00:05:59,620
这是我们上周看过的

110
00:05:59,620 --> 00:06:07,098
多对一的RNN架构的一个例子

111
00:06:07,098 --> 00:06:08,725
有了类似这样的算法后

112
00:06:08,725 --> 00:06:14,260
可以考虑单词的顺序 得到更好的结果<br />并且能意识到

113
00:06:14,260 --> 00:06:16,450
没有好品味 是一个负面评论

114
00:06:16,450 --> 00:06:20,681
而且与之前的算法不同<br />知道 不好 是一个负面评论

115
00:06:20,681 --> 00:06:24,140
因为之前的算法只是把所有的东西加和成一个大的词向量

116
00:06:24,140 --> 00:06:29,345
并没有意识到 不好 的意思与

117
00:06:29,345 --> 00:06:34,130
好 差别很大以及 品味不好 等等情况

118
00:06:34,130 --> 00:06:35,920
那么如果你训练这个算法

119
00:06:35,920 --> 00:06:39,548
最后你会得到一个非常不错的情感分类算法

120
00:06:39,548 --> 00:06:45,150
因为你可以使用一个大得多的数据集训练词嵌入向量

121
00:06:45,150 --> 00:06:46,720
得到的效果会更好

122
00:06:46,720 --> 00:06:49,630
这甚至还可以泛化到没有在训练集中出现过的词语<br />

123
00:06:49,630 --> 00:06:51,580
比如如果有其他人说

124
00:06:51,580 --> 00:06:55,540
完全缺乏好品味

125
00:06:55,540 --> 00:06:57,220
好服务和好环境 或类似的评论

126
00:06:57,220 --> 00:07:02,730
即使 缺乏 这个词不在你的标签训练集中

127
00:07:02,730 --> 00:07:08,373
如果它在你训练词嵌入向量的十亿词或千亿词语料库中存在

128
00:07:08,373 --> 00:07:14,130
或许你能得到正确的结果<br />甚至可以更好到泛化到那些

129
00:07:14,130 --> 00:07:16,900
在训练词嵌入向量的训练集中存在 但是

130
00:07:16,900 --> 00:07:19,465
在标签训练集中不一定存在的词语上

131
00:07:19,465 --> 00:07:21,303
这个标签训练集可能是<br />你为情感分类问题专门准备的

132
00:07:21,303 --> 00:07:25,630
这就是今天我要讲的关于情感分类的内容

133
00:07:25,630 --> 00:07:27,400
我希望本节视频能给你一种感觉

134
00:07:27,400 --> 00:07:31,670
一旦你从学习了一个词嵌入向量<br />或从网上下载了一个词嵌入向量

135
00:07:31,670 --> 00:07:37,000
它可以让你相当迅速地构建出<br />非常有效的自然语言处理系统