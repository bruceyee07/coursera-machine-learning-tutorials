机器学习和AI算法越来越受人信任 可以用来帮人做出非常重要的决策 所以我们需要尽可能确保 算法中没有我们不希望看到的偏见，如性别偏见、种族偏见等 这节课我想教你一些方法 来减少或消除在词嵌入中的这些形式的偏差 当我用术语偏差时，我指的不是“偏差”这个变量 不是说数据偏离，我指的是性别、种族、性取向的偏差 这两者之间的意思是不同的，这里就指的不是我在技术方面提到的偏差 也就是在机器学习方面 而关于词偏差方面的问题，我们要讲的是 如何让词嵌入学习相似性，如男人对应女人，国王对应皇后 但如果你说男人对应程序猿，那么女人对应什么呢？ 所以这篇论文的作者：Tolga Bolukbasi Kai Wei Chang，James Zou，Venkatesh Saligrama和 Adam Kalai找到一种很奇特的方法，使得词嵌入可以做到 这样的输出：男人对应程序猿，女人对应家庭主妇 而这看起来还是错的，因为这导致了一个不正常的性别刻板印象 比较好的算法应该是可以得出：男人对应程序猿 而女人也对应程序猿 同时他们还发现，父亲对应医生，那母亲对应什么呢？ 不幸的是，一些训练好的词嵌入会产生这样的输出： 母亲对应护士 所以词嵌入会反应性别、种族、年龄 性取向，以及其他的一些偏差用来训练模型 其中有一个我特别感兴趣的是社会经济学地位的偏差 我认为每个人，无论你是来自富有的家庭 还是低收入的家庭，或者之间 我认为每个人都应该有很大的机会来发展自己 并且因为机器学习算法能够用来做出许多重要的决定 决定 这些算法能影响每件事，从学校申请到求职 再到申请贷款，无论你申请贷款有没有被批准 再到司法系统里，来量刑审判罪犯 学习算法都在做出非常重要的决策，所以我认为 尽量消除算法中的这些偏差是很重要的 更明确来讲，是消除这些不想看到的偏差结果 目前的单词嵌入可以找出偏差的文本用来 训练模型，而这些找出来的偏差 是由人的行为所影响的 几十年间，几个世纪间 我认为人类在减少这类偏差方面有了很大的进步 对AI而言幸运的是，我们有更好的方法 来更快地减少由AI造成的偏差 而且相比人造成的偏差更快 尽管我们从未说AI已经发展得很好了 仍然有许多研究要做 我们需要很多操作
来减少这些在我们算法中的这些偏差 但在这个视频中我想分享一个例子 这个例子参考了Bolukbasi 和其他一些人在减少词嵌入误差方面的研究 接下来我们来学习其中的原理 假设我们已经得到一个训练好的词嵌入模型 babysister在这，doctor在这 grandmother在这 grandfather在这 可能girl在这，boy在这 she在这 he在这 因此,我们首先要识别 需要减少或消除的特定偏见的方向 这里我将用性别偏见为例 但这些思路可以应用到其他所有 我在之前ppt上提到的偏见类型 那如何才可以明确对应偏见的方向呢？ 对性别而言，我们可以将词向量he 减去词向量she，因为他们是按性别来区分不同的 符号为e_male-e_female 取相类似的，然后取平均值对吧 并采取一些这些差异,基本上对他们去平均数。 这能让你明白在这个案例中应该得出一个怎样的结果 这个方向是性别的方向，即偏差方向 然而这个方向和我们希望得到的偏差方向不一致 所以这个是无偏差方向 按这个例子中，把这个偏差方向视为1维的子空间 然而一个无偏差方向，即299维的子空间 我将简要的描述 偏差方向可以比1维要高 而不是取平均，这里实际上会用到 一个更加复杂的叫SVU算法，
即singular value decomposition 这个和PCA很类似 如果你熟悉主成分分析 它使用的方法类似于这个PCA 在此之后，下一步就是中立化 对于每一个没有定义的词，通过映射来摆脱偏差 有些词本来就带有性别的含义 所以像grandmother grandfather，girl，boy，she，he，
都是本来就有性别相关的定义 然而像其他的词，如doctor babysitter，这些词是性别中性词 在很多情况下，你也许希望doctor babysitter是中性的或者说是
性别导向为中立的 我们现在以性别为例 到目前为止每个词都是没有定义的 这意味着不会有像grandmother和grandfather 这类词，它们有包含性别的组成部分 因为grandmother是女性，grandfather是男性 所以对像doctor和babysitter这类词 让我们把他们映射到这个轴来减少
他们的组成部分 或者消除他们在偏差方向的组成部分 所以要在这个水平方向上减少组成部分 这是第二步的“中立”步骤 最后一步叫均匀化 你有一对词，比如grandmother和 grandfather或girl和boy，你希望 词嵌入中唯一的差别是性别 那为什么你想这么做呢？ 在这个例子中，距离也就是相似度 在babysitter和grandmother之间的距离 比babysitter和grandfather之间的要小 这会加强一种不健康 不希望看到的偏差，
即：grandmother之于babysitter
多余grandermother之于grandfather 所以在最后平均化这一步中 我们希望确保的是像grandmother，
grandfather这类词 有相似性，有相同的距离 比如都是性别中立的，
比如babysitter之于doctor 对这问题有一些线性代数的方法来解决 基本要做的是移动grandmother 和grandfather分别到一个点，
使得两点到中间轴的距离相等 效果是babysitter 到这两点的距离相等 通常有许多对这样的词，比如 grandmother-grandfather，
boy-girl，sorority-fraternity 再比如girlhood-boyhood,
sister-brother,⏎niece-nephew, daughter-son 你可能需要对这些都完成平均化 最后一个细节是，你如何决定什么词需要中立化？ 比如，doctor就是应该性别中立的一个词 使其没有性别特征或种族特征 而grandmother 应该有性别特征 而像beard这类词 只是一个统计事实，男性比 女性可能有更多胡须，
所以也许胡须应该更加接近男性 而作者做的是训练一个分类器来试着明白 哪些词需要定义 哪些词需要性别特征，哪些不要 得出的结论是大多数英语单词不需要定义 这意味着性别是不需要定义的 这一小部分有相关性的词，
如grandmother-grandfather girl-boy, sorority-fraternity不应该中立化 所以一个线性分类器能告诉你什么词要经历 中立化步骤来映射偏差方向 来映射到这个299维的子空间 有多少对词需要平均化 事实上这些词相对较少，
至少对性别这个例子而言只这样的 这是很灵活的，
来手动找出你想平均化的几对词 其实整个算法
是比我现在所陈述的更为复杂的 你可以看看论文里的所有细节 你也会用到这些方法 在之后的编程练习中 总结一下，我认为减少或消除算法中的偏差 是非常重要的问题，因为这些算法是用来 帮我们做出决策的 在这个视频中，我只是分享了一个想法 如何试着说出这个问题 但这仍然是一个正在继续进行的研究方向 所以这周我们就先讲到这里 祝你这周的编程练习顺利 我期待下周还能见到你