1
00:00:01,440 --> 00:00:06,640
我们来具体研究学习字嵌入的问题

2
00:00:06,640 --> 00:00:09,230
当你实现一个算法来学习字嵌入时

3
00:00:09,230 --> 00:00:12,698
最终学习到的是一个嵌入矩阵

4
00:00:12,698 --> 00:00:14,285
我们来看看这意味着什么

5
00:00:14,285 --> 00:00:19,005
比方说, 像往常一样, 使用我们的1万字词汇

6
00:00:19,005 --> 00:00:21,412
单词有A, Aaron

7
00:00:21,412 --> 00:00:29,750
Orange, Zulu， 或是未知词汇作为标记

8
00:00:29,750 --> 00:00:34,475
我们要做的是学习嵌入矩阵 E

9
00:00:34,475 --> 00:00:43,900
这将是一个300维x10000维的矩阵

10
00:00:43,900 --> 00:00:48,933
如果你有1万字的词汇, 或者10001作为我们的字标记

11
00:00:48,933 --> 00:00:51,105
有一个额外的标记

12
00:00:51,105 --> 00:00:54,675
这个矩阵的列将不同于

13
00:00:54,675 --> 00:00:58,245
你的词汇中1万种不同单词的嵌入

14
00:00:58,245 --> 00:01:05,475
所以, Orange是我们一万词汇中的第6257个

15
00:01:05,475 --> 00:01:12,300
那么我们将用一个符号，06257

16
00:01:12,300 --> 00:01:20,995
one hot 向量（除了在6257的位置上有一个1，其他都是0的向量）来表示

17
00:01:20,995 --> 00:01:27,690
这将是一个在一个位置只有一个1的万维向量

18
00:01:27,690 --> 00:01:29,430
所以这并不是一个很有吸引力的量表

19
00:01:29,430 --> 00:01:34,220
这应该和左边的嵌入矩阵一样宽

20
00:01:34,220 --> 00:01:40,530
如果嵌入矩阵被称为大写 E, 那么请注意, 如果

21
00:01:40,530 --> 00:01:49,140
用E去乘一个6257处是0的one-hot向量

22
00:01:49,140 --> 00:01:54,045
那么这将成为一个300维的向量

23
00:01:54,045 --> 00:02:02,170
E 是300x1万, 0是1万x1

24
00:02:02,170 --> 00:02:06,700
乘积是 300×1

25
00:02:06,700 --> 00:02:10,060
用这300维向量

26
00:02:10,060 --> 00:02:13,840
注意要计算这个300维向量的

27
00:02:13,840 --> 00:02:15,385
第一个元素

28
00:02:15,385 --> 00:02:21,565
你要做的是将矩阵 E 的第一行乘以这个

29
00:02:21,565 --> 00:02:24,535
但所有这些元素都是零, 除了

30
00:02:24,535 --> 00:02:27,970
元素6257，所以最后用零乘这个

31
00:02:27,970 --> 00:02:30,490
零乘这个, 零乘这个, 等等

32
00:02:30,490 --> 00:02:34,270
然后, 1乘无论什么

33
00:02:34,270 --> 00:02:37,060
零乘这个, 零乘这个, 等等

34
00:02:37,060 --> 00:02:44,350
所以, 最后得到第一个元素是在Orange列下的

35
00:02:44,350 --> 00:02:46,235
任意元素

36
00:02:46,235 --> 00:02:50,169
然后, 对于我们正在计算的这个300维向量的第二个元素

37
00:02:50,169 --> 00:02:52,210
你会采取向量0657

38
00:02:52,210 --> 00:02:57,555
并乘以矩阵E的第二行。再次

39
00:02:57,555 --> 00:03:00,010
你会计算零乘这个

40
00:03:00,010 --> 00:03:01,835
加上零乘这个

41
00:03:01,835 --> 00:03:07,855
加上零乘所有这些元素, 然后一乘这个

42
00:03:07,855 --> 00:03:10,330
然后零乘所有其他的, 并加到一起

43
00:03:10,330 --> 00:03:19,795
当你沿着这列直到结束时, 你会得到这个，等等

44
00:03:19,795 --> 00:03:25,485
所以, 这就是为什么嵌入矩阵E乘以这个one-hot向量

45
00:03:25,485 --> 00:03:32,430
在300维列里选出对应的字，Orange

46
00:03:32,430 --> 00:03:38,870
所以, 这将等于 E 6257

47
00:03:38,870 --> 00:03:41,245
这是我们要在这个300x1维向量中

48
00:03:41,245 --> 00:03:46,345
代表“Orange”的符号

49
00:03:46,345 --> 00:03:49,658
更笼统地说, E为一个特定的词 W

50
00:03:49,658 --> 00:03:56,195
这将会嵌入一个字 W。更普遍的是

51
00:03:56,195 --> 00:03:59,583
E乘O 代替 J

52
00:03:59,583 --> 00:04:02,500
一个在 J 位置的one-hot向量

53
00:04:02,500 --> 00:04:05,090
这将是 E_J, 那将是

54
00:04:05,090 --> 00:04:11,695
单词 J 在词汇中的嵌入

55
00:04:11,695 --> 00:04:16,325
因此, 从这张幻灯片中可以记住的是

56
00:04:16,325 --> 00:04:21,650
我们的目标将是学习嵌入矩阵 E

57
00:04:21,650 --> 00:04:24,460
在下一个视频你们会看到如何随机初始化 E

58
00:04:24,460 --> 00:04:27,725
学习这300x10000维矩阵的所有参数

59
00:04:27,725 --> 00:04:35,105
E乘这个one-hot向量会给你嵌入向量

60
00:04:35,105 --> 00:04:37,390
这里还有需要注意一点

61
00:04:37,390 --> 00:04:38,742
当我们在写方程式的时候

62
00:04:38,742 --> 00:04:41,750
在用矩阵 E 乘以one-hot向量 O

63
00:04:41,750 --> 00:04:45,726
这样写符号比较方便

64
00:04:45,726 --> 00:04:49,095
但如果你要实现这个

65
00:04:49,095 --> 00:04:52,400
实现一个质量矩阵向量乘法并不是有效的

66
00:04:52,400 --> 00:04:56,627
因为one-hot向量

67
00:04:56,627 --> 00:05:01,355
是一个相对较高的维度向量, 其中大多数元素是零

68
00:05:01,355 --> 00:05:03,560
所以实际上，用矩阵向量乘法实现这一点是不高效的

69
00:05:03,560 --> 00:05:06,770
因为如果

70
00:05:06,770 --> 00:05:10,070
我们把一堆东西乘以零

71
00:05:10,070 --> 00:05:12,950
在实际应用中，你会使用一个专门的函数来查找

72
00:05:12,950 --> 00:05:17,335
矩阵 E 的一列, 而不是用矩阵乘法来完成

73
00:05:17,335 --> 00:05:20,945
但是写地图的时候, 用这种方式写出来很方便

74
00:05:20,945 --> 00:05:24,545
所以, 在Cara的例子中

75
00:05:24,545 --> 00:05:29,637
有一个嵌入层, 我们使用嵌入层

76
00:05:29,637 --> 00:05:33,970
更有效地只是从嵌入矩阵拉出你想要的列

77
00:05:33,970 --> 00:05:38,638
而不是使用比它更慢的矩阵向量乘法

78
00:05:38,638 --> 00:05:40,870
所以, 在这个视频中, 你们看到符号如何被用来

79
00:05:40,870 --> 00:05:43,740
描述算法来学习这些嵌入

80
00:05:43,740 --> 00:05:45,220
关键是

81
00:05:45,220 --> 00:05:50,265
这个矩阵 E 包含了词汇的所有嵌入

82
00:05:50,265 --> 00:05:53,590
在下一视频中, 我们将开始讨论特定的算法

83
00:05:53,590 --> 00:05:57,030
来学习这个矩阵 E。让我们进入下一个视频