我们来具体研究学习字嵌入的问题 当你实现一个算法来学习字嵌入时 最终学习到的是一个嵌入矩阵 我们来看看这意味着什么 比方说, 像往常一样, 使用我们的1万字词汇 单词有A, Aaron Orange, Zulu， 或是未知词汇作为标记 我们要做的是学习嵌入矩阵 E 这将是一个300维x10000维的矩阵 如果你有1万字的词汇, 或者10001作为我们的字标记 有一个额外的标记 这个矩阵的列将不同于 你的词汇中1万种不同单词的嵌入 所以, Orange是我们一万词汇中的第6257个 那么我们将用一个符号，06257 one hot 向量（除了在6257的位置上有一个1，其他都是0的向量）来表示 这将是一个在一个位置只有一个1的万维向量 所以这并不是一个很有吸引力的量表 这应该和左边的嵌入矩阵一样宽 如果嵌入矩阵被称为大写 E, 那么请注意, 如果 用E去乘一个6257处是0的one-hot向量 那么这将成为一个300维的向量 E 是300x1万, 0是1万x1 乘积是 300×1 用这300维向量 注意要计算这个300维向量的 第一个元素 你要做的是将矩阵 E 的第一行乘以这个 但所有这些元素都是零, 除了 元素6257，所以最后用零乘这个 零乘这个, 零乘这个, 等等 然后, 1乘无论什么 零乘这个, 零乘这个, 等等 所以, 最后得到第一个元素是在Orange列下的 任意元素 然后, 对于我们正在计算的这个300维向量的第二个元素 你会采取向量0657 并乘以矩阵E的第二行。再次 你会计算零乘这个 加上零乘这个 加上零乘所有这些元素, 然后一乘这个 然后零乘所有其他的, 并加到一起 当你沿着这列直到结束时, 你会得到这个，等等 所以, 这就是为什么嵌入矩阵E乘以这个one-hot向量 在300维列里选出对应的字，Orange 所以, 这将等于 E 6257 这是我们要在这个300x1维向量中 代表“Orange”的符号 更笼统地说, E为一个特定的词 W 这将会嵌入一个字 W。更普遍的是 E乘O 代替 J 一个在 J 位置的one-hot向量 这将是 E_J, 那将是 单词 J 在词汇中的嵌入 因此, 从这张幻灯片中可以记住的是 我们的目标将是学习嵌入矩阵 E 在下一个视频你们会看到如何随机初始化 E 学习这300x10000维矩阵的所有参数 E乘这个one-hot向量会给你嵌入向量 这里还有需要注意一点 当我们在写方程式的时候 在用矩阵 E 乘以one-hot向量 O 这样写符号比较方便 但如果你要实现这个 实现一个质量矩阵向量乘法并不是有效的 因为one-hot向量 是一个相对较高的维度向量, 其中大多数元素是零 所以实际上，用矩阵向量乘法实现这一点是不高效的 因为如果 我们把一堆东西乘以零 在实际应用中，你会使用一个专门的函数来查找 矩阵 E 的一列, 而不是用矩阵乘法来完成 但是写地图的时候, 用这种方式写出来很方便 所以, 在Cara的例子中 有一个嵌入层, 我们使用嵌入层 更有效地只是从嵌入矩阵拉出你想要的列 而不是使用比它更慢的矩阵向量乘法 所以, 在这个视频中, 你们看到符号如何被用来 描述算法来学习这些嵌入 关键是 这个矩阵 E 包含了词汇的所有嵌入 在下一视频中, 我们将开始讨论特定的算法 来学习这个矩阵 E。让我们进入下一个视频