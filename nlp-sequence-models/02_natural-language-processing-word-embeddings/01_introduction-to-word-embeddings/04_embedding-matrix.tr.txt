Gelin, doğru bir word embedding öğreniminin<br /> problemini şekillendirmeye başlayalım. Bir 'sözcük gömme' öğrenimi adına bir algoritma uyguladığınızda, nihayetinde öğrendiğiniz bir gömülü matris olmaktadır. Bunun ne anlama geldiğine gelin bir göz atalım. Diyelim ki, her zamanki gibi, 10,000'lik kelime sözlüğümüzü kullanıyoruz. Şöyle, sözlük A, Aaron, Orange, Zulu, belki bir andıç olarak tanımsız kelime'ye sahip. Yapmaya çalıştığımız bir gömme matris (E) öğrenimidir, bu 300 x 10,000 boyutunda bir matris olacaktır. Eğer 10,000 kelime sözlüğüne sahipseniz ya da belki 10,001, sizin kelime andıçınız, bir tane ekstra andıç bulunmaktadır. ve bu matrisin sütunları sözlüğünüzde<br /> bulunan 10,000 farklı kelime için farklı gömülü yaklaşım olurdu. Orange 10,000 kelimelik sözlüğünüzde 6257 numaralı kelimedir. kullanacağımız şey, 06257, hepsinin sıfır ve 6257 numaralı pozisyonun 1 olduğu tek-birli vektör'dür. Bu, sadece tek bir yerinde 1 olan <br />10,000 x 1 boyutunda bir vektör olacak. Aslında, bu pek ölçekli bir çizim olmalı. Evet, bu, soldaki geniş embedding matris gibi uzun olmalıdır. ve eğer embedding matris büyük E olarak isimlendiriliyorsa, bilin ki, eğer E'yi alıp tek bir içeren 06257'li vektör ile çarparsanız, bu 300 x 1 boyutlu bir vektör olacaktır. Böylece, E, 300 x 10,000 ve O, 10,000 x 1 boyutundadır. Çarpım 300 x 1 olacaktır. yani 300 boyutlu bir vektör ve bilin ki, bu vektörün ilk elemanını işleme sokmak için, bu 300 x 1 boyutlu vektörün, yapacağınız şey, matris E'nin ilk satırı ile bunu çarpacaksınız. ama 6257 dışındaki tüm elemanlar sıfır ve sıfır kere bu, sıfır kere bu, sıfır kere bu, vesaire, olarak sonuçlanacak. ve sonra 1 kere (her ne ise) bu ve sıfır kere bu, sıfır kere bu, sıfır kere bu, ve vesaire. ve sonra, Orange sütunu altında bu yukarıdaki element her ne ise bu ilk element ile sonuca varacaksınız. sonra 300 x 1 boyutundaki vektörün ikinci elemanı için hesaplama yapıyoruz, 06257 vektörünü alıp Matris E'nin ikinci satırı ile çarpıyorsunuz. Sonra tekrar, sıfır kere buna, artı sıfır kere buna artı sıfır kere tüm buradaki elemanlar ile ve 1 kere buna, ve sıfır kere hepsiyle ve hepsini birlikte ekleyin. Böylece, geri kalan bu sütundan aşağı inerek bu sonuca varıyorsunuz. Bu yüzden embedding matris E kere tek bir içeren vektör (burada), Orange kelimesine karşılık gelen 300 boyutlu bu sütunu seçmiş olur. Bu, e 6257 ifadesine eşit olacaktır ki Orange kelimesi adına 300 x 1 boyutundaki embedding vektörü açıklamak için kullanacağımız gösterimdir. Daha genel bir açıklama olarak,<br /> E ve spesifik olarak 'w' 'w' kelimesi için bir kelime adreslemesi olacaktır. Daha genel bir şekilde, E kere Oj J pozisyonundaki 1 ile birlikte tek birden oluşan vektör, bu ej 'ye eşit olacak ve bu sözlükteki J kelimesine eşlenen adresi (embedding) olacak. Sonucunda, bu slaytta hatırlamamız gereken şey, amacımız bir embedding matris E öğrenmektir ve bir sonraki video'da E'ye rastgele şekilde değer atayıp Gradyan İnişi kullanarak 300 x 10,000 boyutundaki matris'in tüm parametrelerinin öğrenmesini artı, E kere bu tek birden oluşan vektör, size embedding matrisi gösterdiğini göreceksiniz. Sadece ufak bir not, denklemi yazarken, Matris E'yi alıp onunla tek birden oluşan vektörü çarptığınız bu tip bir formülü yazmak daha kullanışlı olacak. Fakat eğer bunu uyguluyorsanız, bir küme matris vektör çarpımı olarak uygulamak için verimli değildir çünkü tek birden oluşan vektör oldukça yüksek boyutlu bir vektör ve çoğu elemanı sıfırdır. O yüzden, bir matris vektör çarpımını kullanmak gerçekte verimli değildir çünkü tümünü sıfır ile çarpıyoruz. Gerçek uygulamalarda, bunu matris çarpımı ile yapmak yerine, sadece matris E'nin bir sütununa bakacağınız belli amaç için oluşturulan bir fonksiyonu kullanmanız gerekecek. hiç olmazsa haritalamayı yazmak, bu şekilde düzenlemek adına işe yaramaktadır. Örneğin, Keras kütüphanesinde, bir Embedding katmanı bulunmaktadır. Bunu kullanarak daha yavaş olan matris vektör çarpımı yerine <br /> embedding matris'den çok daha verimli bir şekilde istediğiniz sütuna ulaşabilirsiniz. Bu videoda, embedding'i öğrenmek adına kullanılacak algoritmaların formüllerini gördük. Ana terminoloji sözlükteki kelimelerin hepsi için tüm embedding yapıyı kapsayan Matris E'dir. Sıradaki video'da, matris E ögrenimi adına spesifik algoritmalar hakkında konuşmaya başlayacağız. Bir sonraki video'ya gelin geçelim.