當您建置您的反向傳播
對於您的神經網路時, 您需要能夠 計算斜率或者說導數
對於這些啟動函數 所以讓我們看看我們的
啟動函數選擇 您如何可以計算
這些函數的斜率 這是您熟悉的S型函數
啟動函數 所以給任何一個z值
也許是這個z值, 這個函數 會有一些斜率, 或者導數
相對於, 如果您畫 一小條線在這裡, 這個高除以
寬在這個小三角形 所以如果g(z) 是S型函數, 那
這個函數的斜率是 d/dz g(z) 從微積分我們知道
這是 g(z) 在 z 的斜率 如果您熟悉微積分
知道如何求導數 如果您求
S狀函數的導數 這可以證明
是這個公式 再次說明
我不做這些微積分的步驟 但如果您熟悉微積分 歡迎隨時暫停影片
試著自己證明 所以
這也是等於 g(z) 乘 (1 - g(z)) 讓我們檢查
這個公式是合理的 首先, 如果 z 很大, 假設 z = 10 g(z) 會趨近於 1, 所以 這個公式告訴我們
d/dz g(z) 趨近於 g(z) (1 - g(z)) 也就是等於 1 乘 (1 - 1) 也就是趨近於 0 而這是正確的, 因為當 z 
很大時斜率會趨近於 0 相反地, 如果 z = -10, 
同樣的方式, g(z) 趨近於 0 所以在左邊的公式告訴我們 d/dz g(z) 會趨近於 g(z)
也就是 0 乘 (1 - 0) 也是趨近於 0
這個也是正確的 最後如果 z = 0 那 g(z) = 1/2 就是用這個S形函數 所以導數
等於 1/2 乘 (1 - 1/2), 等於 1/4 而這個實際上
是正確的導數或者說 這個函數的斜率當 z = 0時 最後, 再介紹
 一個符號 有時候, 與其用這個項目 導數的簡寫
是 g 一撇 of z 所以 g 一撇 of z 在微積分
這在上面的這一撇稱 prime g prime of z 
是微積分的簡寫, 對於 g 函數的導數
相對應於輸入變數 z 在神經網路, 我們有 a = g(z) 等於這個 這個公式也可以
簡化成為 a 乘上 (1 - a) 有時候在建置時 您或許會看到
g prime of z 等於 a 乘上 (1 - a) 而這指的是
觀察 g prime 意思是導數
等於這一個項目 這個公式的好處是，如果你已經計算過的 a 值, 使用這個公式
您可以很快地計算 g prime 斜率的值, 好的
這是有關於 S型啟動函數 讓我們看 tanh
啟動函數 類似於我們前面做的
d/dz g(z) 的定義 是  g(z) 的斜率
在一個特定點 z 上 如果您看這個
雙曲正切函數公式 如果您熟微積分
您可以求導數 證明可以簡化成這個公式 像之前我們用的簡寫 我們稱這個為
g prime of z 如果您要的話, 您可以檢查
這個公式是合理的 舉個例子如果z=10
tanh(z) 趨近於 1 這個從+1 到-1 而 g prime of z 
根據這個公式 會大約是 1 - 1 的平方，所以是 0 所以當 z 很大時
斜率趨近於 0 相反地, 如果 z 很小, 假設 z = -10 那 tanh(z) 會趨近於 -1 所以 g prime of z 會趨近於
1 減 -1 的平方 所以趨近於 1 - 1
也是趨近於 0 最後, 如果 z = 0, 那 tanh(z) = 0 那這個斜率等於 1 也正是
當 z 等於 0 時的斜率 總結一下, 如果 a=g(z) 
也就是如果 a 等於 tanh(z) 這個導數 g prime 
of z 等於 1 - a 的平方 再一次
如果您已經計算 a 的值 您可以用這個公式很
快的計算導數 最後這是我們如何計算
ReLU 跟 Leaky ReLU 啟動函數的導數 對於 ReLU, g(z) 等於 max(0, z) 所以導數是等於 0 如果 z 小於 0
1, 如果 z 大於 0 實際上 a 是未定義
如果 z 剛好為 0 但如果您在軟體中建置 也許不是百分之百
正確的數學 但還是可以運作
如果 z 真的是 0 如果您設導數
等於 1, 或者設為 0 其實無所謂 如果你 [聽不清] 優化 技術上而言 g prime 變成
稱為子梯度 在啟動函數 g(z)
這是為什麼梯度下降仍然可行 但您可以想像成
z 是 0.000000, 它太 小, 小到幾乎無關緊要
不管您設導數為何 當 z 為 0 時 在實踐上, 這是人們
用來建置 z 的導數 最後
如果您訓練神經網路使用 Leaky ReLU 啟動函數 g(z) 會是 max of 
(0.001z, z) 所以 g prime of z 等於 0.001 如果 z 小於 0, 等於 1
如果 z 大於 0 再一次 技術上而言這個梯度是未定義
當 z 剛好為 0 時 但如果您建置一些
程式, 設這個導數或者說 設 g prime 為 0.001 或者1 
無論哪種方式都沒差 當
 z 真的是 0 時您的
程式還是可行 所以，帶著這些公式，您應該能夠計算斜率，或 導數
對於您的啟動函數 現在您有了這些建構基石 準備好去看到如何實現
梯度下降神經網路 我們下一段影片見