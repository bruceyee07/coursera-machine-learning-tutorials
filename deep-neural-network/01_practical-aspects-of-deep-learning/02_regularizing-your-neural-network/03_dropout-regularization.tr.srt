1
00:00:00,000 --> 00:00:02,560
L2 düzenlileştirmesine ek olarak oldukça etkili

2
00:00:02,560 --> 00:00:06,875
düzenlileştirme tekniklerinden
birisi de seyreltmedir (dropout).

3
00:00:06,875 --> 00:00:08,715
Şimdi nasıl çalıştığını görelim.

4
00:00:08,715 --> 00:00:12,600
Diyelim ki burada gördüğünüz gibi bir sinir ağını
eğitiyorsunuz ve aşırı öğrenme durumu sözkonusu.

5
00:00:12,600 --> 00:00:14,998
Şimdi seyreltme ile ne yapacağımızı görelim.

6
00:00:14,998 --> 00:00:16,765
Öncelikle bu sinir ağının bir kopyasını alalım.

7
00:00:16,765 --> 00:00:21,100
Seyreltme ile yapacağımız şey,
sinir ağının her bir katmanında bulunan

8
00:00:21,100 --> 00:00:26,350
düğümleri (node) elemek için bir olasılık değeri belirlemektir.

9
00:00:26,350 --> 00:00:29,305
Diyelim ki bu sinir ağının katmanlarında bulunan

10
00:00:29,305 --> 00:00:30,955
düğümler için yazı tura atacağız.

11
00:00:30,955 --> 00:00:34,165
Bu durumda her bir düğümün elenme ve elenmeme

12
00:00:34,165 --> 00:00:38,005
olasılığını 0.5 olarak bulmuş oluruz.

13
00:00:38,005 --> 00:00:39,820
Diyelim ki yazı tura atmayla işimiz bittikten sonra

14
00:00:39,820 --> 00:00:42,865
örneğin bu düğümleri elemeye karar verdik.

15
00:00:42,865 --> 00:00:49,775
Bu durumda yapmanız gereken şey, bu düğümlerin
girdi ve çıktı bağlantılarını yok etmektir.

16
00:00:49,775 --> 00:00:51,550
Sonuç olarak çok daha küçük ve sadeleştirilmiş

17
00:00:51,550 --> 00:00:53,150
bir sinir ağını elde ederiz.

18
00:00:53,150 --> 00:00:56,145
Ardından geri yayılım ile eğitime devam edersiniz.

19
00:00:56,145 --> 00:00:59,705
Bu yaptıklarımız yalnızca bir eğitim örneği için geçerli.

20
00:00:59,705 --> 00:01:01,130
Diğer eğitim örnekleri için ise,

21
00:01:01,130 --> 00:01:03,700
birçok kez yazı tura attıktan sonra bazı düğümleri
sinir ağında tutarız,

22
00:01:03,700 --> 00:01:07,585
bazılarını ise seyreltiriz
veya başka bir ifade ile, eleriz.

23
00:01:07,585 --> 00:01:09,235
Eğitim sırasında kullanılan her bir örnek için,

24
00:01:09,235 --> 00:01:14,455
sadeleştirilmiş sinir ağlarını kullanarak
eğitimi gerçekleştiririz.

25
00:01:14,455 --> 00:01:16,675
Bu biraz sıra dışı bir teknik gibi görünüyor olabilir.

26
00:01:16,675 --> 00:01:20,470
Düğümlerin bir kısmını rastgele seçip,
geri kalanları ise eliyoruz.

27
00:01:20,470 --> 00:01:22,505
Ancak bu gerçekten de işe yarıyor.

28
00:01:22,505 --> 00:01:28,480
Ama bunu siz de tahmin edebilirsiniz, çünkü burada
her bir örnek için çok daha küçük sinir ağı eğitiyoruz.

29
00:01:28,480 --> 00:01:34,591
Veya burada daha küçük ağların eğitilmesinin neden
bir sinir ağını düzenlileştirebildiğimizi

30
00:01:34,591 --> 00:01:38,590
imkan tanıdığı hakkında bir fikir verebilir.

31
00:01:38,590 --> 00:01:41,535
Şimdi seyreltmeyi nasıl uygulayacağımızı görelim.

32
00:01:41,535 --> 00:01:43,425
Seyretlemeyi uygulamanın birkaç farklı yolu var.

33
00:01:43,425 --> 00:01:44,915
Ben sizlere en çok kullanılanı göstereceğim.

34
00:01:44,915 --> 00:01:47,865
Buna aynı zamanda "ters seyreltme" de denmektedir.

35
00:01:47,865 --> 00:01:49,645
Bütünlüğü sağlamak adına,

36
00:01:49,645 --> 00:01:58,977
diyelim ki seyreltmeyi,
l=3 katmanı ile görselleştirmek istiyoruz.

37
00:01:58,977 --> 00:02:03,000
Birazdan yazacağım kodda bir sürü 3'ler olacak.

38
00:02:03,000 --> 00:02:08,380
Burada tek bir katmandaki seyreltmeyi
görselleştirmeye çalışacağım.

39
00:02:08,380 --> 00:02:12,155
Burada yapacağımız şey, d adında bir vektör oluşturacağız

40
00:02:12,155 --> 00:02:16,503
ve d3, 3. katmanın seyreltme vektörü olacaktır.

41
00:02:16,503 --> 00:02:21,585
d3 vektörünü, np.random.rand() ile oluşturacağım

42
00:02:21,585 --> 00:02:27,708
ve bu vektör, a3 ile aynı boyuta sahip olacak.

43
00:02:27,708 --> 00:02:31,261
Eğer bu ifadenin, keep.prob adını verdiğim sayıdan

44
00:02:31,261 --> 00:02:34,470
küçük olduğunu görürsem

45
00:02:34,470 --> 00:02:37,350
Burada keep.prob bir sayıdır.

46
00:02:37,350 --> 00:02:39,105
Videonun başlarında bu sayıyı 0.5 olarak belirlemiştik.

47
00:02:39,105 --> 00:02:42,045
Şimdi ise bu örnekte 0.8 olarak belirleyeceğim.

48
00:02:42,045 --> 00:02:47,040
Ve bu sayı, hangi gizli birimlerin tutulacağını belirleyen
olasılık değeri olacaktır.

49
00:02:47,040 --> 00:02:49,129
Yani keep.prob = 0.8 olur,

50
00:02:49,129 --> 00:02:54,665
bu da 0.2 ihtimalle gizli birimlerin
eleneceği anlamına gelmektedir.

51
00:02:54,665 --> 00:02:58,130
Burada bu yöntemin yaptığı şey,
rastgele bir matris üretmektir.

52
00:02:58,130 --> 00:03:00,755
Eğer elinizdeki değerleri vektörleştirirseniz
bu yöntem yine oldukça güzel çalışmaktadır.

53
00:03:00,755 --> 00:03:03,180
Yani d3 bir matristir.

54
00:03:03,180 --> 00:03:06,660
Her bir örnek ve her bir gizli birim için

55
00:03:06,660 --> 00:03:10,245
karşılık gelen d3 matrisi, %80 ihtimalle 1

56
00:03:10,245 --> 00:03:12,815
ve %20 ihtimalle 0 olacaktır.

57
00:03:12,815 --> 00:03:20,900
Yani buradaki rastgele sayı 0.8'den küçük olursa,
0.8 ihtimalle 1 veya "True"

58
00:03:20,900 --> 00:03:24,675
ve %20 veya 0.2 ihtimalle 0 veya "False" olma
ihtimaline sahiptir.

59
00:03:24,675 --> 00:03:27,569
Ardından burada yapacağımız şey, 3. katmadan
etkilenimleri (activations) almaktır.

60
00:03:27,569 --> 00:03:30,945
Bu örnekte buna a3 diyelim.

61
00:03:30,945 --> 00:03:33,265
a3, hesapladığımız etkilenimlerdir.

62
00:03:33,265 --> 00:03:37,335
Burada a3'ü, eski a3 çarpı d3 olarak belirleyeceğiz.

63
00:03:37,335 --> 00:03:41,849
Burada a3 ile d3'ün elemanlarını çarpıyoruz.

64
00:03:41,849 --> 00:03:44,857
Bunu ayrıca a3 *= d3 şeklinde de yazabilirsiniz.

65
00:03:44,857 --> 00:03:50,625
d3'ün 0 olan her elemanı için ve

66
00:03:50,625 --> 00:03:53,735
buradaki elemanların bir kısmının %20 ihtimalle
0 olacağı için

67
00:03:53,735 --> 00:03:57,840
bu işlemin yaptığı şey, çarpım işlemi sonucu

68
00:03:57,840 --> 00:04:00,980
d3'ün karşılık gelen
elemanlarını sıfırlamaktır.

69
00:04:00,980 --> 00:04:02,250
Eğer bunu Python'da yaparsanız,

70
00:04:02,250 --> 00:04:05,880
d3, her elemanı 1 veya 0 yerine True veya False olan

71
00:04:05,880 --> 00:04:06,985
bir Boolean dizisi olacaktır.

72
00:04:06,985 --> 00:04:10,057
Ama çarpım işlemi düzgün bir şekilde çalışacak ve

73
00:04:10,057 --> 00:04:13,390
bu dizideki True ve False değerlerini
1 ve 0 olarak yorumlayacaktır.

74
00:04:13,390 --> 00:04:16,260
Eğer bunu Python'da uygularsanız,
bunu bizzat kendiniz göreceksiniz.

75
00:04:16,260 --> 00:04:22,570
Son olarak a3'ü, 0.8'e veya başka bir ifade ile

76
00:04:22,570 --> 00:04:30,015
keep.prob değerine bölerek ölçeklendireceğiz.

77
00:04:30,015 --> 00:04:32,560
Bu son adımın ne yaptığını açıklayayım.

78
00:04:32,560 --> 00:04:36,040
Diyelim ki 3. gizli katmanda 50 birim

79
00:04:36,040 --> 00:04:39,930
veya 50 nöron bulunmaktadır.

80
00:04:39,930 --> 00:04:43,075
Yani a3, 50 * 1 boyutlu veya

81
00:04:43,075 --> 00:04:46,650
vektörizasyon yaptıysanız 50 * m boyutludur.

82
00:04:46,650 --> 00:04:51,625
Eğer bu birimleri %80 ihtimalle tutup,
%20 ihtimalle eleyecekseniz

83
00:04:51,625 --> 00:04:53,050
sonuç olarak

84
00:04:53,050 --> 00:04:59,025
ortalama 10 birimi söndürür veya sıfırlarsınız.

85
00:04:59,025 --> 00:05:02,020
Şimdi z^4'ün değerine bakarsanız,

86
00:05:02,020 --> 00:05:08,775
z^4, w^4 * a^3 + b^4'e eşit olacaktır.

87
00:05:08,775 --> 00:05:10,570
Ve beklendiği üzere

88
00:05:10,570 --> 00:05:14,080
bu %20 oranla azaltılacaktır.

89
00:05:14,080 --> 00:05:18,480
Burada demek istediğim,
elemanların %20'si sıfırlanacaktır.

90
00:05:18,480 --> 00:05:22,240
z^4'ün beklenti değerini azaltmamak için

91
00:05:22,240 --> 00:05:24,380
yapmanız gereken şey

92
00:05:24,380 --> 00:05:28,870
bu değeri 0.8'e bölmektir.

93
00:05:28,870 --> 00:05:33,635
Bu işlem, a3'ün beklenti değerini değiştirmemek için

94
00:05:33,635 --> 00:05:37,455
beklenti değerini yaklaşık %20 arttıracaktır.

95
00:05:37,455 --> 00:05:43,435
İşte burası, tersine seyreltme olarak adlandırdığımız tekniktir.

96
00:05:43,435 --> 00:05:44,830
Ve bunun etkisi,

97
00:05:44,830 --> 00:05:47,230
keep.prob değeri nasıl belirlediğiniz fark etmeksizin

98
00:05:47,230 --> 00:05:50,446
ister 0.8, isterseniz 0.9, hatta 1 olsun

99
00:05:50,446 --> 00:05:52,135
ki bunu 1 olarak belirlediğinizde herhangi bir
seyreltme olmayacağı anlamına gelir

100
00:05:52,135 --> 00:05:54,565
çünkü bu her şeyi veya yarısını ya da
ne kadarlık bir değer belirlediyseniz, o kadarını tutar.

101
00:05:54,565 --> 00:05:57,980
Tersine seyreltme tekniği,
bu değeri keep.prob değerine bölerek

102
00:05:57,980 --> 00:06:02,730
a3'ün beklenti değerinin
değişmeyeceğinin garantisini vermektedir..

103
00:06:02,730 --> 00:06:05,005
Test zamanında gördüğümüz üzere,

104
00:06:05,005 --> 00:06:06,820
bir sinir ağını değerlendirmeye çalıştığınızda

105
00:06:06,820 --> 00:06:08,300
ki bunu bir sonraki slaytta konuşacağız.

106
00:06:08,300 --> 00:06:10,065
Bu tersine seyreltme tekniği,

107
00:06:10,065 --> 00:06:13,160
burada yeşil kutu içine aldığım teknik,

108
00:06:13,160 --> 00:06:17,540
ölçeklendirme problemini bir nebze çözdüğü
için test işlemini çok daha kolaylaştırmaktadır.

109
00:06:17,540 --> 00:06:20,110
Tersine seyreltme tekniği,

110
00:06:20,110 --> 00:06:22,870
şu ana kadar gördüğüm tüm seyreltme
tekniklerinden en çok uygulanandır.

111
00:06:22,870 --> 00:06:24,490
Ben de size bunu uygulamanızı öneriyorum.

112
00:06:24,490 --> 00:06:27,280
Seyreltmenin ilk geliştirme aşamalarında

113
00:06:27,280 --> 00:06:30,165
keep.prob ile bölme işlemi kullanılmamaktaydı.

114
00:06:30,165 --> 00:06:33,660
ve bu da test işlemini oldukça karmaşık
hale bir getirmekteydi.

115
00:06:33,660 --> 00:06:37,040
Ama yine tekrarlayayım, insanlar diğer
versiyonları kullanmayı tercih etmiyorlar.

116
00:06:37,040 --> 00:06:40,125
Burada yaptığınız şey d vektörünü kullanmak

117
00:06:40,125 --> 00:06:43,390
ve farklı eğitim örnekleri için farklı gizli birimleri

118
00:06:43,390 --> 00:06:46,090
sıfırladığınızı göreceksiniz.

119
00:06:46,090 --> 00:06:49,975
Eğer aynı eğitim seti üzerinde, birden çok kez
aynı şekilde ve farklı şekillerde

120
00:06:49,975 --> 00:06:52,566
seyreltme yaparsanız, farklı gizli birimleri

121
00:06:52,566 --> 00:06:55,290
rastgele bir şekilde sıfırlarsınız.

122
00:06:55,290 --> 00:06:57,270
Yani bu, bir eğitim örneği için

123
00:06:57,270 --> 00:07:01,155
her seferinde aynı gizli birimi sıfırlayacaksınız
anlamına gelmez.

124
00:07:01,155 --> 00:07:03,258
eğim azalmasının birinci yinelemesinde

125
00:07:03,258 --> 00:07:05,510
bazı gizli birimleri sıfırlarsınız.

126
00:07:05,510 --> 00:07:07,375
Eğitm azalmasını ikinci yinelemesinde ise

127
00:07:07,375 --> 00:07:09,595
yani eğitm setinin üzerinden
ikinci kez geçtiğinizde

128
00:07:09,595 --> 00:07:13,008
başka gizli birimleri sıfırlarsınız.

129
00:07:13,008 --> 00:07:16,023
3. katmanın vektörü d3,

130
00:07:16,023 --> 00:07:18,395
hem ileri hem de geri yayılım sırasında

131
00:07:18,395 --> 00:07:21,565
nelerin sıfırlanacağını belirlerken kullanılır.

132
00:07:21,565 --> 00:07:22,980
Burada yalnızca ileri yayılımı gösteriyorum.

133
00:07:22,980 --> 00:07:26,950
Şimdi algortitmayı eğittimize göre
test zamanında şunu yaparız:

134
00:07:26,950 --> 00:07:30,535
Test zamanında size tahmin edilmesi
istenen bir x değeri verilir.

135
00:07:30,535 --> 00:07:32,335
Standart notasyonumuza uyarak

136
00:07:32,335 --> 00:07:33,764
buna a^0 diyeceğim.

137
00:07:33,764 --> 00:07:38,180
Burada test örneği x'i temsil etmek için
0. katmanın etkilenimlerini kullanacağım.

138
00:07:38,180 --> 00:07:40,760
Test zamanında yapacağımız şey, aslında

139
00:07:40,760 --> 00:07:44,340
seyreltmeyi kullanmamaktır. Burada

140
00:07:44,340 --> 00:07:48,314
z^1 = w^1.a^0 + b^1

141
00:07:48,314 --> 00:07:56,627
a^1 = g^1(z^1)

142
00:07:56,627 --> 00:08:03,745
z^2 = w^2.a^1 + b^2

143
00:08:03,745 --> 00:08:04,895
a^2 = ...

144
00:08:04,895 --> 00:08:10,060
olarak belirleyeceğiz ve bunu, y^ tahminini
üreten son katmana kadar devam edeceğiz.

145
00:08:10,060 --> 00:08:12,640
Burada dikkat etmeniz gereken şey,
test zamanında seyreltmeyi

146
00:08:12,640 --> 00:08:15,690
açık bir şekilde kullanmıyoruz. Rastgele bir
şekilde yazı tura atarak

147
00:08:15,690 --> 00:08:20,285
hangi gizli birimleri eleyeceğimizi belirlemiyoruz.

148
00:08:20,285 --> 00:08:22,510
Bunun sebebi, test zamanında tahmin yaparken

149
00:08:22,510 --> 00:08:25,615
çıktının rastgele olmasını istemememizdir.

150
00:08:25,615 --> 00:08:27,699
Eğer test zamanında seyreltmeyi uygularsanız

151
00:08:27,699 --> 00:08:29,890
bu yalnızca tahminlerinize gürültü ekler.

152
00:08:29,890 --> 00:08:34,105
Teorik olarak düşündüğünüzde, bir
tahmin süreci oluşturup

153
00:08:34,105 --> 00:08:38,940
seyreltilmiş gizli birimler üzerinden
birden çok kez geçebilirsiniz.

154
00:08:38,940 --> 00:08:43,625
Ancak bu yöntem, hesaplama açısından oldukça verimsiz

155
00:08:43,625 --> 00:08:46,880
ve neredeyse diğeriyle aynı sonucu vermektedir.

156
00:08:46,880 --> 00:08:47,980
Ayrıca bahsetmek istediğim bir şey daha var.

157
00:08:47,980 --> 00:08:49,385
Bu tersine seyreltme tekniğinde,

158
00:08:49,385 --> 00:08:53,455
bir önceki slaytta gördüğümüz üzere keep.prob
 değerine böldüğümüz kısmı hatırlayın.

159
00:08:53,455 --> 00:08:56,450
Bunu yapmamızın sebebi, test zamanında

160
00:08:56,450 --> 00:08:59,664
seyreltme sonucunu ölçeklendirmeyi
uygulamasak bile

161
00:08:59,664 --> 00:09:02,050
beklenti değerinin değişmemesini sağlamaktır.

162
00:09:02,050 --> 00:09:06,540
Bu yüzden test zamanında ekstra ölçeklendirme
parametresi eklemenize gerek yoktur.

163
00:09:06,540 --> 00:09:08,965
Bu, eğitim zamanında yaptığımızdan farklıdır.

164
00:09:08,965 --> 00:09:10,240
İşte seyreltme dediğimiz şey tam olarak bu.

165
00:09:10,240 --> 00:09:13,000
Ve bunu 1. haftanın program
alıştırmasında uyguladığınızda

166
00:09:13,000 --> 00:09:16,660
daha iyi bir tecrübe elde edeceksiniz.

167
00:09:16,660 --> 00:09:18,440
Peki bu neden çalışmaktadır?

168
00:09:18,440 --> 00:09:20,410
Bir sonraki videoda, size seyreltmenin

169
00:09:20,410 --> 00:09:23,630
gerçekten ne yaptığı
hakkında daha iyi bilgi vereceğim.

170
00:09:23,630 --> 00:09:25,160
Haydi bir sonraki videoya geçelim.