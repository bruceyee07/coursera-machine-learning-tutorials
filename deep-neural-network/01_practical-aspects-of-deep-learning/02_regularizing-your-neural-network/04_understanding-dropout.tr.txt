Seyreltme(Drop out), ağınızdaki birimleri rastgele saf dışı bırakmak gibi görünen karmaşık şeyi yapar. Neden bir düzenleyici ile bu kadar iyi çalışıyor? Hadi daha iyi bir bakış açısı kazanalım. Bir önceki videoda ağınızdaki birimleri rastgele ayırarak dışlama, bakış açısını verdim. Yani her tekrarlamada daha küçük bir sinir ağı ile çalışıyormuşsunuz gibi, ve böylece daha küçük bir sinir ağını kullanmak, düzenleyici bir etkiye sahip olması gerektiği gibi görünüyor. İşte ikinci bir bakış açısı, Hadi tek birim perspektifinden bakalım. Diyelim ki bu olsun. Şimdi, bu birim için işini girdi olarak yapması ve bazı anlamlı çıktılar üretmesi gerekiyor. Şimdi seyreltme(drop-out) ile, girdiler rastgele elenebilir. Bazen bu iki birim elenir, bazen farklı bir birimi eleriz. Yani bunun anlamı bu birim, mor daire ile işaretlediğim bu birimin herhangi bir özelliğe bağlı kalamaz çünkü özellik rastgele kaybedilebilir veya kendi girdilerinin herhangi biri rastgele gidebilir. Bazıları tüm ihtimalleri kabul etmekte isteksiz olur, diyelim, sadece bu girdi, doğru mu? Ağırlıklar, herhangi bir girdiye çok ağırlık yüklemek istemeyiz çünkü o çıkarılabilir. Yani bu birim, bu şekilde yayılmaya ve bu birimin 4 girdisine de biraz ağırlık kazandırmaya daha fazla motive olacak. Ve tüm ağırlıkları yayarak, ağırlıklar kare normunda küçülme etkisine sahip olacaktır. Ve bu yüzden, L2 düzenlemesinde gördüğümüze benzer olarak Seyreltme işleminin etkisi ağırlıkları küçültmek ve bazı bu aşırı öğrenmeyi önlemeye yardımcı olan harici düzenlemeyi yapmaktır. Fakat seyreltme düzenleme kullanmadan uyumlu bir form olduğu resmen gösterilebilir. Fakat çeşitli ağırlıklardaki L2 cezası farklıdır, bu şekilde çarpılan aktivasyonların boyutuna bağlıdır. Özetlemek gerekirse, şunu göstermek mümkün ki seyreltme L2 düzenlemesine benzer bir etkiye sahip. Sadece, farklı yollarla uygulanan L2 düzenlemesi biraz farklı olabilir ve hatta çeşitli ölçekli girdiler için daha uyumlu olabilir. seyreltme uyguladığınızda için bir ayrıntı daha var. Burada üç girdi özelliğine sahip bir ağ var. Burada 7 gizli birim var, yedi, üç, iki, bir. Seçmemiz gereken parametrelerden biri her katmanda bir birim tutma şansına sahip ucuz bir dayanak bulmaktır. Dahası, seviyelere göre anahtar dayanaklar değiştirilmeye de uygundur. Bu yüzden ilk seviye için, W1 matrisiniz 3'e 7 olacaktır. İkinci ağırlık matrisimiz 7'ye 7 olacak... W3 ise 7'ye 3 olacak ve bunun gibi. Tabi ki aslında W2 en büyük ağırlığa sahip matris, çünkü en büyük parametre kümesi 7'ye 7 olan W2 de olacaktır. Yani önlemek için, bu matriste ki aşırı öğrenmeyi azaltmak için, belki bu katman için, İkinci katman olduğunu tahmin ediyorum, nispeten daha düşük bir anahtar dayanağı olmalı, diyelim 0.5, buna karşılık, aşırı öğrenme konusunda daha az endişelendirici farklı katmanlar için, daha yüksek bir anahtar dayanağa sahip olabilirsiniz, belki sadece 0.7. Ve eğer aşırı öğrenme konusunda hiç problem olmayan bir katmansa, anahtar değerinizi 1.0 olarak alabilirsiniz. Daha açık olması açısından, numaraları mor kutucuklarla işaretliyorum. Bunlar farklı katmanlar için farklı değerler alabilir. Dikkat edin, 1.0 anahtar değeri tüm birimleri tutacağınız anlamına geliyor ve bu yüzden, bu katmanlarda seyreltme kullanmıyorsunuz. Ancak katmanlarınızın aşırı öğrenme endişesini taşıdığınız zaman katmanlar ile birlikte gelen bir çok parametre ile birlikte daha güçlü bir seyreltme uygulayabilmek için destekleyici küçük bir anahtar atayabilirsiniz. Bazı katmanları diğerlerinden daha fazla düzenli hale getirmeye çalıştığınızda L2 düzenlileştirme parametresinin lamnda parametresini harekete geçirmiş olursunuz. Teknik olarak, giriş katmanına da seyreltme uygulayabilirsiniz, girdi özelliklerinden bir veya daha fazlasını maksimuma çıkarabilme şansınız olabilir. Her ne kadar pratikte olsa bunu sık sık yapmayın. Buradaki girdi için 1.0 değerinin destekleyici bir anahtar olması yaygındır. Ayrıca çok yüksek bir değerde kullanabilirsiniz, belki 0.9 ama girdi özelliklerinin yarısını ortadan kaldırmak istediğinizden çok daha az olasıdır. Yani destekleyici anahtarı kullanıp kuralı uygularsanız, buradaki girdiye hiç seyreltme uygulamazsanız bile bire yakın bir sayı olacaktır. Yani özetlemek gerekirse, Eğer diğerlerinden daha fazla aşırı öğrenme problemi olan katmanlar ile ilgili endişeleniyorsanız, diğerlerinden daha düşük destekleyici anahtar değeri atayabilirsiniz. Kötü tarafı, bu size çapraz doğrulama kullanmak için arama yapma amacıyla daha fazla hiper parametre verir. Bir diğer alternatif seyreltme uyguladığınız bazı katmanlarınız olabilir ve bazı katmanlara da uygulamamış olabilirsiniz bu hiper bir parametreye sahip olduğunuzu gösterir, katmanlar için bu destekleyici anahtarlarla seyreltme yapabilirsiniz. Özetleyecek olursak uygulamaların iki tiplemesi vardır. Seyreltmenin ilk başarılı uygulamalarının çoğu bilgisayar vizyonuydu. Bilgisayar vizyonunda, girdi boyutu çok büyük, tüm bu pikselleri girerek neredeyse hiç yeterli veriye sahip olamuyorsunuz. Bu yüzden, bilgisayar vizyonu tarafından seyreltme sıkça kullanılır. Ve bunu kullanan çok fazla birçok bilgisayar vizyonu araştırmacısı var, neredeyse varsayılan olarak kabul edilecek. Fakat gerçekten unutulmaması gereken şey şudur ki seyreltme bir düzenlileştirme tekniğidir. bu aşırı öğrenmeyi engellemeye yardım eder. Ve bu yüzden, algoritmam aşırı öğrenme olmadan, Seyreltme, gerçekten çok can sıkıcı olduğundan kullanmak istemem. Yani diğer uygulama alanlarından biraz daha sık kullanılır. Bunlardan sadece bilgisayar vizyonunda, genellikle yeterli veriye sahip olmazsınız, neredeyse her zaman aşırı öğrenirsiniz, bazı bilgisayar vizyon araştırmacıları seyreltme tekniğine yeminli gibi eğilimlidirler. Fakat diğer disiplinleri düşünecek olursam onların bakış açıları her zaman genelleştirilmez. Seyreltmenin büyük bir dezavantajı, maliyet fonksiyonunun J'nin artık iyi tanımlanmamış olmasıdır. Her tekrarda bir grup düğümden rastgele birini ortadan kaldırıyorsunuz. Ve böylece, derecenin ve karşıtlığın performansını iki kez kontrol ediyorsanız, her yinelemede yokuş aşağı giden, iyi tanımlanmış bir maliyet fonksiyonuna yani J'ye sahip olduğunuzu kontrol etmek gerçekten daha zordur. Çünkü optimize ettiğiniz maliyet fonksiyonu J aslında daha azdır. Daha az iyi tanımlanmış veya hesaplanması kesinlikle zor. kaybettiğiniz şeyi hata ayıklama aracı ile çizmek isterseniz böyle bir grafik olacak. Yani yaptığım şey seyreltmeyi kapatıp destekleyici anahtarı bire eşitleyip kodumu çalıştırmak, monoton olarak J'yi düşürdüğünden emin olun ve seyreltme özelliğini açın, umuyorum ki seyreltme sırasında kodumda bir hata ile karşılaşmam. Çünkü başka yollara ihtiyacınız var, Sanırım bu rakamlar kodunuzun bu kadar büyüklükte çalıştığından emin olmak için değil, seyreltme ile bile çalışıyor olduğundan emin olmak için. Bu tarz, hala bilmeye değer birkaç tane daha düzenlileştirme tekniği var. Bir sonraki videoda bu gibi tekniklerin bir kaçı hakkında konuşalım.