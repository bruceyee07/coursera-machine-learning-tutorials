1
00:00:00,740 --> 00:00:04,500
欢迎来到这门课程
这门课程将从实际应用的角度介绍深度学习

2
00:00:04,500 --> 00:00:07,650
也许你现在已经学会了如何实现一个神经网络

3
00:00:07,650 --> 00:00:10,620
本周我们将学习
在实际应用中如何使你的神经网络高效工作

4
00:00:10,620 --> 00:00:12,550
本周我们将学习⏎在实际应用中如何使你的神经网络高效工作

5
00:00:12,550 --> 00:00:16,757
这些方法包括超参数调整，数据准备

6
00:00:16,757 --> 00:00:20,297
再到如何确保你的优化算法运行得足够快

7
00:00:20,297 --> 00:00:24,140
以使得你的学习算法能在合理的时间内完成学习任务

8
00:00:24,140 --> 00:00:27,551
在第一周我们首先要介绍一些机器学习问题,

9
00:00:27,551 --> 00:00:29,216
然后我们将讨论正则化

10
00:00:29,216 --> 00:00:30,952
我们也会介绍一些小技巧

11
00:00:30,952 --> 00:00:34,440
这些技巧能够确保你能正确地实现你的神经网络

12
00:00:34,440 --> 00:00:36,170
那我们开始吧

13
00:00:36,170 --> 00:00:39,760
在你考虑如何设置你的训练集/开发集/测试集时

14
00:00:39,760 --> 00:00:43,160
如果能够做出一个好的选择将会帮助你快速地

15
00:00:43,160 --> 00:00:46,090
建立一个高性能的神经网络

16
00:00:46,090 --> 00:00:49,230
在训练一个神经网络时
你必须做出许多决定

17
00:00:49,230 --> 00:00:52,310
例如你的神经网络将会有多少层啊

18
00:00:52,310 --> 00:00:55,400
并且每一层中包含多少个隐藏神经元啊

19
00:00:55,400 --> 00:00:57,067
学习速率是多少啊

20
00:00:57,067 --> 00:01:01,150
还有每一层你想用什么激活函数啊

21
00:01:01,150 --> 00:01:03,040
当你开始一个新的应用时

22
00:01:03,040 --> 00:01:07,400
你几乎不可能一次性就正确地猜到上面提及的

23
00:01:07,400 --> 00:01:12,250
以及未提及的超参数的准确数值

24
00:01:12,250 --> 00:01:16,290
因此在实际应用中 机器学习是一个高度迭代的过程

25
00:01:16,290 --> 00:01:18,450
在这个过程中
你经常以一个想法为起点

26
00:01:18,450 --> 00:01:21,990
例如你想建立一个具有一定层数

27
00:01:21,990 --> 00:01:25,670
一定数量的隐藏神经元
或许是基于某个特定数据集的或者满足其他的需求神经网络

28
00:01:25,670 --> 00:01:29,660
然后你只要将你的想法转换为代码
并运行你的代码来尝试实现它

29
00:01:29,660 --> 00:01:33,950
在你运行并且实验之后
你会得到一个结果

30
00:01:33,950 --> 00:01:37,570
这个结果会告诉你这个特定的网络
或者说这个特定的配置执行得好不好

31
00:01:37,570 --> 00:01:39,090
然后根据这个结果

32
00:01:39,090 --> 00:01:44,330
你可能会改进你的想法
并改变你的选择

33
00:01:44,330 --> 00:01:49,474
而且你也许会为了尝试找出一个越来越好的神经网络
而不断迭代

34
00:01:50,890 --> 00:01:54,390
如今深度学习在许多领域获得成功

35
00:01:54,390 --> 00:01:59,256
从自然语言处理到计算机视觉到

36
00:01:59,256 --> 00:02:04,579
语音识别再到许多基于结构化数据的应用

37
00:02:04,579 --> 00:02:10,000
结构化数据包括很多东西 包括广告 网页搜索

38
00:02:10,000 --> 00:02:16,840
而网页搜索不只包括搜索引擎 还包括例如购物网站等

39
00:02:16,840 --> 00:02:19,340
所有的那些 想要在你于搜索栏中输入关键词后

40
00:02:19,340 --> 00:02:23,800
返回高质量搜索结果的网站

41
00:02:23,800 --> 00:02:29,436
再到计算机安全 后勤物流 比如计算出应该让司机

42
00:02:29,436 --> 00:02:34,665
在何处装卸货物 再到其他许多方面

43
00:02:34,665 --> 00:02:39,530
所以我现在能看到 一个经验丰富的自然语言处理研究员

44
00:02:39,530 --> 00:02:43,170
尝试去做一些计算机视觉相关的研究

45
00:02:43,170 --> 00:02:48,120
或者是一个在语音识别方面
经验丰富的研究员可能会

46
00:02:48,120 --> 00:02:50,190
开始尝试去做一些与广告相关的研究

47
00:02:50,190 --> 00:02:54,670
亦或是具有安全背景的人去尝试做物流相关的研究

48
00:02:54,670 --> 00:02:57,940
我能看到从一个研究领域 或应用领域中的直觉

49
00:02:57,940 --> 00:03:02,920
通常是并不能直接套用到其它的领域的

50
00:03:02,920 --> 00:03:06,471
最好的选择可能取决于你所拥有的数据量

51
00:03:06,471 --> 00:03:10,983
输入数据的特征个数 也取决于你的计算机配置

52
00:03:10,983 --> 00:03:13,464
比如你是在GPU上训练还是在CPU上训练

53
00:03:13,464 --> 00:03:18,280
以及GPU和CPU和具体配置是怎样的 还有很多其它因素

54
00:03:18,280 --> 00:03:21,470
所以我认为对很多应用来说 想猜准超参数是几乎不可能的

55
00:03:21,470 --> 00:03:26,430
即使是经验非常丰富的深度学习从业者都发现

56
00:03:26,430 --> 00:03:30,300
想一次就猜中最优的超参数是几乎不可能的

57
00:03:30,300 --> 00:03:34,160
所以目前 机器学习的应用是相当反复的 迭代的过程

58
00:03:34,160 --> 00:03:39,150
你只需要将这个循环进行许多次

59
00:03:39,150 --> 00:03:43,790
就有希望能为你的应用中的网络找出好的参数

60
00:03:43,790 --> 00:03:48,100
所以有一件事能决定你能多快地取得进展

61
00:03:48,100 --> 00:03:51,510
那就是你进行迭代过程时的效率

62
00:03:51,510 --> 00:03:55,830
而恰当地将你的数据集分为训练集 开发集和测试集

63
00:03:55,830 --> 00:03:59,030
就能让你的迭代效率更高

64
00:03:59,030 --> 00:04:06,430
假设这是你的训练数据 我们把它画成一个大矩形

65
00:04:06,430 --> 00:04:11,140
那么传统的做法是你可能会从所有数据中

66
00:04:11,140 --> 00:04:15,520
取出一部分用作训练集

67
00:04:15,520 --> 00:04:21,790
然后再留出一部分作为hold-out交叉验证集

68
00:04:23,290 --> 00:04:30,398
这个数据集有时也称为开发集

69
00:04:30,398 --> 00:04:33,940
为了简洁 我就把它称为"dev set" 不过

70
00:04:33,940 --> 00:04:36,810
这些不同的术语大致指代的是同一个东西

71
00:04:36,810 --> 00:04:41,940
再接下来你可能会从最后取出一部分用作测试集

72
00:04:41,940 --> 00:04:46,390
整个工作流程是首先你不停地用训练集来训练你的算法

73
00:04:46,390 --> 00:04:51,080
然后用你的开发集或说hold-out交叉验证集来测试

74
00:04:51,080 --> 00:04:54,670
许多不同的模型里哪一个在开发集上效果最好

75
00:04:54,670 --> 00:04:56,910
当这个过程进行的时间够长之后

76
00:04:56,910 --> 00:05:00,030
你可能想评估一下你最终的训练结果

77
00:05:00,030 --> 00:05:03,420
你可以用测试集对结果中最好的模型进行评估

78
00:05:03,420 --> 00:05:08,040
这样以使得评估算法性能时不引入偏差

79
00:05:08,040 --> 00:05:13,054
在上一个时代的机器学习中 通常的分割法是

80
00:05:13,054 --> 00:05:18,246
训练集和测试集分别占整体数据70%和30%

81
00:05:18,246 --> 00:05:23,460
也就是人们说的 70/30训练测试分割

82
00:05:23,460 --> 00:05:28,845
如果你明确地设定了开发集 那比例可能是60/20/20%

83
00:05:28,845 --> 00:05:33,680
也就是测试集占60% 开发集20% 测试集20%

84
00:05:33,680 --> 00:05:37,300
数年以前这个比例被广泛认为是

85
00:05:37,300 --> 00:05:38,910
机器学习中的最佳方法

86
00:05:38,910 --> 00:05:41,470
如果你一共只有100个样本

87
00:05:41,470 --> 00:05:46,740
也许1000个样本 甚至到1万个样本时

88
00:05:46,740 --> 00:05:50,743
这些比例作为最佳选择都是合理的

89
00:05:50,743 --> 00:05:55,920
但是在这个大数据的时代 趋势可能会变化

90
00:05:55,920 --> 00:06:03,600
你可能有多达100万个训练样本 而开发集

91
00:06:03,600 --> 00:06:09,390
和测试集在总体数据中所占的比例就变小了

92
00:06:09,390 --> 00:06:13,410
这是因为 回想开发集存在的意义是用来

93
00:06:13,410 --> 00:06:17,370
测试不同的算法并确定哪种最好

94
00:06:17,370 --> 00:06:20,010
所以开发集只要足够大到

95
00:06:20,010 --> 00:06:23,380
能够用来在评估两种不同的算法

96
00:06:23,380 --> 00:06:27,020
或是十种不同的算法时快速选出较好的一种

97
00:06:27,020 --> 00:06:30,500
达成这个目标可能不需要多达20%的数据

98
00:06:30,500 --> 00:06:34,200
所以如果你有100万个训练样本

99
00:06:34,200 --> 00:06:39,250
可能开发集只要1万个样本就足够了

100
00:06:39,250 --> 00:06:43,180
足够用来评估两种算法中哪一种更好

101
00:06:43,180 --> 00:06:47,220
与开发集相似 测试集的主要功能是

102
00:06:47,220 --> 00:06:51,885
对训练好的分类器的性能 给出可信度较高的评估

103
00:06:51,885 --> 00:06:56,695
同样如果你可能有100万个样本 但是只要1万个

104
00:06:56,695 --> 00:07:00,960
就足够评估单个分类器的性能

105
00:07:00,960 --> 00:07:03,680
能够对其性能给出比较准确的估计了

106
00:07:03,680 --> 00:07:07,280
以此为例 如果你有100万个样本

107
00:07:07,280 --> 00:07:11,550
而只需要1万个用作开发集 1万个用作测试集

108
00:07:11,550 --> 00:07:17,240
那么1万个只是100万个的百分之一

109
00:07:17,240 --> 00:07:23,330
所以你的比例就是98/1/1%

110
00:07:23,330 --> 00:07:25,360
我还看见过一些应用

111
00:07:25,360 --> 00:07:29,910
这些应用中样本可能多于100万个

112
00:07:29,910 --> 00:07:35,050
分割比率可能会变成99.5/0.25/0.25%

113
00:07:35,050 --> 00:07:42,060
或者开发集占0.4% 测试集占0.1%

114
00:07:42,060 --> 00:07:45,920
所以总结起来 当设定机器学习问题时

115
00:07:45,920 --> 00:07:50,380
我通常将数据分为训练集 开发集和测试集

116
00:07:50,380 --> 00:07:55,740
如果数据集比较小 也许就可以采用传统的分割比率

117
00:07:55,740 --> 00:07:59,560
但如果数据集大了很多 那也可以使开发集

118
00:07:59,560 --> 00:08:05,660
和测试集远小于总数据20% 甚至远少于10%

119
00:08:05,660 --> 00:08:08,640
更具体的确定开发集和测试集大小的准则

120
00:08:08,640 --> 00:08:11,110
我们将在这门专项课程后面的时间中讲解

121
00:08:11,110 --> 00:08:16,170
当前的深度学习中还有一个趋势是

122
00:08:16,170 --> 00:08:20,080
有越来越多的人的训练集与测试集的数据分布不匹配

123
00:08:20,080 --> 00:08:25,100
假设说你在构建一个应用 允许用户上传大量图片

124
00:08:25,100 --> 00:08:29,380
你的目标是找出猫的图片再展示给用户

125
00:08:29,380 --> 00:08:31,590
也许因为你的用户都是爱猫之人

126
00:08:31,590 --> 00:08:37,180
你的训练集可能来自网上下载的猫的图片

127
00:08:37,180 --> 00:08:42,178
而开发集和测试集则包含用户用应用上传的图片

128
00:08:42,178 --> 00:08:46,250
所以 一边是你的训练集可能有很多从网上爬取的图片

129
00:08:46,250 --> 00:08:49,470
另一边是 开发集和测试集中有许多用户上传的图片

130
00:08:49,470 --> 00:08:53,370
你会发现许多网页上的图片都是高分辨率

131
00:08:53,370 --> 00:08:55,610
专业制作过 构图也很漂亮的猫的图片

132
00:08:55,610 --> 00:08:58,290
而用户上传的图则相对比较模糊

133
00:08:58,290 --> 00:09:03,450
分辨率低 用手机在更加随意的情况下拍摄的

134
00:09:03,450 --> 00:09:07,960
所以这可能就造成两种不同的分布

135
00:09:07,960 --> 00:09:13,042
在这种情况下我建议的经验法则是

136
00:09:13,042 --> 00:09:18,737
确保开发集和测试集中的数据分布相同

137
00:09:23,079 --> 00:09:26,199
我们也会详细讲解这个准则 原因是

138
00:09:26,199 --> 00:09:30,039
你需要用开发集对许多不同的模型进行评估

139
00:09:30,039 --> 00:09:33,380
费尽全力改善模型在开发集上的性能

140
00:09:33,380 --> 00:09:38,380
如果开发集和测试集的数据分布相同就很方便

141
00:09:38,380 --> 00:09:43,440
但是因为深度学习算法对训练数据量需求巨大

142
00:09:43,440 --> 00:09:47,660
我能看到一种趋势是用各种有创意的办法

143
00:09:47,660 --> 00:09:49,560
比如爬取网页

144
00:09:49,560 --> 00:09:53,650
来获得比其它途径大得多的训练集

145
00:09:53,650 --> 00:09:57,300
即使这会带来一些代价 也就是训练集的数据分布

146
00:09:57,300 --> 00:10:00,950
与开发集和测试集的数据分布不同

147
00:10:00,950 --> 00:10:03,980
但你只需要遵守这个经验法则

148
00:10:03,980 --> 00:10:08,600
你的算法进步速度就会更快

149
00:10:08,600 --> 00:10:10,750
在这门专项课程稍后的时间内

150
00:10:10,750 --> 00:10:13,910
我也会对这条经验法则进行更详细的解释

151
00:10:13,910 --> 00:10:18,320
最后 即使没有测试集也许也是可以的

152
00:10:18,320 --> 00:10:22,289
回想一下 测试集的目的是给你一个无偏估计

153
00:10:22,289 --> 00:10:26,995
来评价你最终所选取的网络的性能

154
00:10:26,995 --> 00:10:29,315
但如果你不需要无偏的估计的话

155
00:10:29,315 --> 00:10:32,090
没有测试集也许也没有问题

156
00:10:32,090 --> 00:10:35,030
所以当你只有开发集而没有测试集的时候

157
00:10:35,030 --> 00:10:40,210
你所做的就是用训练集尝试不同的模型结构

158
00:10:40,210 --> 00:10:44,450
然后用开发集去评估它们 根据结果进一步迭代

159
00:10:44,450 --> 00:10:46,140
并尝试得到一个好的模型

160
00:10:46,140 --> 00:10:48,020
因为你的模型拟合了开发集中的数据

161
00:10:48,020 --> 00:10:50,657
所以开发集不能给你无偏的估计

162
00:10:50,657 --> 00:10:53,690
但如果你不需要无偏估计的话也许也完全无妨

163
00:10:53,690 --> 00:10:55,950
在机器学习的世界中如果你只有训练集

164
00:10:55,950 --> 00:10:58,500
和开发集 而没有单独的测试集的话

165
00:10:58,500 --> 00:11:01,260
大多数人会将训练集就称为训练集

166
00:11:01,260 --> 00:11:04,640
而把开发集称为测试集

167
00:11:04,640 --> 00:11:08,881
但是它们实际上做的事情是

168
00:11:08,881 --> 00:11:09,902
把测试集当成了hold-out交叉验证集

169
00:11:09,902 --> 00:11:13,460
这种提法对术语的使用可能并不完全准确

170
00:11:13,460 --> 00:11:17,320
因为测试集上会发生过拟合现象

171
00:11:17,320 --> 00:11:21,310
所以如果一个团队告诉你说只有训练集和测试集

172
00:11:21,310 --> 00:11:26,140
我会小心 想他们是否其实只有训练集和开发集

173
00:11:26,140 --> 00:11:28,520
因为他们的模型是在测试集上过拟合

174
00:11:28,520 --> 00:11:33,348
从文化角度看 想改变团队的用语可能比较难

175
00:11:33,348 --> 00:11:38,410
不能让所有人都把训练和测试集称为训练和开发集

176
00:11:38,410 --> 00:11:40,170
即使从我的角度认为 把它们称为训练集

177
00:11:40,170 --> 00:11:43,250
和开发集 在用语上是更准确的

178
00:11:43,250 --> 00:11:45,970
况且如果不需要模型性能的无偏估计的话

179
00:11:45,970 --> 00:11:48,665
这样的做法也是可以接受的

180
00:11:48,665 --> 00:11:53,575
所以建立好训练 开发 测试集 你会迭代得更快

181
00:11:53,575 --> 00:11:57,631
而且你还能更高效地测量算法存在的偏差和方差

182
00:11:57,631 --> 00:12:02,215
然后就能更高效的选用适当的方法来改进算法

183
00:12:02,215 --> 00:12:04,225
我们将在下一个视频中讨论这个话题