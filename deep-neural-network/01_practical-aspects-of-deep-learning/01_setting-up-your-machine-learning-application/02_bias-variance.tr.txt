Makine öğrenimini iyi bir şekilde uygulayanların hemen hemen hepsinin Yanlılık ve varyans hakkında iyi bir bilgiye sahip olduğunu fark ettim. Yanlılık ve varyans öğrenmesi kolay fakat ustalaşması zor konseptlerden birer tanesidir Yanlılık ve varyansın temel mekanizmasını bildiğinizi düşünseniz bile genellikle daha fazla öğrenilecek şey vardır. Derin Öğrenme çağında, başka bir eğilim ise yanlılık-varyans uzlaşımı tartışmasıdır. Yanlılık-varyans uzlaşımını daha önce duymuş olabilirsiniz fakat derin öğrenme çağında feragat daha azdır bu sayede hala yanlılığı çözebilir ve hala varyansı çözebiliriz fakat hadi daha az bu konuyu konuşup ne anlama geldiğini konuşalım Veri setimiz bu şekilde gözüküyor Eğer verilere düz bir çizgi oturtursak belki buna mantıksal bağlanım uygulayabiliriz fakat bu çok iyi bir seçim olmaz ve bu yüzden bu yüksek yanlılık sınıfına girer dolayısıyla bu duruma eksik öğrenme deriz Diğer tarafta ise, eğer çok karmaşık bir sınıflandırıcı oturtacak olursanız belki derin öğrenme ağı ya da sinir ağı ve bütün gizli ünitelerini, belki verilere mükemmel bir şelikde oturtabilirsiniz fakat bu da veriye çok iyi bir şekilde oturduğu anlamına gelmez Çünkü bu durumda yüksek varyanslı bir sınıflandırma ve veriyi fazla öğrenmeden bahsetmiş oluruz Ve bu iki uç arasında başka bir sınıflandırıcı olabilir bu sınıflandırıcı orta karmaşıklıkta olabilir ve veriye doğru bir şekilde oturabilir. Bu çok daha mantıklı bir oturma gibi gözüküyor buna tam olarak iyi bir seçim diyebiliriz, ikisinin arasında bir seçim. Bunun gibi 2 boyutlu bir örnekte, sadece 2 öznitelik olan X1 ve X2 ile,verileri çizim haline getirebilirsiniz ve yanlılık ile varyansı görselleştirebilirsiniz. Yüksek boyutlu problemlerde, verileri çizim haline getiremez ve görselleştiremezsiniz dolayısıyla karar sınırını çizemezsiniz. Bunun yerine, birkaç farklı ölçev mevcut, ve bunlara bakıp yanlılık ve varyansı anlamaya çalışacağız Kedi resmi sınıflandırması örneğimize devam edecek olursak, bunun pozitif örnek olduğu ve bunun negatif sayacak olursak yanlılık ve varyansı anlamak için bakacağımız iki anahtar sayı eğitim seti hatası ve geliştirme seti hatası olacaktır. Bu düşünceye yönelik olarak, diyelim ki resimlerdeki kedileri tanımlıyorsunuz, bu insanların mükemmel olarak yaptığı birşey değil mi? Diyelim ki, eğitim seti hatanız yüzde 1 ve geliştirme seti hatası, bu örneği daha iyi açıklamak için, diyelim ki yüzde 11 olsun Bu yüzden bu örnekte, eğitim setinde çok iyi sonuç alırken, geliştirme setinde göreceli olarak daha kötü bir sonuç alıyoruz. Bu eğitim setinde fazla oturtmadan ileri gelmekte gibi görünüyor, bu yüzden geliştirme setindeki bütün çapraz geçerleme setinde genelleştirmede zayıf kalınıyor ve eğer böyle bir örneğiniz varsa, buna yüksek varyanslı deriz. Dolayısıyla eğitim seti hatasına ve geliştirme seti hatasına bakarak, algoritmanızda yüksek varyansa sebep olan hataları anlayabilirsiniz. Şimdi, diyelim ki eğitim seti ve geliştirme seti hatalarını ölçüyorsunuz, ve farklı bir sonuç aldınız. Diyelim ki eğitim seti hatanız yüzde 15, -eğitim seti hatanızı yukarı yazıyorum- ve geliştirme seti hatan yüzde 16, Bu durumda, insanların yüzde 0 hataya sahip olduğunuz varsayarsak, insanlar resimlere bakıp kedi olup olmadığını söyleyebilir, bu durumda, algoritmenız eğitim setinde bie iyi sonuç almıyor demektir. Dolayısıyla eğer eğitim seti verilerine oturması bile yetersiz kalıyorsa, bu duruma eksik öğrenme deriz. ve bu algoritma yüksek yanlılığa sahip olmuş olur. Fakat yine de, bu durumda yeterinde iyi şekilde geliştirme setinde genelleştirme yapabiliyor, çünkü, geliştirme setindeki performansı eğitim setindeki performansından yalnızca yüzde 1 daha düşük. Dolayısıyla bu algoritma yüksek yanlılığa sahiptir, çünkü,eğitim setindeki oturması yetersiz. Bu önceki slayttaki ensoldaki çizime benzemekte. Şimde, bir başka örnek verelim, Diyeilm ki yüzde 15 eğitim seti hatasına sahibiz, dolayısıyla bu epey yüksek yanlılığa sahip, fakat bunu geliştirme setinde değerlendirdiğinizde daha da kötü oluyor, belki yüzde 30 hata. Bu durumda, bu algoritmayı ben yüksek yanlılığa sahip olarak değerlendirdim, çünkü, hem eğitim setinde iyi sonuç almıyor hem de yüksek varyansa sahip. Dolayısıyla bu iki durumun kesişimine benziyor. Ve son olarak bir örnek daha verelim, eğer yüzde 0.5 eğitim seti hatasına sahipseniz, ve yüzde 1 geliştirme seti hatasıba sahipseniz, bu durumda kedi sınıflandırıcınız yüzde 1 hataya sahip olduğu için ve düşük yanlılığa ve düşük varyansa sahip olduğumuz için, kullanıcı gayet mutlu olacaktır. Kısaca bahsedeceğim ve ayrıntısını daha sonraya bırakacağımız küçük bir nokta bu analizin insanın bu durumdaki hatasının yüzde 0 olduğu varsayımıyla yola çıkarak ve bunun genel olarak en uygun hata olduğu veya bazen bayes hatası olarak anıldığını söylemek olacaktır. Dolayısıyla en uygun hatanın yani temel hatanın yüzde 0 olduğunu söyleyebiliriz. Bu konu hakkında çok fazla detaya girmek istemiyorum, fakat gerçek şu ki eğer en uygun hata ya da temel hatası çok daha fazla olsaydı, diyelim ki yüzde 15, bu durumda eğer bu sınıflandırıcıya bakarsak, yüzde 15 hata çok yeterli bir hata olarak karşımıza çıkar. Bu durumda yüksek yanlılık görmeyiz ve yine düşük varyanstanc söz etmiş oluruz. Dolayısıyla, yanlılık ve varyansı hiçbir sınıflandırıcı mükemmel sonuç vermeyeceğinden dolayı nasıl inceleyeceğimize gelirsek Örnek olarak, eğer bulanık görüntülere sahipseniz, dolayısıyla herhangi bir sistemin hatta insanın bile iyi bir sonuç elde edemeyeceği bir durumda, bayes hatası çok daha yüksek olabilir ve bu durumda analizin nasıl değişeceği ile ilgili yorum yapabiliriz. Fakat bu noktayı şimdilik bir kenara bırakırsak, öğreneceğimiz şey şu, eğitim seti hatasına bakarak sisteminizi ne kadar iyi oturttuğunuz hakkında fikir sahibi olabilirsiniz, en azından eğitim verisi size yanlılık probleminizin olup olmadığını söyleyebilir. Daha sonrasında eğitim setinden geliştirme setine doğru giderken hatanın ne kadar yukarı çıktığına bakarak varyans probleminizin ne kadar olduğu hakkında bilgi sahibi olmuş olursunuz. dolayısıyla eğer eğitim setinden geliştirme setine genelleştirme yapabiliyorsanız, bu varyans probleminizin düşük olduğu hakkında bilgi verir Tüm bunlarda bayes hatasının oldukça düşük olduğu ve eğitim ve geliştirme setlerinin aynı dağılımdan ileri geldiği varsayılmıştır. Eğer bu varsayımlar ihlal edilmiş olsaydı, bu durumda yapılabilecek daha gelişmiş analizler mevcut fakat bunları daha ileri videolarda konuşacağız Şimdi, önceki slaytta, yanlılığın ne olduğunu ve varyansın nası göründüğünü gördünüz. Aynı zamanda iyi bir sınıflandırmanın nasıl olduğunu anladınız Peki, yüksek yanlılık ve yüksek varyans nasıl gözüküyor? Bu ikisinin kötü yanlarını toplamak gibi bir şey. Hatırlayın bunun gibi bir sınıflandırıcının yani doğrusal sınıflandırıcının, yüksek yanlılığa sahip olduğunu görmüştük çünkü veriye eksik öğrenme söz konusu bu durumda. Dolayısıyla burada büyük oranda doğrusal bir sınıflandırıcı olduğundan dolayı genellikle eksik öğrenme söz konusu, burada mor ile çiziyoruz, fakat bir şekilde sınıflandırıcı bunun gibi ilginç şeyler yaparsa o zaman burada fazla öğrenmeden söz edebiliriz. Dolayısıyla burada mor ile çizdiğim sınıflandırıcı, hem yüksek yanlılığa hem de yüksek varyansa sahip. Yüksek yanlılığa sahip çünkü, büyük oranda doğrusal sınıflandırıcıya sahip, yani aslında tam oturmuyor. yani gördüğünüz ikinci dereceden şekle, fakat ortası kısımda çok fazla esnekliğe sahip olarak, bir şekilde bu sonuca yol açıyor ve bu sonuçta iki örnekte fazla öğrenmeden söz edebiliriz. Dolayısıyla bu sınıflandırıcı büyük oranda doğrusal sınıflandırıcıya sahip olduğundan dolayı yüksek yanlılığa sahip, dolayısıyla burada ikinci dereceden bir fonksiyona veya eğimli bir fonksiyona ihtiyacınız var. ve aynı zamanda bu sınıflandırıcı yüksek varyansa sahip, çünkü gözüken iki yanlış etiketlemeye sebebiyet verecek şekilde çok fazla esnekliğe sahip orta kısımda bu iki hatalı etiketlemeyi görebilirsiniz. Bu örnek elle yapılmış gibi duruyor, kabul , çünkü iki boyutta tasarlanan bir örnek ve bu şekilde verdik örneği fakat çok yüksek boyutlu girdilerde, gerçek anlamda bazı bölgelerde hem yüksek yanlılığa sahip hem de yüksek varyansa sahip kısımlarla karşılaşabilirsiniz dolayısıyla bunun gibi olan fakat elle tasarlanmamış bir örnekle karşılaşmanız mümkün. Özetlemek gerekirse, algoritmanızın eğitim setindeki hatasına ve geliştirme setindeki hatasına bakarak bunu probleminizin yüksek yanlılığa sahip mi veya yüksek varyansa sahip mi konularında sorunları teşhis etmekte kullanabilirsiniz belki de hem ikisi de vardır veya hiçbiri yoktur. Algoritmanızın yüksek yanlılığa veya yüksek varyansa sahip olması konusunda görünen o ki farklı çözümler üretmek mümkün. Dolayısıyla bir sonraki videoda sizlere Makine Öğreniminin temel reçetesi olarak adlandırdığım ve yüksek yanlılık veya yüksek varyansa bağlı olarak sistematik bir şekilde algoritmanızı geliştirmeye yarayacak yöntemler sunacağım. Haydi bir sonraki videoya geçelim.