1
00:00:00,740 --> 00:00:04,500
딥러닝에서 현실적인 부분들에 대한 강의에 오신 것을 환영합니다.

2
00:00:04,500 --> 00:00:07,650
아마 지금쯤이면 신경망을 구현하는 것을 배우셨을 것입니다.

3
00:00:07,650 --> 00:00:10,620
이번 주에는 어떻게 우리의 신경망이 잘 동작하게 할 수 있는지

4
00:00:10,620 --> 00:00:12,550
현실적인 문제들을 배울 것입니다.

5
00:00:12,550 --> 00:00:16,757
하이퍼파라메터를 튜닝부터 데이터를 준비하는 것까지 다루면서,

6
00:00:16,757 --> 00:00:20,297
자신감을 가지고 최적화 알고리즘을 빠르게 실행 시켜보고

7
00:00:20,297 --> 00:00:24,140
학습 알고리즘이 적정한 시간내에 학습이 될 수 있게 해봅니다.

8
00:00:24,140 --> 00:00:27,551
이번 첫째 주에는 신경망을 만드는 것에 대해 알아보고

9
00:00:27,551 --> 00:00:29,216
레귤라-라이제이션(regularization,정규화)에 대해 알아보고

10
00:00:29,216 --> 00:00:30,952
또, 말해 볼 것은 몇가지 트릭들로

11
00:00:30,952 --> 00:00:34,440
신경망 구현이 제대로 되었는지
확인하는 방법을 알아보겠습니다.

12
00:00:34,440 --> 00:00:36,170
그렇게 할텐데, 시작해 봅니다.

13
00:00:36,170 --> 00:00:39,760
학습셋, 개발셋과 테스트셋을 설정 방법을 잘 선택하면,

14
00:00:39,760 --> 00:00:43,160
이것이 좋은 성능의 신경망을 빨리 찾는데

15
00:00:43,160 --> 00:00:46,090
큰 도움을 줄 수 있습니다.

16
00:00:46,090 --> 00:00:49,230
신경망 훈련에는 결정해야될 많은 것들이 있지요.

17
00:00:49,230 --> 00:00:52,310
몇개의 레이어로 할지,

18
00:00:52,310 --> 00:00:55,400
각 레이어에 히든유닛(hidden unit)은 몇개로 할지,

19
00:00:55,400 --> 00:00:57,067
러닝레이트(learning rate)은 얼마로 하고,

20
00:00:57,067 --> 00:01:01,150
서로 다른 레이어에는 활성화 함수는 어떤 것으로 할지.

21
00:01:01,150 --> 00:01:03,040
처음 새로 응용을 시작할 때는

22
00:01:03,040 --> 00:01:07,400
이러한 것들이나 다른 하이퍼파라메터들 선택에

23
00:01:07,400 --> 00:01:12,250
적당한 값들을 옳게 짐작하기가 거의 불가능합니다.

24
00:01:12,250 --> 00:01:16,290
그래서, 실제는 기계학습 응용은 매우 반복적인 과정인데,

25
00:01:16,290 --> 00:01:18,450
한번 어떤 아이디어를 갖고 시작해 보면,

26
00:01:18,450 --> 00:01:21,990
예를들어, 레이어는 몇개 정도로 하고, 

27
00:01:21,990 --> 00:01:25,670
히든 유닛은 몇개로,
또 어떤 데이터셋들에다가 등등.

28
00:01:25,670 --> 00:01:29,660
그리고 나서, 코딩을 해보고,
그 코드를 돌려보고.

29
00:01:29,660 --> 00:01:33,950
그렇게 동작 시켜 실험해 보면
결과로 알 수 있는데

30
00:01:33,950 --> 00:01:37,570
이 신경망이 얼마나 좋은지,
이 설정이 효과는 있는지.

31
00:01:37,570 --> 00:01:39,090
그렇게, 결과를 바탕으로

32
00:01:39,090 --> 00:01:44,330
아이디어를 개선해 볼 수도 있고
선택들을 바꿔보고

33
00:01:44,330 --> 00:01:49,474
계속 이 과정을 반복하면서, 점점 더 나은 신경망을 찾아 볼 수 있습니다.

34
00:01:50,890 --> 00:01:54,390
요새 딥러닝은 많은 분야에서 큰 성공을 거두었습니다.

35
00:01:54,390 --> 00:01:59,256
자연어처리,컴퓨터비젼,음성인식,

36
00:01:59,256 --> 00:02:04,579
많은 응용분야들과 
구조화된 데이터들까지도 해결합니다.

37
00:02:04,579 --> 00:02:10,000
또, 구조화된 데이터로는 광고,

38
00:02:10,000 --> 00:02:16,840
웹검색, 그냥 인터넷 검색 엔진 뿐만아니라, 쇼핑 웹사이트 까지.

39
00:02:16,840 --> 00:02:19,340
이미 어떤 웹사이트들은
검색바에 입력하면

40
00:02:19,340 --> 00:02:23,800
더 나은 것을 찾아 보여주려고 합니다.

41
00:02:23,800 --> 00:02:29,436
컴퓨터 보안, 물류 등
예를 들어 운전자를
어디로 보내야 할지를

42
00:02:29,436 --> 00:02:34,665
알아내고 물건을 더 많이
떨어뜨릴 수 있는 방법등 입니다.

43
00:02:34,665 --> 00:02:39,530
그래서 내가 보고 있는 것은 때때로
NLP에서 많은 경험을 가진 연구자가

44
00:02:39,530 --> 00:02:43,170
컴퓨터 비전에서 뭔가를 
시도할 수도 있다는 것입니다.

45
00:02:43,170 --> 00:02:48,120
또는 음성 인식에
경험이 많은 연구자가

46
00:02:48,120 --> 00:02:50,190
광고에 대해 뭔가 
시도할 수도 있습니다.

47
00:02:50,190 --> 00:02:54,670
또는 보안 담당자가 물류에 대해
뭔가를 하고 싶어 할 수도 있습니다.

48
00:02:54,670 --> 00:02:57,940
제가 본 것은 하나의 영역이나
한 응용 영역에서의 직관은

49
00:02:57,940 --> 00:03:02,920
종종 다른 응용 영역으로
이전하지 않는 것입니다.

50
00:03:02,920 --> 00:03:06,471
그리고 최고의 선택은
당신이 가진 데이터의 양,

51
00:03:06,471 --> 00:03:10,983
컴퓨터 구성을 통해
얻은 입력 기능의 수,

52
00:03:10,983 --> 00:03:13,464
GPU나 CPU를 사용해
학습하고 있는지에 달려 있습니다.

53
00:03:13,464 --> 00:03:18,280
GPU와 CPU의 구성과 그 밖의
 많은 것들이 정확히 어떻게
구성되는지 알아 봅시다.

54
00:03:18,280 --> 00:03:21,470
많은 응용 프로그램에서
나는 그것이 거의
불가능하다고 생각합니다.

55
00:03:21,470 --> 00:03:26,430
경험 많은 딥러닝 학습자들조차도
초보 매개 변수를

56
00:03:26,430 --> 00:03:30,300
가장 잘 선택하는 것은
거의 불가능합니다.

57
00:03:30,300 --> 00:03:34,160
그래서 오늘날 적용된 딥러닝은
매우 반복적인 과정으로

58
00:03:34,160 --> 00:03:39,150
여러 번 반복해서 실행해 보면

59
00:03:39,150 --> 00:03:43,790
응용 프로그램을 위한 좋은
네트워크를 찾을 수 있습니다.

60
00:03:43,790 --> 00:03:48,100
따라서 당신이 얼마나 빨리
발전할 수 있는지를
결정하는 것 중 하나는

61
00:03:48,100 --> 00:03:51,510
당신이 이 순환을 얼마나
효율적으로 할 수 있느냐입니다.

62
00:03:51,510 --> 00:03:55,830
그리고 데이터를 훈련, 개발,
시험 세트로 잘 설정하면

63
00:03:55,830 --> 00:03:59,030
훨씬 더 효율적으로 만들 수 있습니다.

64
00:03:59,030 --> 00:04:06,430
그럼, 이것이 우리 학습 데이터라고 합시다. 
큰 네모 박스로 그려보죠.

65
00:04:06,430 --> 00:04:11,140
자, 옛날에는 

66
00:04:11,140 --> 00:04:15,520
그 일부분을 당신의 훈련
세트로 분리할 수 있습니다.

67
00:04:15,520 --> 00:04:21,790
일부분은 상호 검증셋(croos validation set)으로 잡아주고,

68
00:04:23,290 --> 00:04:30,398
이것은 가끔 개발셋(development set)이라고 하고,

69
00:04:30,398 --> 00:04:33,940
저는 개발셋을 줄여서 데브셋(dev set)이라고 부를게요.

70
00:04:33,940 --> 00:04:36,810
모두 대충 같은 뜻으로 씁니다.

71
00:04:36,810 --> 00:04:41,940
마지막 부분은 잘라서 테스트 셋으로 만들고요.

72
00:04:41,940 --> 00:04:46,390
그래서 워크플로우는 학습 세트에서
계속 학습 알고리즘을 사용하게 됩니다.

73
00:04:46,390 --> 00:04:51,080
그리고 당신의 개발 세트 또는
교차 검증 세트를 사용하여

74
00:04:51,080 --> 00:04:54,670
많은 다른 모델 중 어떤 모델이
개발 세트에서 가장 잘
수행되는지 확인합니다.

75
00:04:54,670 --> 00:04:56,910
이렇게 충분히 오래 돌려보고 나서

76
00:04:56,910 --> 00:05:00,030
당신이 평가하고 싶은
최종 모델이 있을 때,

77
00:05:00,030 --> 00:05:03,420
가장 좋은 모델이 찾아졌다 싶으면,
이제 테스트 셋을 가지고 평가해 봅니다.

78
00:05:03,420 --> 00:05:08,040
우리 알고리즘이 얼마나 좋은지
공정한 평가를 해보는 것이죠. 

79
00:05:08,040 --> 00:05:13,054
그래서, 기계학습이 예전에는 일반적으로

80
00:05:13,054 --> 00:05:18,246
데이터 전체를 70%,30%로 나누곤 했는데,

81
00:05:18,246 --> 00:05:23,460
70대 30의 훈련셋과 테스트셋을
쓴다고 말했습니다.

82
00:05:23,460 --> 00:05:28,845
개발셋(dev set)도 있다면,
60/20/20%로 나눴다고 할 때,

83
00:05:28,845 --> 00:05:33,680
60% 훈련셋, 20% 데브셋, 20% 테스트셋을 뜻하죠.

84
00:05:33,680 --> 00:05:37,300
몇년전만 해도 기계학습에서 이게 널리 통용된

85
00:05:37,300 --> 00:05:38,910
좋은 실전 사례입니다.

86
00:05:38,910 --> 00:05:41,470
전체 100개의 샘플이 있다고 하면,

87
00:05:41,470 --> 00:05:46,740
또는 전부 천개의 샘플이 있다면 ,
또는 만개의 샘플이 있다면,

88
00:05:46,740 --> 00:05:50,743
이 비율로 셋을 나누는 것은
아주 완벽하고 합리적인 최고의 룰입니다.

89
00:05:50,743 --> 00:05:55,920
그런데, 최근 빅 데이터 세상에서는
예를 들면 

90
00:05:55,920 --> 00:06:03,600
전체 백만개 샘플이 있다고 하면,
요즘 추세는 

91
00:06:03,600 --> 00:06:09,390
개발셋(dev set)과 테스트셋은
전체의 매우 작은 퍼센트로 합니다.

92
00:06:09,390 --> 00:06:13,410
기억하시겠지만,
데브셋 또는 개발셋의 목적은

93
00:06:13,410 --> 00:06:17,370
다른 알고리즘들을 시험해 보고
어떤게 더 좋은지 알아내려는 것이니까,

94
00:06:17,370 --> 00:06:20,010
개발셋은 단지 평가하기에 충분히 많으면 됩니다.

95
00:06:20,010 --> 00:06:23,380
2개의 다른 알고리즘에서 선택하거나

96
00:06:23,380 --> 00:06:27,020
열개의 알고리즘에서 선택하거나 할 때
어떤 것이 더 좋은지 빨리 결정하는데

97
00:06:27,020 --> 00:06:30,500
전체 데이터의 20%나 필요하지는 않습니다.

98
00:06:30,500 --> 00:06:34,200
그래서, 백만개의 훈련 샘플이 있다면,

99
00:06:34,200 --> 00:06:39,250
개발셋은 그냥 만개면 충분하고,

100
00:06:39,250 --> 00:06:43,180
한,두개 알고리즘이 더 나은지 평가할 수 있습니다.

101
00:06:43,180 --> 00:06:47,220
비슷한 맥락에서, 당신의
테스트 세트의 주요 목표는
최종 분류자를 고려할 때

102
00:06:47,220 --> 00:06:51,885
그것이 얼마나 잘하고 있는지에
대한 추정치 제공하는 것입니다.

103
00:06:51,885 --> 00:06:56,695
마찬가지로, 백만 개의 예시가 있으면,

104
00:06:56,695 --> 00:07:00,960
싱글 classifier를 평가하는데 만개의 
예시가 충분하다고 결정할 수 있습니다.

105
00:07:00,960 --> 00:07:03,680
얼마나 잘 성능을 발휘하는지 꽤 정확한 추정 수치를 제공하는데 말이죠.

106
00:07:03,680 --> 00:07:07,280
이번 사례에서처럼 백만 개의 예시가 있는 경우,

107
00:07:07,280 --> 00:07:11,550
dev를 위한 만개의 예시, 테스트를 위한 만개의 예시이면
충분합니다.

108
00:07:11,550 --> 00:07:17,240
이 경우, 비율은 1퍼센트가 되기 때문에,

109
00:07:17,240 --> 00:07:23,330
98퍼센트 트레이닝, 1퍼센트 dev, 나머지 1퍼센트가 테스트가 되겠습니다.

110
00:07:23,330 --> 00:07:25,360
또한 저는 이미 

111
00:07:25,360 --> 00:07:29,910
예시가 백만 개를 초과하는 경우의 어플을 
많이 봐왔는데요,

112
00:07:29,910 --> 00:07:35,050
99.5퍼센트 트레이닝, 0.25퍼센트 dev, 0.25퍼센트 테스트 예시인 경우도 봤고,

113
00:07:35,050 --> 00:07:42,060
99.5퍼센트 트레이닝, 0.4퍼센트 dev, 0.1퍼센트 테스트인 경우도 봤습니다.

114
00:07:42,060 --> 00:07:45,920
복습하자면, 머신러닝 문제를 세팅하는 경우,

115
00:07:45,920 --> 00:07:50,380
저는 보통 트레이닝, dev, 테스트 세트 이런 식으로
세팅을 할 텐데요,

116
00:07:50,380 --> 00:07:55,740
꽤 작은 데이터세트를 보유하고 있다면
이런 전통적인 비율이 괜찮을 것입니다.

117
00:07:55,740 --> 00:07:59,560
하지만 훨씬 더 큰 데이터세트를 보유하고 있으면, 
dev와 테스트 세트를 더 작은 비율로 하는 것도 

118
00:07:59,560 --> 00:08:05,660
괜찮습니다. 총 데이터의 20퍼센트 또는 10퍼센트
내의 비율로 말이죠.

119
00:08:05,660 --> 00:08:08,640
dev나 테스트 세트의 자세한 가이드라인에 대해서는 

120
00:08:08,640 --> 00:08:11,110
이후에 설명 드리도록 하겠습니다.

121
00:08:11,110 --> 00:08:16,170
근래 딥러닝 분야에서의 또 다른 트렌드는

122
00:08:16,170 --> 00:08:20,080
더욱 더 많은 사람들이 불일치한 트레인과 테스트 분포에서 
트레이닝을 하는 것입니다.

123
00:08:20,080 --> 00:08:25,100
예를 들어, 유저들이 사진을 업로드 하는 어플에서 

124
00:08:25,100 --> 00:08:29,380
목표는 유저들에게 보여줄 수 있도록 고양이의 사진을
색출해내는 것이라고 가정하 보죠,

125
00:08:29,380 --> 00:08:31,590
아마도 모든 유저가 고양이를 좋아할 수도 있겠죠.

126
00:08:31,590 --> 00:08:37,180
트레이닝 세트가 인터넷에서 다운받은 
고양이 이미지로 이루어진 데이터일수도 있습니다.

127
00:08:37,180 --> 00:08:42,178
하지만 dev나 테스트 세트는 유저들이 올린 사진을
포함할 수 있습니다.

128
00:08:42,178 --> 00:08:46,250
그러므로 트레이닝 세트는 인터넷에서 찾은 여러 가지
사진으로 구성될 수 있지만

129
00:08:46,250 --> 00:08:49,470
테스트 세트는 유저가 올린 사진일 수 있겠죠. 

130
00:08:49,470 --> 00:08:53,370
알고 보니, 많은 수의 웹페이지는
고화질의 프로페셔널한

131
00:08:53,370 --> 00:08:55,610
고프레임의 고양이 사진이 많았습니다.

132
00:08:55,610 --> 00:08:58,290
반면에 유저들이 업로드 하는 사진은
흐릿하고,

133
00:08:58,290 --> 00:09:03,450
화질이 좋지 않거나, 핸드폰으로 캐쥬얼하게 찍은
사진일 수 있겠죠.

134
00:09:03,450 --> 00:09:07,960
그렇기 때문에 데이터의 분포도가 전혀 다를 수 있습니다.

135
00:09:07,960 --> 00:09:13,042
이런 경우, 저는 경험을 근거로 하는 규칙을
권장드립니다.

136
00:09:13,042 --> 00:09:18,737
dev와 테스트 세트가 똑같은 분포도에서 오게끔 말이죠.

137
00:09:23,079 --> 00:09:26,199
상세한 가이드라인은 나중에 언급하겠습니다만, 

138
00:09:26,199 --> 00:09:30,039
dev set를 이용하여 다양한 모델들을 평가하고

139
00:09:30,039 --> 00:09:33,380
동시에 dev set를 개선하려고 할 것이기 때문에 

140
00:09:33,380 --> 00:09:38,380
dev set가 테스트 세트와 같은 분포도에서 오는 것이 좋습니다.

141
00:09:38,380 --> 00:09:43,440
딥러닝 알고리즘은 데이터를 트레이닝 하고 싶어하기 때문에

142
00:09:43,440 --> 00:09:47,660
모든 다양한 수단과 전술을 이용해서, 

143
00:09:47,660 --> 00:09:49,560
crawling webpage와 같은 방법을 동원하여, 

144
00:09:49,560 --> 00:09:53,650
훨씬 더 큰 트레이닝 세트를 구축할 수 있습니다.

145
00:09:53,650 --> 00:09:57,300
이것에 따른 대가가 

146
00:09:57,300 --> 00:10:00,950
트레이닝세트 데이터들이 dev와 테스트 세트와는 
다른 분포도를 갖는 것일 수 있지만,

147
00:10:00,950 --> 00:10:03,980
이 경험에 근거한 규칙을 따르면, 

148
00:10:03,980 --> 00:10:08,600
여러분의 러닝 알고리즘이 더욱 빠르게 발달할 수 있을 것입니다.

149
00:10:08,600 --> 00:10:10,750
이 경험을 바탕으로 한 규칙에 대해서는 

150
00:10:10,750 --> 00:10:13,910
나중에 더 자세히 설명해 드리겠습니다.

151
00:10:13,910 --> 00:10:18,320
마지막으로, 테스트 세트가 없는 게 괜찮을 수도 있습니다.

152
00:10:18,320 --> 00:10:22,289
기억하시겠지만, 테스트 세트의 목표는 

153
00:10:22,289 --> 00:10:26,995
여러분의 선택한 마지막 네트워크에 대해서
바이어스 없는 성능 추정치를 제공하는 것입니다.

154
00:10:26,995 --> 00:10:29,315
만약 여러분이 바이어스 없는 추정치가 필요치 
않을 경우,

155
00:10:29,315 --> 00:10:32,090
테스트 세트가 없어도 괜찮을 것 입니다.

156
00:10:32,090 --> 00:10:35,030
여러분이 dev set는 있고 테스트 세트는 없는 경우, 

157
00:10:35,030 --> 00:10:40,210
트레이닝 세트에서 트레이닝을 진행하고, 
다른 모델 구조를 시도해보는 것입니다.

158
00:10:40,210 --> 00:10:44,450
dev set에서 평가하고, 이를 이용해 
반복 업무를 통해

159
00:10:44,450 --> 00:10:46,140
가장 좋은 모델을 찾습니다.

160
00:10:46,140 --> 00:10:48,020
데이터를 dev set에 피팅했기 때문에

161
00:10:48,020 --> 00:10:50,657
이제 더 이상 성능에 대한 바이어스 없는 추정치를 주지 않습니다.

162
00:10:50,657 --> 00:10:53,690
만약 필요 없을 시, 굳이 없으셔도 무방합니다.

163
00:10:53,690 --> 00:10:55,950
머신러닝 세계에서는
트레인과 dev set만 있고

164
00:10:55,950 --> 00:10:58,500
별도의 테스트 세트가 없을 시, 

165
00:10:58,500 --> 00:11:01,260
대부분의 사람들은 이것을
트레이닝 세트라고 부르고,

166
00:11:01,260 --> 00:11:04,640
dev set를 테스트 세트라고 부를 것입니다.

167
00:11:04,640 --> 00:11:08,881
실제로 그렇게 한 다음, 테스트 세트를 
hold-out cross

168
00:11:08,881 --> 00:11:09,902
validation set로 이용하는 것이죠, 

169
00:11:09,902 --> 00:11:13,460
표현하기 편한 용어는 아니지만

170
00:11:13,460 --> 00:11:17,320
그렇게 해서 사람들은 테스트 세트에 오버피팅 시킵니다.

171
00:11:17,320 --> 00:11:21,310
팀들이 만약 트레인과 테스트 세트만 있다고 하면

172
00:11:21,310 --> 00:11:26,140
조심스럽게 생각할 것입니다.
그들은 진짜로 트레인 dev set가 있는 것인가?

173
00:11:26,140 --> 00:11:28,520
테스트 세트에 오버피팅하니까 말이죠.

174
00:11:28,520 --> 00:11:33,348
문화적으로 이 팀들이 쓰는 용어는 바꾸기 어려울 수도 있습니다.

175
00:11:33,348 --> 00:11:38,410
‘trained test set’ 대신 ‘trained dev set’라고 바꾸는 것 말이죠.

176
00:11:38,410 --> 00:11:40,170
물론 제가 생각하기에는 train and development set라고 

177
00:11:40,170 --> 00:11:43,250
부르는 게 더 정확한 용어라고 생각하지만요.

178
00:11:43,250 --> 00:11:45,970
만약 바이어스 없는 알고리즘의 성능 추정치가 

179
00:11:45,970 --> 00:11:48,665
필요 없는 경우엔, 이렇게 해도 상관없습니다.

180
00:11:48,665 --> 00:11:53,575
train dev와 테스트 세트를 세팅하면서
더 빨리 통합시킬 수 있도록 할 것입니다.

181
00:11:53,575 --> 00:11:57,631
알고리즘의 바이어스와 편차를 더 효율적으로

182
00:11:57,631 --> 00:12:02,215
계산하고, 알고리즘을 더 효율적으로 개선할 수 있게
될 것입니다.

183
00:12:02,215 --> 00:12:04,225
이런 내용을 다음 비디오에서 이야기해보죠.