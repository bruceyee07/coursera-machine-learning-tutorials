1
00:00:00,000 --> 00:00:03,600
我注意到，几乎所有真正优秀的机器学习参与者

2
00:00:03,600 --> 00:00:07,890
对偏差（偏离度）和方差（集中度）的处理都是非常有经验的

3
00:00:07,890 --> 00:00:12,330
偏差和方差的处理往往非常容易入门，但是非常难以精通

4
00:00:12,330 --> 00:00:16,155
即使你认为你已经看完了偏差和方差的基础理论

5
00:00:16,155 --> 00:00:18,805
也常常会发现总会有一些出乎你意料的东西

6
00:00:18,805 --> 00:00:20,620
在深度学习领域

7
00:00:20,620 --> 00:00:22,650
另一个现象是有关

8
00:00:22,650 --> 00:00:26,035
偏差-方差困境（也有叫做偏差-方差权衡）的讨论很少

9
00:00:26,035 --> 00:00:28,657
你可能之前已经听说过这个被称为“偏差-方差困境”的东西

10
00:00:28,657 --> 00:00:31,330
但是在深度学习领域，这不仅仅是两者间的权衡问题

11
00:00:31,330 --> 00:00:32,520
我们仍然讨论偏差

12
00:00:32,520 --> 00:00:33,865
也仍然讨论方差

13
00:00:33,865 --> 00:00:37,295
但是我们对偏差-方差困境讨论的不多

14
00:00:37,295 --> 00:00:39,795
让我们一起来看看为什么这么说

15
00:00:39,795 --> 00:00:42,750
大家应该看到了屏幕上这些训练集

16
00:00:42,750 --> 00:00:44,800
如果你用一条直线来区分样本数据

17
00:00:44,800 --> 00:00:48,130
那么用逻辑回归可能画出图上的这条直线

18
00:00:48,130 --> 00:00:50,415
这和训练数据的拟合度并不高

19
00:00:50,415 --> 00:00:52,380
这样的分类我们称之为高偏差

20
00:00:52,380 --> 00:00:56,400
或者换一种说法，这是欠拟合

21
00:00:56,400 --> 00:00:57,850
相对的

22
00:00:57,850 --> 00:01:00,645
如果你使用一个极为复杂的分类器

23
00:01:00,645 --> 00:01:02,640
例如深度神经网络

24
00:01:02,640 --> 00:01:05,995
或者含有所有隐藏神经元的神经网络

25
00:01:05,995 --> 00:01:10,255
或许你可以像图上画的这样完美区分训练数据

26
00:01:10,255 --> 00:01:12,220
但那看上去也并不是一个非常好的分类算法

27
00:01:12,220 --> 00:01:17,535
这个高方差的分类器，我们也称之为过拟合

28
00:01:17,535 --> 00:01:19,650
在这两种分类器之间

29
00:01:19,650 --> 00:01:22,070
我们应该能找到一种不那么复杂的

30
00:01:22,070 --> 00:01:24,585
但是能正确分类的算法，像图上这样

31
00:01:24,585 --> 00:01:27,300
这看起来对数据的区分非常合理

32
00:01:27,300 --> 00:01:31,705
我们认为这才是完美匹配的算法，结果居于欠拟合与过拟合之间

33
00:01:31,705 --> 00:01:34,260
像图上的这个有两个特征值

34
00:01:34,260 --> 00:01:35,610
的2D样例

35
00:01:35,610 --> 00:01:39,700
我们把横轴标为x1，纵轴标为x2，你可以绘制数据，把偏差和方差可视化

36
00:01:39,700 --> 00:01:41,250
在高维度问题中

37
00:01:41,250 --> 00:01:44,735
你无法将数据绘制在图上，并可视化决策边界

38
00:01:44,735 --> 00:01:46,830
然而，对应这样的情况也会有几个不同的方法

39
00:01:46,830 --> 00:01:49,750
让我们来探讨一下，试着去理解偏差和方差的含义

40
00:01:49,750 --> 00:01:51,960
让我们接着讲猫的图片分类的例子

41
00:01:51,960 --> 00:01:57,600
这里有一个正确的样本和一个错误的样本

42
00:01:57,600 --> 00:02:01,455
理解偏差和方差的两个关键数据是

43
00:02:01,455 --> 00:02:06,415
训练集误差和开发集误差

44
00:02:06,415 --> 00:02:07,716
为了便于讨论

45
00:02:07,716 --> 00:02:10,290
我们假设你已经在图片中识别出了猫

46
00:02:10,290 --> 00:02:13,860
这几乎每个人都能完美做到的，对不？

47
00:02:13,860 --> 00:02:22,155
所以我们可以理解为，你的训练集误差是1%，而对于开发集误差

48
00:02:22,155 --> 00:02:23,580
为了便于讨论

49
00:02:23,580 --> 00:02:25,585
我们假设是11%

50
00:02:25,585 --> 00:02:26,730
在这个例子里

51
00:02:26,730 --> 00:02:29,495
你的模型对训练集处理得非常好

52
00:02:29,495 --> 00:02:34,355
但是相对来说，开发集处理得就有些不尽如人意

53
00:02:34,355 --> 00:02:38,215
所以这可能是在处理训练集时过拟合了

54
00:02:38,215 --> 00:02:40,620
模型在某种程度上对于交叉验证集合

55
00:02:40,620 --> 00:02:43,815
（开发集）泛化性不够好

56
00:02:43,815 --> 00:02:46,440
如果你得到的结果和这个例子一样

57
00:02:46,440 --> 00:02:50,785
我们将它定义成高方差

58
00:02:50,785 --> 00:02:54,240
通过观察训练集误差和开发集误差

59
00:02:54,240 --> 00:02:59,730
你将能判断出你的模型算法是否有高方差的问题

60
00:02:59,730 --> 00:03:04,435
现在，让我们再来看第二个例子，假设你得到了训练集和开发集的误差

61
00:03:04,435 --> 00:03:06,095
有了与第一个例子不一样的结果

62
00:03:06,095 --> 00:03:09,610
假设训练集的误差是15%

63
00:03:09,610 --> 00:03:12,375
我把这个训练集误差写在第一行

64
00:03:12,375 --> 00:03:15,880
假设你的开发集误差是16%

65
00:03:15,880 --> 00:03:22,870
在这种情况下，我们假设人工识别误差是0%

66
00:03:22,870 --> 00:03:27,451
因为人可以直接看到这些图片，并判断出这是否是一只猫

67
00:03:27,451 --> 00:03:31,600
所以看上去，这个算法在训练集上的表现并不尽如人意

68
00:03:31,600 --> 00:03:35,380
如果它并未将训练集数据处理得很好

69
00:03:35,380 --> 00:03:38,220
这就是欠拟合

70
00:03:38,220 --> 00:03:40,895
我们认为这个算法是高偏差的

71
00:03:40,895 --> 00:03:45,390
但相比之下，这个算法应用在开发集时还处于一个可接受的水准

72
00:03:45,390 --> 00:03:49,365
和应用在训练集时的表现相比，误差只多了1%

73
00:03:49,365 --> 00:03:52,355
所以这个算法的问题是高偏差

74
00:03:52,355 --> 00:03:56,325
因为它并不能在训练集上对样本进行很好的识别

75
00:03:56,325 --> 00:04:01,030
这种情况和我们在上一页PPT中最左边的图极为相似

76
00:04:01,030 --> 00:04:03,329
好了，我们来讲下一个例子

77
00:04:03,329 --> 00:04:06,430
假设你的算法在训练集上的误差是15%

78
00:04:06,430 --> 00:04:08,127
这是相当高的偏差

79
00:04:08,127 --> 00:04:11,446
但当你将该算法应用在开发集时，情况变得更糟

80
00:04:11,446 --> 00:04:13,450
可能有30%的误差

81
00:04:13,450 --> 00:04:18,175
在这种情况下，我可以判断出这个算法是高偏差的

82
00:04:18,175 --> 00:04:23,780
它并没有将训练集处理好，并且还是高方差的

83
00:04:23,780 --> 00:04:27,950
这是一种非常、十分、极其糟糕的算法

84
00:04:27,950 --> 00:04:29,325
让我们看看最后一个例子

85
00:04:29,325 --> 00:04:32,605
假设你有0.5%的训练集误差

86
00:04:32,605 --> 00:04:35,145
以及1%的开发集误差

87
00:04:35,145 --> 00:04:37,130
这是让大家都喜闻乐见的算法

88
00:04:37,130 --> 00:04:39,850
对猫的分类仅有1%的误差

89
00:04:39,850 --> 00:04:44,340
所以这个算法是低偏差和低方差的

90
00:04:44,340 --> 00:04:47,610
有一点要注意，我简单地提一下

91
00:04:47,610 --> 00:04:50,955
我们会在之后的视频教程中详细讨论

92
00:04:50,955 --> 00:04:54,188
这种分析方法的前提基于真人识别的

93
00:04:54,188 --> 00:04:59,115
误差为0%的假设

94
00:04:59,115 --> 00:05:01,749
一般来说，我们称之为理想误差

95
00:05:01,749 --> 00:05:04,225
或者有时我们叫它贝叶斯误差

96
00:05:04,225 --> 00:05:10,355
贝叶斯误差接近0%

97
00:05:10,355 --> 00:05:13,565
在这期视频中我就不展开来说这个问题了

98
00:05:13,565 --> 00:05:18,070
但是如果理想误差或贝叶斯误差比较高，假设

99
00:05:18,070 --> 00:05:22,360
是15%，那么如果我们继续来看这个分类算法

100
00:05:22,360 --> 00:05:25,460
15%误差实际上对训练集来说是一个近乎完美的结果了

101
00:05:25,460 --> 00:05:30,120
你不应该认为它是高偏差的、低方差的算法

102
00:05:30,120 --> 00:05:33,440
所以如果没有好的分类器存在，

103
00:05:33,440 --> 00:05:37,460
如何来分析偏差和方差呢？ 假设

104
00:05:37,460 --> 00:05:40,833
如果你的图像真的很模糊

105
00:05:40,833 --> 00:05:46,081
哪怕是真人或者任何系统都不能进行分类

106
00:05:46,081 --> 00:05:49,237
那贝叶斯误差就会非常高

107
00:05:49,237 --> 00:05:52,295
然后会有一些不同的手段来改变分析方法

108
00:05:52,295 --> 00:05:54,725
但是我们现在先不讨论这个问题

109
00:05:54,725 --> 00:05:57,430
而我们可以发现，通过观察

110
00:05:57,430 --> 00:06:02,676
训练集的误差，至少可以知道你的算法是否可以

111
00:06:02,676 --> 00:06:04,331
很好的拟合训练集数据

112
00:06:04,331 --> 00:06:06,770
然后总结出是否属于高偏差问题

113
00:06:06,770 --> 00:06:10,190
然后通过观察同一个算法

114
00:06:10,190 --> 00:06:12,965
在开发集上的误差了多少

115
00:06:12,965 --> 00:06:17,055
可以知道这个算法是否有高方差问题

116
00:06:17,055 --> 00:06:20,857
这样你就能判断训练集上的算法是否在开发集上同样适用

117
00:06:20,857 --> 00:06:22,645
这会让你意识到方差问题

118
00:06:22,645 --> 00:06:26,210
上述结果都基于贝叶斯误差非常低并且

119
00:06:26,210 --> 00:06:30,235
你的训练集和开发集都来自与同一个分布

120
00:06:30,235 --> 00:06:32,210
如果不满足这些假设

121
00:06:32,210 --> 00:06:34,323
那么你需要做一个更复杂的分析

122
00:06:34,323 --> 00:06:36,510
我们将在之后几期视频教程中讨论

123
00:06:36,510 --> 00:06:38,780
好了，在上一张PPT中

124
00:06:38,780 --> 00:06:40,849
我们展示了高偏差

125
00:06:40,849 --> 00:06:42,185
和高方差的形态

126
00:06:42,185 --> 00:06:44,920
我猜你已经意识到一个优秀的分类器看上去是什么样的了

127
00:06:44,920 --> 00:06:48,110
高偏差和高方差的算法看上去如何呢？

128
00:06:48,110 --> 00:06:50,535
这是一种无比糟糕的情况

129
00:06:50,535 --> 00:06:53,415
你应该还记得，我们说过一个像这样的

130
00:06:53,415 --> 00:06:55,755
线性分类器是高偏差的

131
00:06:55,755 --> 00:06:58,185
因为欠拟合（它没有很好的拟合数据）

132
00:06:58,185 --> 00:07:04,030
所以可以说，由于这几乎是个线性分类算法（直线）因此欠拟合了

133
00:07:04,030 --> 00:07:05,570
我们用紫色来标一下

134
00:07:05,570 --> 00:07:09,546
但是如果在某些情况下你的分类算法
做了些诡异的事情（像我现在画的这样）

135
00:07:09,546 --> 00:07:14,460
那么实际上这部分在部分数据上过拟合了

136
00:07:14,460 --> 00:07:16,500
所以我在紫色部分标示的分类器

137
00:07:16,500 --> 00:07:19,455
同时具有高偏差和高方差的问题

138
00:07:19,455 --> 00:07:21,300
从图上看，这里的偏差很高

139
00:07:21,300 --> 00:07:23,325
因为这几乎是一个线性分类器

140
00:07:23,325 --> 00:07:24,875
而它无法拟合分类

141
00:07:24,875 --> 00:07:28,466
你看，就像图上这个曲线形状的类别

142
00:07:28,466 --> 00:07:31,200
但是这个分类算法中间，又变得十分扭曲

143
00:07:31,200 --> 00:07:32,995
虽然某种程度上来说 它正确地区分了这个叉样本

144
00:07:32,995 --> 00:07:36,720
和这个圈样本。过拟合了这两个孤立的样本

145
00:07:36,720 --> 00:07:40,515
我们称这个分类算法是高偏差的，因为它几乎是直线

146
00:07:40,515 --> 00:07:43,620
但你需要的可能是一个曲线函数或二次函数

147
00:07:43,620 --> 00:07:45,115
同时它也是高方差的

148
00:07:45,115 --> 00:07:49,595
因为它在中间用极为扭曲的算法，对两个孤立的

149
00:07:49,595 --> 00:07:52,475
甚至可能是错误的样本进行了拟合

150
00:07:52,475 --> 00:07:54,300
看上去这比较像人为的

151
00:07:54,300 --> 00:07:57,585
这个样例在二维中看上去不太自然

152
00:07:57,585 --> 00:07:59,883
但是当你有相当高维度的输入特征

153
00:07:59,883 --> 00:08:01,795
你可能在获取特征的过程中

154
00:08:01,795 --> 00:08:04,800
在一些地方遇到了高偏差的问题，一些地方遇到了高方差的问题

155
00:08:04,800 --> 00:08:07,410
所以很可能最终得到了在高维度特征输入情况下

156
00:08:07,410 --> 00:08:11,415
产生了这样不自然的分类

157
00:08:11,415 --> 00:08:15,690
让我们总结一下，这节课我们学习了如何通过观察算法

158
00:08:15,690 --> 00:08:20,550
在训练集和开发集的误差来诊断

159
00:08:20,550 --> 00:08:23,413
它是否有高偏差或者高方差的问题

160
00:08:23,413 --> 00:08:25,420
或许两者都有，或许都没有

161
00:08:25,420 --> 00:08:28,995
基于算法遇到高偏差或高方差问题的不同情况

162
00:08:28,995 --> 00:08:31,765
我们可以尝试不同的方法来进行改进

163
00:08:31,765 --> 00:08:33,840
在下一个视频教程中，我想要给你介绍一种方法

164
00:08:33,840 --> 00:08:37,390
我称之为机器学习的基本准则

165
00:08:37,390 --> 00:08:40,905
那会让你在遇到高偏差或者高方差问题时

166
00:08:40,905 --> 00:08:44,370
能够更系统地去尝试改进你的算法

167
00:08:44,370 --> 00:08:46,110
让我们继续下一期教程