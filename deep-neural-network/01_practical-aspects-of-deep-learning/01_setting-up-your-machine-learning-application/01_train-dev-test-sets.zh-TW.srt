1
00:00:00,740 --> 00:00:04,500
歡迎來到這個從實用
觀點來看深度學習的課程

2
00:00:04,500 --> 00:00:07,650
也許您已經學到如何
建置一個神經網路

3
00:00:07,650 --> 00:00:10,620
在這個禮拜您將學到
用實用的觀點如何去

4
00:00:10,620 --> 00:00:12,550
讓您的神經網路可行

5
00:00:12,550 --> 00:00:16,757
從像是超參數
調整到如何設定您的資料

6
00:00:16,757 --> 00:00:20,297
如何確認您的最佳化
演算法跑得最快

7
00:00:20,297 --> 00:00:24,140
使得您的學習演算法
的學習時間合理

8
00:00:24,140 --> 00:00:27,551
在第一個星期我們先談到
如何設定機器學習問題

9
00:00:27,551 --> 00:00:29,216
然後我們會談到正規化

10
00:00:29,216 --> 00:00:30,952
然後我們會談到一些技巧來

11
00:00:30,952 --> 00:00:34,440
確認您的神經網路
建置是正確的

12
00:00:34,440 --> 00:00:36,170
這樣，讓我們開始吧

13
00:00:36,170 --> 00:00:39,760
選擇好您如何
設定訓練, 開發

14
00:00:39,760 --> 00:00:43,160
及測試集可能會造成很大
的不同在幫助您很快的

15
00:00:43,160 --> 00:00:46,090
找到一個高
效能的神經網路

16
00:00:46,090 --> 00:00:49,230
當訓練一個神經網路您
必須做很多決定

17
00:00:49,230 --> 00:00:52,310
像是您的神經網路要幾層?

18
00:00:52,310 --> 00:00:55,400
您每一層要幾個隱藏單元？

19
00:00:55,400 --> 00:00:57,067
學習率是多少?

20
00:00:57,067 --> 00:01:01,150
您在不同層要用哪些啟動函數？

21
00:01:01,150 --> 00:01:03,040
當您開始一個新的應用時

22
00:01:03,040 --> 00:01:07,400
幾乎不可能正確的
猜出所有這些正確值

23
00:01:07,400 --> 00:01:12,250
還有其他超參數
的選擇在您第一次嘗試時

24
00:01:12,250 --> 00:01:16,290
實際上應用機器學習
是高度的循環程序

25
00:01:16,290 --> 00:01:18,450
您通常開始於一個想法

26
00:01:18,450 --> 00:01:21,990
像是您想建立一個神經
網路有特定的層數

27
00:01:21,990 --> 00:01:25,670
特定的隱藏單元
也許特定的資料集等等

28
00:01:25,670 --> 00:01:29,660
然後您就開始寫程式
試著去跑它

29
00:01:29,660 --> 00:01:33,950
跑完以後
您得到結果告訴您

30
00:01:33,950 --> 00:01:37,570
這個特定的網路作用得如何
或者說這個特定的設定作用如何

31
00:01:37,570 --> 00:01:39,090
基於成果

32
00:01:39,090 --> 00:01:44,330
您也許改進您的想法
改變您的選擇

33
00:01:44,330 --> 00:01:49,474
也許繼續循環為了試著
找到更好的神經網路

34
00:01:50,890 --> 00:01:54,390
在今天, 深度學習已經在
很多領域獲得很大的成功

35
00:01:54,390 --> 00:01:59,256
從自然語言處理
到電腦視覺

36
00:01:59,256 --> 00:02:04,579
到語音辨識到很多
應用在結構式資料

37
00:02:04,579 --> 00:02:10,000
而結構性資料包含了
從廣告到網路搜尋

38
00:02:10,000 --> 00:02:16,840
不只是網路搜尋引擎
同時, 舉個例子, 購物網站

39
00:02:16,840 --> 00:02:19,340
任何網站想要

40
00:02:19,340 --> 00:02:23,800
送出好的搜尋結果
當您在搜尋欄中鍵入術語時

41
00:02:23,800 --> 00:02:29,436
到電腦安全, 到物流
像是找出

42
00:02:29,436 --> 00:02:34,665
送司機到取貨點及送貨點到其他更多的應用

43
00:02:34,665 --> 00:02:39,530
我見到的是有時候
有很多 NLP 經驗的研究人員

44
00:02:39,530 --> 00:02:43,170
也許試著
做電腦視覺

45
00:02:43,170 --> 00:02:48,120
或者也許有很多語音辨識經驗
的研究人員也許

46
00:02:48,120 --> 00:02:50,190
進入
試圖做廣告有關的東西

47
00:02:50,190 --> 00:02:54,670
或者從保全也許
進入做起物流相關

48
00:02:54,670 --> 00:02:57,940
我見到的是
一個領域的直覺或者

49
00:02:57,940 --> 00:03:02,920
從一個應用領域通常並不能
轉換到另一個應用領域上

50
00:03:02,920 --> 00:03:06,471
最佳的選擇則是依靠在
您有的資料量多寡

51
00:03:06,471 --> 00:03:10,983
您有多少輸入特徵
您的電腦設定

52
00:03:10,983 --> 00:03:13,464
是否訓練在 GPU 或 CPU 上

53
00:03:13,464 --> 00:03:18,280
如果有，真正的 GPU 跟 CPU 的配置等等很多事

54
00:03:18,280 --> 00:03:21,470
對於很多的應用, 我
想那是不可能

55
00:03:21,470 --> 00:03:26,430
即使有經驗的深度學習達人
也不可能正確

56
00:03:26,430 --> 00:03:30,300
猜出最佳的
超參數選擇在第一次時

57
00:03:30,300 --> 00:03:34,160
所以在今天
應用深度學習是很循環

58
00:03:34,160 --> 00:03:39,150
的程序您需要
循環這個圈圈很多次

59
00:03:39,150 --> 00:03:43,790
期望找出
對於您的應用的一個好的選擇

60
00:03:43,790 --> 00:03:48,100
如何快速獲得進展
的其中一件事是

61
00:03:48,100 --> 00:03:51,510
您如何用最有效的方式
來循環這個圈圈

62
00:03:51,510 --> 00:03:55,830
而設定您的資料集
成為訓練, 開發及

63
00:03:55,830 --> 00:03:59,030
測試集可以讓您更有效率

64
00:03:59,030 --> 00:04:06,430
如果這是您的訓練集
我們畫一個框框

65
00:04:06,430 --> 00:04:11,140
傳統上您也許
拿所有的資料

66
00:04:11,140 --> 00:04:15,520
切成一部分是您的訓練集

67
00:04:15,520 --> 00:04:21,790
一部分是您的交叉驗證集

68
00:04:23,290 --> 00:04:30,398
有時候也稱為開發集

69
00:04:30,398 --> 00:04:33,940
簡化起見我叫它為 dev 集

70
00:04:33,940 --> 00:04:36,810
但所有這些名詞大約同義

71
00:04:36,810 --> 00:04:41,940
然後您也許切剩下的部分成為您的測試集

72
00:04:41,940 --> 00:04:46,390
所以程序是您一直
訓練演算法在訓練集上

73
00:04:46,390 --> 00:04:51,080
然後使用您的開發集或者說
交叉驗證集看看

74
00:04:51,080 --> 00:04:54,670
哪一種模型
在您的開發集作用得最好

75
00:04:54,670 --> 00:04:56,910
然後做完足夠長的時間

76
00:04:56,910 --> 00:05:00,030
當您有最後的模型
您想要評估

77
00:05:00,030 --> 00:05:03,420
您可以拿這個您找到的最佳模型
在測試集評估

78
00:05:03,420 --> 00:05:08,040
為了得到您演算法
作用如何的無偏估計

79
00:05:08,040 --> 00:05:13,054
在先前的機器學習時代
通常做法是

80
00:05:13,054 --> 00:05:18,246
拿所有您的資料
拆開成也許是 70/30%

81
00:05:18,246 --> 00:05:23,460
這方面，人們通常談到 70/30 訓練測試分拆

82
00:05:23,460 --> 00:05:28,845
當您不用開發集的話, 
或者 60/20/20%

83
00:05:28,845 --> 00:05:33,680
分拆, 就是 60% 訓練
 20% 開發, 20% 測試

84
00:05:33,680 --> 00:05:37,300
幾年前這是
廣泛使用的

85
00:05:37,300 --> 00:05:38,910
機器學習最佳典範

86
00:05:38,910 --> 00:05:41,470
如果您也許有 100 個例子

87
00:05:41,470 --> 00:05:46,740
也許 1000 個例子
也許 10,000 個例子

88
00:05:46,740 --> 00:05:50,743
這樣的比率
是完美的經驗法則

89
00:05:50,743 --> 00:05:55,920
但在現代大數據時代
舉個例子

90
00:05:55,920 --> 00:06:03,600
您也許有數百萬個例子
趨勢是您的開發跟

91
00:06:03,600 --> 00:06:09,390
測試集已經變得
小一點的比率了

92
00:06:09,390 --> 00:06:13,410
因為記得, 開發集的目標是

93
00:06:13,410 --> 00:06:17,370
您用不同的演算法來測試看看哪一種演算法作用最好

94
00:06:17,370 --> 00:06:20,010
所以開發集只需要夠大來

95
00:06:20,010 --> 00:06:23,380
讓您評估
兩個不同的演算法或者

96
00:06:23,380 --> 00:06:27,020
十個不同演算法選擇
很快決定哪一個最好

97
00:06:27,020 --> 00:06:30,500
而您不需要整個
20% 的資料來做這件事

98
00:06:30,500 --> 00:06:34,200
舉個例子, 如果您有百萬個
訓練例子, 您也許決定

99
00:06:34,200 --> 00:06:39,250
只需要用 10,000 個例子
在開發集已經夠了

100
00:06:39,250 --> 00:06:43,180
來評估哪一個
或兩個演算法作用最好

101
00:06:43,180 --> 00:06:47,220
同樣地，您測試集的目的是給您最終的

102
00:06:47,220 --> 00:06:51,885
分類器， 給您相當自信
的評估它作用的如何?

103
00:06:51,885 --> 00:06:56,695
再次， 如果您有百萬個例子
您也許決定用 10,000

104
00:06:56,695 --> 00:07:00,960
個例子已經夠了為了要
評估一個單一分類器而

105
00:07:00,960 --> 00:07:03,680
給您一個好的評估
對於它作用得如何?

106
00:07:03,680 --> 00:07:07,280
所以在這個例子
當您有百萬個例子

107
00:07:07,280 --> 00:07:11,550
如果您只需要用 10,000
給開發集, 10,000 給測試集

108
00:07:11,550 --> 00:07:17,240
您的比率會是
 10,000 是 1% 的一百萬

109
00:07:17,240 --> 00:07:23,330
您有98% 訓練，1% 開發, 1% 測試

110
00:07:23,330 --> 00:07:25,360
我也看過一些應用

111
00:07:25,360 --> 00:07:29,910
如果您有甚至比百萬個
例子還多, 您或許

112
00:07:29,910 --> 00:07:35,050
用 99.5% 訓練, 
0.25% 開發, 0.25% 測試

113
00:07:35,050 --> 00:07:42,060
或者 0.4% 開發, 0.1% 測試

114
00:07:42,060 --> 00:07:45,920
總結一下，當設定
您的機器學習問題時

115
00:07:45,920 --> 00:07:50,380
我通常設定成訓練,
開發,跟測試集

116
00:07:50,380 --> 00:07:55,740
如果您有相對小的資料集
傳統的比率也許可用

117
00:07:55,740 --> 00:07:59,560
但如果您有很大的資料集
設定您的開發跟

118
00:07:59,560 --> 00:08:05,660
測試集小一點像是
比20%小甚至10% 也都可行

119
00:08:05,660 --> 00:08:08,640
我們會給予特定的
準則在開發集

120
00:08:08,640 --> 00:08:11,110
及測試集
在晚一點這個學程中

121
00:08:11,110 --> 00:08:16,170
另一個趨勢我們在現代深度學習時代是越來越多

122
00:08:16,170 --> 00:08:20,080
人們訓練在不同的訓練及測試分佈

123
00:08:20,080 --> 00:08:25,100
假釋您設置一個應用
讓使用者上傳很多的照片

124
00:08:25,100 --> 00:08:29,380
您的目標是找出
貓的照片來給您的使用者

125
00:08:29,380 --> 00:08:31,590
也許您所有個使用者都是愛貓者

126
00:08:31,590 --> 00:08:37,180
也許您的訓練集是
從網路下載的貓的照片

127
00:08:37,180 --> 00:08:42,178
您的開發及測試集也許包括了
從我們 app 的使用者來的貓照片

128
00:08:42,178 --> 00:08:46,250
也許您的訓練集很多
來自網路爬下來的

129
00:08:46,250 --> 00:08:49,470
但是開發跟
測試集是從使用者上傳來的

130
00:08:49,470 --> 00:08:53,370
結果是很多網頁有很
高解析度專業

131
00:08:53,370 --> 00:08:55,610
很棒的貓的照片

132
00:08:55,610 --> 00:08:58,290
但或許您的使用者
上傳模糊

133
00:08:58,290 --> 00:09:03,450
低解析度影像從手機
照相或是比較休閒的狀況下

134
00:09:03,450 --> 00:09:07,960
所以這兩種分佈
的資料是不同的

135
00:09:07,960 --> 00:09:13,042
按照經驗準則是鼓勵您
在這情況下

136
00:09:13,042 --> 00:09:18,737
確定您的開發及
測試集來自相同的分佈

137
00:09:23,079 --> 00:09:26,199
我們將會談到這個
準則，但

138
00:09:26,199 --> 00:09:30,039
因為您會使用開發集來
評估很多不同的模型

139
00:09:30,039 --> 00:09:33,380
努力試著增進
在開發集的表現

140
00:09:33,380 --> 00:09:38,380
如果您的開發集跟測試集
來自同樣的分佈會很好

141
00:09:38,380 --> 00:09:43,440
但因為深度學習演算法
對訓練資料極度飢渴

142
00:09:43,440 --> 00:09:47,660
一種趨勢我看到的是您或許
使用種種創意的策略

143
00:09:47,660 --> 00:09:49,560
像是爬網路

144
00:09:49,560 --> 00:09:53,650
為了獲得比原先
更大的訓練集

145
00:09:53,650 --> 00:09:57,300
即使部分的成本會是
您的訓練集

146
00:09:57,300 --> 00:10:00,950
資料也許不是來自於
您開發及測試集同樣的分佈

147
00:10:00,950 --> 00:10:03,980
但您會發現只要您遵循這個準則

148
00:10:03,980 --> 00:10:08,600
您機器學習演算法的進度會更快

149
00:10:08,600 --> 00:10:10,750
我會給更多的解釋對於

150
00:10:10,750 --> 00:10:13,910
這種特別的準則
在往後的學程中

151
00:10:13,910 --> 00:10:18,320
最後, 也許沒有測試集是可行的

152
00:10:18,320 --> 00:10:22,289
記得測試集的目的是給您一種無偏估計

153
00:10:22,289 --> 00:10:26,995
在您最終網路的表現
您所選擇的網路

154
00:10:26,995 --> 00:10:29,315
但如果您不需要無偏估計

155
00:10:29,315 --> 00:10:32,090
那也許不需要
測試集是可行的

156
00:10:32,090 --> 00:10:35,030
如果您只有開發集
而沒有測試集您會做的是

157
00:10:35,030 --> 00:10:40,210
您在訓練集上訓練然後
您試著不同的模型架構

158
00:10:40,210 --> 00:10:44,450
在開發集評估它們
然後運用它們用循環的方式

159
00:10:44,450 --> 00:10:46,140
來試著得到好的模型

160
00:10:46,140 --> 00:10:48,020
因為您用您的開發集來配模型

161
00:10:48,020 --> 00:10:50,657
這不再能給您模型
表現的無偏估計

162
00:10:50,657 --> 00:10:53,690
但如果您不需要這個
也許完全可行

163
00:10:53,690 --> 00:10:55,950
在機器學習世界裡
當您只有訓練跟

164
00:10:55,950 --> 00:10:58,500
開發集沒有另外的測試集

165
00:10:58,500 --> 00:11:01,260
大部分的人會稱
這個為訓練集而

166
00:11:01,260 --> 00:11:04,640
稱開發集為測試集

167
00:11:04,640 --> 00:11:08,881
但其實他們是用測試集來作為

168
00:11:08,881 --> 00:11:09,902
交叉驗證集用

169
00:11:09,902 --> 00:11:13,460
也許不是好的
專業術語使用方式

170
00:11:13,460 --> 00:11:17,320
因為他們會
對測試集過適

171
00:11:17,320 --> 00:11:21,310
所以當一個團隊告訴您他們
只有訓練及測試集

172
00:11:21,310 --> 00:11:26,140
我會謹慎地想
他們真的有訓練開發集？

173
00:11:26,140 --> 00:11:28,520
因為他們會
對測試集過適

174
00:11:28,520 --> 00:11:33,348
文化上也許要改變
一些團隊的術語很難

175
00:11:33,348 --> 00:11:38,410
要他們稱之為訓練開發集
而不是訓練測試集

176
00:11:38,410 --> 00:11:40,170
即使我想稱之為訓練跟

177
00:11:40,170 --> 00:11:43,250
開發集是
比較正確的術語

178
00:11:43,250 --> 00:11:45,970
而這實際上是可行的
如果您完全不需要

179
00:11:45,970 --> 00:11:48,665
您演算法表現
的無偏估計

180
00:11:48,665 --> 00:11:53,575
所以設定好訓練, 開發, 測試集
會讓您更快循環

181
00:11:53,575 --> 00:11:57,631
也會讓您更有效地測量
變異及偏差對於您的

182
00:11:57,631 --> 00:12:02,215
演算法, 所以您可以有效地
選擇改進您演算法的方式

183
00:12:02,215 --> 00:12:04,225
我們在下一段影片
來開始談這個