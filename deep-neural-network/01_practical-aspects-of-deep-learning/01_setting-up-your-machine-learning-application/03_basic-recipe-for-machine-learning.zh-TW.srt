1
00:00:00,000 --> 00:00:01,470
在先前的影片中,在先前的影片中,

2
00:00:01,470 --> 00:00:04,778
您看到訓練誤差及開發誤差如何幫助您

3
00:00:04,778 --> 00:00:09,280
診斷是否您的演算法有偏差或是變異
或是兩者皆有的問題

4
00:00:09,280 --> 00:00:11,880
實際上這些資訊讓您比較

5
00:00:11,880 --> 00:00:15,030
有系統化的使用他們稱之為基本

6
00:00:15,030 --> 00:00:18,165
機器學習的良方，讓你更系統化

7
00:00:18,165 --> 00:00:21,510
去提高你的演算法的性能。我們來看看

8
00:00:21,510 --> 00:00:22,900
當訓練神經網路時

9
00:00:22,900 --> 00:00:24,975
這是我會使用的基本配方 

10
00:00:24,975 --> 00:00:26,920
經過訓練完一個初期的模型後

11
00:00:26,920 --> 00:00:28,185
我首先會問

12
00:00:28,185 --> 00:00:30,570
您的演算法有高的偏差嗎?

13
00:00:30,570 --> 00:00:33,709
試著評估是否有高的偏差

14
00:00:33,709 --> 00:00:35,820
您真的應該看看

15
00:00:35,820 --> 00:00:40,260
在訓練集或者說訓練資料的表現

16
00:00:40,260 --> 00:00:43,260
如果它真的有高的偏差

17
00:00:43,260 --> 00:00:45,735
甚至不是那麼配適訓練集

18
00:00:45,735 --> 00:00:49,695
您可以試著選一個網路

19
00:00:49,695 --> 00:00:52,680
加上更多的隱藏層或者隱藏單元

20
00:00:52,680 --> 00:00:54,825
或者訓練長一點的時間

21
00:00:54,825 --> 00:00:58,953
也許梯度下降跑長一點
或者更進階的最佳化演算法

22
00:00:58,953 --> 00:01:00,795
我們將在這堂課的後面談到

23
00:01:00,795 --> 00:01:03,030
或者您也可以試

24
00:01:03,030 --> 00:01:06,285
這是一種， 也許可行, 以許不可行的方法

25
00:01:06,285 --> 00:01:10,680
但我們將來會看到很多
不同的神經網路架構

26
00:01:10,680 --> 00:01:15,450
也許您可以找到一種神經網路架構
適合這個問題

27
00:01:15,450 --> 00:01:17,760
將這個放上括號, 因為一件事

28
00:01:17,760 --> 00:01:19,380
您就是要去試

29
00:01:19,380 --> 00:01:20,925
也許您可以找到, 也許找不到

30
00:01:20,925 --> 00:01:24,170
但是用大一點的網路
幾乎都會有幫助

31
00:01:24,170 --> 00:01:26,761
訓練長一點的時間
並不一定有幫助

32
00:01:26,761 --> 00:01:28,450
但也不會造成傷害

33
00:01:28,450 --> 00:01:29,793
所以當訓練一個學習演算法時

34
00:01:29,793 --> 00:01:34,100
我會試這些事情
直到至少去掉偏差問題

35
00:01:34,100 --> 00:01:39,945
回頭試試這些東西
直到我可以配適

36
00:01:39,945 --> 00:01:42,460
至少很配適訓練集

37
00:01:42,460 --> 00:01:44,760
通常如果您有足夠大的網路

38
00:01:44,760 --> 00:01:49,470
您應該可以能夠很配適這些訓練資料

39
00:01:49,470 --> 00:01:54,150
只要這個問題可解的話, 對吧?

40
00:01:54,150 --> 00:01:55,787
如果影像很模糊

41
00:01:55,787 --> 00:01:57,300
也許沒辦法來配適它

42
00:01:57,300 --> 00:01:59,531
但如果人類可以做得到

43
00:01:59,531 --> 00:02:01,540
如果您覺得基本誤差不大

44
00:02:01,540 --> 00:02:04,244
那用足夠大的網路訓練的話
您應該可以做到

45
00:02:04,244 --> 00:02:07,275
希望至少在訓練集可以做得很好

46
00:02:07,275 --> 00:02:09,970
至少配適或者過適訓練集

47
00:02:09,970 --> 00:02:14,743
一旦您減低偏差到可以接受的數字後

48
00:02:14,743 --> 00:02:17,040
就要問您有變異的問題嗎?

49
00:02:17,040 --> 00:02:21,410
要做評估的話, 我會看開發集的表現

50
00:02:21,410 --> 00:02:24,310
您可以從很棒的訓練集表現推廣

51
00:02:24,310 --> 00:02:28,595
到很棒的開發集表現嗎？

52
00:02:28,595 --> 00:02:30,915
如果您有很高的變異

53
00:02:30,915 --> 00:02:34,015
最佳解決變異問題的方法是
獲得更多資料

54
00:02:34,015 --> 00:02:35,199
如果您可以得到的話

55
00:02:35,199 --> 00:02:36,875
就會有幫助

56
00:02:36,875 --> 00:02:40,490
但有時候您無法獲得更多資料

57
00:02:40,490 --> 00:02:43,300
或者您可以試試正規化

58
00:02:43,300 --> 00:02:45,078
我們在下一段影片會談到

59
00:02:45,078 --> 00:02:46,630
試著去除過適問題

60
00:02:46,630 --> 00:02:50,930
然後再說一次
有時候您只能試試

61
00:02:50,930 --> 00:02:54,310
但如果您可以找到更合適的
神經網路架構

62
00:02:54,310 --> 00:02:57,335
有時候您可以減少您的變異問題

63
00:02:57,335 --> 00:03:00,785
就像減低偏差問題一樣
但如何做?

64
00:03:00,785 --> 00:03:04,045
要完全系統化做這個很難

65
00:03:04,045 --> 00:03:06,175
但當我試這些時
我會一直回頭

66
00:03:06,175 --> 00:03:11,785
直到希望找到可以
同時低偏差跟低變異

67
00:03:11,785 --> 00:03:14,594
那您就做到了

68
00:03:14,594 --> 00:03:16,390
要注意幾個點

69
00:03:16,390 --> 00:03:19,736
首先, 根據是否您有高偏差或者高變異

70
00:03:19,736 --> 00:03:24,405
您可以試的東西
可能非常不同

71
00:03:24,405 --> 00:03:26,860
我通常會用訓練開發集試著

72
00:03:26,860 --> 00:03:29,920
診斷是否您有偏差或者變異問題

73
00:03:29,920 --> 00:03:33,920
然後選擇適當的子集來試

74
00:03:33,920 --> 00:03:37,270
舉個例子, 如果您有高偏差問題

75
00:03:37,270 --> 00:03:40,300
獲取更多的資料其實並沒有幫助

76
00:03:40,300 --> 00:03:44,140
或者說並不是最有效的方法

77
00:03:44,140 --> 00:03:47,770
所以確認是偏差問題
或者是變異問題

78
00:03:47,770 --> 00:03:52,563
或者兩者皆是
可以幫助您專注於最有用的事情來試

79
00:03:52,563 --> 00:03:56,725
第二, 在早期機器學習時代

80
00:03:56,725 --> 00:04:02,465
曾經有很多的討論
有關於稱為偏差變異權衡

81
00:04:02,465 --> 00:04:04,604
而原因是

82
00:04:04,604 --> 00:04:06,385
對很多事情你可以試試

83
00:04:06,385 --> 00:04:09,340
您可以增加偏差跟減低變異

84
00:04:09,340 --> 00:04:11,920
或者減低偏差增加變異

85
00:04:11,920 --> 00:04:15,400
但回到深度學習前時代

86
00:04:15,400 --> 00:04:17,165
我們沒有很多工具

87
00:04:17,165 --> 00:04:19,755
我們並沒有很多工具來
只是減低

88
00:04:19,755 --> 00:04:24,380
偏差或者只是減低變異
而不影響另一個

89
00:04:24,380 --> 00:04:28,750
但在現代深度學習, 大數據時代

90
00:04:28,750 --> 00:04:31,705
只要您可以一直訓練大一點的網路

91
00:04:31,705 --> 00:04:34,200
只要您可以獲得更多資料

92
00:04:34,200 --> 00:04:36,360
並不總是可以辦到

93
00:04:36,360 --> 00:04:37,950
但如果可以做到

94
00:04:37,950 --> 00:04:40,590
那用大ㄧ點的網路幾乎總是可以

95
00:04:40,590 --> 00:04:43,625
只減低您的偏差
並不一定傷害您的變異

96
00:04:43,625 --> 00:04:46,157
只要您適當的正規化

97
00:04:46,157 --> 00:04:48,810
而獲得更多的資料通常總是

98
00:04:48,810 --> 00:04:52,370
減低您的變異
而不會傷害您的偏差

99
00:04:52,370 --> 00:04:54,195
真正發生的是

100
00:04:54,195 --> 00:04:55,845
使用這兩個步驟

101
00:04:55,845 --> 00:04:57,405
能夠去訓練, 選擇一個網路

102
00:04:57,405 --> 00:04:58,560
或者獲取更多資料

103
00:04:58,560 --> 00:05:03,375
我們現在有工具來減低偏差
且只減低偏差

104
00:05:03,375 --> 00:05:05,700
或者減低變異且只減低變異

105
00:05:05,700 --> 00:05:09,655
而不會傷害其他的東西

106
00:05:09,655 --> 00:05:12,240
我想這是一個很大的原因

107
00:05:12,240 --> 00:05:16,348
深度學習對於監督式學習如此有用

108
00:05:16,348 --> 00:05:18,840
當然或多或少這種權衡
您

109
00:05:18,840 --> 00:05:21,345
必須仔細去平衡偏差跟變異

110
00:05:21,345 --> 00:05:25,053
但有時候您就是有比較多的選項
來減低偏差

111
00:05:25,053 --> 00:05:30,315
或者減低變異
而不一定增加另外一項

112
00:05:30,315 --> 00:05:33,698
實際上只要您有好的正規化網路

113
00:05:33,698 --> 00:05:36,795
我們會在下一段影片談到正規化

114
00:05:36,795 --> 00:05:40,110
訓練大一點的網路
幾乎永遠不會有壞事

115
00:05:40,110 --> 00:05:44,634
而主要的成本來訓練太大的神經網路
只是運算時間

116
00:05:44,634 --> 00:05:46,490
只要您做了正規化

117
00:05:46,490 --> 00:05:49,440
我希望這給您一點基本架構的感覺
如何

118
00:05:49,440 --> 00:05:53,255
組織您的機器學習問題
去診斷偏差及變異

119
00:05:53,255 --> 00:05:57,325
然後試著選擇正確的動作
來讓您的問題有所進展

120
00:05:57,325 --> 00:06:01,367
我在這段影片一直提到正規化這件事

121
00:06:01,367 --> 00:06:03,825
是非常有用的技巧來減低變異

122
00:06:03,825 --> 00:06:07,130
這裡有一點點偏差變異權衡
當您使用正規化

123
00:06:07,130 --> 00:06:09,045
它也許會增加一點點偏差

124
00:06:09,045 --> 00:06:13,090
雖然通常不會太大
如果您有足夠大的網路

125
00:06:13,090 --> 00:06:16,735
但讓我們在下一段影片深入探討這些細節
所以您可以

126
00:06:16,735 --> 00:06:21,000
比較了解如何應用正規化到您的神經網路