딥러닝에서 현실적인 부분들에 대한 강의에 오신 것을 환영합니다. 아마 지금쯤이면 신경망을 구현하는 것을 배우셨을 것입니다. 이번 주에는 어떻게 우리의 신경망이 잘 동작하게 할 수 있는지 현실적인 문제들을 배울 것입니다. 하이퍼파라메터를 튜닝부터 데이터를 준비하는 것까지 다루면서, 자신감을 가지고 최적화 알고리즘을 빠르게 실행 시켜보고 학습 알고리즘이 적정한 시간내에 학습이 될 수 있게 해봅니다. 이번 첫째 주에는 신경망을 만드는 것에 대해 알아보고 레귤라-라이제이션(regularization,정규화)에 대해 알아보고 또, 말해 볼 것은 몇가지 트릭들로 신경망 구현이 제대로 되었는지
확인하는 방법을 알아보겠습니다. 그렇게 할텐데, 시작해 봅니다. 학습셋, 개발셋과 테스트셋을 설정 방법을 잘 선택하면, 이것이 좋은 성능의 신경망을 빨리 찾는데 큰 도움을 줄 수 있습니다. 신경망 훈련에는 결정해야될 많은 것들이 있지요. 몇개의 레이어로 할지, 각 레이어에 히든유닛(hidden unit)은 몇개로 할지, 러닝레이트(learning rate)은 얼마로 하고, 서로 다른 레이어에는 활성화 함수는 어떤 것으로 할지. 처음 새로 응용을 시작할 때는 이러한 것들이나 다른 하이퍼파라메터들 선택에 적당한 값들을 옳게 짐작하기가 거의 불가능합니다. 그래서, 실제는 기계학습 응용은 매우 반복적인 과정인데, 한번 어떤 아이디어를 갖고 시작해 보면, 예를들어, 레이어는 몇개 정도로 하고, 히든 유닛은 몇개로,
또 어떤 데이터셋들에다가 등등. 그리고 나서, 코딩을 해보고,
그 코드를 돌려보고. 그렇게 동작 시켜 실험해 보면
결과로 알 수 있는데 이 신경망이 얼마나 좋은지,
이 설정이 효과는 있는지. 그렇게, 결과를 바탕으로 아이디어를 개선해 볼 수도 있고
선택들을 바꿔보고 계속 이 과정을 반복하면서, 점점 더 나은 신경망을 찾아 볼 수 있습니다. 요새 딥러닝은 많은 분야에서 큰 성공을 거두었습니다. 자연어처리,컴퓨터비젼,음성인식, 많은 응용분야들과 
구조화된 데이터들까지도 해결합니다. 또, 구조화된 데이터로는 광고, 웹검색, 그냥 인터넷 검색 엔진 뿐만아니라, 쇼핑 웹사이트 까지. 이미 어떤 웹사이트들은
검색바에 입력하면 더 나은 것을 찾아 보여주려고 합니다. 컴퓨터 보안, 물류 등
예를 들어 운전자를
어디로 보내야 할지를 알아내고 물건을 더 많이
떨어뜨릴 수 있는 방법등 입니다. 그래서 내가 보고 있는 것은 때때로
NLP에서 많은 경험을 가진 연구자가 컴퓨터 비전에서 뭔가를 
시도할 수도 있다는 것입니다. 또는 음성 인식에
경험이 많은 연구자가 광고에 대해 뭔가 
시도할 수도 있습니다. 또는 보안 담당자가 물류에 대해
뭔가를 하고 싶어 할 수도 있습니다. 제가 본 것은 하나의 영역이나
한 응용 영역에서의 직관은 종종 다른 응용 영역으로
이전하지 않는 것입니다. 그리고 최고의 선택은
당신이 가진 데이터의 양, 컴퓨터 구성을 통해
얻은 입력 기능의 수, GPU나 CPU를 사용해
학습하고 있는지에 달려 있습니다. GPU와 CPU의 구성과 그 밖의
 많은 것들이 정확히 어떻게
구성되는지 알아 봅시다. 많은 응용 프로그램에서
나는 그것이 거의
불가능하다고 생각합니다. 경험 많은 딥러닝 학습자들조차도
초보 매개 변수를 가장 잘 선택하는 것은
거의 불가능합니다. 그래서 오늘날 적용된 딥러닝은
매우 반복적인 과정으로 여러 번 반복해서 실행해 보면 응용 프로그램을 위한 좋은
네트워크를 찾을 수 있습니다. 따라서 당신이 얼마나 빨리
발전할 수 있는지를
결정하는 것 중 하나는 당신이 이 순환을 얼마나
효율적으로 할 수 있느냐입니다. 그리고 데이터를 훈련, 개발,
시험 세트로 잘 설정하면 훨씬 더 효율적으로 만들 수 있습니다. 그럼, 이것이 우리 학습 데이터라고 합시다. 
큰 네모 박스로 그려보죠. 자, 옛날에는 그 일부분을 당신의 훈련
세트로 분리할 수 있습니다. 일부분은 상호 검증셋(croos validation set)으로 잡아주고, 이것은 가끔 개발셋(development set)이라고 하고, 저는 개발셋을 줄여서 데브셋(dev set)이라고 부를게요. 모두 대충 같은 뜻으로 씁니다. 마지막 부분은 잘라서 테스트 셋으로 만들고요. 그래서 워크플로우는 학습 세트에서
계속 학습 알고리즘을 사용하게 됩니다. 그리고 당신의 개발 세트 또는
교차 검증 세트를 사용하여 많은 다른 모델 중 어떤 모델이
개발 세트에서 가장 잘
수행되는지 확인합니다. 이렇게 충분히 오래 돌려보고 나서 당신이 평가하고 싶은
최종 모델이 있을 때, 가장 좋은 모델이 찾아졌다 싶으면,
이제 테스트 셋을 가지고 평가해 봅니다. 우리 알고리즘이 얼마나 좋은지
공정한 평가를 해보는 것이죠. 그래서, 기계학습이 예전에는 일반적으로 데이터 전체를 70%,30%로 나누곤 했는데, 70대 30의 훈련셋과 테스트셋을
쓴다고 말했습니다. 개발셋(dev set)도 있다면,
60/20/20%로 나눴다고 할 때, 60% 훈련셋, 20% 데브셋, 20% 테스트셋을 뜻하죠. 몇년전만 해도 기계학습에서 이게 널리 통용된 좋은 실전 사례입니다. 전체 100개의 샘플이 있다고 하면, 또는 전부 천개의 샘플이 있다면 ,
또는 만개의 샘플이 있다면, 이 비율로 셋을 나누는 것은
아주 완벽하고 합리적인 최고의 룰입니다. 그런데, 최근 빅 데이터 세상에서는
예를 들면 전체 백만개 샘플이 있다고 하면,
요즘 추세는 개발셋(dev set)과 테스트셋은
전체의 매우 작은 퍼센트로 합니다. 기억하시겠지만,
데브셋 또는 개발셋의 목적은 다른 알고리즘들을 시험해 보고
어떤게 더 좋은지 알아내려는 것이니까, 개발셋은 단지 평가하기에 충분히 많으면 됩니다. 2개의 다른 알고리즘에서 선택하거나 열개의 알고리즘에서 선택하거나 할 때
어떤 것이 더 좋은지 빨리 결정하는데 전체 데이터의 20%나 필요하지는 않습니다. 그래서, 백만개의 훈련 샘플이 있다면, 개발셋은 그냥 만개면 충분하고, 한,두개 알고리즘이 더 나은지 평가할 수 있습니다. 비슷한 맥락에서, 당신의
테스트 세트의 주요 목표는
최종 분류자를 고려할 때 그것이 얼마나 잘하고 있는지에
대한 추정치 제공하는 것입니다. 마찬가지로, 백만 개의 예시가 있으면, 싱글 classifier를 평가하는데 만개의 
예시가 충분하다고 결정할 수 있습니다. 얼마나 잘 성능을 발휘하는지 꽤 정확한 추정 수치를 제공하는데 말이죠. 이번 사례에서처럼 백만 개의 예시가 있는 경우, dev를 위한 만개의 예시, 테스트를 위한 만개의 예시이면
충분합니다. 이 경우, 비율은 1퍼센트가 되기 때문에, 98퍼센트 트레이닝, 1퍼센트 dev, 나머지 1퍼센트가 테스트가 되겠습니다. 또한 저는 이미 예시가 백만 개를 초과하는 경우의 어플을 
많이 봐왔는데요, 99.5퍼센트 트레이닝, 0.25퍼센트 dev, 0.25퍼센트 테스트 예시인 경우도 봤고, 99.5퍼센트 트레이닝, 0.4퍼센트 dev, 0.1퍼센트 테스트인 경우도 봤습니다. 복습하자면, 머신러닝 문제를 세팅하는 경우, 저는 보통 트레이닝, dev, 테스트 세트 이런 식으로
세팅을 할 텐데요, 꽤 작은 데이터세트를 보유하고 있다면
이런 전통적인 비율이 괜찮을 것입니다. 하지만 훨씬 더 큰 데이터세트를 보유하고 있으면, 
dev와 테스트 세트를 더 작은 비율로 하는 것도 괜찮습니다. 총 데이터의 20퍼센트 또는 10퍼센트
내의 비율로 말이죠. dev나 테스트 세트의 자세한 가이드라인에 대해서는 이후에 설명 드리도록 하겠습니다. 근래 딥러닝 분야에서의 또 다른 트렌드는 더욱 더 많은 사람들이 불일치한 트레인과 테스트 분포에서 
트레이닝을 하는 것입니다. 예를 들어, 유저들이 사진을 업로드 하는 어플에서 목표는 유저들에게 보여줄 수 있도록 고양이의 사진을
색출해내는 것이라고 가정하 보죠, 아마도 모든 유저가 고양이를 좋아할 수도 있겠죠. 트레이닝 세트가 인터넷에서 다운받은 
고양이 이미지로 이루어진 데이터일수도 있습니다. 하지만 dev나 테스트 세트는 유저들이 올린 사진을
포함할 수 있습니다. 그러므로 트레이닝 세트는 인터넷에서 찾은 여러 가지
사진으로 구성될 수 있지만 테스트 세트는 유저가 올린 사진일 수 있겠죠. 알고 보니, 많은 수의 웹페이지는
고화질의 프로페셔널한 고프레임의 고양이 사진이 많았습니다. 반면에 유저들이 업로드 하는 사진은
흐릿하고, 화질이 좋지 않거나, 핸드폰으로 캐쥬얼하게 찍은
사진일 수 있겠죠. 그렇기 때문에 데이터의 분포도가 전혀 다를 수 있습니다. 이런 경우, 저는 경험을 근거로 하는 규칙을
권장드립니다. dev와 테스트 세트가 똑같은 분포도에서 오게끔 말이죠. 상세한 가이드라인은 나중에 언급하겠습니다만, dev set를 이용하여 다양한 모델들을 평가하고 동시에 dev set를 개선하려고 할 것이기 때문에 dev set가 테스트 세트와 같은 분포도에서 오는 것이 좋습니다. 딥러닝 알고리즘은 데이터를 트레이닝 하고 싶어하기 때문에 모든 다양한 수단과 전술을 이용해서, crawling webpage와 같은 방법을 동원하여, 훨씬 더 큰 트레이닝 세트를 구축할 수 있습니다. 이것에 따른 대가가 트레이닝세트 데이터들이 dev와 테스트 세트와는 
다른 분포도를 갖는 것일 수 있지만, 이 경험에 근거한 규칙을 따르면, 여러분의 러닝 알고리즘이 더욱 빠르게 발달할 수 있을 것입니다. 이 경험을 바탕으로 한 규칙에 대해서는 나중에 더 자세히 설명해 드리겠습니다. 마지막으로, 테스트 세트가 없는 게 괜찮을 수도 있습니다. 기억하시겠지만, 테스트 세트의 목표는 여러분의 선택한 마지막 네트워크에 대해서
바이어스 없는 성능 추정치를 제공하는 것입니다. 만약 여러분이 바이어스 없는 추정치가 필요치 
않을 경우, 테스트 세트가 없어도 괜찮을 것 입니다. 여러분이 dev set는 있고 테스트 세트는 없는 경우, 트레이닝 세트에서 트레이닝을 진행하고, 
다른 모델 구조를 시도해보는 것입니다. dev set에서 평가하고, 이를 이용해 
반복 업무를 통해 가장 좋은 모델을 찾습니다. 데이터를 dev set에 피팅했기 때문에 이제 더 이상 성능에 대한 바이어스 없는 추정치를 주지 않습니다. 만약 필요 없을 시, 굳이 없으셔도 무방합니다. 머신러닝 세계에서는
트레인과 dev set만 있고 별도의 테스트 세트가 없을 시, 대부분의 사람들은 이것을
트레이닝 세트라고 부르고, dev set를 테스트 세트라고 부를 것입니다. 실제로 그렇게 한 다음, 테스트 세트를 
hold-out cross validation set로 이용하는 것이죠, 표현하기 편한 용어는 아니지만 그렇게 해서 사람들은 테스트 세트에 오버피팅 시킵니다. 팀들이 만약 트레인과 테스트 세트만 있다고 하면 조심스럽게 생각할 것입니다.
그들은 진짜로 트레인 dev set가 있는 것인가? 테스트 세트에 오버피팅하니까 말이죠. 문화적으로 이 팀들이 쓰는 용어는 바꾸기 어려울 수도 있습니다. ‘trained test set’ 대신 ‘trained dev set’라고 바꾸는 것 말이죠. 물론 제가 생각하기에는 train and development set라고 부르는 게 더 정확한 용어라고 생각하지만요. 만약 바이어스 없는 알고리즘의 성능 추정치가 필요 없는 경우엔, 이렇게 해도 상관없습니다. train dev와 테스트 세트를 세팅하면서
더 빨리 통합시킬 수 있도록 할 것입니다. 알고리즘의 바이어스와 편차를 더 효율적으로 계산하고, 알고리즘을 더 효율적으로 개선할 수 있게
될 것입니다. 이런 내용을 다음 비디오에서 이야기해보죠.