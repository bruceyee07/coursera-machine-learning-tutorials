1
00:00:00,000 --> 00:00:03,600
我注意到幾乎所有很棒的機器學習

2
00:00:03,600 --> 00:00:07,890
達人往往是很精於理解偏差跟變異

3
00:00:07,890 --> 00:00:12,330
偏差跟變異是一種很容易學習但很難駕馭的概念

4
00:00:12,330 --> 00:00:16,155
即使您想您已經看了偏差及變異的基本概念

5
00:00:16,155 --> 00:00:18,805
還會有一些新的您意想不到的概念出現

6
00:00:18,805 --> 00:00:20,620
在深度學習時代

7
00:00:20,620 --> 00:00:22,650
另一種趨勢比較

8
00:00:22,650 --> 00:00:26,035
少討論到的是稱為偏差變異權衡

9
00:00:26,035 --> 00:00:28,657
您或許聽過偏差變異權衡

10
00:00:28,657 --> 00:00:31,330
但在深度學習時代比較少權衡

11
00:00:31,330 --> 00:00:32,520
所以我們還是解決偏差

12
00:00:32,520 --> 00:00:33,865
還是解決變異

13
00:00:33,865 --> 00:00:37,295
但我們比較少有關偏差變異權衡

14
00:00:37,295 --> 00:00:39,795
我們來看這是什麼意思

15
00:00:39,795 --> 00:00:42,750
我們看一個資料集像這樣

16
00:00:42,750 --> 00:00:44,800
如果您用一條直線來配合這些資料

17
00:00:44,800 --> 00:00:48,130
也許用羅吉斯迴歸分析來配合它

18
00:00:48,130 --> 00:00:50,415
這不是很配這些資料

19
00:00:50,415 --> 00:00:52,380
所以這是一種高偏差的類別

20
00:00:52,380 --> 00:00:56,400
我們說這個模型低適這些資料

21
00:00:56,400 --> 00:00:57,850
相反地

22
00:00:57,850 --> 00:01:00,645
如果您用極度複雜的分類器

23
00:01:00,645 --> 00:01:02,640
也許深度神經網路

24
00:01:02,640 --> 00:01:05,995
或者神經網路用很多的隱藏單元

25
00:01:05,995 --> 00:01:10,255
也許您可以完美的配合這些資料

26
00:01:10,255 --> 00:01:12,220
但這看起來也不像是好的配適

27
00:01:12,220 --> 00:01:17,535
這是一種高變異的分類器而這樣會過適這些資料

28
00:01:17,535 --> 00:01:19,650
而也許有一些分類器介於其中

29
00:01:19,650 --> 00:01:22,070
有中度的複雜性

30
00:01:22,070 --> 00:01:24,585
也許是一條曲線像這樣

31
00:01:24,585 --> 00:01:27,300
看起來更合理的配適這些資料

32
00:01:27,300 --> 00:01:31,705
我們稱它為剛剛好，它是介於中間

33
00:01:31,705 --> 00:01:34,260
所以在 2D 的例子像這樣

34
00:01:34,260 --> 00:01:35,610
只有兩個特徵

35
00:01:35,610 --> 00:01:39,700
X-1 跟 X-2 您可以畫這些資料來視覺化它們的偏差及變異

36
00:01:39,700 --> 00:01:41,250
在高維度的問題中

37
00:01:41,250 --> 00:01:44,735
您不能畫這些資料來視覺化這些邊界

38
00:01:44,735 --> 00:01:46,830
取而代之, 有一些不同的量測

39
00:01:46,830 --> 00:01:49,750
我們用來試著理解偏差及變異

40
00:01:49,750 --> 00:01:51,960
繼續我們的貓圖片辨識例子

41
00:01:51,960 --> 00:01:57,600
這是一個正面的例子，這是一個負面的例子

42
00:01:57,600 --> 00:02:01,455
兩個重要的數字來理解偏差跟變異會是

43
00:02:01,455 --> 00:02:06,415
訓練集誤差及開發集誤差

44
00:02:06,415 --> 00:02:07,716
為了便於討論

45
00:02:07,716 --> 00:02:10,290
假設您能夠辨識貓的相片

46
00:02:10,290 --> 00:02:13,860
這是一般人都可以完全做到的, 對吧?

47
00:02:13,860 --> 00:02:22,155
假設說您的訓練集誤差是 1%, 而您的開發集誤差

48
00:02:22,155 --> 00:02:23,580
為了便於討論

49
00:02:23,580 --> 00:02:25,585
假設說是 11%

50
00:02:25,585 --> 00:02:26,730
在這個例子中

51
00:02:26,730 --> 00:02:29,495
您在訓練集做得很好

52
00:02:29,495 --> 00:02:34,355
但您在開發集就相對做得比較差

53
00:02:34,355 --> 00:02:38,215
看起來您也許過適於訓練集

54
00:02:38,215 --> 00:02:40,620
或許您沒能一般化得很好

55
00:02:40,620 --> 00:02:43,815
到整個交叉驗證集, 也就是開發集

56
00:02:43,815 --> 00:02:46,440
所以如果您有這樣的例子

57
00:02:46,440 --> 00:02:50,785
我們會說這個有高的變異

58
00:02:50,785 --> 00:02:54,240
所以看著訓練集誤差跟開發集誤差

59
00:02:54,240 --> 00:02:59,730
您能夠診斷您的演算法有高的變異

60
00:02:59,730 --> 00:03:04,435
假設您測量您的訓練集誤差跟開發集誤差

61
00:03:04,435 --> 00:03:06,095
而得到不同的結果

62
00:03:06,095 --> 00:03:09,610
假設您的訓練集誤差是 15%

63
00:03:09,610 --> 00:03:12,375
我將訓練集誤差寫在上面的列上

64
00:03:12,375 --> 00:03:15,880
而您的開發集誤差是 16%

65
00:03:15,880 --> 00:03:22,870
在這個狀況下, 假設人類大致能達到 0% 誤差

66
00:03:22,870 --> 00:03:27,451
人類可以看看這些照片，直接判斷是不是貓

67
00:03:27,451 --> 00:03:31,600
然後看到這個演算法甚至在
訓練集做得不是很好

68
00:03:31,600 --> 00:03:35,380
所以如果甚至在訓練集
對資料配合得不是很好

69
00:03:35,380 --> 00:03:38,220
那這是低適於這些資料

70
00:03:38,220 --> 00:03:40,895
所以這個演算法有高的偏差

71
00:03:40,895 --> 00:03:45,390
但相反的, 這個實際上
在開發集上一般化得很好

72
00:03:45,390 --> 00:03:49,365
它在開發集的表現只有
比在訓練集差一個百分點

73
00:03:49,365 --> 00:03:52,355
所以這個演算法有高偏差的問題

74
00:03:52,355 --> 00:03:56,325
因為它甚至不配適在訓練集上

75
00:03:56,325 --> 00:04:01,030
這是相當類似於我們
前一張投影片的最左邊

76
00:04:01,030 --> 00:04:03,329
現在, 有另一個例子

77
00:04:03,329 --> 00:04:06,430
假設您有 15% 的訓練集誤差

78
00:04:06,430 --> 00:04:08,127
所以這是很高的偏差

79
00:04:08,127 --> 00:04:11,446
但當您衡量開發集時, 情況更糟

80
00:04:11,446 --> 00:04:13,450
也許是 30%

81
00:04:13,450 --> 00:04:18,175
在這種情況下，我會診斷該演算法具有高的偏差

82
00:04:18,175 --> 00:04:23,780
因為在訓練集做得不是很好, 而且有高的變異

83
00:04:23,780 --> 00:04:27,950
所以這真的是兩個世界裡最差的狀況

84
00:04:27,950 --> 00:04:29,325
最後一個例子

85
00:04:29,325 --> 00:04:32,605
如果您有 0.5% 訓練集誤差

86
00:04:32,605 --> 00:04:35,145
跟 1% 開發集誤差

87
00:04:35,145 --> 00:04:37,130
也許我們的使用者很高興

88
00:04:37,130 --> 00:04:39,850
您有一個貓咪分類器只有 1% 誤差

89
00:04:39,850 --> 00:04:44,340
我們同時有低的偏差及低的變異

90
00:04:44,340 --> 00:04:47,610
一個細微之處，我只簡要地提及

91
00:04:47,610 --> 00:04:50,955
我們會留到以後的影片
再來詳細討論

92
00:04:50,955 --> 00:04:54,188
這種分析是基於假設

93
00:04:54,188 --> 00:04:59,115
人類幾乎可以達到 0% 誤差

94
00:04:59,115 --> 00:05:01,749
或更一般來講, 最佳誤差

95
00:05:01,749 --> 00:05:04,225
有時候也稱為基本誤差

96
00:05:04,225 --> 00:05:10,355
所以最佳誤差將近 0%

97
00:05:10,355 --> 00:05:13,565
我在這段影片
不想深入探討這個

98
00:05:13,565 --> 00:05:18,070
但實際上最佳誤差或是
基本誤差高很多

99
00:05:18,070 --> 00:05:22,360
假設說是 15%, 那當您看這個分類器

100
00:05:22,360 --> 00:05:25,460
15% 實際上是很合理的在訓練集上

101
00:05:25,460 --> 00:05:30,120
就不會當它是高的偏差同時變異也很低

102
00:05:30,120 --> 00:05:33,440
所以如何分析偏差跟變異

103
00:05:33,440 --> 00:05:37,460
當沒有分類器可以做得很好時， 舉個例子

104
00:05:37,460 --> 00:05:40,833
如果您有很模糊的照片

105
00:05:40,833 --> 00:05:46,081
即使人類或者
沒有一個系統可以做得很好時

106
00:05:46,081 --> 00:05:49,237
也許基本誤差高很多

107
00:05:49,237 --> 00:05:52,295
這時一些細節對於
如何做分析也會改變

108
00:05:52,295 --> 00:05:54,725
但除此細節之外

109
00:05:54,725 --> 00:05:57,430
重點是看著

110
00:05:57,430 --> 00:06:02,676
您的訓練集誤差會讓您感覺到
資料配適做得如何

111
00:06:02,676 --> 00:06:04,331
至少在訓練集上

112
00:06:04,331 --> 00:06:06,770
所以可以告訴您是否有偏差的問題

113
00:06:06,770 --> 00:06:10,190
然後看著您的誤差有多高

114
00:06:10,190 --> 00:06:12,965
當您從訓練集到開發集時

115
00:06:12,965 --> 00:06:17,055
這應該會給您一些感覺
有關變異問題有多糟

116
00:06:17,055 --> 00:06:20,857
所以您從訓練集一般化到
開發集時做得好不好

117
00:06:20,857 --> 00:06:22,645
給您一些有關
變異的感覺

118
00:06:22,645 --> 00:06:26,210
所有這些都基於一個假設
就是基本誤差是相當

119
00:06:26,210 --> 00:06:30,235
小的而且您的訓練集跟您的開發集
都是從同一分佈抽樣出來的

120
00:06:30,235 --> 00:06:32,210
如果違反這些假設

121
00:06:32,210 --> 00:06:34,323
您可以有一些更複雜的分析

122
00:06:34,323 --> 00:06:36,510
我們會在以後影片中談到

123
00:06:36,510 --> 00:06:38,780
在前面的投影片中

124
00:06:38,780 --> 00:06:40,849
您看到高偏差, 

125
00:06:40,849 --> 00:06:42,185
高變異的樣子

126
00:06:42,185 --> 00:06:44,920
我猜您對於一個
好的分類器有一些感覺

127
00:06:44,920 --> 00:06:48,110
同時高偏差跟高變異的樣子如何?

128
00:06:48,110 --> 00:06:50,535
這是一種兩個世界裡
最糟的狀況

129
00:06:50,535 --> 00:06:53,415
您記得, 我們說一個分類器像這樣

130
00:06:53,415 --> 00:06:55,755
那您的分類器有高的偏差

131
00:06:55,755 --> 00:06:58,185
因為它低適了這些資料

132
00:06:58,185 --> 00:07:04,030
這會是一種將近線性的分類器
所以低適了這些資料

133
00:07:04,030 --> 00:07:05,570
我們用紫色來畫

134
00:07:05,570 --> 00:07:09,546
如果您的分類器做很奇怪的事

135
00:07:09,546 --> 00:07:14,460
那這也其實過適了這些資料

136
00:07:14,460 --> 00:07:16,500
所以我用紫色畫的

137
00:07:16,500 --> 00:07:19,455
有高偏差同時也有高變異

138
00:07:19,455 --> 00:07:21,300
有高的偏差因為

139
00:07:21,300 --> 00:07:23,325
將近是一個線性分類器

140
00:07:23,325 --> 00:07:24,875
並不是很配適這些資料

141
00:07:24,875 --> 00:07:28,466
像是這個二次曲線的形狀

142
00:07:28,466 --> 00:07:31,200
但有著相當彈性在中間

143
00:07:31,200 --> 00:07:32,995
它為了包含這個例子

144
00:07:32,995 --> 00:07:36,720
跟這個例子, 過適於這兩個例子

145
00:07:36,720 --> 00:07:40,515
所以這個分類器有高的偏差
因為它幾乎是線性的

146
00:07:40,515 --> 00:07:43,620
您需要的也許是
曲線函數或者二次函數

147
00:07:43,620 --> 00:07:45,115
而那也有高的變異

148
00:07:45,115 --> 00:07:49,595
因為它太彈性的
去配適這兩個誤標的例子

149
00:07:49,595 --> 00:07:52,475
或者在中間的異常值

150
00:07:52,475 --> 00:07:54,300
如果這看起來很做作

151
00:07:54,300 --> 00:07:57,585
這個例子是有點做作
在二度空間

152
00:07:57,585 --> 00:07:59,883
但在高維度的輸入時

153
00:07:59,883 --> 00:08:01,795
您實際上會得到

154
00:08:01,795 --> 00:08:04,800
高偏差在一些區域裡
跟高變異在一些區域裡

155
00:08:04,800 --> 00:08:07,410
所以這樣的分類器是可能的

156
00:08:07,410 --> 00:08:11,415
在高維度輸入時
似乎會比較不做作

157
00:08:11,415 --> 00:08:15,690
總結一下, 您看到了
如何看待您演算法的誤差在

158
00:08:15,690 --> 00:08:20,550
訓練集上跟演算法誤差在開發集上

159
00:08:20,550 --> 00:08:23,413
診斷是否有高偏差或高變異的問題

160
00:08:23,413 --> 00:08:25,420
也許同時有，或者同時沒有

161
00:08:25,420 --> 00:08:28,995
依據是否您的演算法
承受著偏差或者變異

162
00:08:28,995 --> 00:08:31,765
實際上有不同的方式
來試著解決

163
00:08:31,765 --> 00:08:33,840
在下一段影片， 我們將談到

164
00:08:33,840 --> 00:08:37,390
所謂的機器學習的基本食譜

165
00:08:37,390 --> 00:08:40,905
讓您有系統化地
改進您的演算法

166
00:08:40,905 --> 00:08:44,370
依據是否有高偏差
或者高變異問題

167
00:08:44,370 --> 00:08:46,110
讓我們進入下一段影片