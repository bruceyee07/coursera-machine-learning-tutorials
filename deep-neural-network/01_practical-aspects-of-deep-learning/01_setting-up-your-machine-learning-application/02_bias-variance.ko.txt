제가 느낀 바로는 거의 모든 머신러닝 분야 종사자들은 편향과 편차에 대한 이해도가 매우 뛰어난 편입니다. 편향과 편차의 컨셉은 사실 배우기 굉장히 쉬운 것이지만 마스터하기가 어려운 내용입니다. 편향과 편차의 기본 컨셉을 보셨다고 하더라도, 항상 여러분이 예상하지 못했던 새로운 부분이 있습니다. 딥러닝 오류에서는, 또 하나의 트렌드는, 편향과 편차의 균형에 대한 토론은 줄었다는 것입니다. 여러분은 편향-편차-균형이라는 말을 들어보셨을텐데요, 딥러닝에서는 요즘 편향, 평균 편차에 대한 내용은 줄어들었습니다. 물론 아직 편향에 대한 문제도 해결하고, 편차에 대한 문제도 해결합니다. 그냥 단순히, 2개의 균형에 대한 내용을 덜 다룬다는 것입니다. 이것이 무슨 뜻인지 알아보겠습니다. 이게 뭘 의미하는지 보시죠. 이렇게 생긴 데이터 세트를 보겠습니다. 이렇게 생긴 일직선에 데이터를 넣으면, 로지스틱 회귀모영으로 데이터를 피팅시킬 수 있겠습니다. 이것은 데이터가 잘 피팅되지 않은 경우인데요, 큰 편향을 초래합니다. 이것은 데이터를 underfitting한다고도 하는데요, 반대로, 아주 복잡한 분류기를 피팅시키면, 예를 들어, 심층신경망 같은 것을 말이죠, 또는 숨겨진 유닛을 가진 신경망을요, 그런 경우에는 데이터를 거의 완벽히 피팅 시킬 수 있습니다. 그런데 여기 보이는 것은 그렇게 fit이 좋지도 않죠. 큰 편차를 가지고 있는 케이스로 데이터를 overfitting 한다고 할 수 있겠습니다. 가운데에 classifier가 있을 수도 있습니다. 중간 정도레벨의 복잡성(complexity)를 가지고 있는 것이요. 그래서 이렇게 잘 피팅될 수 있겠죠. 이것이 조금 더 데이터의 합리적인 fit이라고 볼 수 있겠죠. 이것이 딱 맞다고 표현하는데요. 가운데 정도로요. 이러한 2차원의 예제에서, 2가지의 특성을 갖고, X-1 그리고 X-2 와 같은 특성이죠. 데이터를 그리고 편향과 편차를 시각화시킬 수 있는 것입니다. 고차원의 문제에서는, 데이터를 그려서 이렇게 시각화하고 바운더리를 찾기가 불가능합니다. 대신에, 몇가지 다른 매트릭이 있기는 한데요. 이런 매트릭을 봐서 편향과 편차에대해 이해해보도록 하겠습니다. 고양이 이미지를 분류하여 세는 알고리즘 예제를 이어서 이야기해보겠습니다. 이 예제는 positive example 과 negative emaple을 동시에 갖추고 있습니다. 편향과 편차에 대해서 이해하기 위한 2가지 핵심 수치는 바로 train set 오류와 dev set 도는 development 세트 오류입니다. 의논을 하기 위한 목적으로, 여기 보이는 고양이 이미지롤 인식하고 있다고 해봅시다. 이것은 일반 사람이면 거의 완벽히 맞출 수 있겠죠? 그러면 training 오류가 1퍼센트이로 dev set 오류가 역시 마찬가지로 의논 목적을 위해, 11퍼센트라고 가정해봅시다. 이 예제에서는 그러면 트레이닝세트에서는 아주 잘 작동하고, development set에서는 아주 못하는 것으로 볼 수 있죠. 그러면 트레이닝세트를 overfit했다고 볼 수 있습니다. 무슨 이유에서는 잘 일반화시키지 못하고 있는 것이죠. 여기 development set에 있는 cross-validation set 에 전체적으로 말이죠. 그러면 여기 예제에서 보면, 이것은 큰 편차를 갖고 있다고 할 수 있습니다. 그러면 트레이닝 세트 오류과 development set오류를 보면서, 편차가 큰 알고리즘을 진단할 수 있습니다. 예를 들어 트레이닝 세트와 dev set 오류를 측정한다고 합시다. 그랬는데 다른 결과가 나왔다고 해봅시다. 트레이닝 세트가 15퍼센트가 나왔다고 해보죠. 여러분이 트레이닝 세트 오류를 가장 윗줄에 적겠습니다. 그리고 dev set 오류는 16퍼센트입니다. 이 경우, 인간이 거의 0퍼센트의 오류수치라고 하면, 즉, 인간은 이 사진을 보고 고양이인지 아닌지를 분류할 수 있는 것입니다. 그러면 알고리즘이 트레이닝세트에서 마저도 잘 못하는 것으로 보여집니다. 만약 트레이닝 데이터에도 잘 피팅되지 않는 경우라면, 이것은 데이터를 underfitting 하는 것입니다. 그럼 이 알고리즘은 큰 편향을 갖는 것입니다. 이것은 dev set에 비교적 괜찮게 일반화되고 있는 반면에 dev set의 성능은 트레이닝 세트대비 1퍼센트 못하고 있습니다. 그렇기 때문에 이 알고리즘은 큰 편향의 문제가 생깁니다. 트레이닝세트에 피팅도 잘 안되고 있기 때문이죠. 이전 슬라이드에서 봤던 가장 왼쪽 plot과 비슷합니다. 다른 예제가 1개 더 있습니다. 트레이닝 세트가 15퍼센트라고 해봅시다. 그러면 편향이 꽤 큰 편인데요. dev set에서 평가하면 훨씬 더 좋지 않습니다. 30퍼센트라고 해보겠습니다. 이 경우, 이 알고리즘은 큰 편향을 갖고 있다고 진단할 것입니다. 트레이닝 세트에서 작 작동하지 않고, 큰 편차를 갖기 때문이죠. 거의 최악의 경우인 것이죠. 마지막 예제를 보겠습니다. 0.5 트레이닝 세트 오류가 있을 경우, 그리고 1퍼센트 dev set 오류를 갖고, 이 경우에 유저는 꽤 만족할 수도 있습니다. 고양이 분류 시스템이 낮은 편향과 편차를 보인 샘플 과 비교하여 1퍼센트 차이만 보이는 경우 말이죠, 1가지 미묘한 부분이 있는데요 이것은 다음 비디오에서 상세히 다루도록 하겠습니다. 대충 내용은 분석하는 과정에서 인간레벨성능이 0퍼센트 오류 또는 일반적으로 optimal 오류, 가끔씩은 base 오류라고 불리는 오류가 0퍼센트에 근접한다는 가정에 입각하여 이루어진다는 것입니다. 그러므로 optimal 오류의 base가 거의 0퍼센트 입니다. 이번 비디오에서는 그리 구체적으로 이야기 하지 않겠습니다. 만약 optomal 오류가 또는 base 오류가 훨씬 더 큰 값인 경우엔, 예를 들어, 15퍼센트였다고 하면, 이 분류기를 보면, 15퍼센트는 사실 트레이닝세트에서는 그리 나쁜 값이 아닙니다. 또, 그리 큰 편향으로 인식하지 않을 것이고, 또한 편차도 꽤 작은 수치입니다. 어떠한 classifier가 작 작동하지 않는 경우, 편향과 편차를 분석하는 방법은 만약 흐릿한 이미지가 있는 경우, 심지어 사람도 잘 맞추지 못하고, 어떠한 시스템도 잘 분류하지 못하는 사진의 경우, error base가 훨씬 클 수 있겠죠, 그러면 상세적으로 분석하는 방법이 변할 것입니다. 이러한 미묘한 부분은 일단 나중에 다루겠습니다. 가지고 가실 내용은, 트레이닝세트를 봄으로써, 데이터가 얼마나 잘 fitting하는지 감을 잡을 수 있다는 것입니다. 적어도 트레이닝 데이터는요. 그럼 편향의 문제가 있는 경우, 얼마나 오류가 올라가는지를 보면서, 트레이닝세트에서 dev set로 넘어가는 경우, 얼마나 편차의 문제가 심한지 직감할 수 있습니다. 그렇게해서 training set 에서 dev set로 잘 일반화 시킬 수 있는 것이죠. 편차에 문제를 잘 대비할 수 있게 말이죠. 이런 모든 내용은 바로 base error가 꽤 작은 값을 갖고, 트레이닝고 dev set가 같은 분포에서 그려진 가정하에 성립합니다. 이 가정들이 부합하지 않는 경우에는, 할 수 있는 조금 더 정교한 부분이 있습니다. 이 부분은 나중에 다루도록 하겠습니다. 이전 슬라이드에서는 큰 편향과, 큰 편차를 가진 것이 어떻게 생겼는지 보았는데요, good class가 어떻게 생겼는지 보셨을 것입니다. 큰 편향과 큰 편차는 어떻게 생긴 것일까요? 최악의 경우 2가지를 합친 것인데요, 이전에 이런 classifier는 큰 편향을 가진 classifier라고 했을 것입니다. 데이터를 underfit하기 때문이죠. 이런 classifier는 대부분 선형이며, 그렇기 때문에 데이터를 underfit하게 됩니다. 보라색으로 그리겠습니다. 그런데 만약 여러분의 classifier가 이상하게 작동하여, 데이터를 overfitting한다고 해봅시다. 이렇게 보라색으로 그린 그림이 그러면 큰 평향과 큰 편차의 값을 갖게 됩니다. 큰 편향을 갖는 부분은, 대부분의 선형을 띄는 classiifier로써, 이렇게 잘 fitting하지 못하게 됩니다. 이런 2차 함수 모양인데요, 하지만 가운데 부분에 너무 많은 유동성을 갖게 됩니다. 어떻게하여 이 example과 이 example을, 2가지 example 모두 overfit하기 됩니다. 이 분류는 꽤 큰 편향을 갖습니다. 대부분 선형이기 때문이죠, 하지만 이런 커브함수 또는 2차함수의 경우, 또 큰 편차를 갖습니다. 이 2개 레이블을 피팅하는데 너무 많은 유동성을 갖고, 또는 여기 가운데 example들을 말이죠. 억지로 짜 맞춘것 같이 보이면, 2차원에서는 약간 이 예제가 그래보일 수 있지만, 고차원의 입력값을 갖는 경우, 사실 큰 편향을 갖는 범위가 있고 큰 편차를 갖는 범위가 있는데요, 그렇기 때문에 고차원의 입력값을 갖는 경우, 이렇게 너무 억지로 짠 것처럼 보이지는 않는 classifier들을 가질 수도 있습니다. 정리를 해드리자면, 지금까지 여러분의 트레이닝 세트의 알고리즘 오류, dev set의 알고리즘 오류를 보면서 큰 편향이나 변동이 있는지 여부를 진단할 수 있다는 사실을 직접 보았습니다. 둘다 일수도 있도, 둘다 아닐수도 있겠죠. 여러분의 알고리즘이 편향이나 변동의 악영향을 받고 있는 경우에 따라 알고보니 시도할 수 있는 여러 방법이 있더군요. 다음 비디오에서 보여드릴 내용은 개인적으로 머신러닝의 기본 레시피라고도 부르건데요, 알고리즘을 시스템적으로 향상시키는 방법입니다. 편향이 높은지 또는 변동이 큰지 여부에 따라 알고리즘을 이에 맞게 향상시키는 방법을 살펴보도록 하겠습니다. 그럼 다음 비디오로 넘어가겠습니다. 다음 강좌로 가보시죠