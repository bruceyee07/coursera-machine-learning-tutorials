1
00:00:03,182 --> 00:00:05,735
Hi, Yoshua, 今天真的很高興你能加入我們

2
00:00:05,735 --> 00:00:06,602
>> 我也很高興

3
00:00:06,602 --> 00:00:11,892
>> 你現在不僅是一個深度學習的研究者或工程師

4
00:00:11,892 --> 00:00:16,458
你已經變成了深度學習中的名人、偶像

5
00:00:16,458 --> 00:00:19,660
不過我很想聽聽這故事的起源

6
00:00:19,660 --> 00:00:26,242
那麼，當初你是怎麼踏入這深度學習，然後持續這旅程呢？

7
00:00:26,242 --> 00:00:31,289
>> 是的，其實呢，故事從小時候就開始了，少年時

8
00:00:31,289 --> 00:00:35,912
讀了很多科幻小說，我猜我們很多人都這樣

9
00:00:35,912 --> 00:00:42,374
當我1985年開始研究所的時候，
我開始讀類神經網路的論文

10
00:00:42,374 --> 00:00:48,040
這讓我非常興奮，變得真正的熱情

11
00:00:48,040 --> 00:00:52,230
>> 實際上，那感覺是怎麼樣的呢，
在80中期對吧，1985，

12
00:00:52,230 --> 00:00:54,492
在讀那些論文的時候，你還記得嗎？

13
00:00:54,492 --> 00:00:55,545
有對

14
00:00:59,565 --> 00:01:05,277
你知道的，本來我學的是專家系統那種古典AI的課程

15
00:01:05,277 --> 00:01:09,981
然後突然發現有那麼一個新大陸

16
00:01:09,981 --> 00:01:14,445
是去思考人類如何學習、人類的智慧

17
00:01:14,445 --> 00:01:19,347
然後可能可以跟人工智慧、

18
00:01:19,347 --> 00:01:21,100
跟電腦聯結起來。

19
00:01:21,100 --> 00:01:25,230
當我發現這些文獻時，我真的很興奮

20
00:01:25,230 --> 00:01:27,730
我開始閱讀 Connectionists，這當然，

21
00:01:27,730 --> 00:01:31,682
還有 Geoffrey Hinton、Rumelhart 的論文，等等等

22
00:01:31,682 --> 00:01:38,462
我研究 RNN (遞歸神經網絡)，我研究語音辨識

23
00:01:38,462 --> 00:01:42,666
我研究 HMM (隱馬爾可夫模型)，所以有
圖模型 (graphical model)

24
00:01:42,666 --> 00:01:50,295
然後很快地，我進入 AT&T 貝爾實驗室和麻省理工學院，
我在那邊做博士後研究

25
00:01:50,295 --> 00:01:54,629
就是在那裡，我發現一些訓練神經網路會碰到的

26
00:01:54,629 --> 00:01:57,335
長期相依性的問題 (long-term dependencies)

27
00:01:57,335 --> 00:02:02,505
過了不久，蒙特婁大學招募我，回去蒙特婁

28
00:02:02,505 --> 00:02:06,475
那也是我度過大半少年時期之處

29
00:02:08,260 --> 00:02:12,948
>> 那麼，身為一個在那打滾數十年、閱歷無數

30
00:02:12,948 --> 00:02:17,049
見多識廣，告訴我你的想法

31
00:02:17,049 --> 00:02:21,610
關於深度學習、神經網路在這些年的演進

32
00:02:22,740 --> 00:02:25,590
>> 一開始，我們從實驗、從直覺觀念出發，

33
00:02:25,590 --> 00:02:27,030
算是之後再看理論

34
00:02:27,030 --> 00:02:30,540
現在，我們了解的更多更深，例如

35
00:02:30,540 --> 00:02:35,132
為什麼反向傳播這麼有用，為什麼深度這麼重要

36
00:02:35,132 --> 00:02:41,904
而對這些見解，在當時我們講不出很確實的理由

37
00:02:41,904 --> 00:02:46,488
在2000年初期，當我們開始研究深度的網路，
我們有個直覺，

38
00:02:46,488 --> 00:02:50,680
更深的網路應該更強大，這很合理

39
00:02:50,680 --> 00:02:54,450
但是，我們不知道要怎麼運用

40
00:02:54,450 --> 00:02:57,680
怎麼證明，而當然我們的實驗在一開始並沒有成功

41
00:02:59,260 --> 00:02:59,910
>> 實際上

42
00:02:59,910 --> 00:03:04,580
回顧過去，你覺得有哪些最重要的事情，
最後被發現是正確的

43
00:03:04,580 --> 00:03:08,120
而哪些事最終發現是錯的、最讓人訝異的

44
00:03:08,120 --> 00:03:09,680
如果和三十年前我們所知的來比較？

45
00:03:11,070 --> 00:03:15,880
>> 當然，我過去犯的最大的錯誤，是認為

46
00:03:15,880 --> 00:03:18,686
— 就和90年代的每個人一樣

47
00:03:18,686 --> 00:03:24,980
認為反向傳播要有效，就一定要有平滑非線性的性質

48
00:03:24,980 --> 00:03:31,330
因為我以為，如果有像是整流般非線性
(rectifying nonlinearities)

49
00:03:31,330 --> 00:03:35,010
其中有個平坦的部份，這樣會非常難訓練

50
00:03:35,010 --> 00:03:38,090
因為有太多地方的導數會是零

51
00:03:38,090 --> 00:03:41,981
而我們一開始嘗試 ReLU 的時候

52
00:03:41,981 --> 00:03:48,065
大約在2010年，用在深度網路上，我很執著在

53
00:03:48,065 --> 00:03:55,270
「喔我們要小心，
會不會神經元有很多在0那邊飽和啊？」

54
00:03:55,270 --> 00:03:59,679
不過最後事實證明，ReLU 實際上表現遠比

55
00:03:59,679 --> 00:04:03,751
S型函數 (sigmoid) 還要好，這讓人非常驚訝

56
00:04:03,751 --> 00:04:07,969
我們會做這個探索，其實是因為生物學的關聯

57
00:04:07,969 --> 00:04:11,105
並不是因為我們覺得這樣比較容易優化

58
00:04:11,105 --> 00:04:16,300
不過最終他表現的比較好，而不是像我想的比較難訓練

59
00:04:16,300 --> 00:04:17,490
>> 那麼讓我問你

60
00:04:17,490 --> 00:04:20,890
深度學習和大腦之間有什麼關聯？

61
00:04:20,890 --> 00:04:25,491
有一個明顯的答案，但我很好奇你的答案是什麼？

62
00:04:25,491 --> 00:04:31,093
>> 嗯，一開始讓我對神經網路

63
00:04:31,093 --> 00:04:37,839
感到興奮的見解，是 Connectionists 上的某個意見：

64
00:04:37,839 --> 00:04:43,003
資訊是分佈在眾多神經元的啟動 (activation) 上

65
00:04:43,003 --> 00:04:47,431
而不是由某種「祖母細胞」(grandmother cell) 來表示

66
00:04:47,431 --> 00:04:51,209
像那時他們稱呼的，一種符號性的表示法

67
00:04:51,209 --> 00:04:54,972
那是古典人工智慧中的傳統觀點。

68
00:04:54,972 --> 00:04:58,860
我現在仍然相信這真的很重要

69
00:04:58,860 --> 00:05:03,573
甚至在最近，我看到也有人也發現了這個的重要性

70
00:05:03,573 --> 00:05:06,850
因此那真的是個基礎。

71
00:05:06,850 --> 00:05:12,919
「深度」這件事是之後出現的，在2000年初期

72
00:05:12,919 --> 00:05:16,563
至少不是我在90年代在想的

73
00:05:16,563 --> 00:05:21,318
>> 的確，我記得你當時建了很多比較淺

74
00:05:21,318 --> 00:05:26,859
但是很分散式的表示法來做 word embedding (詞向量)，
在很早期的時候

75
00:05:26,859 --> 00:05:28,897
>> 是的，沒錯

76
00:05:28,897 --> 00:05:33,661
那是在90年代後期讓我很興奮的其中一件事

77
00:05:33,661 --> 00:05:38,351
事實上，我和我的兄弟 Samy 當時在研究一個點子：
我們可以用神經網路

78
00:05:38,351 --> 00:05:42,171
來解決 curse of dimensionality (高維詛咒)，這被認為

79
00:05:42,171 --> 00:05:45,980
是統計學習裡其中一個主要的問題

80
00:05:45,980 --> 00:05:51,440
而我們有了這些分布式表示 (distributed representation) 後
我們就可以

81
00:05:51,440 --> 00:05:57,150
很有效率地表示多個隨機變數的聯合分布

82
00:05:57,150 --> 00:06:01,250
這個最後非常有效，然後我把他擴展到

83
00:06:01,250 --> 00:06:04,920
一串字的聯合分布，這個就是 word embedding 的由來

84
00:06:04,920 --> 00:06:10,525
因為我認為，這可以讓許多那些

85
00:06:10,525 --> 00:06:16,373
意義類似的字有更共同、廣義的表示 (generalization)

86
00:06:16,373 --> 00:06:20,974
>> 所以在過去幾十年，你的研究團隊發明了超級多的想法

87
00:06:20,974 --> 00:06:24,030
多到沒有人可以用幾分鐘說完

88
00:06:24,030 --> 00:06:26,879
所以我很好奇，你團隊的哪些發明或點子

89
00:06:26,879 --> 00:06:29,810
是你最感到驕傲的？

90
00:06:29,810 --> 00:06:35,640
>> 好，我想我曾經提到長期相依性
(long-term dependencies)，那個研究

91
00:06:35,640 --> 00:06:40,770
我覺得人們還不夠了解這個。

92
00:06:40,770 --> 00:06:45,214
然後我剛剛說的故事，關於高維詛咒，

93
00:06:45,214 --> 00:06:49,887
用神經網路處理聯合分布 (joint distribution)，
這在最近演進成

94
00:06:49,887 --> 00:06:52,435
Hugo Larochelle 研究的 NADE
(Neural Autoregressive Distribution Estimation)

95
00:06:52,435 --> 00:06:55,255
然後像我剛說的，這啟發了許多研究

96
00:06:55,255 --> 00:06:59,660
訓練 word embedding 來探討字詞的聯合分布。

97
00:06:59,660 --> 00:07:04,410
接下來我想，或許是深度學習中我們最有名的研究

98
00:07:04,410 --> 00:07:07,639
利用堆疊的 autoencoders 和堆疊的 RBMs
(自編碼器 和 受限玻爾茲曼機)。

99
00:07:09,580 --> 00:07:15,500
然後是一個研究，對深度網路訓練的難處了解更多

100
00:07:15,500 --> 00:07:20,530
和 Glorot 想出初始化的點子

101
00:07:20,530 --> 00:07:24,840
還有深度網路的消失梯度問題 (vanishing gradient)

102
00:07:24,840 --> 00:07:29,440
實際上就是這項研究，引發了大家的實驗來證明

103
00:07:29,440 --> 00:07:34,986
分段的線性啟動函數有多麼重要。

104
00:07:34,986 --> 00:07:38,804
然後我會說，我們最重要的研究，有一些和

105
00:07:38,804 --> 00:07:43,706
非監督學習、denoising autoencoders、GANs 有關
(降噪自編碼器 ; 生成式對抗網路)

106
00:07:43,706 --> 00:07:48,340
GAN 最近非常流行，Generative Adversarial Network。

107
00:07:48,340 --> 00:07:54,563
還有我們利用 attention 做神經機器翻譯的研究

108
00:07:54,563 --> 00:08:01,132
後來發現這個對機器翻譯非常的重要

109
00:08:01,132 --> 00:08:05,540
而且現在業界系統也在用，例如Google翻譯

110
00:08:05,540 --> 00:08:09,800
不過這個 "attention" 機制真的改變我對神經網路的看法

111
00:08:09,800 --> 00:08:14,860
我們曾經認為，神經網路就是把一個向量對應到另一個向量

112
00:08:14,860 --> 00:08:19,300
但是有了 attention 機制，你可以處理任何的資料結構

113
00:08:19,300 --> 00:08:24,565
這開創了很多條有趣的研究路線。

114
00:08:24,565 --> 00:08:27,415
而和生物學有關的方向

115
00:08:27,415 --> 00:08:31,403
近幾年我在做的一件事情是

116
00:08:31,403 --> 00:08:36,970
我們怎麼弄出一套類似反向傳播的東西，
但是人類大腦可以實作

117
00:08:36,970 --> 00:08:41,500
在這方向我們有幾篇論文，看起來神經科學領域的人

118
00:08:41,500 --> 00:08:43,930
覺得這很有趣

119
00:08:43,930 --> 00:08:46,240
當然我們也持續在這個方向進行研究。

120
00:08:47,890 --> 00:08:50,785
>> 我知道有一個主題，你一直花了很多心力思考

121
00:08:50,785 --> 00:08:52,990
是深度學習和人類大腦之間的關連

122
00:08:52,990 --> 00:08:56,720
可以和我們多談一些嗎？

123
00:08:56,720 --> 00:09:03,030
>> 這個生物學的問題，實際上我不斷想了很久

124
00:09:03,030 --> 00:09:08,110
或者可以說，做了很多白日夢吧

125
00:09:08,110 --> 00:09:12,897
因為，我覺得這就像個拼圖

126
00:09:12,897 --> 00:09:16,957
我們有一些片段的證據，是關於大腦以及大腦怎麼學習

127
00:09:16,957 --> 00:09:21,042
例如 Spike-timing-dependent plasticity

128
00:09:21,042 --> 00:09:27,490
而另一方面，我們有這一堆機器學習的概念

129
00:09:27,490 --> 00:09:31,822
例如對一個目標函數做整個、整體系統的訓練

130
00:09:31,822 --> 00:09:35,440
還有反向傳播這個概念

131
00:09:35,440 --> 00:09:37,370
其實，到底「反向傳播」是什麼意思？

132
00:09:37,370 --> 00:09:42,710
就像，"Credit Assignment" 到底是什麼意思？

133
00:09:42,710 --> 00:09:47,515
當我開始思考，人類大腦是如何做類似反向傳播的事

134
00:09:47,515 --> 00:09:53,070
這讓我繼續思考，嗯，或許在反向傳播的背後

135
00:09:53,070 --> 00:09:58,271
有個更一般的道理，讓反向傳播能如此有效

136
00:09:58,271 --> 00:10:02,217
而或許有很多種類的方式可以解決 credit assignment

137
00:10:02,217 --> 00:10:06,973
而這些和做 reinforcemnet learning (增強式學習) 的人
一直在問的問題有關

138
00:10:06,973 --> 00:10:12,161
所以有趣的是，有時候問一個簡單的問題

139
00:10:12,161 --> 00:10:18,366
能導引你去思考眾多不同方面，迫使你去思考

140
00:10:18,366 --> 00:10:23,387
許多不同的元素，像拼一個很大的拼圖把他們都串起來

141
00:10:23,387 --> 00:10:26,510
我這樣已經很多年了

142
00:10:26,510 --> 00:10:30,538
而我必須說，這整個努力、我追逐的很多主題

143
00:10:30,538 --> 00:10:34,714
一直以來都是受 Geoffrey Hinton 的強烈啟發

144
00:10:34,714 --> 00:10:41,171
特別是，我猜是在2007年，他給了一個演講

145
00:10:41,171 --> 00:10:46,013
在第一次的深度學習研討會上

146
00:10:46,013 --> 00:10:51,270
他分享了他認為人腦怎麼運作，

147
00:10:52,840 --> 00:10:56,515
類似像時序編碼 (temporal code) 可能怎麼

148
00:10:56,515 --> 00:11:00,719
做到反向傳播所做的

149
00:11:00,719 --> 00:11:06,700
這讓我在最近幾年有很多探索的想法

150
00:11:07,850 --> 00:11:12,700
嗯，這算是個滿有趣的故事

151
00:11:13,830 --> 00:11:16,090
算算也十年了

152
00:11:17,100 --> 00:11:21,030
>> 還有一個主題我也聽你談過很多次，是關於

153
00:11:21,030 --> 00:11:23,090
非監督學習 (unsupervised learning)

154
00:11:23,090 --> 00:11:25,000
你可以分享一下你的觀點嗎？

155
00:11:26,010 --> 00:11:29,880
>> 當然當然，非監督式學習相當重要

156
00:11:29,880 --> 00:11:34,744
目前業界的系統是基於監督式的學習
(supervised learning)

157
00:11:34,744 --> 00:11:40,259
這本質上需要人類去定義
在某個問題中，什麼是重要的概念

158
00:11:40,259 --> 00:11:43,845
以及在資料中把那些概念標示出來

159
00:11:43,845 --> 00:11:49,740
你知道的，我們藉此做出許多玩意和服務和系統

160
00:11:49,740 --> 00:11:52,397
不過人類能做的比這還多

161
00:11:52,397 --> 00:11:57,869
藉由對這世界的觀察和互動，我們能探索、

162
00:11:57,869 --> 00:12:00,360
能發現新的概念。

163
00:12:00,360 --> 00:12:05,362
一個兩歲的小孩，能理解直觀的物理現象

164
00:12:05,362 --> 00:12:08,490
換句話說，他知道重力，他了解壓力

165
00:12:08,490 --> 00:12:11,990
他知道慣性

166
00:12:11,990 --> 00:12:14,480
他懂得液體和固體

167
00:12:14,480 --> 00:12:18,140
當然，他的父母從來沒教他這些東西，對吧？

168
00:12:18,140 --> 00:12:21,110
那他是怎麼知道的？

169
00:12:21,110 --> 00:12:26,160
這種問題就是非監督式學習想要回答的

170
00:12:26,160 --> 00:12:30,460
這不僅僅是我們有沒有資料的標籤的問題

171
00:12:30,460 --> 00:12:33,790
實際上這是一種心靈的建構

172
00:12:33,790 --> 00:12:38,630
藉由觀察，來了解、解釋世界的運作

173
00:12:38,630 --> 00:12:42,430
而最近，我一直在結合

174
00:12:42,430 --> 00:12:45,810
非監督學習和增強學習兩者的概念

175
00:12:45,810 --> 00:12:50,430
因為我認為，有很強烈的跡象顯示

176
00:12:50,430 --> 00:12:54,899
那些我們想要釐清的、想要區分的

177
00:12:54,899 --> 00:12:57,020
那些重要的最根本的概念

178
00:12:58,150 --> 00:13:03,166
可以由人類或機器透過和世界互動、

179
00:13:03,166 --> 00:13:08,969
探索這個世界、嘗試事物、嘗試控制來獲得

180
00:13:08,969 --> 00:13:13,598
所以我認為這些和非監督學習的原始概念息息相關

181
00:13:13,598 --> 00:13:14,354
學習.

182
00:13:14,354 --> 00:13:17,082
所以我對非監督學習的意見：

183
00:13:17,082 --> 00:13:22,027
十五年前當我們開始做 autoencoder 和 RBM 之類的

184
00:13:22,027 --> 00:13:26,819
我們非常專注在如何學習良好的表示法

185
00:13:26,819 --> 00:13:29,350
現在我仍然認為這是必要的課題

186
00:13:29,350 --> 00:13:34,370
不過我們不清楚的是，什麼叫一個「良好的表示」

187
00:13:34,370 --> 00:13:39,569
例如我們怎麼知道目標函數是什麼?

188
00:13:39,569 --> 00:13:41,945
所以這些年我們試過非常多的東西

189
00:13:41,945 --> 00:13:46,262
實際上，這是研究非監督式學習很酷的一件事

190
00:13:46,262 --> 00:13:48,449
有超多各式各樣的點子

191
00:13:48,449 --> 00:13:51,079
太多不同的方法來解決問題

192
00:13:51,079 --> 00:13:56,482
這實在是...搞不好明年我們會發現完全不一樣的東西

193
00:13:56,482 --> 00:14:01,066
而或許人腦運作方式又是另一種不一樣的

194
00:14:01,066 --> 00:14:03,197
這種研究不是慢慢疊加上去的

195
00:14:03,197 --> 00:14:06,300
這領域本身就非常值得探索

196
00:14:07,500 --> 00:14:11,150
對於正確的目標函數該是什麼，我們沒有好的定義

197
00:14:11,150 --> 00:14:14,446
更不用說怎麼測量一個系統的好壞，
在非監督學習的領域中。

198
00:14:14,446 --> 00:14:19,710
所以當然，這很有挑戰，但同時

199
00:14:19,710 --> 00:14:23,140
這也意味著無窮開放的可能性

200
00:14:23,140 --> 00:14:26,980
而研究人員很喜歡這樣，至少這很吸引我

201
00:14:28,600 --> 00:14:31,536
>> 時至今日，深度學習有太多事在發生了

202
00:14:31,536 --> 00:14:34,175
我覺得我們已經過了某個階段

203
00:14:34,175 --> 00:14:37,410
一個人已經沒辦法讀過所有深度學習的論文了

204
00:14:38,590 --> 00:14:44,397
所以我很好奇，深度學習的哪些事最讓你興奮呢？

205
00:14:44,397 --> 00:14:49,059
>> 那麼，我很有野心，而我覺得現今

206
00:14:49,059 --> 00:14:54,780
深度學習的科學面還遠不及我所期望的

207
00:14:54,780 --> 00:15:01,060
我有一種印象是，我們系統犯的那樣子的錯誤

208
00:15:01,060 --> 00:15:05,480
顯示了那些系統對這世界的了解還很膚淺

209
00:15:06,510 --> 00:15:11,504
因此，最讓我興奮算是研究的方向

210
00:15:11,504 --> 00:15:15,527
我們不是想建造系統讓他們做有用的事情

211
00:15:15,527 --> 00:15:21,494
我們是回歸到基本原理：電腦如何觀察世界

212
00:15:21,494 --> 00:15:26,030
和世界互動，以及發掘世界如何運作？

213
00:15:26,030 --> 00:15:30,348
就算那個「世界」是很單純的，例如做成電動遊戲的形式

214
00:15:30,348 --> 00:15:32,718
我們仍然不知道如何表現得好

215
00:15:32,718 --> 00:15:36,655
這很棒，因為我不需要和Google和Facebook競爭

216
00:15:36,655 --> 00:15:38,400
以及百度等等，對吧

217
00:15:38,400 --> 00:15:41,300
因為這算是基礎研究

218
00:15:41,300 --> 00:15:45,640
任何人可以在他的車庫進行，然後改變全世界

219
00:15:45,640 --> 00:15:50,130
因此，當然，有很多很多的方向來著手

220
00:15:50,130 --> 00:15:54,509
不過我看到很多深度學習和增強學習的點子

221
00:15:54,509 --> 00:15:59,311
彼此間有豐碩的交流，這非常重要

222
00:15:59,311 --> 00:16:03,076
而且我非常興奮這方向的進展

223
00:16:03,076 --> 00:16:06,940
其實可能對實際應用有巨大的影響

224
00:16:06,940 --> 00:16:11,774
因為，如果你觀察我們在應用層面碰到的一些大挑戰

225
00:16:11,774 --> 00:16:14,044
例如怎麼處理新的領域，或者

226
00:16:14,044 --> 00:16:16,921
一個類別裡面我們只有非常稀少的資料

227
00:16:16,921 --> 00:16:21,100
以及那些人類非常擅長的情況。

228
00:16:21,100 --> 00:16:25,336
所以這類 transfer learning 和 generalization 的挑戰
(遷移學習 ; 一般化/泛化)

229
00:16:25,336 --> 00:16:30,201
如果我們的系統可以更了解這世界如何運作

230
00:16:30,201 --> 00:16:33,821
那麼這些挑戰就顯得輕而易舉

231
00:16:33,821 --> 00:16:35,280
要有深入的了解，對吧

232
00:16:35,280 --> 00:16:36,215
到底發生什麼事？

233
00:16:36,215 --> 00:16:40,218
造成我看到這些的原因為何？

234
00:16:40,218 --> 00:16:44,170
我要採取什麼行動來影響我所看到的？

235
00:16:44,170 --> 00:16:50,542
所以這一類的問題是我最近倍感興趣的

236
00:16:50,542 --> 00:16:56,029
我也認為，隨著深度學習研究演進了幾十年

237
00:16:56,029 --> 00:17:01,060
這些已經牽涉到了更古老的 AI 課題

238
00:17:01,060 --> 00:17:07,760
因為現今深度學習大部分的成功
都和「感知」能力有關

239
00:17:07,760 --> 00:17:08,917
那接下來呢？

240
00:17:08,917 --> 00:17:11,305
剩下來的是更高層次的

241
00:17:11,305 --> 00:17:14,890
也就是在抽象的層面上，理解萬物之運作

242
00:17:14,890 --> 00:17:19,093
我們要理解高層次的抽象，而我認為

243
00:17:19,093 --> 00:17:23,109
還沒達到那麼高的境界，所以我們必須要達到

244
00:17:23,109 --> 00:17:28,796
我們必須思考推理、思考時序性的資訊處理

245
00:17:28,796 --> 00:17:31,087
我們必須思考因果關係怎麼運作

246
00:17:31,087 --> 00:17:34,540
以及要怎麼樣讓機器自己發掘這些事情

247
00:17:34,540 --> 00:17:39,555
或許需要人類引導，至少機器要越自主越好

248
00:17:39,555 --> 00:17:42,395
>> 你剛剛說的某一段，聽起來像是

249
00:17:42,395 --> 00:17:46,160
你很喜歡用作研究的方法，也就是

250
00:17:46,160 --> 00:17:49,730
— 我要用「玩具問題」這個詞，並沒有貶低之意

251
00:17:49,730 --> 00:17:51,354
>> 好。  >> 在小問題上實驗

252
00:17:51,354 --> 00:17:55,670
而你很樂觀認為這小問題可以轉移、類推到更大的問題

253
00:17:55,670 --> 00:18:00,634
>> 對對沒錯，在高層次上類似地轉移

254
00:18:00,634 --> 00:18:05,223
當然我們要花些功夫把格局弄大

255
00:18:05,223 --> 00:18:08,170
然後解決那些問題

256
00:18:08,170 --> 00:18:11,295
不過追求「玩具問題」的主要動機是，

257
00:18:11,295 --> 00:18:17,233
我們能更清楚了解失敗在哪

258
00:18:17,233 --> 00:18:22,233
我們可以把問題簡化到

259
00:18:22,233 --> 00:18:26,528
從直觀上就能處理，更容易理解

260
00:18:26,528 --> 00:18:31,031
好比典型科學在做的 divide and conquer 各個擊破

261
00:18:31,031 --> 00:18:35,591
還有，我覺得，有件事大家想的不透徹

262
00:18:35,591 --> 00:18:38,750
研究的週期會變快的多，對吧

263
00:18:38,750 --> 00:18:44,225
如果我可以幾小時就做完一個實驗，我的進展就更快

264
00:18:44,225 --> 00:18:49,448
如果我要嘗試一個超巨大模型，

265
00:18:49,448 --> 00:18:55,511
試著捕捉所有的常識和知識 — 其實總有一天可以的

266
00:18:55,511 --> 00:18:59,010
只不過以現今的硬體，每一個實驗就等到天荒地老

267
00:18:59,010 --> 00:19:02,984
所以當我們的硬體夥伴還在建造那些

268
00:19:02,984 --> 00:19:06,050
千倍萬倍飛快的機器，在那之前我還是做玩具實驗

269
00:19:06,050 --> 00:19:11,094
>> 我也聽你說過

270
00:19:11,094 --> 00:19:15,904
深度學習的科學，不只是一門工程學科

271
00:19:15,904 --> 00:19:19,610
更是多多研究，了解究竟是怎麼回事

272
00:19:19,610 --> 00:19:22,185
你想分享一下嗎？

273
00:19:22,185 --> 00:19:24,287
>> 好啊，當然

274
00:19:24,287 --> 00:19:29,105
我擔心很多我們正在做的研究，恐怕像是

275
00:19:29,105 --> 00:19:30,278
盲人尋路

276
00:19:30,278 --> 00:19:37,247
如果你運氣夠好，這樣也能找到有趣的收穫

277
00:19:37,247 --> 00:19:40,487
不過說真的，如果我們稍微停下腳步

278
00:19:40,487 --> 00:19:45,619
用可以類推的方式，試著了解我們在做什麼

279
00:19:45,619 --> 00:19:49,220
因為我們遵照原理、遵照理論

280
00:19:49,220 --> 00:19:53,378
— 但是我說的「理論」不見得是「數學」

281
00:19:53,378 --> 00:19:57,733
當然我喜歡數學啦，不過我覺得

282
00:19:57,733 --> 00:20:01,221
不用把每件事都用數學公式化 — 但是要有邏輯

283
00:20:01,221 --> 00:20:05,567
換句話說，我可以說服大家這個應該有用、

284
00:20:05,567 --> 00:20:07,348
這個有沒有道理

285
00:20:07,348 --> 00:20:09,550
這是最重要的一點

286
00:20:09,550 --> 00:20:14,650
然後數學讓我們更強更穩固

287
00:20:14,650 --> 00:20:17,330
不過真的，這其實和「理解」有關

288
00:20:17,330 --> 00:20:21,145
也和做研究的道理有關

289
00:20:21,145 --> 00:20:25,396
不是為了成為下一個目標、基準

290
00:20:25,396 --> 00:20:30,850
也不是擊敗其他實驗室或公司的其他人

291
00:20:30,850 --> 00:20:35,148
而是：我們要問什麼樣的問題，才能讓我們

292
00:20:35,148 --> 00:20:38,200
更理解有趣的事物現象

293
00:20:38,200 --> 00:20:40,330
舉個例子

294
00:20:40,330 --> 00:20:45,247
是什麼導致訓練深層網路或 RNN 很難？

295
00:20:45,247 --> 00:20:48,110
我們有一些想法，但很多事情我們還不明白

296
00:20:49,310 --> 00:20:54,624
所以或許我們能設計實驗，其目的不在得到更好的演算法

297
00:20:54,624 --> 00:20:58,987
而僅是更加了解現有的演算法

298
00:20:58,987 --> 00:21:03,857
或是某個演算法在什麼樣的情況下比較有效？為什麼？

299
00:21:03,857 --> 00:21:05,346
「為什麼」才是最重要的

300
00:21:05,346 --> 00:21:06,595
這就是科學在做的

301
00:21:06,595 --> 00:21:07,669
找到「為什麼」

302
00:21:07,669 --> 00:21:09,826
>> 好的，現在有很多人想要

303
00:21:09,826 --> 00:21:10,764
進入這個領域

304
00:21:10,764 --> 00:21:14,496
我相信你已經在很多一對一的場合回答過

305
00:21:14,496 --> 00:21:18,288
不過對於正在看這影片的大家，如果他們

306
00:21:18,288 --> 00:21:21,238
想踏入 AI，想開始深度學習，你有什麼建議？

307
00:21:21,238 --> 00:21:26,160
>> 好，首先呢，動機有很多種

308
00:21:26,160 --> 00:21:28,537
你能做的也不一樣

309
00:21:28,537 --> 00:21:33,064
要成為一個深度學習的研究者所需要的，可能和

310
00:21:33,064 --> 00:21:37,333
使用深度學習開發產品的工程師，兩者需要的不一樣

311
00:21:37,333 --> 00:21:40,844
這兩個狀況所要求的理解程度會不同

312
00:21:40,844 --> 00:21:46,090
不過無論如何，練習、再練習

313
00:21:46,090 --> 00:21:51,004
如果要真正掌握深度學習

314
00:21:51,004 --> 00:21:54,166
當然你要讀的多

315
00:21:54,166 --> 00:21:56,899
你要嘗試自己手刻程式做練習

316
00:21:58,450 --> 00:22:02,516
我常常面試到一些學生，他們用一些軟體

317
00:22:02,516 --> 00:22:06,788
而現今有太多太好的軟體，你只消裝來就用

318
00:22:06,788 --> 00:22:09,690
完全不用知道自己在做什麼

319
00:22:09,690 --> 00:22:12,890
或者只有很粗淺的了解，於是乎

320
00:22:12,890 --> 00:22:16,027
就很難發現何時無效、哪兒出問題

321
00:22:16,027 --> 00:22:19,880
所以，試著自己實作東西，即使這沒效率 

322
00:22:19,880 --> 00:22:24,366
這只是為了確保你真的理解發生了什麼事

323
00:22:24,366 --> 00:22:26,972
這真的很有用，自己多嘗試

324
00:22:26,972 --> 00:22:29,886
>> 所以不要光是拿某個程式框架，

325
00:22:29,886 --> 00:22:33,432
做每件事只需要幾行程式，但你其實不了解背後發生的事

326
00:22:33,432 --> 00:22:37,480
>> 沒錯、沒錯！甚至不只如此

327
00:22:37,480 --> 00:22:42,911
試著靠自己從基本原理推導各種東西，如果可以的話

328
00:22:42,911 --> 00:22:44,597
這真的很有用

329
00:22:44,597 --> 00:22:48,275
不過呢，至少一些平常的要做，像是閱讀、

330
00:22:48,275 --> 00:22:52,110
看別人的程式、自己寫程式、

331
00:22:52,110 --> 00:22:57,066
做很多的實驗、確保你都理解你所做的

332
00:22:57,066 --> 00:23:00,621
特別是科學的方面

333
00:23:00,621 --> 00:23:05,810
試著問自己：為什麼我在做這個？為什麼大家在做這個？

334
00:23:05,810 --> 00:23:10,470
或許答案在某本書，而你要多多閱讀

335
00:23:11,490 --> 00:23:14,340
不過如果你能自己想通，那樣更棒

336
00:23:15,580 --> 00:23:16,992
>> 讚讚

337
00:23:16,992 --> 00:23:21,547
事實上說到閱讀，你和 Ian Goodfellow

338
00:23:21,547 --> 00:23:25,207
和 Aaron Courville 寫了一本很高評價的書

339
00:23:25,207 --> 00:23:27,240
>> 謝謝、謝謝

340
00:23:27,240 --> 00:23:28,607
嗯，這本賣得很好

341
00:23:28,607 --> 00:23:30,206
有點誇張

342
00:23:30,206 --> 00:23:35,027
我覺得在讀這本書的人比目前看得懂的

343
00:23:35,027 --> 00:23:36,816
還要多

344
00:23:36,816 --> 00:23:40,188
不過對，還有 ICLR 的論文

345
00:23:40,188 --> 00:23:44,968
ICLR 大概是最佳的好論文集散地

346
00:23:44,968 --> 00:23:49,145
當然 NIPS 和 ICML 和其他研討會也有非常棒的論文

347
00:23:49,145 --> 00:23:54,345
不過如果你真的想看很多好的論文，就去讀

348
00:23:54,345 --> 00:23:59,648
最近幾次的 ICLR 論文，會給你這領域的全貌

349
00:23:59,648 --> 00:24:01,454
>> 太好了

350
00:24:01,454 --> 00:24:02,940
還有其他的想法嗎？

351
00:24:02,940 --> 00:24:09,337
如果請你給個建議，要如何擅長深度學習

352
00:24:09,337 --> 00:24:14,949
>> 嗯，這要看你的背景

353
00:24:14,949 --> 00:24:17,590
不要害怕數學

354
00:24:17,590 --> 00:24:22,557
先養成直覺，當你能從直觀上了解

355
00:24:22,557 --> 00:24:27,870
熟悉事物的原理，那數學方面就很容易理解了

356
00:24:27,870 --> 00:24:32,218
而且有個好消息是，你不需要去讀五年的博士

357
00:24:32,218 --> 00:24:34,300
來變成深度學習的專家

358
00:24:34,300 --> 00:24:35,637
事實上你可以很快學會

359
00:24:35,637 --> 00:24:40,040
如果你有電腦科學和數學的良好背景

360
00:24:40,040 --> 00:24:44,742
幾個月的學習你就可以使用、做出東西

361
00:24:44,742 --> 00:24:48,962
開始研究、開始實驗

362
00:24:48,962 --> 00:24:53,312
經過正確的訓練，大概約莫六個月

363
00:24:53,312 --> 00:24:56,224
就算可能對機器學習一無所知

364
00:24:56,224 --> 00:24:59,427
如果他們擅長數學和電腦科學，這可以很快

365
00:24:59,427 --> 00:25:02,722
不過當然，這意味著你要受過正確的數學

366
00:25:02,722 --> 00:25:03,640
和電腦科學的訓練

367
00:25:03,640 --> 00:25:08,920
有時候只靠電腦課所教的並不夠

368
00:25:08,920 --> 00:25:13,928
特別是你還需要
連續函數的數學 (相對於離散數學)

369
00:25:13,928 --> 00:25:20,309
也就是例如機率、代數、最佳化

370
00:25:20,309 --> 00:25:22,313
>> 了解。還有微積分

371
00:25:22,313 --> 00:25:24,037
>> 還有微積分，對對 

372
00:25:24,037 --> 00:25:28,809
>> 非常感謝, Yoshua, 分享這些意見、洞見和忠告

373
00:25:28,809 --> 00:25:32,561
就算我已經認識你很久了，有很多細節、

374
00:25:32,561 --> 00:25:35,084
早期歷史我到現在才知道，謝謝你

375
00:25:35,084 --> 00:25:39,880
>> 也謝謝你 Andrew

376
00:25:39,880 --> 00:25:44,819
特別做這影片，還有你所作的這些

377
00:25:44,819 --> 00:25:47,150
我希望這能被很多人看見