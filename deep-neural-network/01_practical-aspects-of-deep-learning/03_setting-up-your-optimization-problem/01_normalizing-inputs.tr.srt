1
00:00:00,436 --> 00:00:03,390
Sinir ağlarını eğitirken kullanılabilecek, eğitme hızınızı arttırabilecek

2
00:00:03,390 --> 00:00:06,060
yöntemlerden birisi ise girdilerinizi normalleştirmektir.

3
00:00:06,060 --> 00:00:07,730
Hadi ne anlama geldiğini konuşalım

4
00:00:07,730 --> 00:00:10,240
Diyelim ki eğitim setiniz iki girdi özelliğine sahip olsun.

5
00:00:10,240 --> 00:00:13,520
Girdi olan x 2 boyutlu olsun(x1, x2)

6
00:00:13,520 --> 00:00:16,550
burada eğitim setinizin saçılım çizimini görüyoruz

7
00:00:16,550 --> 00:00:20,730
Girdilerinizi normalleştirmek iki adımdan oluşur.

8
00:00:20,730 --> 00:00:26,270
Birincisi ortalamasını çıkartmak veya ortalamayı sıfıra çekmek

9
00:00:26,270 --> 00:00:34,140
yani burada mü = (1/ m) çarpı x lerin toplamı(ortalamasını almak)

10
00:00:34,140 --> 00:00:39,786
Daha sonra x, x- mü ye eşitleniyor 

11
00:00:39,786 --> 00:00:44,571
yani x leri, ortalamaları sıfır olacak şekilde yer değiştiriyoruz.

12
00:00:44,571 --> 00:00:49,530
ve ikinci adım ise değişinti leri normalleştirmek

13
00:00:49,530 --> 00:00:54,640
burada dikkat ederseniz x1 , x2 den çok daha fazla 

14
00:00:54,640 --> 00:00:55,410
alana yayılmış

15
00:00:55,410 --> 00:01:00,030
Yani yaptığımız şey burada sigmayı

16
00:01:00,030 --> 00:01:04,580
(1/m) * x'lerin karelerinin toplamına eştliyoruz

17
00:01:04,580 --> 00:01:07,220
Burada her bir elemanın karesini alıyoruz

18
00:01:07,220 --> 00:01:13,040
Dolayısıyla kare-sigma her özelliğin değişintisini içermiş oluyor

19
00:01:13,040 --> 00:01:15,435
ve daha sonra x'leri ( x1 veya x2) kare-sigmaya bölüyoruz 

20
00:01:15,435 --> 00:01:19,600
bu şekilde x leri değişintilerine bölerek

21
00:01:19,600 --> 00:01:24,580
her birinin değişintisini 1 e eşitlemiş oluyoruz

22
00:01:24,580 --> 00:01:28,490
bu da şekilde görülen çizime yol açıyor

23
00:01:28,490 --> 00:01:34,785
Eğer bir öneri verecek olursak,

24
00:01:35,975 --> 00:01:42,627
eğer bunu eğitim setinizi normalleştirmek için kullanacaksanız,

25
00:01:42,627 --> 00:01:47,735
aynı mü ve sigma yı test seti için de kullanın, değil mi?

26
00:01:47,735 --> 00:01:51,015
Özellikle, eğitim setini ve test setini farklı bir şekilde

27
00:01:51,015 --> 00:01:52,865
normalleştirmek istemezsiniz.

28
00:01:52,865 --> 00:01:57,520
Her iki değer ne olursa olsun bu değerleri

29
00:01:57,520 --> 00:02:02,190
bu iki formülde yani eğitim ve test setinde aynı şekilde kullanın

30
00:02:02,190 --> 00:02:06,500
bu şekilde iki setinizi aynı şekilde normalleştirmiş olursunuz

31
00:02:06,500 --> 00:02:10,167
Çünkü hem eğitim hem de test örneklerinde verinizin eğitim setinde hesaplanan

32
00:02:10,167 --> 00:02:13,831
aynı mü ve aynı sigma tarafından tanımlanan

33
00:02:13,831 --> 00:02:16,752
aynı değişimden geçmesini istersiniz.

34
00:02:16,752 --> 00:02:18,210
Peki neden bunu yapıyoruz?

35
00:02:18,210 --> 00:02:21,290
Neden girdi değerlerini normalleştirmek istiyoruz?

36
00:02:21,290 --> 00:02:25,790
Sağ üstte yazan Bedel fonksiyonunu hatırlayın.

37
00:02:25,790 --> 00:02:31,030
Görünen o ki eğer normalleştirilmemiş girdiler kullanırsanız, bedel fonksiyonunuzun

38
00:02:31,030 --> 00:02:35,860
bu şekilde gözükme ihtimali yüksek, ezilmiş ve uzatılmış şekilde,

39
00:02:35,860 --> 00:02:41,500
belki de bulmak istediğiniz minimum değer burada bir yerdedir.

40
00:02:41,500 --> 00:02:46,890
Fakat eğer özellikleriniz çok farklı ölçeklendirmeye sahipse, diyelim ki,

41
00:02:46,890 --> 00:02:52,280
x1 1'den 1000 e kadar olsun ve x2 0'dan 1'e kadar olsun

42
00:02:52,280 --> 00:02:56,790
bu durumda w1 ve w2 parametreleri için oran ya da

43
00:02:56,790 --> 00:03:02,020
değer aralıkları çok farklı sonuçlar alacaktır.

44
00:03:02,020 --> 00:03:06,771
(Belki de bu eksenler w1 ve w2 adını almalı fakat ben w ve b şeklinde çizeceğim.)

45
00:03:06,771 --> 00:03:11,270
Dolayısıyla bedel fonksiyonunuz bu şekilde uzatılmış kase gibi olacaktır.

46
00:03:11,270 --> 00:03:14,440
Eğer bu fonksiyonu incelerseniz,

47
00:03:14,440 --> 00:03:17,705
bu şekilde uzatılmış bir görüntü elde edersiniz.

48
00:03:17,705 --> 00:03:19,500
Fakat bunun yerine özellikleri normalleştirirseniz,

49
00:03:19,500 --> 00:03:24,570
o zaman bedel fonksiyonunuz daha simetrik görünecektir.

50
00:03:24,570 --> 00:03:28,728
ve eğer bedel fonksiyonunda solda olduğu gibi eğim azalması çalıştırıyorsanız,

51
00:03:28,728 --> 00:03:33,216
bu durumda küçük bir öğrenme hızı kullanmak isteyebilirsiniz çünkü

52
00:03:33,216 --> 00:03:37,242
örneğin burada adımlarınız minimumu bulmadan önce

53
00:03:37,242 --> 00:03:40,800
fazla miktarda salınım yapabilir.

54
00:03:40,800 --> 00:03:45,466
Bunun yerine eğer daha küresel sınırlarınız varsa, bu durumda eğim azalmasını

55
00:03:45,466 --> 00:03:49,125
nerede başlatırsanız başlatın bu direk minimuma doğru gidecektir.

56
00:03:49,125 --> 00:03:53,665
Bu durumda soldaki resimde görülen salınımlar daha az olacağı için çok daha

57
00:03:53,665 --> 00:03:56,345
büyük adımlar(öğrenme hızı)atabilirsiniz.

58
00:03:56,345 --> 00:04:00,250
Tabi ki paratikte w yüksek boyutlu bir vektör, dolayısıyla

59
00:04:00,250 --> 00:04:04,530
bunu 2 boyutta çizmeye çalışmak tam olarak anlamını yansıtamıyor.

60
00:04:04,530 --> 00:04:08,220
Fakat temel iç görü bedel fonksiyonunuzun, eğer özellikler benzer ölçeklerde olursa

61
00:04:08,220 --> 00:04:12,510
daha yuvarlak ve eniyilemesi daha kolay olduğu olacaktır.

62
00:04:12,510 --> 00:04:15,600
1'den 1000'e veya 0'dan bire değil çoğunlukla -1'den 1'e

63
00:04:15,600 --> 00:04:20,880
veya çoğunlukla benzer değişintilere sahip olacaktır.

64
00:04:20,880 --> 00:04:25,630
Bu bedel fonksiyonu j'nin kolay ve hızlı bir şekilde eniyilenmesi anlamına gelir

65
00:04:25,630 --> 00:04:30,450
Paratikte, eğer bir özellik, diyelim ki x1, 0'dan 1'e,

66
00:04:30,450 --> 00:04:35,530
x2 -1'den 1'e ve x3 1'den ikiye kadarsa,

67
00:04:35,530 --> 00:04:38,730
bunlar genel olarak benzer uzaklıklara sahip olduğu için bunlar iyi bir şeklide çalışacaktır.

68
00:04:38,730 --> 00:04:41,430
Fakat uzaklıklar arasında çok fazla fark olduğu zaman, örneğin

69
00:04:41,430 --> 00:04:42,470
1'den 1000'e kadarsa ve diğer özellik 0'dan 1'e kadarsa bu,

70
00:04:42,470 --> 00:04:46,720
eniyileme algoritmanızı gerçek manada baltalar.

71
00:04:46,720 --> 00:04:50,664
Fakat bunların hepsinin ortalamasını 0'a eşitleyerek ve değişintisini 1'e eşitleyerek,

72
00:04:50,664 --> 00:04:54,857
-son slaytta yaptığımız gibi-, özelliklerin benzer ölçeklere sahip olmasını garanti edebiliriz

73
00:04:54,857 --> 00:04:58,290
ve bu öğrenme algoritmanızın daha hızlı çalışmasına çoğunlukla fayda sağlar

74
00:04:58,290 --> 00:05:01,600
Dolayısıyla eğer girdi fonksiyonlarınız çok farklı ölçeklerdeyse,

75
00:05:01,600 --> 00:05:03,410
belki bazı özellikler 0'dan 1'e kadar,

76
00:05:03,410 --> 00:05:08,130
bazıları 1'den 1000'e kadarsa, bu durumda özelliklerinizi normalleştirmek önemli olacaktır.

77
00:05:08,130 --> 00:05:11,630
Eğer özellikleriniz benzer ölçeklerdeyse, o zaman bu işlem daha az önemli olacaktır.

78
00:05:11,630 --> 00:05:15,235
Böyle bir normalleştirme hiçbir zarar getirmeyeceği için,

79
00:05:15,235 --> 00:05:19,170
eğer işlemlerinizde eğitme hızını artırmak için fayda sağlayıp sağlamayacağından

80
00:05:19,170 --> 00:05:21,970
emin değilsem ben genellikle uyguluyorum.

81
00:05:22,970 --> 00:05:26,020
Pekala, girdi özelliklerinizi normalleştirmek buraya kadardı,

82
00:05:26,020 --> 00:05:29,840
Bir sonraki derste yeni sinir ağınızın eğitimenizi hızlandırma konusunu konuşmaya devam edeceğiz.