이제 여러분은 좋은 하이퍼 파라미터를 찾는 방법데 대해 
많이 들으셨을 텐데요 하이퍼 파라미터 서치에 대한
토론내용을 정리하기 전에 앞서, 마지막으로 몇가지의 팁을 공유하고 싶습니다. 하이퍼 파라미터 서치 과정을 조직화하는 방법에 대해서 말이죠. 딥러닝은 오늘날 많은 다양한 
어플분야에서 적용되고 있는데요 한 어플 분야에서 사용되는 하이퍼 파라미터의 직관이 다른 어플로 이동되지 않을 수 있습니다. 서로 다른 어플 도메인에서는 
cross-fertilization이 많이 있습니다. 예를 들어, 저는 컴퓨터 비전 커뮤니티에서
아이디어가 생기는 것을 많이 보았는데요, Confonets or ResNets 와 같은 것들 말이죠. 
이것들은 나중의 코스에서 다루도록 하겠습니다. 이런 아이디어는 성공적으로 스피치 분야에 적용되었습니다. 이러한 아이디어들이 처음으로 개발되고 
스피치 분야에서 NLP로 성공적으로 
적용되고 말이죠. 등등이 계속 이어집니다. 그렇게해서 딥러닝에서 보여준 훌륭한 개발은 다른 어플 영역, 분야의 사람들이 
다양한 분야의 논문을 더 많이 읽고 cross-fertilization의 영감을 얻으려 한다는 것입니다. 하지만 하이퍼 파라미터의 설정에 있어서는 이런 직관적인 부분이
잘 이루어지지 않는 것을 보게됩니다. 여러분이 한개의 문제를 다루게 되더라도, 
예를 들어, 로지스틱 말이죠. 하이퍼 파라미터를 위한 좋은 값을 찾았을 수 있습니다. 
그리소 계속 알고리즘을 개발했겠죠. 또는 데이터가 차차 몇개월간 
변해가는 것을 경험했겠어죠. 또는 여러분의 데이터 센터에 있는 서버를 
업그레이드 했을 수도 있죠. 이러한 변화 때문에, 여러분의 하이퍼 파라미터 최적 설정값이 
오래될 수 있습니다. 그렇기 때문에 저는 여러분이 retesting 하거나 하이퍼 파라미터를 재평가하는 것을 추천드립니다. 몇개월에 한번씩은 말이죠. 여러분이 가지고 있는 값들에 대해서
만족하기 위해서 말입니다. 그리고 마지막으로 사람들이 
하이퍼 파라미터를 서칭하는 것에 대해 이야기해볼 텐데요, 여기서는 2가지 정도가 떠 오릅니다. 또는 사람들이 하는 2가지 방법이죠. 한가지 방법은 바로 1개의 모델을 babysit하는 것입니다. 이것은 아주 큰 데이터가 있고 산출 자원은 많이 없을 때 적용될텐데요, 산출자원이라 하면 CPU나 GPU같은것이 많이 없어 1가지 모델만 트레이닝할 여력 밖에 없는 경우 또는
아주 작은 수의 모델만 한번에 트레이닝 시킬 수 밖에 없는 경우에 해당합니다. 이런 경우, 차차 이 모델을 babysit하는 것입니다. 트레이닝을 할때도 말이죠. 예를 들어, day 0일 때, 
파라미터를 임의로 초기화시키고 바로 트레이닝을 할 수 있겠죠. 그리고 점차 러닝커브를 보고, 
아마 J 비용함수일 수 있겠죠 또는 데이터세트이거나 다른 것일 수도 있고요
이런 것들이 점차 첫째날동안 줄어들 것입니다. 그리고 첫째날의 마지막 부분에 이르러서 
아주 잘 러닝하고 있다고 생각하실 수 있습니다. 이런 경우, 러닝속도를 약간 높혀서 
어떤 결과가 나오는지 보겠습니다. 그러면 아마 더 잘할 수도 있겠죠. 그럼 이것이 둘째날의 성능이 되는 것이고요. 그리고 이틀후에, 
아직 잘하고 있다고 판단할 수 있습니다. 그러면 이제 모멘텀 항을 조금 더해서 
또는 이제는 러닝 변수를 조금 줄일것이라 할 수 있습니다. 이제 그렇게되면 셋째날로 접어드는 것이죠. 이렇게 여러분은 매일 보면서
조금씩 위로 또는 밑으로 파라미터에 변형을 줄 수 있는 것이지요. 그러면 아마 어느날에는 러닝속도가 매우 컸다는 
것을 깨달을 수 있습니다. 그러면 이전 모델로 다시 돌아갈 것입니다. 이렇듯, 모델을 babysitting 하는 것과 같은데요, 
하루씩 babysitting을 하는 것입니다. 트레이닝이 몇일간 또는 몇주간 이루어지는 경우에도 말이죠. 이렇게 하는 것이 한가지 접근 방식이구요. 이런 방식에서는, 사람들이 한가지의 모델을 babysit하여 
성능을 보면서 차분하게 러닝속도를 조정해줍니다. 이 경우는 그러나 산출자원이 많이 없는 경우에 진행하는 경우이고요, 보통 한번에 여러모델을 트레이닝
시킬 여력이 없을 때 사용하는 방법입니다. 다른 방법으로는 parallel 방식으로
여러 모델을 트레이닝 시키는 방법인데요. 어떤 하이퍼 파라미터의 특정 설정 값으로 혼자 작동하게 놔둘 수 있는데요, 
하루 또는 며칠 간 이렇게 놔둘 수 있습니다. 그러면 이렇게 생긴 러닝커브를 얻게 될텐데요, 이것은 j 비용함수의 그래프일 것이거나 
트레이닝 오류의 비용이거나 데이터세트의 비용일 수 있을 텐데요, 
여러분이 트래킹하는 것 의 어떤 특정 매트릭일 것입니다. 그리고 동시에 다른 설정값의 하이퍼 파라미터를 가진 다른 모델을 시작할 수 있습니다. 그러면 두번째 모델은 다른 러닝 커브를 줄 것입니다. 이렇게 생길 수도 있겠죠. 이것이 조금 더 나아 보이네요. 동시에, 세번째 모델도 트레이닝 시킬 수 있습니다. 이렇게 생긴 러닝커브를 만들게 말이죠. 
그리고 또 하나를 만들수도 있고요. 이것은 이렇게 나뉘어질 수 있는데요, 
이렇게 생길것입니다. 아니면 여러분은 여러개의 모델을 parallel하게 트레이닝 시킬 수 있습니다. 그러면 여기 오렌지색 선이 다른 모델들인데요, 이런 방식으로 다른 하이퍼 파라미터 설정값을 시도하고 마지막에 가장 잘 작동하는 것을 찾을 수 있습니다. 여기 예제에서는 이 커브가 가장 잘 보일 수 있겠죠. 그럼 비유를 하자면, 여기 왼쪽 방식을 panda approach라고 할 것입니다. panda가 아이를 갖는 경우, 
굉장히 조금 갖는데요, 한번에 1명씩 낳습니다. 그렇게 1명을 낳아 그 아기가 잘 생존해서
자랄 수 있도록 많은 노력을 기울입니다. 이것은 babysitting 방법과도 같죠. 한개의 모델 또는 한게의 아기 panda입니다. 오른쪽 방법은 물고기가 하는 방식과 비슷합니다. 이것을 캐비아 전략이라고 할 것입니다. 1시즌에 1억개가 넘는 생선알을 낳는 물고기가 있는데요, 물고기가 번식하는 방법은 생선알은 한번에 많이 낳는 방법인데요, 일일히 신경쓰지 않고 하나가 잘 되기를 바라면 또는 몇개가 잘되기를 
바라는 원리라고 할 수 있겠습니다. 이것이 사실 포유동물과 물고기 또는 파충류가 번식하는 방법의
차이겠죠. 저는 이것을 인용하여
panda approach와 caviar approach라고 할 것입니다. 이것이 더 흥미롭고 쉽게 외울 수 있는 방법이기 때문입니다. 이 2개의 접근 방식 중 고르는 방법은, 여러분이 얼마나 산출 자원을 가지고 있느냐에 따라 달라집니다. 여러분이 충분히 많은 컴퓨터를 가지고 있어
여러개의 모델을 parallel 방식으로 트레이닝 시킬 수 있으면, caviar approach를 택하셔도 무방합니다. 여러개의 하이퍼 파라미터를 시도하여 
어떤 것이 잘 작동하는 것인지 확인하는 것입니다. 하지만 어떤 어플 영역에서는, 
저는 이것을 몇개의 온라인 광고 설정에서 보기도 하고 컴퓨터 비전 어플에서도 보는데요, 데이터가 무수히 많아 트레이닝 시키려고 하는 모델이 너무 방대해서 모델들을 한번에 트레이닝 시키기가 매우 어렵습니다. 어플에 마다 물론 다를 수 있겠죠. 저는 이런 커뮤니티와 같은 경우, 
panda approach를 더 많이 쓰는 경우를 봤습니다. 이 경우, 한개의 모델을 babysitting하고 파라미터의 값을 올리거나 내리는 등의 방식으로
변형을 주어 잘 작동하게 만들어주는 방식입니다. 물론 panda approach도 한개의 모델에서 작동하는지 그렇지 않은지 확인을 하는 
절차이지만, 2번째 주나, 또는 세번째 주 시점에서 다른 모델로 초기화하여 옆에서 쌍둥이 panda처럼 babysit해야할 수도 있습니다.
이런 경우 복수의 아기를 갖는 셈이죠. 오로지 한개만 또는 아주 작은 수의 모델만
한번에 처리한다고 해도 말이죠. 바라건대 여러분이 이 강의를 통해 
하이퍼 파라미터 서치에 대해 조금 더 이해할 수 있었던 강의가 되었길 바랍니다. 이제 여러분의 신경망이 하이퍼 파라미터를 선정하는데 있어 
더 잘 작동하게 하기 위해서 사용할 수 있는 기술이 한개 더 있는데요. 모든 신경망에서 작동하는 것은 아닙니다만, 잘 작동하는 경우, 하이퍼 파라미터 서치 절차를 아주 간단하게 해주고
트레이닝의 속도를 높혀줄 수 있습니다. 이 기술에 대해서는 다음 비디오를 통해 이야기하겠습니다.