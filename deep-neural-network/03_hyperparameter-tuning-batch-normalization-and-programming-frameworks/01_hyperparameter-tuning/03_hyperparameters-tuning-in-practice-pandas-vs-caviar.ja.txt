これまでハイパーパラメータの探し方をたくさん聞いてきましたね。 この議論を終える前に、 ハイパーパラメータサーチのプロセスを整理するために使える コツをいくつか紹介しましょう。 ディープラーニングは今や多くの異なる応用分野で使われています。 ハイパーパラメータ設定について、1つの応用分野からの知識は、異なる応用分野にそのまま使えるかもしれませんし、 使えないかもしれません。 異なる応用分野の間で、たくさんの相互交流があります。 例えば、私はコンピュータビジョンのコミュニティで発展したConvNetやResNetのようなアイデアが、 後のコースで話す スピーチ（認識）の分野に、うまく適用されたことを見てきました。 私は、最初スピーチの分野で発展したアイデアが、自然言語処理の分野でうまく適用されたことを見てきました。 などなど。 だから、ディープラーニングにおける良い発展は、異なる応用分野の人々が、 他の応用分野の研究論文を読むことで、 お互いの分野のインスピレーションを探すことにあります。 ハイパーパラメータ設定に関する直観は 使えなくなることが多々あります。 例えば物流とか、一つの問題に取り組んでいる過程で 良いハイパーパラメータの設定を見つけ、そのアルゴリズムを開発し続けたとしよう。 しかし数ヶ月の間にデータが少しずつ変化していったとか、 データセンターのサーバーをアップグレードしたかもしれない。 それらの変化によって あなたが考えたハイパーパラメータの最良な設定は使えなくなる可能性があります。 だから、私は再テストすること、 あるいは、ハイパーパラメータを再評価することを数ヶ月ごとに行うことを推奨します。 持っている値が基準を満たしていることを確認するためです。 最後に、人々がどうハイパーパラメータを探すかについては、 2つのメジャーな思想流派、 もしくは、人々がとる2つの道があります。 1つの方法は、1モデルをベビーシットすることです。 この方法をとる場合は主に、たくさんのデータを持っているが、 CPUやGPUなどの計算資源が少ないため 一度に一つか、少数のモデルしか訓練することができない場合です。 こんなときは、そのモデルの学習中にもベビーシットする場合もあります。 例えばday0に、パラメータをランダムに初期化し、 訓練をスタートする。 それから学習曲線、コスト関数 J、 あるいはエラーや他の何かが段階的に減ることを初日に観察したとします。 だとするとその日の終わりに、「学習がとてもうまくいっているようだ。 学習率を少し大きくして様子を見よう」というかもしれない。 そして、パフォーマンスはさらに良くなるとします。 day2のパフォーマンスです。 day2のあと、「まだうまくいっている。 momentumを少し変えて、学習率も下げよう」と考え そして3日目に入ったとします。 そのようにして毎日モデルを観察し、パラメータを上下にいじっていく中で ある時、学習率が大きすぎることが分かったら、 前の日のモデルに戻ることができます。 要は、数日・数週間の間、毎日 1つのモデルをベビーシットするということです。 これが一つ目のアプローチです。ベビーシットしているモデルのパフォーマンスを見ながら、 忍耐強く学習率を手動で上下させる。 先ほど述べたように、このパターンは多くのモデルを同時に訓練するほどの CPUやGPUなどの資源がない時に取るパターンです。 2つ目のアプローチは多くのモデルを並列して訓練する方法です。 その時はいくつかのハイパーパラメタの設定を考えており モデルをそのうちの1つの設定で訓練させる、1日でもそれ以上でも。 すると図のような学習曲線を得ます。 これはコスト関数 J や訓練データの誤差、あるいは データセット誤差のプロットと考えてもらって構いません。 そしてそれと同時にまた別のハイパーパラメータの設定で もう一つモデルを訓練させます。 こっちのほうのモデルは こんな感じの学習曲線を描くとしましょう。 「ふむ、こっちのほうがよく見えるな。」 そして3つ目のモデルも訓練してみましょう。 こんな感じの学習曲線かな。 4つ目の曲線はこんな感じとしましょう。 このようにしてたくさんのモデルを訓練します。 このオレンジ色のはまた別のモデルです。 結果として、いろんなハイパーパラメータの設定でモデルを同時に訓練させ その中から一番よさそうなモデルを選択することができます。 この中では多分この曲線が一番よさそうですね。 たとえ話をすると 左のアプローチをパンダアプローチを呼びましょう。 パンダは基本少数の子供を産みますね、 1度に1匹。 そしてそれらの子供たちがそれぞれちゃんと成長できるように<br />全力を注ぎます。 つまりベイビーシッティングですね、 一つのモデルは1匹の子供パンダ。 一方で右のアプローチは魚の産卵みたいですね。 キャビアアプローチとでも呼びましょうか。 魚の中には同時に1億の卵を産む種類があります。 しかしその魚は1億個の卵 一つ一つに注意を払うのではなく その中から確率的に成長できそうなものが<br />産まれる感じになります。 要約すると、哺乳類と 魚や爬虫類の繁殖の違いのようなものです。 ここではパンダアプローチとキャビアアプローチと呼びます、 そのほうが覚えやすそうですしね。 この2つのアプローチの選び方は 手元にどれだけのCPUやGPUがあるかによります。 モデルを並列で訓練できるほどの資源があるなら キャビアアプローチを選択し いろんなハイパーパラメータを同時に試しましょう。 しかし例えばオンライン広告など特定の分野では データが多すぎるし モデルも大きいので 別のモデルを同時進行で訓練するキャパがない場合があります。 このように分野によるとしか言えませんが 様々なコミュニティーでパンダアプローチのように 一つのモデルをベビーシットしながら パラメータを上げ下げしてモデルを訓練する方法が主流です。 でもパンダアプローチといっても 最初に訓練したモデルがうまくいかなくて 2週目や3週目で「よしもう一度別の設定でやり直そう」と いうこともあるでしょう。 パンダも一人っ子である必要はありませんから。 さて、このビデオではハイパーパラメータのサーチをどのようにして行うべきかを 一緒に考えました。 しかし実はお教えしていないテクニックがまだあります。 このテクニックはあなたのモデルを<br />ハイパーパラメータの選択に対してロバストにします。 すべてのモデルに組み込むことはできませんが、<br />できる場合は ハイパーパラメータのサーチをもっと簡単に、<br />そして訓練のスピードもより速くすることができます。 このテクニックは次のビデオで紹介しましょう。