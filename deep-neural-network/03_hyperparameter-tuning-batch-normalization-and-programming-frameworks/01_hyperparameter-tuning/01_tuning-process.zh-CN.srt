1
00:00:00,000 --> 00:00:01,710
大家好，欢迎回来

2
00:00:01,710 --> 00:00:04,140
到目前为止 同学们应该已经了解了

3
00:00:04,140 --> 00:00:07,415
调整神经网络的过程 包含了对很多不同超参数的设置

4
00:00:07,415 --> 00:00:11,155
然而 你该怎样为这些参数 找到比较合适的设定值呢

5
00:00:11,155 --> 00:00:13,710
在这个视频中 我会与你们分享一些指导原则

6
00:00:13,710 --> 00:00:18,235
以及系统化进行超参数调优的技巧

7
00:00:18,235 --> 00:00:20,640
它们将帮助你更有效地

8
00:00:20,640 --> 00:00:23,760
获得合适的超参数

9
00:00:23,760 --> 00:00:25,929
有一种痛苦 是在深度神经网络训练中

10
00:00:25,929 --> 00:00:29,250
面对大量超参数

11
00:00:29,250 --> 00:00:35,935
包括学习速率α 如果使用动量算法的话 还包括动量超参数β

12
00:00:35,935 --> 00:00:41,370
还有Adam优化算法里的超参数β1

13
00:00:41,370 --> 00:00:44,185
β2和ε

14
00:00:44,185 --> 00:00:47,270
也许还包括网络层数

15
00:00:47,270 --> 00:00:50,820
以及每层网络中隐藏单元的数量

16
00:00:50,820 --> 00:00:55,093
也许你还想使用学习率衰减

17
00:00:55,093 --> 00:00:59,899
这种情况下不可能只有单一的学习速率α

18
00:00:59,899 --> 00:01:01,065
当然接下来

19
00:01:01,065 --> 00:01:06,220
你需要选择Mini-Batch的大小

20
00:01:06,220 --> 00:01:09,990
根据我的实践经验 一部分超参数比其他的更加重要

21
00:01:09,990 --> 00:01:12,235
我认为 对于大多数学习算法应用

22
00:01:12,235 --> 00:01:16,015
学习速率α 是需要调优的超参数中最重要的一个 没有之一

23
00:01:16,015 --> 00:01:21,595
除了α 我接下来会调整的一些超参数

24
00:01:21,595 --> 00:01:25,040
也许是动量项

25
00:01:25,040 --> 00:01:27,795
0.9是一个不错的默认值

26
00:01:27,795 --> 00:01:30,700
我还会调整Mini-Batch的大小

27
00:01:30,700 --> 00:01:34,465
来保证最优化算法的运行效率

28
00:01:34,465 --> 00:01:36,985
我还经常调试隐藏单元数量

29
00:01:36,985 --> 00:01:39,250
就是那些我用橙色圈起来的参数

30
00:01:39,250 --> 00:01:43,660
这三个是我认为重要性仅次于

31
00:01:43,660 --> 00:01:46,060
学习速率α的超参数 在调整好这些超参数后

32
00:01:46,060 --> 00:01:49,060
接下来是重要性排在第三的超参数

33
00:01:49,060 --> 00:01:51,925
网络层数有时候对结果起到重要作用

34
00:01:51,925 --> 00:01:55,000
学习率衰减有时也一样

35
00:01:55,000 --> 00:01:58,870
当使用Adam优化算法时 我几乎不调节β1

36
00:01:58,870 --> 00:02:00,434
β2和epsilon

37
00:02:00,434 --> 00:02:01,930
我几乎都是用0.9 0.999和10^(-8)

38
00:02:01,930 --> 00:02:08,570
如果你有兴趣 也可以对这些参数进行调整

39
00:02:08,570 --> 00:02:12,130
希望这让你对超参数的重要性排序 有一个大概的了解

40
00:02:12,130 --> 00:02:16,463
知道哪些参数可能会比其他的重要

41
00:02:16,463 --> 00:02:19,005
毋庸置疑 α是最重要的

42
00:02:19,005 --> 00:02:22,270
其次也许是那些我用橙色圈起来的超参数

43
00:02:22,270 --> 00:02:25,235
再次也许是那些我用紫色圈起来的超参数

44
00:02:25,235 --> 00:02:27,760
但这并不是一个死板的规定

45
00:02:27,760 --> 00:02:30,490
我想其他深度学习从业者也许

46
00:02:30,490 --> 00:02:33,670
不同意我的观点 或者有自己的不同见解

47
00:02:33,670 --> 00:02:37,240
我们继续说下去 如果你要调整一些超参数

48
00:02:37,240 --> 00:02:40,060
该怎样选择这些值的组合呢

49
00:02:40,060 --> 00:02:42,845
在早期的机器学习算法中

50
00:02:42,845 --> 00:02:44,660
如果你有两个超参数

51
00:02:44,660 --> 00:02:47,662
假设是超参数1和超参数2

52
00:02:47,662 --> 00:02:53,380
人们经常会像这样 在一个网格中对点进行取样

53
00:02:53,380 --> 00:02:59,435
然后系统化地尝试这些点所代表的值

54
00:02:59,435 --> 00:03:00,935
在这里我放的是一个5*5的网格

55
00:03:00,935 --> 00:03:06,070
实际上可能比这个大 或者比这个小

56
00:03:06,070 --> 00:03:12,430
在这个例子中 当你尝试过所有25个点后 选择最优的超参数

57
00:03:12,430 --> 00:03:18,010
当超参数的数量相对较少时 这样的取参方法较为实用

58
00:03:18,010 --> 00:03:19,840
但是在深度学习中

59
00:03:19,840 --> 00:03:21,415
我推荐你采取另一种方法

60
00:03:21,415 --> 00:03:23,975
在网格中进行随机取样

61
00:03:23,975 --> 00:03:27,970
像这样随机选择一些点 同样的 我们选择25个点

62
00:03:27,970 --> 00:03:34,590
然后在这些随机选取的点中 尝试所有的超参数

63
00:03:34,590 --> 00:03:38,350
这样做的原因是

64
00:03:38,350 --> 00:03:43,040
事先你很难知道 在你的问题中 哪个超参数是最重要的

65
00:03:43,040 --> 00:03:44,480
正如你在上一页幻灯片中看到的

66
00:03:44,480 --> 00:03:47,910
有一些超参数 实际上比其它的要重要很多

67
00:03:47,910 --> 00:03:49,190
举个例子

68
00:03:49,190 --> 00:03:53,505
假设超参数1是学习速率α

69
00:03:53,505 --> 00:03:55,175
举一个极端一点的例子

70
00:03:55,175 --> 00:03:58,180
假设超参数2

71
00:03:58,180 --> 00:04:02,730
是Adam优化算法分母中的ε

72
00:04:02,730 --> 00:04:07,455
按照我们之前说的 α的选择很关键 而ε的选择却影响不大

73
00:04:07,455 --> 00:04:12,410
那么如果你在网格中取样 当你尝试过

74
00:04:12,410 --> 00:04:16,300
5个α的值之后

75
00:04:16,300 --> 00:04:18,550
可能会发现即使ε的值有所不同

76
00:04:18,550 --> 00:04:21,190
得到的结果却基本上相同

77
00:04:21,190 --> 00:04:24,400
所以你相当于训练了25个模型

78
00:04:24,400 --> 00:04:27,925
但是只尝试了5个有用的α的值

79
00:04:27,925 --> 00:04:29,740
而其实α才是最重要的

80
00:04:29,740 --> 00:04:33,430
相对而言 如果你在网格中随机取样

81
00:04:33,430 --> 00:04:37,960
那么你将获得25个不同的

82
00:04:37,960 --> 00:04:40,390
学习速率α 因此你找到理想值

83
00:04:40,390 --> 00:04:43,690
的概率也就变得更大

84
00:04:43,690 --> 00:04:44,980
我刚才举的例子

85
00:04:44,980 --> 00:04:47,160
只用到两个超参数

86
00:04:47,160 --> 00:04:50,270
实际上 你可能会面对更多的超参数

87
00:04:50,270 --> 00:04:52,000
比如说 你有

88
00:04:52,000 --> 00:04:55,080
3个超参数 那么你将不是在平面正方形中寻找

89
00:04:55,080 --> 00:05:00,820
而是在三维立方体中寻找 超参数3即为第三个维度

90
00:05:00,820 --> 00:05:03,010
通过在

91
00:05:03,010 --> 00:05:05,380
这个三维立方体中抽样

92
00:05:05,380 --> 00:05:08,080
你需要尝试更多这三个超参数的组合值

93
00:05:08,080 --> 00:05:11,440
而在实践中 你要寻找的

94
00:05:11,440 --> 00:05:14,980
可能不仅仅是三个超参数

95
00:05:14,980 --> 00:05:17,160
有时 真正的困难在于 你需要事先知道哪一个超参数

96
00:05:17,160 --> 00:05:22,120
对于你的模型更重要 这种情况下 使用随机取样

97
00:05:22,120 --> 00:05:25,390
而不是在网格中规则抽样 将帮助你更充分地

98
00:05:25,390 --> 00:05:28,085
为最重要的超参数 尝试尽可能多的值的组合

99
00:05:28,085 --> 00:05:31,045
无论最重要的超参数是哪个

100
00:05:31,045 --> 00:05:33,130
当你对超参数进行取样时

101
00:05:33,130 --> 00:05:37,875
另一个常见的做法是 使用区域定位的抽样方案

102
00:05:37,875 --> 00:05:42,130
比如在这个二维的例子中 你抽取了这些点

103
00:05:42,130 --> 00:05:45,600
也许你发现这个点能产生最好的结果

104
00:05:45,600 --> 00:05:49,210
并且旁边的一些点的结果也不错

105
00:05:49,210 --> 00:05:53,530
那么在这个方案中 你需要做的是对

106
00:05:53,530 --> 00:06:00,820
这些点所在的区域进行限定 然后在这个区域内进行密度更高的抽样

107
00:06:00,820 --> 00:06:02,795
或者依然选择随机抽样

108
00:06:02,795 --> 00:06:06,690
但是需要把更多资源集中在这个蓝色方块中搜索

109
00:06:06,690 --> 00:06:11,265
前提是你大体能确定这个区域内取的值能产生最优结果

110
00:06:11,265 --> 00:06:13,600
即最理想的超参数来自于这个区域

111
00:06:13,600 --> 00:06:18,365
在对整个框定范围进行粗略的抽样后

112
00:06:18,365 --> 00:06:22,375
结果会引导你集中在一个更小的区域内

113
00:06:22,375 --> 00:06:26,105
然后你可以在更小的方块内 进行更密集的抽样

114
00:06:26,105 --> 00:06:29,720
所以这种区域型的搜索 也是一种常用方法

115
00:06:29,720 --> 00:06:33,565
通过尝试这些超参数的不同值 接下来你可以

116
00:06:33,565 --> 00:06:37,740
选择最理想的参数

117
00:06:37,740 --> 00:06:41,230
使训练集或者开发集有最理想的结果

118
00:06:41,230 --> 00:06:46,660
或者在超参数搜寻的过程中 实现你希望获得的其它优化结果

119
00:06:46,660 --> 00:06:48,570
希望以上内容能帮助你找到

120
00:06:48,570 --> 00:06:51,670
系统化组织超参数搜索过程的方法

121
00:06:51,670 --> 00:06:53,200
本期我们学习的两个主要内容是

122
00:06:53,200 --> 00:06:55,930
使用随机取样 而不是在网格中定点搜索

123
00:06:55,930 --> 00:07:01,585
或者使用区域定位的搜索过程

124
00:07:01,585 --> 00:07:04,750
但是除此以外 还有很多超参数探寻的方法

125
00:07:04,750 --> 00:07:07,300
让我们在下一个视频中继续讨论

126
00:07:07,300 --> 00:07:10,020
如何正确选择超参数取样的范围<br />翻译 | 审阅：Cousera Global Translator Community