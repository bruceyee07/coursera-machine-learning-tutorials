1
00:00:00,280 --> 00:00:05,140
上一节你们看到了,超参数值域的随机抽样

2
00:00:05,140 --> 00:00:09,330
能让你更有效地搜索超参数空间

3
00:00:09,330 --> 00:00:14,980
但实际上,随机抽样并不意味着在有效值范围内的

4
00:00:14,980 --> 00:00:16,990
均匀随机抽样(sampleing uniformly at random)

5
00:00:16,990 --> 00:00:20,320
相反,更重要的是选取适当的尺度(scale)

6
00:00:20,320 --> 00:00:22,340
用以研究这些超参数

7
00:00:22,340 --> 00:00:25,700
这一节我想向你们展示这个方法

8
00:00:25,700 --> 00:00:30,230
假设你现在要选择第l层隐藏单元的个数n[l]

9
00:00:30,230 --> 00:00:31,250
假设你现在要选择第l层隐藏单元的个数n[l]

10
00:00:31,250 --> 00:00:36,310
再假设你认为50~100是个不错的范围

11
00:00:36,310 --> 00:00:41,110
那么,参考数轴上从50~100的范围

12
00:00:41,110 --> 00:00:46,090
也许你会在这个线段上随机地取一些数值

13
00:00:46,090 --> 00:00:50,500
这是搜索这个超参数的非常直观的方法

14
00:00:50,500 --> 00:00:54,351
或者如果你要决定神经网络的层数

15
00:00:54,351 --> 00:00:56,480
我们用大写L来表示

16
00:00:56,480 --> 00:01:02,245
也许你认为这个层数应该在2~4之间

17
00:01:02,245 --> 00:01:08,030
那么均匀随机的抽样,即2,3,4,这样也是合理的

18
00:01:08,030 --> 00:01:11,920
或者甚至用网格搜索,显式计算

19
00:01:11,920 --> 00:01:15,340
l=2,3,4的结果,可能也是合理的

20
00:01:15,340 --> 00:01:19,091
所以这里有好几个例子说明在你所关注的域中

21
00:01:19,091 --> 00:01:23,480
均匀随机抽样是合理的方案

22
00:01:23,480 --> 00:01:26,432
但它并不是对所有的超参数都适用

23
00:01:26,432 --> 00:01:28,850
从这里开始 增加θ 似乎这也是我希望得到的 也就是

24
00:01:28,850 --> 00:01:33,530
比如你正在搜索超参数alpha,即学习率

25
00:01:33,530 --> 00:01:38,000
假设你认为它的下限是0.0001

26
00:01:38,000 --> 00:01:42,130
上限是1

27
00:01:42,130 --> 00:01:48,451
现在画出从0.0001~1的数轴

28
00:01:48,451 --> 00:01:55,456
并均匀随机地抽取样本值

29
00:01:55,456 --> 00:02:02,219
那么90%的样本值将落在0.1~1的范围内

30
00:02:02,219 --> 00:02:07,274
即你用90%的资源搜索0.1~1

31
00:02:07,274 --> 00:02:12,120
只有10%的资源用于搜索0.0001~0.1范围内的值

32
00:02:12,120 --> 00:02:14,330
看起来不大对

33
00:02:14,330 --> 00:02:19,175
更合理的方法似乎应该以对数尺度(log scale)来搜索

34
00:02:19,175 --> 00:02:25,437
而不是用线性尺度(linear scale)<br />那么0.0001在这里

35
00:02:25,437 --> 00:02:30,377
然后是0.001,0.01,0.1和1

36
00:02:30,377 --> 00:02:37,360
接下来你可以在这个对数尺度上均匀随机的取样

37
00:02:37,360 --> 00:02:44,133
现在你可以有更多的资源致力于搜索

38
00:02:44,133 --> 00:02:50,270
0.0001~0.001,0.001~0.01这样的范围了

39
00:02:50,270 --> 00:02:53,950
用Python实现就是

40
00:02:55,780 --> 00:03:00,877
r=-4*np.random.rand()

41
00:03:00,877 --> 00:03:07,260
然后再随机取alpha值,即alpha=10^r

42
00:03:08,350 --> 00:03:15,410
第一行运行之后,r为-4~0的随机数

43
00:03:15,410 --> 00:03:20,505
则alpha值在10^(-4)~10^0之间

44
00:03:20,505 --> 00:03:25,710
10^(-4)在最左边,这里

45
00:03:25,710 --> 00:03:28,320
1=10^0

46
00:03:28,320 --> 00:03:30,140
更一般的来说

47
00:03:30,140 --> 00:03:35,750
如果你要在10^a~10^b的范围内取样

48
00:03:35,750 --> 00:03:40,700
这个例子里,这里是10^a

49
00:03:40,700 --> 00:03:45,358
你可以用基于10的对数计算a

50
00:03:45,358 --> 00:03:49,170
这里a=-4

51
00:03:49,170 --> 00:03:51,430
右边的值是10^b

52
00:03:51,430 --> 00:03:52,800
计算出b的值

53
00:03:52,800 --> 00:03:56,655
这里b=log10(1)=0

54
00:03:58,200 --> 00:04:04,353
那么你要做的就是在a~b的范围内均匀随机取样

55
00:04:04,353 --> 00:04:06,857
这个例子中的范围为-4~0

56
00:04:06,857 --> 00:04:08,358
然后为alpha赋值为

57
00:04:08,358 --> 00:04:14,000
10^r,r为随机取样的基于10的对数

58
00:04:14,000 --> 00:04:18,210
整理一下,要基于对数尺度取样,首先取得下限值

59
00:04:18,210 --> 00:04:20,252
取其对数得到a

60
00:04:20,252 --> 00:04:23,911
再取上限值,取其对数得到b

61
00:04:23,911 --> 00:04:28,270
然后在对数尺度上在10^a~10^b范围内取样

62
00:04:28,270 --> 00:04:32,810
即在a~b的范围内均匀随机的取r值

63
00:04:32,810 --> 00:04:35,850
最后得到超参数值为10^r

64
00:04:35,850 --> 00:04:40,070
这就是对数尺度上取样方法的实现

65
00:04:40,070 --> 00:04:46,010
最后,另一个棘手的情况是超参数beta的取样

66
00:04:46,010 --> 00:04:49,630
beta用于计算指数加权平均值

67
00:04:49,630 --> 00:04:55,800
假设你认为beta值应该在0.9~0.999之间

68
00:04:55,800 --> 00:04:59,870
也许这是你要搜索的值空间

69
00:04:59,870 --> 00:05:03,440
要记住的是,用0.9计算指数加权平均值

70
00:05:03,440 --> 00:05:09,605
相当于计算最后10个值的平均值

71
00:05:09,605 --> 00:05:13,304
比如计算10天气温的平均值

72
00:05:13,304 --> 00:05:18,403
而使用0.999就相当于计算1000个值的平均值

73
00:05:18,403 --> 00:05:23,434
类似上一页ppt所展示,如果你要搜索

74
00:05:23,434 --> 00:05:28,558
0.9~0.999的范围,线性尺度的取样

75
00:05:28,558 --> 00:05:31,140
即均匀的,随机的,0.9至0.999范围内的搜索,没什么意义

76
00:05:31,140 --> 00:05:33,970
那么考虑这个问题的最好的方法是

77
00:05:33,970 --> 00:05:38,650
将这个范围展开为1-beta

78
00:05:38,650 --> 00:05:43,339
得到0.1~0.001的范围

79
00:05:43,339 --> 00:05:47,060
那么我们对beta的采样范围

80
00:05:47,060 --> 00:05:53,057
为0.1~0.001

81
00:05:53,057 --> 00:05:57,739
现在运用我们之前学到的方法

82
00:05:57,739 --> 00:06:01,532
这是10^(-1),这是10^(-3)

83
00:06:01,532 --> 00:06:05,163
请注意,之前的数轴是从左至右递增的

84
00:06:05,163 --> 00:06:08,182
这里我们要反过来

85
00:06:08,182 --> 00:06:12,290
大的值在左边,小的值在右边

86
00:06:12,290 --> 00:06:19,870
所以你要做的是在-3~-1的范围内均匀随机的取样

87
00:06:19,870 --> 00:06:25,700
然后置1-beta=10^r,即beta=1-10^r

88
00:06:25,700 --> 00:06:29,638
就得到了这个超参数在适当尺度上

89
00:06:29,638 --> 00:06:31,551
的随机取样值

90
00:06:31,551 --> 00:06:35,139
希望这能解释:

91
00:06:35,139 --> 00:06:39,979
你在探索0.9~0.99和0.99~0.999的范围时

92
00:06:39,979 --> 00:06:43,409
使用了同样数量的资源

93
00:06:43,409 --> 00:06:47,699
如果你想要知道关于这个做法的更规范的数学证明

94
00:06:47,699 --> 00:06:52,100
也就是说,为什么以线性尺度取样是个坏主意？

95
00:06:52,100 --> 00:06:57,120
这是因为随着beta趋近于1<br />其结果对于beta的改变非常敏感

96
00:06:57,120 --> 00:07:02,230
即使是对beta非常小的改变

97
00:07:02,230 --> 00:07:08,750
如果beta从0.9变成0.9005

98
00:07:08,750 --> 00:07:15,730
这没什么大不了,你的结果几乎没有任何变化

99
00:07:15,730 --> 00:07:19,720
但是如果beta从0.999变成0.9995

100
00:07:19,720 --> 00:07:26,615
它将会对你正在运行的算法产生巨大的影响

101
00:07:26,615 --> 00:07:30,580
在前一个例子中,都是取大约10个值的平均

102
00:07:30,580 --> 00:07:35,359
但是这里,取指数加权平均的情况下

103
00:07:35,359 --> 00:07:40,790
它从取最后1000个样例变成了取最后2000个样例的平均

104
00:07:40,790 --> 00:07:44,460
因为我们的公式是1/(1-beta)

105
00:07:44,460 --> 00:07:49,140
所以当beta趋近于1时,它对beta的改变非常敏感

106
00:07:49,140 --> 00:07:52,059
那么上述整个取样过程所做的

107
00:07:52,059 --> 00:07:57,426
就是使你在beta趋近于1的区域内以更大的密度取样

108
00:07:59,186 --> 00:08:03,480
换一种说法,也就是在1-beta趋近于0的时候

109
00:08:03,480 --> 00:08:07,630
因此你能得到更高效的样本分布

110
00:08:07,630 --> 00:08:11,430
即在搜索可能的超参数空间时更有效率

111
00:08:11,430 --> 00:08:14,250
我希望这能够帮助你

112
00:08:14,250 --> 00:08:15,901
在对超参数取样时选择正确的尺度

113
00:08:15,901 --> 00:08:20,900
如果对于某个超参数你最后选择的尺度是不对的

114
00:08:20,900 --> 00:08:23,232
也不用太担心

115
00:08:23,232 --> 00:08:26,720
即使在存在更优尺度的情况下<br />你依然选择了均匀尺度(uniform scale)

116
00:08:26,720 --> 00:08:30,050
你仍然可能得到不错的结果

117
00:08:30,050 --> 00:08:33,830
尤其是如果你采取从粗到精(coarse to fine)的搜索策略<br />在后期的迭代中

118
00:08:33,830 --> 00:08:38,190
你将更专注于在最有用的超参数值域取样

119
00:08:38,190 --> 00:08:40,894
我希望这能对你的超参数搜索有所帮助

120
00:08:40,894 --> 00:08:44,731
下一节我将分享

121
00:08:44,731 --> 00:08:46,695
如何组织超参数搜索过程的一些想法

122
00:08:46,695 --> 00:08:49,570
希望能使你的工作流程更有效率