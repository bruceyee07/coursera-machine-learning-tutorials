Şimdiye kadar iyi hiper parametre seçimi için nasıl araştırma yapacağınız hakkında epeyi
şey duydunuz. Hiper parametre araştırması ile ilgili konuşmamızı tamamlamadan önce, hiper parametre arama sürecinizi nasıl düzenleyeceğiniz konusunda birkaç ipucu ve püf noktasını sizlerle paylaşmak istiyorum. Günümüzde derin öğrenme birçok farklı alana uygulanmakta ve hiper parametre ayarları hakkındaki sezgiler bir uygulama alanından diğerine aktarılabilir veya aktarılamaz. Farklı uygulama alanları arasında çok fazla etkileşim söz konusudur, örneğin, ilerleyen derslerde üzerinde konuşacağımız Confonet veya ResNet gibi bilgisayarlı görü topluluğunda geliştirilen ve konuşma uygulamalarına başarılı şekilde uygulanan fikirleri gördüm. İlk olarak konuşma uygulamasında başarılı bir şekilde geliştirilip NLP’ de uygulanan fikirler gördüm, ve benzeri. Yani, derin öğrenmede güzel bir gelişme, farklı uygulama alanlarındaki insanların, etkileşim için ilham aramak amacıyla diğer uygulama alanları hakkında sayıları giderek artan araştırma makalelerini okumalarıdır. Hiper parametre ayarlarınız açısından, sezgilerin bayatladığını gördüm. Yani sadece tek bir problem üzerinde çalışıyor olsanız bile, lojistik deyin, hiper
parametreler için iyi bir ayar bulmuş olabilir ve algoritmanızı geliştirmeye devam etmiş olabilirsiniz, veya verilerinizin birkaç ay boyunca aşamalı olarak değiştiğini görebilir veya belki de veri merkezinizde bulunan sunucuları yeni sürüme henüz geçirmiş olabilirsiniz. Ve bu değişikliklerden dolayı, hiper parametrelerinizin en iyi ayarı artık bayatlamış olabilir. Sahip olduğunuz değerlerden hala memnun olduğunuza emin olmak için, hiper parametrelerinizi birkaç ayda bir en az bir kere tekrar test etmenizi veya yeniden değerlendirmenizi tavsiye ederim. Son olarak; insanların hiper parametreleri nasıl aradıkları konusunda, belki iki büyük görüş veya belki de insanların bu konuya yönelmeleri için iki farklı yol görüyorum. İlk yol,bir modelin bebek bakıcısı olmak. Ve genellikle bunu  yeterli sayısal kaynak ,CPU ve GPU olmamasına rağmen çok büyük bir veri kümesine sahipseniz yaparsınız, yani bir seferde sadece bir modeli veya çok az sayıda modeli eğitmeyi başarabilirsiniz. Bu durumda yavaş yavaş bu modeli eğitirken bile bebeğe bakabilirsin. Yani, örneğin, sıfırıncı günde parametrenizi rastgele olarak başlatabilir ve daha sonra eğitime başlayabilirsiniz. Ve kademeli olarak öğrenme eğrinizi izlersiniz, belki maliyet fonksiyonu J veya veri kümesi hatası ya da başka bir şey, ilk gün boyunca yavaş yavaş azalır. Daha sonra, birinci günün sonunda, vay be,görünüşe göre oldukça iyi öğreniyor , öğrenme oranını biraz arttırmayı deneyeceğim ve nasıl olduğunu göreceğim, diyebilirsiniz. Ve sonra belki daha iyi olur. Ve sonra ikinci gün performansınız. Ve iki gün sonra, tamam, hala gayet iyi diyeceksiniz. Belki momentum terimini biraz dolduracağım veya öğrenme değişkenini şimdi biraz azaltacağım, ve şimdi 3. Gün'e gireceksiniz. Ve her gün bakıp parametrelerinizi yukarı ve aşağı doğru çekmeyi deneyin. Ve belki bir gün öğrenme oranınızın çok büyük olduğunu gördünüz. O zaman önceki günün modeline geri dönebilirsiniz, vb. Ancak, bir kaç gün boyunca ya da birkaç hafta boyunca devam eden bir eğitimden geçse bile, günün birinde modele bebek bakıcılığı yapıyorsunuz. Yani bu, insanların bir modele bebek bakıcılığı yaptığı, performansını izleyerek öğrenme oranını sabırla yukarı ve aşağı düşürdüğü bir yaklaşım. Ancak bu yaklaşım genellikle; aynı anda birçok modeli eğitmek için yeterli hesaplama kapasitesi olmadığı zamanlarda kullanılır. Paralel olarak birçok modeli eğitiyorsanız diğer yaklaşım olacaktır. Yani, hiper parametrelerin bazı ayarlarına sahip olabilirsiniz ve sadece bir günlüğüne, hatta birkaç günlüğüne kendi başına koşmasına izin verin, ve o zaman böyle bir öğrenme eğrisi elde edersiniz; ve bu maliyet fonksiyonunun (J) veya eğitim hatanızın maliyetinin veya veri seti hatanızın maliyetinin bir çizimi olabilir, ancak takibinizdeki bazı metriklerdir. Ve daha sonra aynı anda farklı bir modeli hiper parametrelerin farklı bir ayarı ile başlatabilirsiniz. Ve böylece, ikinci modeliniz farklı bir öğrenme eğrisi oluşturabilir, belki biri bu şekilde görünür. Bunun daha iyi göründüğünü söyleyeceğim. Ve aynı zamanda, şu şekilde görünen bir öğrenme eğrisi üreten üçüncü bir modeli eğitebilirsiniz, ve bir tane daha, belki biri şu şekilde ayrılır, vb. Ya da, bu turuncu çizgilerin farklı modeller olduğu, paralel birçok farklı modeli eğitebilirsiniz, bu sayede çok sayıda farklı hiper parametre ayarını deneyebilir ve sonra belki de sonunda en hızlı şekilde en iyi olanı seçebilirsiniz. Bu örnekte göründüğü gibi, belki de en iyi görünen bu eğri. Bir benzetme yapmak için, soldaki yaklaşımı panda yaklaşımı olarak adlandıracağım. Bildiğiniz gibi,pandaların çok az sayıda çocuğu olur, genellikle tek seferde bu sayı birdir ve bebek pandanın hayatta kalmasını sağlamak için çok büyük çaba sarf ederler. Yani bu gerçekten bebek bakıcılığı. Bir model ya da bir bebek panda. Oysa sağdaki yaklaşım daha çok balıkların yaptığı gibi. Bunu havyar stratejisi olarak adlandıracağım. Bir çiftleşme döneminde 100 milyondan fazla yumurta bırakan balıklar var. Ama balıkların üreme biçimleri çok fazla yumurta bırakma şeklindedir ve bu yumurtalardan herhangi birine diğerlerinden daha fazla önem vermezler sadece umutla bunlardan birinin, belki de birçoğunun iyi olacağını görürüz. Sanırım, bu gerçekten memeliler ile balıklar ve sürüngenlerin birçoğunun nasıl üredikleri arasındaki fark. Daha eğlenceli ve akılda kalıcı olacağı için , ben bunu havyar yaklaşımına karşı panda yaklaşımı olarak adlandıracağım. Dolayısıyla, bu iki yaklaşım arasında seçim yapmanın yolu, ne kadar hesaplama kaynaklarına sahip olduğunuzun bir fonksiyonudur. Çok sayıda modeli paralel olarak eğitmek için yeterli bilgisayarınız varsa, o zaman havyar yaklaşımını kullanın ve birçok farklı hiper parametre deneyin ve neyin işe yaradığını görün. Çok fazla verinin olduğu ve eğitilecek modellerin çok büyük olması nedeniyle aynı anda eğitilmesinin zor olduğu  bazı çevrimiçi reklamcılık ayarlarında ve bilgisayarlı görü uygulamaları gibi bazı alanlarda bunu görüyorum Bu elbette gerçekten kursa bağlı bir
uygulamadır, ancak tek bir modele bakıp, parametreleri aşağı yukarı hareket
ettirerek, bu modelin çalışmasını sağlamaya çalıştığınız yerde, toplulukların
panda yaklaşımını biraz daha fazla kullandıklarını gördüm. Tabii ki, panda yaklaşımı olsa bile
, bir model eğitilmiş ve sonra çalışıp  çalışmadığı görülmüş olabilir, belki ikinci
hafta ya da üçüncü haftada, belki de farklı bir modeli
başlatmalıyım ve sonra,bebek pandalar gibi, sanıyorum ki, yaşamlarında çok sayıda yavru sahibi
olsalar da, tek seferde bir veya çok az sayıda yavruları olabiliyor. Umarım bu, hiper parametre arama sürecine nasıl başlayacağınıza dair iyi bir fikir verir. Şimdi, sinir ağınızı hiper parametrelerin seçimine daha güçlü hale getirebilecek başka bir teknik var. Tüm sinir ağları için işe
yaramıyor,ama ne zaman uygulanırsa, hiper parametre aramasını daha kolay hale
getirebilir ve aynı zamanda eğitimin daha hızlı ilerlemesini sağlayabilir. Bir sonraki videoda bu teknik hakkında konuşacağız.