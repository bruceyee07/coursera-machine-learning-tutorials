在上一部影片，你看到了
隨機從超參數數值的範圍取樣 能讓你更有效率地搜索超參數所在的空間 不過呢，隨機取樣並不代表
從數值可能的範圍中 均勻地隨機取出來 相反地，選擇適當的尺度比例 來探索超參數是很重要的 在這部影片，我來示範該怎麼作到這一點 假設你想決定隱藏單元的個數, n[l] 對於第 l 層 然後假設，你認為這數量可能介在50到100之間 這樣的話，你看這50到100的數線 或許在數線上隨機取幾個數字 是搜尋這個超參數一個顯然的方法 或者，如果你想決定神經網路的層數 讓我們用大寫L表示 假設你認為層數大概在2到4中間 那麼均勻地從2, 3, 4中隨機挑出來，是很合理的 或者用格子法，評估層數為2, 3, 或4時的效能也是合理的 所以這邊的幾個例子，是均勻隨機地 從預期的範圍取樣，滿合理的 但是，並不是所有的超參數都可以這樣 讓我們看另一個例子讓我們看另一個例子 如果你在尋找alpha學習率這個超參數 假設你認為最低可能到0.0001 最高可能到1 那如果你畫一條數線從0.0001到1 均勻地在這數線上隨機取值 那取出來的值，大約有90%都會落在0.1到1之間 所以你花了90%的資源，在0.1到1之間找尋 而只有10%在找0.0001到0.1之間 這感覺不太對 在這裡，根據「對數尺度」來搜索超參數似乎更合理 和線性尺度不一樣，在這裡是0.0001 然後0.001, 0.01, 0.1，然後1在這 你是在這種對數尺度比例上，均勻隨機地取樣 這樣，你就有更多資源在搜索0.0001到 0.001之間，還有0.001到0.01，依此類推 用Python實作這個的方法 是讓 r = -4 * np.random.rand() 然後隨機的alpha會是 alpha = 10的r次方 所以第一行會讓 r 變成 -4 到 0 之間的一個亂數 所以 alpha 會介在
10的-4次方 到 10的0次方之間 10的-4次方就是左邊這個 然後 1 就是10的0次方 一般來說 如果你想在對數尺度上，
在10的a次方和10的b次方之間取樣 在這個例子，這個是10的a次方 要知道a是多少，你可以取以10為底的 0.0001的對數 也就是 -4 而右邊這個數字，10的b次方 要知道b是多少 就取以10為底的，1的對數，也就是 b=0 所以你要做的，就是均勻地從a到b隨機取出 r 在這個例子，r會介在-4到0之間 那你就可以設定alpha為 10的r次方，就成了隨機取樣的超參數 再複習一下，在對數尺度上取樣，你把最小值 取對數，以得知a是多少 把最大值取對數，得到b 也就是你想在10的a次方到10的b次方之間取樣，
在對數尺度上 所以你在a到b之間
均勻地隨機取數字，設作r 然後把超參數的值，設成10的r次方 這就是如何實作
在對數尺度上取樣的方法 最後，另一個棘手的情況是
隨機取樣超參數beta 用在指數加權平均的beta 假設你認為beta應該在0.9到0.999之間 假設這是你想搜尋的範圍 還記得嗎，當計算指數加權平均的時候 取 0.9 就類似於對最後10個值做平均 就好像取十天的溫度平均 而取 0.999 就像把最後1000個值做平均 與上一張投影片類似，如果我們想在 0.9和0.999之間搜尋，
以線性尺度來取樣並不合理對吧 從0.9到0.999之間均勻地取出 那麼，思考這個問題最好的角度 是我們想探索 1 - beta 這範圍裡面的值 也就是從 0.1 到 0.001 那我們在取樣beta的時候 先從0.1，也許從0.1到0.001挑數字 利用前一張投影片的手法 這是10的-1次方，這是10的-3次方 注意在前一張投影片，比較小的值在左邊 比較大的值在右邊。不過在這裡則是相反 大的值在左邊，小的值在右邊 所以你要做的，就是均勻地從-3到-1隨機取出 r 然後讓 1 - beta = 10的r次方，
所以beta = 1 - 10的r次方 那這個，就變成了你取樣的超參數的值 是在適當的尺度上取出的 希望這聽起來有道理，用這種方法取樣 你花了同樣的資源在探索0.9到0.99 以及0.99到0.999之間 如果你想要了解比較正式的
從數學的理由來看為什麼 我們要這樣做，為什麼在線性尺度上取樣是個爛主意 這是因為，當beta接近1時， 你的結果的敏感度也會隨之改變，
就算beta改變得再小 所以如果beta從0.9增加到0.9005 這沒什麼大不了的，這幾乎不會對你的結果有影響 但是，如果beta從0.999增加到0.9995 這對你的演算法所做的
會有很大的影響，對吧 在這兩個情況，大概都是對10個值平均 但在這裡，這指數加權平均從 最後1000個的平均，變成最後2000個的平均 這是因為我們的公式，1 / 1- beta 當beta靠近1時，他對beta的改變非常的敏感 所以，這整個隨機取樣的方法所作的 是當beta靠近1時，讓你更密集地挑出beta 或換個方式說，當 1 - beta 靠近 0 的時候 所以你更有效地分配了你的取樣 更有效率地探索可能的結果 我希望這能幫助你選擇正確的尺度比例 來取樣超參數 萬一你沒有為某些超參數
決定好的尺度 也不用太過於擔心 就算你用了均勻的取樣，而實際上有些尺度 可能更適合，你仍然可能得到還不錯的結果 特別是當你用由粗糙到精細的搜索方式
所以在後期 你會更集中在比較有效的
超參數數值的範圍 我希望這能幫助你找尋超參數 在下一部影片，我也會分享一些想法，
關於該怎麼建立 搜尋超參數的程序 希望能讓你的流程更有效率