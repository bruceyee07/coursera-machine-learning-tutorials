En son videoda , soft master ve softmax etkilenim fonksiyonunu öğrendiniz. Bu videoda, softmax sınıflandırmasını daha derinleştireceksiniz ve ayrıca softmax katmanını kullanan eğitim modelinin nasıl olduğunu öğreneceksiniz. Geçen örnekteki,burdaki gibi çıktı katmanının hesapladığı z[L] i hatırlayalım. 4 tane sınıfımız var, c eşittir 4 ve z[L] 4 e 1(4,1) bir vektör ve y'nin üssünü alan geçici değişkeni hesaplayan t yi hesapladığımızı söyledik. Sonuç olarak, eğer çıktı katmanı için etkilenim fonksiyonu g[L] softmax etkilenim fonksiyonuysa,çıktı bu olacak. Basitçe geçici bir t değişkeni alıyoruz ve 1'in toplamına normalleştiriyoruz. Bu a(L) oluyor. z vektöründe, en büyük eleman 5 ve en büyük olasılık bu ilk olasılık olarak sonuçlandığına dikkat edin. softmax adı z vektörünü alan ve onu bu vektörle eşleştiren hard max le zıtlığından gelmektedir. Hard max fonksiyonu Z nin elemanına bakar ve z nin en büyük elemanının yerine 1 koyar diğer yerlere sıfır koyar. ve böylece bu bir en büyük eleman 1 çıktısı diğer elemanların 0 çıktısı alan çok hard max dır. Aksine, softmax z den bu olasılıklara daha yumuşak bir haritalamadır Bunun iyi bir ad olduğundan emin değilim fakat en azından,hard max a kıyasla neden buna softmax dediğimizin arkasındaki seziydi. ve benim göstermediğim fakat ima ettiğim şey softmax regresyonu ya da softmax teşhis fonksiyonu lojistik etkilenim fonksiyonunu sadece iki sınıf yerine C sınıflarına genelleştirir. Şöyle bir anlam çıkıyor eğer c ikiye eşitse, c nin ikiye eşit olmasıyla softmax lojistik regresyona dönüşür. bu videoda bunu kanıtlamıyacağım ama kaba taslak bir kanıt için eğer c ikiye eşitse ve softmax ı uygularsak çıktı katmanı a[L] 2 çıktı olacak eğer c ikiye eşitse belki çıktı 0.842 ve 0.158 olacak. ve bu sayıların toplamı daima 1 e eşittir. bu iki sayının toplamı 1 olduğu için, bular gereksizdir. ikisini de hesaplamaya gerek yok belkide bunların birini hesaplamak yeterlidir. Böylece,senin lojistik regresyona azalttığın hesaplamanın sonuçlandığı yol bunun tek çıktısını hesaplıyor. bu çok fazla kanıt değildi ama ikiden fazla sınıfa lojistik regresyonun softmax fonksiyonunun bir anafikriydi. Şimdi bir softmax çıktı katmanıyla nasıl yapay sinir aği eğitileceğini görelim. Özellikle, senin sinir ağını eğitirken kullandığın kayıp fonksiyonunu tannımlayalım. Hadi bir örnek alalım. hedef çıktının 0 1 0 0 olduğu eğitim setindeki bir örneğe bakalım. Önceki videodaki örnek, bunun anlamı bu bir kedi fotoğrafı çünkü sınıf 1 de yer alıyor. Ve şimdi sinir ağı çıktı olarak y şapka veriyor, y şapka toplamları 1 olan bir olasılık vektörü olabilir. 01.,0.4 toplamlarının bir olduğunu kontrol edebilirsiniz ve bu a[L] olacak. bu örnekte sinir ağı çok iyi yapamıyor çünkü bu gerçekten bir kedi ve kedi olma şansı %20 olarak belirlenmiş. bu örnekte çok iyi iş çıkaramadı. bu sinir ağını eğitmek için kayıp fonksiyonu neydi? Softmax sınıflandırmasında en son kullandığımız eksi j yi 1 den 4 e kadar toplamı. genelde bu 1 den c ye kadardır. burada 4 kulanacağız, yj logy şapka j neler olduğunu daha iyi anlamak için yukarıdaki örneğe bakalım. bu örnekte dikkat edin, y1 y3 y4 0 a eşit çünkü bunlar 0 ve sadece y2 1 e eşit. eğer bu toplama bakarsak, bütün terimler yj nin 0 olmasıyla 0 a eşit. tek kalan terim -y2 log y şapka2, çünkü j nin indeks toplamlarını kullanıyoruz j nin ikiye eşit olma durumu dışında bütün terimler 0 a eşit. y2 1 e eşit olduğu için, bu -log yşapka2. Bunun anlamı, eğer senin öğrenme algoritman bunu küçük yapmaya çalışıyorsa, çünkü eğitim setinde kaybı azaltmak için dereceli alçalma kullanıyorsun. Bunu küçültmenin tek yolu bunu küçültmektir. Bunun tek yolu y şapka 2 yi mümkün olduğunca büyük yapmak. bunlar asla birden büyük olamayan olasılıklar. bu anlamlı bu örnekte x bir kedi resmi ve mümkün olduğunca büyük bir olasılık çıktısı istiyorsunuz. Daha genel olarak, kayıp fonksiyonunun yaptığı,eğitim setinde gerçek sınıfında ne varsa, ve mümkün olduğunca yüksek bir olasılıkla cevap vermeye çalışıyor. Eğer maksimum olasılık tahmini istatistiğine aşnaysanız, bu bir maksimum olasılık tahmini formuna dönüşür. Eğer bunun anlamını bilmiyorsanız,endişelenmeyin. Bu konuştuğumuz sezgiler yeterlidir. Bu bir eğitim örneğindeki kayıp. Bütün eğitim setindeki maliyet J nasıldır. maliyetin bildiğiniz parametre ayarları buna benzer. tannımladığınız daha çok tahmin ettiğiniz bütün yollar ve önyargılar (bias) bütün eğitim setinin kaybının toplamı senin öğrenme algoritmanın tahminleri eğitim örneklerin toplamıdır. Her neyse... Yapacağımız şey dereceli alçalma kullanarak bu sınıfı küçültmeye çalışmak. Sonunda,Bir tane daha uygulama detayı. Dikkat edin c 4 e eşit ve y 4 e 1 vektör ve y şapka da 4 e 1 vektör. Eğer vektörleştirme kullanıyorsanız, Y matrisi y(1),y(2) ... y(m) e kadar yatay olarak kümelenecek. Örnek olarak ,eğer bu örnek ilk eğitim örneği olsaydı Y nin ilk kolonu 0 1 00 olacak ve ikinci örnek köpek belki üçüncü örnek yukarıdakilerin hiçbiri olmayacaktı. Ve Y matrisi 4 e m boyulu bir matris olacaktı. Benzer şekilde,Y şapka y hat 1 yatay olarak t şapka m e kadar kümeleştirilecek, bu aslında y şapka 1. İlk eğitim örneğinin bütün çıktısı y şapka 0.3 0.2 0.1 ve 0.4 ve böyle gidecek. ve y şapka 4 e m boyult bir matris olacak. Sonuç olarak, nasıl dereceli alçalmayı softmax çıktı katmanı olduğunda uygulayacağımızı görelim. bu çıktı katmanı c ye 1 yani 4 e 1 olan z[L] matrisini hesaplayacak sonra softmax etkilenim fonksiyonunu a[L] ya da y şapkayı bulmak için uygulayacağız. sonrasında kaybı hesaplayabileceğiz. Bir sinir ağında ileri yayılım adımlarını Böylece bu çıktıları almak ve kaybı hesaplamak için nasıl uygulayacağımızı konuştuk. Geri yayılım adımları ve dereceli alçaltma nasıldır. Anahtar adım ya da geri yayılımı başlatmak için gereken anahtar formül son katmanda z ye göre türevi olan bu ifadedir. 4 e 1 vektör olan y şapka - ay 4 e 1 vektörün hesabını yapabiliriz. Dikkat edin bütün bunlar 4 e 1 vektör olacak 4 sınıfımız olduğunda ve genel kullanım c e 1dir. bu bizim dz nin ne olduğunun klasik tanımına gidiyor, bu sınıf fonksiyonunun z[L] e göre parçalı türevidir. Eğer yüksek matematikte(calculus) uzmansanız kendiniz türevini alabilirsiniz. Eğer yüksek matematikte(calculus) uzmansanız, kendiniz türevi almayı deneyebilirsiniz, Fakat bu formülü kullanmakta sorun yok. Eğer bunu sıfırdan uygulamaya ihtiyacınız varsa. Bununla,dz[L] i hesaplayabilirsin ve sinir ağının baştan sona bütün türevleri hesaplamak için geri yayılım işlemini başlatabiliriz. Bu haftanın temel alıştırması, derin öğrenme program sistemlerini(framework) kullanmaya başlayacağız ve bu temel sistemler için genellikle sadece senin ileri yayılıma odaklanman gerekir. temel sistemi(framework) belirttiğiniz sürece, ileri yayılım geçişi, temel sistem(framework) geri yayılımın nasıl yapılacağını geriye doğru nasıl gidileceğini senin için bulacak. Bu ifadeyi aklında tutman iyi olur eğer softmax regresyonunu ya da softmax sınıflandırmasını 0 dan uygulaman gerekirse. Bu haftadaki temel alışırmada buna ihtiyacın olmayacak çünkü Senin kullandığın temel sistem(framework) bu türevleri senin için hesaplayacak. Softmax sınıflandırması bu kadar Bununla sen girdileri karakterize etmek için öğretme algoritmalarını uygulayabilirsin sadece 2 sınıftan birine değil c farklı sınıftan birine de yapabilirsin. Sonrasında,derin ögrenme algoritmalarını uygulama açısından sizi daha etkili yapan bazi derin öğrenme programlama sistemlerini(framework) göstermek istiyorum. Bunu tartışmak için hadi sonraki videoya geçelim.