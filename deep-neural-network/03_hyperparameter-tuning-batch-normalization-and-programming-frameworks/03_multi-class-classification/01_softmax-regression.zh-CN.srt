1
00:00:00,990 --> 00:00:04,140
到目前为止，我们已经讨论过的分类示例使用了

2
00:00:04,140 --> 00:00:08,410
二分类方法,也就是当你只有两类标签的情况

3
00:00:08,410 --> 00:00:10,520
这是猫,或者不是猫

4
00:00:10,520 --> 00:00:13,050
如果我们有多种可能的分类目标呢?

5
00:00:13,050 --> 00:00:17,140
有一种更普遍的逻辑回归的方法叫做softmax回归

6
00:00:17,140 --> 00:00:21,130
这种方法能够让你试图预测一个

7
00:00:21,130 --> 00:00:26,280
多种分类中的类别时做出预测,而不是识别两类中的类别

8
00:00:26,280 --> 00:00:26,915
让我们一起来看看让我们一起来看看

9
00:00:26,915 --> 00:00:31,264
假设你不单需要识别猫,你还需要识别狗

10
00:00:31,264 --> 00:00:31,984
和小鸡

11
00:00:31,984 --> 00:00:38,050
因此我将会把这个猫叫做类别1,狗就是类别2,小鸡就是类别3

12
00:00:38,050 --> 00:00:40,914
并且如果一个类别不属于上面这三种

13
00:00:40,914 --> 00:00:44,406
那么我们把它们分类成类别0

14
00:00:44,406 --> 00:00:49,900
这里显示的图片和他们对应的分类就是一个例子

15
00:00:49,900 --> 00:00:52,680
这一张是小鸡 因此它属于类别3

16
00:00:52,680 --> 00:00:57,395
猫是类别1,狗是类别2,而这个就是一只考拉

17
00:00:57,395 --> 00:01:02,498
它不属于任何一类 所以分为类别0
这是类别3 依次类推

18
00:01:02,498 --> 00:01:07,554
我们将使用一些缩写

19
00:01:07,554 --> 00:01:13,340
大写的C表示你将要预测的总的类别数

20
00:01:13,340 --> 00:01:17,628
这种情况下 你共有4个类别 其中包括了一类

21
00:01:17,628 --> 00:01:19,298
不属于3类任何一类

22
00:01:19,298 --> 00:01:23,921
那么当你有4个类别时 类别序号就是

23
00:01:23,921 --> 00:01:28,660
从0到C-1

24
00:01:28,660 --> 00:01:31,550
换句话说,就是0,1,2,3

25
00:01:31,550 --> 00:01:36,653
这种情况下,我们就需要构建一个新的神经网络
其中输出层是4个

26
00:01:36,653 --> 00:01:40,870
或者说有C个输出单元

27
00:01:43,140 --> 00:01:48,908
因此输出层L的单元数N等于4

28
00:01:48,908 --> 00:01:51,807
或者说等于C

29
00:01:51,807 --> 00:01:56,619
我们想得到的是输出层的单元告诉我们

30
00:01:56,619 --> 00:02:00,860
每个类别的概率

31
00:02:00,860 --> 00:02:04,320
因此这里的第一个单元应该输出的

32
00:02:04,320 --> 00:02:08,110
概率就是"其他"类别的概率

33
00:02:08,110 --> 00:02:12,840
给定输入x 网络这个节点就会输出概率为猫的概率

34
00:02:12,840 --> 00:02:16,980
这个就会输出x是狗的概率

35
00:02:16,980 --> 00:02:20,170
这个就会输出x是小鸡的概率

36
00:02:20,170 --> 00:02:27,910
这里我把小鸡简写为bc

37
00:02:29,160 --> 00:02:36,600
所以这里输出的层y^就是一个4*1维度的向量

38
00:02:36,600 --> 00:02:41,760
因为他有四个输出,代表四个概率

39
00:02:42,850 --> 00:02:48,070
由于输出的概率加和应该是1

40
00:02:48,070 --> 00:02:48,980
因此y^输出层的总和就应该是1

41
00:02:50,630 --> 00:02:55,390
标准化的做法就是使你的网络使用

42
00:02:55,390 --> 00:03:00,170
这里的softmax层,以及生成这些输出的层

43
00:03:00,170 --> 00:03:02,040
我们先把网络画下来 等下回来再看的时候

44
00:03:02,040 --> 00:03:04,680
就会对softmax的作用有一个直观的理解了

45
00:03:06,610 --> 00:03:08,940
在网络的最后一层

46
00:03:08,940 --> 00:03:13,360
你需要像往常那样计算每层的线性部分

47
00:03:13,360 --> 00:03:17,800
因此这个就是最后一层的变量

48
00:03:17,800 --> 00:03:21,980
请记住这个大写的L层

49
00:03:21,980 --> 00:03:26,619
像往常一样你计算w*L

50
00:03:26,619 --> 00:03:32,170
再乘以上一层输出的激活层加上一个偏差

51
00:03:32,170 --> 00:03:33,180
现在有了z

52
00:03:33,180 --> 00:03:37,690
现在你需要把这个softmax激活函数用起来

53
00:03:38,880 --> 00:03:43,340
这个激活函数和softmax层有一点不同

54
00:03:43,340 --> 00:03:44,150
但它就是这样

55
00:03:45,380 --> 00:03:50,081
首先我们计算一个临时的值

56
00:03:50,081 --> 00:03:54,180
这里我们把它叫做t 他是我写的这样的

57
00:03:54,180 --> 00:03:56,119
这适用于每个元素

58
00:03:56,119 --> 00:04:00,824
所以这里的zL就是4*1维度的

59
00:04:00,824 --> 00:04:03,470
这里是一个4维的向量

60
00:04:03,470 --> 00:04:08,720
所以这个t的公式就是对所有元素求幂

61
00:04:08,720 --> 00:04:13,100
t就是一个4*1的向量

62
00:04:13,100 --> 00:04:14,825
这个输出层a^[L]

63
00:04:14,825 --> 00:04:20,415
基本上就是t 但是需要归一化到1

64
00:04:20,415 --> 00:04:28,673
于是al就需要图中这样计算出来

65
00:04:28,673 --> 00:04:33,994
由于我们有四个类别

66
00:04:33,994 --> 00:04:40,082
也就是说我们想要aL层也是一个4*1层的向量

67
00:04:40,082 --> 00:04:44,780
第i个元素的向量

68
00:04:44,780 --> 00:04:50,885
写出来就是

69
00:04:50,885 --> 00:04:56,660
需要如图中这样计算

70
00:04:56,660 --> 00:04:58,690
为了避免数学公式不够清晰

71
00:04:58,690 --> 00:05:02,320
我们接下来将展示一个例子来解除大家的疑惑

72
00:05:02,320 --> 00:05:03,835
为了避免大家不明白

73
00:05:03,835 --> 00:05:06,775
现在让我们来看一个特殊的例子

74
00:05:06,775 --> 00:05:10,905
假设你计算出了zL

75
00:05:10,905 --> 00:05:18,277
而zL是一个4维的向量

76
00:05:18,277 --> 00:05:22,256
我们将要使用这个针对每个元素计算的幂

77
00:05:22,256 --> 00:05:23,665
计算这个向量t

78
00:05:23,665 --> 00:05:29,465
所以t就是这几个e的指数形式

79
00:05:29,465 --> 00:05:32,529
如果你使用计算器计算一下,你就得到了想要的值

80
00:05:32,529 --> 00:05:38,750
e^5就是148.4 e^2就是7.4

81
00:05:38,750 --> 00:05:44,697
e^-1就是0.4 e^3就是20.1

82
00:05:44,697 --> 00:05:49,519
于是根据向量t得到aL的方法就是

83
00:05:49,519 --> 00:05:52,910
把输入的归一化到1

84
00:05:52,910 --> 00:05:56,808
如果你把t的值加起来

85
00:05:56,808 --> 00:06:03,232
大概就是176.3

86
00:06:03,232 --> 00:06:09,565
最后aL就是这个向量t

87
00:06:09,565 --> 00:06:14,515
整体除以176.3

88
00:06:14,515 --> 00:06:18,580
举个例子,这里的第一个数就是

89
00:06:18,580 --> 00:06:23,885
e^5除以176.3

90
00:06:23,885 --> 00:06:27,777
结果就是0.842

91
00:06:27,777 --> 00:06:32,675
也就是说加入这个是z的值

92
00:06:32,675 --> 00:06:36,434
那么也就是说图片属于类别0的概率是84.2％

93
00:06:36,434 --> 00:06:42,192
下一个节点就是e^2除以176.3

94
00:06:42,192 --> 00:06:48,200
结果就是0.042 所以就是4.2％的概率

95
00:06:48,200 --> 00:06:53,449
下一个就是e^-1除以这个数

96
00:06:53,449 --> 00:06:56,891
就是0.002

97
00:06:56,891 --> 00:07:04,235
最后一个就是e^3除以这个数就是0.0.114

98
00:07:04,235 --> 00:07:08,312
也就是11.4%的概率是类别3

99
00:07:08,312 --> 00:07:10,683
也就是小鸡的概率

100
00:07:10,683 --> 00:07:15,568
所以我们就得到了类别0,1,2,3的概率

101
00:07:15,568 --> 00:07:21,930
神经网络aL的输出 也就是y^

102
00:07:21,930 --> 00:07:25,170
就是4*1维的向量

103
00:07:25,170 --> 00:07:29,800
其中的元素就是这里的4个数

104
00:07:29,800 --> 00:07:31,060
然后我们来计算它然后我们来计算它

105
00:07:31,060 --> 00:07:38,077
这个算法通过向量zL计算出总和为1的四个概率

106
00:07:38,077 --> 00:07:43,013
并且如果我们总结一下从zL到aL的计算过程

107
00:07:43,013 --> 00:07:47,741
这整个的计算过程从计算幂

108
00:07:47,741 --> 00:07:52,469
到得出临时变量 再做归一化

109
00:07:52,469 --> 00:07:57,827
我们可以把这个过程总结为一个softmax激活函数

110
00:07:57,827 --> 00:08:03,625
假设aL等于向量zL的激活函数g

111
00:08:03,625 --> 00:08:08,379
这个激活函数不同之处在于

112
00:08:08,379 --> 00:08:12,654
这个函数g需要输入一个4*1的向量

113
00:08:12,654 --> 00:08:15,060
也会输出一个4*1的向量

114
00:08:15,060 --> 00:08:19,280
以前我们的激活通常是接收单行输入

115
00:08:19,280 --> 00:08:20,875
比如 sigmoid函数和ReLU函数就是接收一个实数输入

116
00:08:20,875 --> 00:08:24,840
然后输出一个实数的输出

117
00:08:24,840 --> 00:08:28,255
softmax函数的不同之处就是

118
00:08:28,255 --> 00:08:32,262
由于它需要把输出归一化

119
00:08:32,262 --> 00:08:35,365
以及输入输出都是向量

120
00:08:35,365 --> 00:08:39,219
因此softmax分类器还能代表什么呢?

121
00:08:39,219 --> 00:08:43,383
现在我将向你们展示一些例子 其中输入是x1和x2

122
00:08:43,383 --> 00:08:48,435
这些输入直接送入一个softmax层

123
00:08:48,435 --> 00:08:53,500
它有三四个或者更多的输出节点

124
00:08:53,500 --> 00:08:58,801
所以我将会向你展示一个没有隐藏层的网络

125
00:08:58,801 --> 00:09:04,777
他的作用就是计算z1=w1*x+b

126
00:09:04,777 --> 00:09:07,359
输出的a1

127
00:09:07,359 --> 00:09:13,210
或者说y^就是在z1上使用softmax激活函数

128
00:09:13,210 --> 00:09:15,615
所以这个没有隐藏层的神经网络

129
00:09:15,615 --> 00:09:20,260
应该可以让你有一个关于softmax函数意义的直观感觉

130
00:09:20,260 --> 00:09:23,677
这里是一个例子:输入x1和x2

131
00:09:23,677 --> 00:09:28,662
一个输出类别C=3的softmax层可以代表

132
00:09:28,662 --> 00:09:31,661
这种形式的决策边界

133
00:09:31,661 --> 00:09:35,289
请注意这是一种线性决策边界

134
00:09:35,289 --> 00:09:39,223
但是它可以把我们的数据区分为三类

135
00:09:39,223 --> 00:09:44,126
这个图中我们所做的就是

136
00:09:44,126 --> 00:09:47,335
选择图中展示的训练数据

137
00:09:47,335 --> 00:09:52,079
使用数据的三种标签训练这个softmax分类器

138
00:09:52,079 --> 00:09:54,750
图中的颜色显示了

139
00:09:54,750 --> 00:09:59,330
分类器输出的阈值

140
00:09:59,330 --> 00:10:03,790
输入的颜色是基于三种输出中概率最高的那种

141
00:10:03,790 --> 00:10:07,917
这就是一种泛化的逻辑回归

142
00:10:07,917 --> 00:10:11,182
它使用一类似种线性的决策边界

143
00:10:11,182 --> 00:10:16,065
分类结果不只是只有0和1的两类结果 还可以是0,1,2

144
00:10:16,065 --> 00:10:20,238
这是softmax可以代表决策边界的另一个例子

145
00:10:20,238 --> 00:10:23,625
使用三个分类

146
00:10:23,625 --> 00:10:28,731
这里还有另一种 就像图中右边这样

147
00:10:28,731 --> 00:10:34,211
但是直觉告诉我们两类之间的决策边界是线性的

148
00:10:34,211 --> 00:10:38,325
这就是为什么你看的例子中

149
00:10:38,325 --> 00:10:42,312
黄色和其他分类之间的分类界面是线性的

150
00:10:42,312 --> 00:10:46,949
紫色和红色直接也是线性的 黄色和紫色之间也是线性的

151
00:10:46,949 --> 00:10:49,729
但是它能使用这照片不同的线性函数

152
00:10:49,729 --> 00:10:52,660
来把数据区分为不同类别

153
00:10:52,660 --> 00:10:55,460
我们来看一个有更多分类的例子

154
00:10:55,460 --> 00:10:58,199
这是一个有分类数C=4的例子

155
00:10:58,199 --> 00:11:03,096
其中绿色的类别和softmax仍然可以代表线

156
00:11:03,096 --> 00:11:07,280
不同类别直接的线性决策平面

157
00:11:07,280 --> 00:11:11,796
这是另一个例子 其中C=5

158
00:11:11,796 --> 00:11:15,190
这是另一个例子 其中C=6

159
00:11:15,190 --> 00:11:20,184
这些图展示了softmax分类器在没有隐藏层的时候

160
00:11:20,184 --> 00:11:24,545
可以做什么 当然有的网络会更深

161
00:11:24,545 --> 00:11:28,860
有更多的隐藏层 以及更多的隐藏单元

162
00:11:28,860 --> 00:11:32,850
然后你就可以发现更复杂的非线性决策平面来区分

163
00:11:32,850 --> 00:11:34,065
这些不同的类别

164
00:11:35,240 --> 00:11:37,990
我希望这部分的讲解可以让你直观的理解在网络中的

165
00:11:37,990 --> 00:11:41,820
softmax激活函数的工作原理

166
00:11:41,820 --> 00:11:42,650
这里这个

167
00:11:42,650 --> 00:11:46,940
下个视频我们来看一下如何训练
一个带有softmax层的神经网络