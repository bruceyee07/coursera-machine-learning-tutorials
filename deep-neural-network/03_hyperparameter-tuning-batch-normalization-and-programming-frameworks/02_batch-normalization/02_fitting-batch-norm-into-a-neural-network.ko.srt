1
00:00:00,000 --> 00:00:02,115
여러분은 한가지 숨겨진 층에 대해 

2
00:00:02,115 --> 00:00:05,020
배치 정규화를 개발하는 공식을 보았는데요, 

3
00:00:05,020 --> 00:00:08,610
심층신경망의 트레이닝에는 어떻게 피팅되는지 한번 보겠습니다.

4
00:00:08,610 --> 00:00:10,969
그럼 이렇게 생긴 신경망이 있다고 가정해보겠습니다.

5
00:00:10,969 --> 00:00:16,395
여러분은 제가 이런 개별 유닛을 2가지를 계산한다는 것으로 보면 되다고 이야기한 것을
들으셨을텐데요, 

6
00:00:16,395 --> 00:00:22,960
첫번째로, z의 값을 계산하고 다음으로 activation 함수를 적용하여 A를 구합니다.

7
00:00:22,960 --> 00:00:31,005
그러면 여기 각각의 동그라미를 2가지 계산을 대표한다고 생각하면 됩니다.

8
00:00:31,005 --> 00:00:33,130
다음층도 이와 비슷하게, 

9
00:00:33,130 --> 00:00:41,125
z21, a21 등등 말이죠, 

10
00:00:41,125 --> 00:00:45,250
그러므로 여러분이 배치 정규화를 적용하지 않는 것이면,

11
00:00:45,250 --> 00:00:50,935
x가 첫번째 숨겨진 유닛으로 삽입되고, 

12
00:00:50,935 --> 00:00:53,395
먼저 z1의 값을 산출하고, 

13
00:00:53,395 --> 00:00:57,940
이 값은 파라미터 w1, b1에 따라 달라집니다.

14
00:00:57,940 --> 00:01:04,630
그리고 보통은 z1을 activation 함수에 삽입하여 A1의 값을 구할 것입니다.

15
00:01:04,630 --> 00:01:09,165
하지만 배치 정규화에서 할 것은 여기 z1의 값을 갖고,

16
00:01:09,165 --> 00:01:12,975
배치 정규화를 적용시킬 것입니다.

17
00:01:12,975 --> 00:01:16,935
가끔씩 BN으로 줄여서 부릅니다.

18
00:01:16,935 --> 00:01:19,685
그리고 이 값은 파라미터

19
00:01:19,685 --> 00:01:23,465
베타1과 감마 1에 의해 지배될 것입니다.

20
00:01:23,465 --> 00:01:28,340
그러면 여기 새롭게 정규화된 z1 값을 줄 것입니다.

21
00:01:28,340 --> 00:01:32,930
그리고 이 값을 activation 함수에 삽입합니다. A1의 값을 갖기 위해서 말이죠. 

22
00:01:32,930 --> 00:01:38,355
이 값은 g1 (z tilde 1)입니다.

23
00:01:38,355 --> 00:01:41,770
그러면 이제 첫번째 층에 대한 계산을 마쳤는데요, 

24
00:01:41,770 --> 00:01:47,520
Z와 A사이에서 실제로 산출 과정에서 배치 정규화이 발생합니다.

25
00:01:47,520 --> 00:01:53,785
다음으로 여기 A1값을 갖고 z2를 계산합니다.

26
00:01:53,785 --> 00:01:58,115
이제 그러면 이 값은 w2, b2에 의해 결정되겠죠. 

27
00:01:58,115 --> 00:02:01,125
그리고 첫번째 층에서 했던 것과 같이 비슷하게, 

28
00:02:01,125 --> 00:02:06,470
z2의 값을 갖고, 배치 정규화에 적용시킵니다. 이것은 이제 BN으로 줄여서 쓰죠.

29
00:02:06,470 --> 00:02:11,575
이것은 다음 층에 특정한 배치 정규화 파라미터에 의해 지배됩니다.

30
00:02:11,575 --> 00:02:14,580
즉, 베타2와 감마2 겠죠.

31
00:02:14,580 --> 00:02:17,845
그럼 이제 z tilde 2의 값을 얻을텐데요, 

32
00:02:17,845 --> 00:02:25,220
이제 이 값을 이용해서 a2를 구합니다. activation 함수를 이용해서 말이죠,

33
00:02:25,220 --> 00:02:31,960
다시 한번, 배치 정규화는 Z와 A를 계산하는 사이에서 발생합니다.

34
00:02:31,960 --> 00:02:33,260
그럼 직관적인 부분은, 

35
00:02:33,260 --> 00:02:36,115
정규화가 안된 Z의 값을 사용하는 대신에,

36
00:02:36,115 --> 00:02:40,360
정규화 Z tilde값을 사용할 수 있으면, 그것은 첫번째 층이겠죠. 

37
00:02:40,360 --> 00:02:41,480
두번째 층에서도, 

38
00:02:41,480 --> 00:02:44,310
마찬가지로 정규화 안된 Z2값을 사용하는 대신에,

39
00:02:44,310 --> 00:02:48,990
평균값고 variance가 정규화된 Z tilde 2값을 이용할 수 있습니다

40
00:02:48,990 --> 00:02:56,320
그러면 파라미터의 네트워크는 w1, b1이 될 것입니다.

41
00:02:56,320 --> 00:03:00,355
저희는 파라미터 들을 없앨 것인데요, 그 이유는 다음 슬라이드에서 보겠습니다.

42
00:03:00,355 --> 00:03:06,740
일단은 파라미터가 기존 w1, b1,wl,의 

43
00:03:06,740 --> 00:03:12,260
값이라고 생각하겠습니다. 그리고 여기 새로운 네트워크에

44
00:03:12,260 --> 00:03:14,420
추가적인 파라티머 베타1, 

45
00:03:14,420 --> 00:03:18,290
감마1, 베타2 , 감마2를 더했습니다.

46
00:03:18,290 --> 00:03:24,283
여러분이 배치 정규화를 더하는 각각의 층에 말이죠. 

47
00:03:24,283 --> 00:03:26,630
명료성을 위해 여기 베타를 보십시오, 

48
00:03:26,630 --> 00:03:30,800
여기 값은 여러 기하급수적 가중 평균을 구했을 때 산출했던 모멘텀에서

49
00:03:30,800 --> 00:03:36,165
있었던 하이퍼 파라미터 베타와는 상관이 없습니다.

50
00:03:36,165 --> 00:03:42,620
Adam paper의 저자들은 베타를 사용해서 하이퍼 파라미터를 표기합니다.

51
00:03:42,620 --> 00:03:47,405
그리고 배치 정규화 paper의 저자들은 여기 이 파라미터를 나타내기위해 
베타를 썼고요, 

52
00:03:47,405 --> 00:03:49,630
하지만 여기 2개는 완전히 다른 베타들입니다.

53
00:03:49,630 --> 00:03:53,300
저는 2개의 경우 모두에서 베타를 쓰기로 했는데요, 

54
00:03:53,300 --> 00:03:55,114
논문을 읽으시면, 

55
00:03:55,114 --> 00:03:57,230
베타1, 

56
00:03:57,230 --> 00:03:58,535
베타2 등등과 같이, 

57
00:03:58,535 --> 00:04:02,650
배치 정규화가 배우려고 하는 것은 다른 베타입니다.

58
00:04:02,650 --> 00:04:10,055
모멘텀 에서 사용된 하이퍼 파라미터 Adam과 RmsProp 알고리즘에서의 베타와 비교하였을 때 말이죠,

59
00:04:10,055 --> 00:04:14,795
그러면 이제 이러한 것들이 알고리즘의 새로운 파라미터기 때문에,  

60
00:04:14,795 --> 00:04:18,065
이제 어떤 최적화 방법을 사용할 것입니다.

61
00:04:18,065 --> 00:04:21,710
도입하기 위해 기울기 강하 와 같은 방법을 말이죠. 

62
00:04:21,710 --> 00:04:26,885
예를 들어, 어떤 층에 대해 d 베타 l을 계산할 수 있겠죠, 

63
00:04:26,885 --> 00:04:28,720
그 후로, 파라미터를 업데이트 하는데요, 

64
00:04:28,720 --> 00:04:32,270
베타는 베타 빼기 러닝속도 곱하기

65
00:04:32,270 --> 00:04:37,415
d 곱하기 베타 L로 업데이트되는데요, 

66
00:04:37,415 --> 00:04:43,405
여러분은 Adam 이나 RmsProp 또는 모멘텀을 사용해서 베타나 감마와 같안
파라미터를 업데이트할 수 있습니다.

67
00:04:43,405 --> 00:04:45,575
기울기 강하뿐만 아니고요. 

68
00:04:45,575 --> 00:04:48,065
그리고 이번 비디오에서는, 

69
00:04:48,065 --> 00:04:51,570
배치 정규화가 하는 일을 설명 드렸는데요, 

70
00:04:51,570 --> 00:04:55,590
평균값, variance를 계산하고 이 값을 빼고 나눈다고 했는데, 

71
00:04:55,590 --> 00:05:00,625
딥러닝 프로그래밍 프레임웍을 쓰는 경우엔, 

72
00:05:00,625 --> 00:05:06,485
보통은 배치 정규화 단계 또는 배치 정규화 레이어를 본인이 직접 도입할 필요가 없을 것입니다.

73
00:05:06,485 --> 00:05:07,840
그래서 프로빙 프레임웍은, 

74
00:05:07,840 --> 00:05:09,990
이것은 한줄의 코드일 수 있는데요,

75
00:05:09,990 --> 00:05:13,140
예를 들어서, tensor flow 프레임웍 같은 경우,

76
00:05:13,140 --> 00:05:17,490
여기 이 함수를 이용해서 배치 정규화를 도입할 수 있습니다.

77
00:05:17,490 --> 00:05:19,530
프로그래밍 프레임웍에 대해서는 나중에 더 이야기 하겠습니다.

78
00:05:19,530 --> 00:05:24,435
하지만 실제로는 여기 이런 상세한 부분들은 본인이 직접 도입할 필요가 없을 것입니다. 

79
00:05:24,435 --> 00:05:27,480
여러분이 이것이 어떻게 작동하는지 이해하고 

80
00:05:27,480 --> 00:05:30,930
코드가 무엇을 하는지 배우는 것입니다.

81
00:05:30,930 --> 00:05:36,805
그런데 배치 정규화를 도입하는 것은 딥러닝 프레임웍에서 보통 한줄의 코드입니다.

82
00:05:36,805 --> 00:05:40,560
현재까지 배치 정규화가 마치 전체 트레이닝 세트에서 한번에 트레이닝

83
00:05:40,560 --> 00:05:45,390
시키는 것처럼 이야기 했는데요, 마치 배치 기울기 강하를 쓰는 것처럼 말이죠. 

84
00:05:45,390 --> 00:05:51,720
실제로는, 배치 정규화는 보통 트레이닝 세트의 미니 배치와 같이 적용됩니다.

85
00:05:51,720 --> 00:05:54,360
그러면 배치 정규화를 적용하는 방식은

86
00:05:54,360 --> 00:05:59,830
첫번째 미니 배치를 가지고 z1을 계산합니다.

87
00:05:59,830 --> 00:06:03,460
w1과 b1 파라미터를 사용해서 이전 슬라이드에서 한 것 처럼 말이죠, 

88
00:06:03,460 --> 00:06:11,365
그 다음 이 미니 배치를 가지고 Z1의 평균값과 variance

89
00:06:11,365 --> 00:06:14,695
구합니다. z1에서 말이죠. 그러면 

90
00:06:14,695 --> 00:06:21,580
배치 정규화는 평균값에서 빼지고 표준편차로 나뉘면서 베타 1,감마 1의 값으로 re-scale되어

91
00:06:21,580 --> 00:06:24,490
z1의 값을 줄 것입니다.

92
00:06:24,490 --> 00:06:27,375
이 모든 것은 그러면 첫번째 미니 배치에 있겠죠. 

93
00:06:27,375 --> 00:06:33,325
그 이후에, activation 함수를 적용하여 A1을 구합니다.

94
00:06:33,325 --> 00:06:38,110
그 다음, w2, b2 등을 이용하여 

95
00:06:38,110 --> 00:06:41,190
z2를 구합니다.

96
00:06:41,190 --> 00:06:45,360
그러면 여러분은 이 모든 것을 첫번째 미니 배치에서의 기울기 강하 적용하기 위해 

97
00:06:45,360 --> 00:06:50,660
진행한 것인데요, 그 다음에 두번째 미니 배치 인 x2로 넘어갑니다.

98
00:06:50,660 --> 00:06:54,190
여기서도 비슷하게 하는데요, 이제는 두번째 미니 배치에서

99
00:06:54,190 --> 00:06:59,085
z1을 계산하고, 배치 정규화를 이용해서 z1 tilde를 구합니다.

100
00:06:59,085 --> 00:07:02,390
그러면 여기 배치 정규화 단계에서

101
00:07:02,390 --> 00:07:08,890
단순히 두번째 미니 배치에 있는 데이터만을 이용해서 z tilde를 종교화합니다. 

102
00:07:08,890 --> 00:07:10,640
그럼 여기 배치 정규화 단계에서, 

103
00:07:10,640 --> 00:07:13,580
두번째 mini-batch의 example을 볼텐데요

104
00:07:13,580 --> 00:07:18,320
z1의 평균값과 variance을 계산하는데요,

105
00:07:18,320 --> 00:07:24,175
그 다음에 베타와 감마로 re-scaling하여 z tilde를 얻습니다.

106
00:07:24,175 --> 00:07:28,840
그리고 이것을 세번째 미니 배치에서도 하여 계속 트레이닝합니다.

107
00:07:28,840 --> 00:07:34,415
parameterization 에서 한가지 정리하고 싶은 상세 부분이 있는데요

108
00:07:34,415 --> 00:07:38,990
이전에 저는파라미터가 각각의 층에 대해서 

109
00:07:38,990 --> 00:07:43,640
wl, bl, 그리고 베타 l, 그리고 

110
00:07:43,640 --> 00:07:50,900
감마 L이라고 했는데요, z가 계산된 방식을 한번 보겠습니다.

111
00:07:50,900 --> 00:08:00,590
ZL = WL x A of L - 1 + B of L 인데요, 그런데 배치 정규화 이 

112
00:08:00,590 --> 00:08:02,985
하는 것은 미니 배치를 보고나서 ZL을 첫번째 평균값 0

113
00:08:02,985 --> 00:08:06,515
그리고 표준편차로 정규화하고나서,

114
00:08:06,515 --> 00:08:09,275
베타와 감마로 re-scale할 것입니다.

115
00:08:09,275 --> 00:08:10,745
이것이 뜻하는 바는, 

116
00:08:10,745 --> 00:08:15,125
bl이 어떤 값을 갖더라도, 이 것은 빠질 것입니다.

117
00:08:15,125 --> 00:08:17,735
그 이유는 배치 정규화 단계에서, 

118
00:08:17,735 --> 00:08:22,090
ZL의 평균값을 구한 뒤에, 평균값을 뺄 것이기 때문입니다.

119
00:08:22,090 --> 00:08:27,675
그러므로 여기 모든 미니 배치 예제에서 상수를 더하는 것은 

120
00:08:27,675 --> 00:08:28,865
아무 변화도 일으키지 않습니다.

121
00:08:28,865 --> 00:08:34,170
그 이유는 상수가 더해지더라도 평균값이 빼지므로 그 효과가 캔슬되기 때문입니다.

122
00:08:34,170 --> 00:08:35,960
그러므로 배치 정규화를 쓰는 경우,

123
00:08:35,960 --> 00:08:38,225
이 파라미터를 제거할 수 있습니다.

124
00:08:38,225 --> 00:08:42,020
아니면 원할 경우, 이것을 영구적으로 0으로 설정하는 것을 생각해보십시요.

125
00:08:42,020 --> 00:08:49,235
그러면 zl의 parameterization wl 곱하기 al 빼기 1이 됩니다.

126
00:08:49,235 --> 00:08:54,375
그 다음에는 ZL 정규화값을 구하는데요, 

127
00:08:54,375 --> 00:09:04,610
그 다음 z tilde값은 가마 ZL 더하기 베타인데요

128
00:09:04,610 --> 00:09:09,080
여기 베타 L 파라미터를 쓰게 됩니다. z tilde l의 평균값

129
00:09:09,080 --> 00:09:15,095
을 정하기 위해서 말이죠.  그 다음 이 값이 다음 층으로 넘어갑니다.

130
00:09:15,095 --> 00:09:16,430
복습하자면,

131
00:09:16,430 --> 00:09:24,020
배치 정규화는 평균값을 0으로 만들기 때문에, 여기 층에 있는 ZL 값들에 대해서 말이죠.

132
00:09:24,020 --> 00:09:27,445
그렇기 때문에 여기 BL 파라미터를 갖는 의미가 없습니다.

133
00:09:27,445 --> 00:09:29,400
그러므로 그냥 없애는 것입니다.

134
00:09:29,400 --> 00:09:32,330
그리고 대신해서 베타 L로 대체되었습니다.

135
00:09:32,330 --> 00:09:39,050
베타 L은 이동이나 bias 항들에 영향을 주는 파라미터입니다.

136
00:09:39,050 --> 00:09:43,250
마지막으로 ZL의 다이멘션은 

137
00:09:43,250 --> 00:09:45,255
하나의 예시에서 진행할 경우, 

138
00:09:45,255 --> 00:09:48,255
그 값은 NL x 1 인데요

139
00:09:48,255 --> 00:09:53,270
그러면 BL 은 다이멘션 NL x 1인데요, 

140
00:09:53,270 --> 00:09:56,365
만약 NL이 l층에서의 숨겨진 유닛개수라고 하면

141
00:09:56,365 --> 00:10:00,230
말이죠. 그러면 베타 L과 감마 L의 디아멘션도 역시

142
00:10:00,230 --> 00:10:07,575
마찬가지로 NL x 1이 될것입니다. 그 이유는 이것이 숨겨진 유닛의 개수이기 때문입니다.

143
00:10:07,575 --> 00:10:12,555
NL개의 숨겨진 유닛이 있고, 각각의 숨겨진 유닛에 대해서 

144
00:10:12,555 --> 00:10:14,670
베타 L, 감마 L을 통해 평균값과 variance이 

145
00:10:14,670 --> 00:10:19,195
scale 되는 것입니다. 네트워크가 원하는 설정값대로 말이죠. 

146
00:10:19,195 --> 00:10:21,990
이제 그러면 모든 것들을 취합해서 

147
00:10:21,990 --> 00:10:25,195
배치 정규화를 이용해서 기울기 강하를 도입하는 방법을 보겠습니다.

148
00:10:25,195 --> 00:10:28,925
여러분이 미니 배치 기울기 강하를 사용한다는 가정하에

149
00:10:28,925 --> 00:10:34,245
T=1에서 미니 배치 숫자 까지  반복하는데요,

150
00:10:34,245 --> 00:10:39,265
그리고 미니 배치 XT에 대해서

151
00:10:39,265 --> 00:10:44,635
전 방향전파을 도입할텐데요, 그리고 각각의 숨겨진 유닛에 대해서 

152
00:10:44,635 --> 00:10:50,330
전 방향전파을 하는 것은 ZL을 Z tilde L로 

153
00:10:50,330 --> 00:10:57,265
바꾸기 위해 배치 정규화를 사용하십시오. 그러면 여기 미니 배치 안에서

154
00:10:57,265 --> 00:11:02,810
z의 값은 정규화된 평균값과 variance를 갖게 되는데요, 

155
00:11:02,810 --> 00:11:09,200
여기 값과 버전은 z tilde l이 됩니다.

156
00:11:09,200 --> 00:11:17,025
그 다음에 후 방향전파를 이용해서 dw,db, 

157
00:11:17,025 --> 00:11:20,065
그리고 모든 l의 값에 대해서

158
00:11:20,065 --> 00:11:23,530
d 베타, d 감마,

159
00:11:23,530 --> 00:11:26,805
사실 엄밀히 이야기하면, B를 없앴으므로, 

160
00:11:26,805 --> 00:11:28,494
이거는 사실 사라집니다.

161
00:11:28,494 --> 00:11:33,595
마지막으로 파라미터를 업데이트 시킵니다.

162
00:11:33,595 --> 00:11:40,085
그러면 w 는 w 빼기 러닝속도 곱하기, 이걸로 이전과 같이 말이죠, 그리고 

163
00:11:40,085 --> 00:11:47,775
베타는 베타 빼기 러닝속도 곱하기 db

164
00:11:47,775 --> 00:11:49,595
감마도 비슷하게 계산합니다.

165
00:11:49,595 --> 00:11:52,770
그리고 여러분이 기울기를 이와 같이 계산한 경우, 

166
00:11:52,770 --> 00:11:54,805
기울기 가하를 이용할 수 있습니다.

167
00:11:54,805 --> 00:11:56,910
여기 그렇게 적은 것이고요, 

168
00:11:56,910 --> 00:12:01,845
하지만 이것은 기울기 강하 와 모멘텀에서도 잘 작동합니다.

169
00:12:01,845 --> 00:12:07,200
또는 RmsProp 또는 Adam에서도 말이죠. 

170
00:12:07,200 --> 00:12:08,890
여기 기울기 강하 업데이트를 갖는 대신에, 

171
00:12:08,890 --> 00:12:11,220
여기 다른 알고리즘에서 주어진.

172
00:12:11,220 --> 00:12:16,615
업데이트를 이용할 수 있습니다. 지난 비디오에서 다뤘던 것과 같이 말이죠. 

173
00:12:16,615 --> 00:12:19,790
여기 다른 최적화 알고리즘은 베타와 감마와 같은 배치 정규화가 알고리즘에 더한
것들을 이용해서 파리미터를

174
00:12:19,790 --> 00:12:25,730
업데이트 하는데 사용될 수도 있습니다.

175
00:12:25,730 --> 00:12:27,780
바라건대 이 내용이 여러분이 

176
00:12:27,780 --> 00:12:30,375
배치 정규화를 처음부터 도입하는 방법을 익히는데 도움이 됐기 바랍니다.

177
00:12:30,375 --> 00:12:31,530
여러분이 만약에 

178
00:12:31,530 --> 00:12:34,455
딥러닝 프로그래밍 프레입웍을 쓰는 경우, 나중에 이야기 하겠지만

179
00:12:34,455 --> 00:12:37,700
이상적으로 여러분이 다른 사람의 프로그래밍

180
00:12:37,700 --> 00:12:41,720
프레임웍 도입을 불러서 배치 정규화를 더 쉽게 만들 수 있습니다.

181
00:12:41,720 --> 00:12:45,515
아직 배치 정규화에 대한 내용이 조금 이해하기 어려우시면 

182
00:12:45,515 --> 00:12:49,375
왜 트레이닝 속도를 드라마틱하게 올려주는지 잘 모르겠으면

183
00:12:49,375 --> 00:12:52,140
다음 비디오로 넘어가서

184
00:12:52,140 --> 00:12:55,210
왜 배치 정규화가 잘 작동하는지 무엇을 하는지 이야기 해보겠습니다.