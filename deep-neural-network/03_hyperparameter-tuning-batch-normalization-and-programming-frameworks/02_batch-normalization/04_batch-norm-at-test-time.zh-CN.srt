1
00:00:00,000 --> 00:00:03,685
批标准化每次处理一个最小批的数据

2
00:00:03,685 --> 00:00:07,760
但是在测试时你大概会需要一个一个实例来处理

3
00:00:07,760 --> 00:00:10,585
我们来看一下你如何修改神经网络来实现这一功能

4
00:00:10,585 --> 00:00:12,233
回忆一下 在训练时

5
00:00:12,233 --> 00:00:15,260
这些是我们在实现批标准化时用到的等式

6
00:00:15,260 --> 00:00:17,025
在一个最小批中

7
00:00:17,025 --> 00:00:22,610
我们会把最小批中的ZI值加和来得到平均值

8
00:00:22,610 --> 00:00:25,910
在这里 我们就把最小批里所有的实例加和

9
00:00:25,910 --> 00:00:28,440
我这里用M来表示

10
00:00:28,440 --> 00:00:31,870
最小批里面而不是所有训练集里面实例的个数

11
00:00:31,870 --> 00:00:35,955
接下来我们来计算方差 然后再

12
00:00:35,955 --> 00:00:41,325
通过比例缩放平均数和标准差来计算Z_norm 注意我们加上epsilon是为了数值稳定性

13
00:00:41,325 --> 00:00:47,100
然后我们把Z_norm乘以gamma加上beta来得到Z_total

14
00:00:47,100 --> 00:00:51,995
所以 注意到我们计算缩放比例所需要的mu和sigma平方

15
00:00:51,995 --> 00:00:57,620
是在整个最小批上计算的

16
00:00:57,620 --> 00:01:00,495
但是在测试时你可能并没有一个最小批的

17
00:01:00,495 --> 00:01:05,240
64 128 或者256个实例来同时处理

18
00:01:05,240 --> 00:01:07,815
所以你需要一种不同的方式来得到mu和sigma平方

19
00:01:07,815 --> 00:01:10,290
如果你只有一个实例

20
00:01:10,290 --> 00:01:15,060
那么计算这一个实例的平均值和标准差显然是不合理的

21
00:01:15,060 --> 00:01:16,860
所以实际上该如何做呢？

22
00:01:16,860 --> 00:01:21,240
以便于我们在测试时使用我们的神经网络

23
00:01:21,240 --> 00:01:25,735
我们需要一种单独的方式来估算mu和sigma平方

24
00:01:25,735 --> 00:01:27,975
在批标准化的通常实现中

25
00:01:27,975 --> 00:01:32,145
我们是通过

26
00:01:32,145 --> 00:01:37,020
指数加权平均数来估算的

27
00:01:37,020 --> 00:01:42,678
这个平均数是根据最小批来计算的

28
00:01:42,678 --> 00:01:45,900
我们来非常具体地看一下我的意思

29
00:01:45,900 --> 00:01:51,750
我们来选取一层L 假设我们现在在处理最小批X^{1} X^{2} 等等

30
00:01:51,750 --> 00:01:57,500
以及它们相对应的Y值

31
00:01:57,500 --> 00:02:02,280
在用X^{1}训练L层时

32
00:02:02,280 --> 00:02:06,383
我们得到一个mu^[l] (如图示)

33
00:02:06,383 --> 00:02:12,485
注意我会把这个写作mu^{1}[l] (如图示)

34
00:02:12,485 --> 00:02:15,540
然后当我们用第二个最小批来训练这一层时

35
00:02:15,540 --> 00:02:19,055
我们得到第二个mu值 (如图示 mu^{2}[l])

36
00:02:19,055 --> 00:02:23,194
之后从第三个最小批训练这个隐藏层时

37
00:02:23,194 --> 00:02:29,090
我们又得到第三个mu值 (如图示 mu^{3}[l])

38
00:02:29,090 --> 00:02:31,830
所以 就像我们之前看到的

39
00:02:31,830 --> 00:02:37,600
当我们在试图计算当前温度的指数加权平均数的时候

40
00:02:37,600 --> 00:02:40,020
我们是如何用指数加权平均数来计算

41
00:02:40,020 --> 00:02:44,173
theta_1 theta_2 theta_3的平均值的

42
00:02:44,173 --> 00:02:47,250
我们会这样做来记住

43
00:02:47,250 --> 00:02:50,790
我们看到的这个均值矢量的最新平均值

44
00:02:50,790 --> 00:02:54,195
于是这个指数加权平均数会被我们用来估算

45
00:02:54,195 --> 00:03:00,120
这个隐藏层的Z的平均值

46
00:03:00,120 --> 00:03:03,930
相似得来说 我们用一个指数加权平均数来记住

47
00:03:03,930 --> 00:03:09,015
我们得到的第一个最小批的sigma平方的值

48
00:03:09,015 --> 00:03:13,510
第二个最小批的sigma平方的值 以此类推

49
00:03:13,510 --> 00:03:18,780
也就是说 在我们用不同的最小批来训练神经网络时

50
00:03:18,780 --> 00:03:24,535
我们会保持一个移动均值来记录每一层的mu和sigma平方

51
00:03:24,535 --> 00:03:26,895
最后 在测试时

52
00:03:26,895 --> 00:03:30,275
我们不用这些公式来计算Z_norm

53
00:03:30,275 --> 00:03:35,855
而是用我们当前的Z值

54
00:03:35,855 --> 00:03:39,735
和之前训练时最新的mu和sigma 的指数加权平均数

55
00:03:39,735 --> 00:03:45,340
来进行这个比例缩放

56
00:03:45,340 --> 00:03:48,780
之后我们会用刚刚在左边算的Z_norm

57
00:03:48,780 --> 00:03:53,670
以及之前训练神经网络时学到的

58
00:03:53,670 --> 00:03:57,240
beta和gamma参数值

59
00:03:57,240 --> 00:04:02,695
来计算一个测试实例的Z tilde

60
00:04:02,695 --> 00:04:07,020
所以 重点就是在训练时我们是用整个最小批

61
00:04:07,020 --> 00:04:11,620
比如说64个或者128个或者其他数量的训练实例

62
00:04:11,620 --> 00:04:14,580
来计算mu和sigma平方

63
00:04:14,580 --> 00:04:18,345
但是在测试时 我们可能会需要处理单个测试实例

64
00:04:18,345 --> 00:04:21,605
那么 处理的方式就是通过训练集来估算mu和sigma平方

65
00:04:21,605 --> 00:04:25,325
我们有很多方式来做估算

66
00:04:25,325 --> 00:04:27,450
理论上 我们可以用我们最后的网络运行整个训练集

67
00:04:27,450 --> 00:04:30,960
来得到mu和sigma平方

68
00:04:30,960 --> 00:04:33,550
但是实际上 

69
00:04:33,550 --> 00:04:36,330
人们通常会实现某种指数加权平均

70
00:04:36,330 --> 00:04:38,970
来记住在训练时见到的mu和sigma平方的值

71
00:04:38,970 --> 00:04:42,130
然后用这个指数加权平均数 

72
00:04:42,130 --> 00:04:44,095
有时也被称作移动均值

73
00:04:44,095 --> 00:04:46,330
来得到mu和sigma平方的粗略的估算

74
00:04:46,330 --> 00:04:49,800
然后我们用这些mu和sigma平方的估算值

75
00:04:49,800 --> 00:04:55,860
在测试时进行比例缩放来获取隐藏神经元的Z值

76
00:04:55,860 --> 00:04:58,980
实际上 对于你具体如何估算mu和sigma平方

77
00:04:58,980 --> 00:05:03,125
这个过程是比较鲁棒(稳定)的

78
00:05:03,125 --> 00:05:06,440
所以我不会太担心你具体怎么做

79
00:05:06,440 --> 00:05:09,729
而且如果你在用一个深度学习框架

80
00:05:09,729 --> 00:05:13,080
他们通常会有一些默认的方式来估算mu和sigma平方

81
00:05:13,080 --> 00:05:17,665
这些方式一般效果也会比较好

82
00:05:17,665 --> 00:05:21,965
但是实际上 任何合理的方式来估算隐藏神经元的均值和方差

83
00:05:21,965 --> 00:05:28,600
应该在测试时都是效果可以的

84
00:05:28,600 --> 00:05:31,270
所以 这就是批标准化

85
00:05:31,270 --> 00:05:33,520
应用批标准化我相信你们可以训练更深的神经网络

86
00:05:33,520 --> 00:05:37,205
并且让你们的学习算法运行的更快

87
00:05:37,205 --> 00:05:38,870
在我们结束这周前

88
00:05:38,870 --> 00:05:43,080
我想和你们分享一些我对于深度学习框架的想法

89
00:05:43,080 --> 00:05:46,000
我们将在下一个视频中讨论这个话题