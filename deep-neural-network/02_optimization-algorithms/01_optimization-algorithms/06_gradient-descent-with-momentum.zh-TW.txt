有個演算法叫「動量法」 (momentum)，或叫
動量梯度下降法 (gradient descent with momentum) 他幾乎都比標準的梯度下降法還要快 一句話來解釋：基本概念是計算梯度的指數加權平均 然後改用那一個梯度來更新你的權重。 在這部影片，就讓我們把這一句話抽絲剝繭 看看實際上如何實作之。 如同往常一樣，假設你想要最佳化一個成本函數 其等值線像這樣 而紅點表示極小值的地方 假設你在這邊開始梯度下降，如果你跑一步 無論是批次或小批次的梯度下降，可能會跑到那裡 不過呢，你現在跑到橢圓的另一側了 如果你再跑一步梯度下降，可能會這樣 然後再一步，又一步，依此類推 你可以觀察到這梯度下降法會跑很多步，對吧 慢慢地往最小值搖擺過去 這樣的上下震盪減緩了梯度的下降 也讓你無法用比較大的學習率 特別是，如果你真要用很大的學習率，最後有可能 會射得太遠，最後像這樣發散 為了不要有過大的震盪，這強迫你 不能用太大的學習率。 另一個看這問題的角度是，從垂直軸的方向看 你希望你學習得比較慢，因為你不想要那些震盪 但是在水平軸上，你希望學習快一些 因為你想要積極地由左跑到右 往最小值、往紅點的方向。 那麼如果你把「動量」加入梯度下降法的實作，就可以這樣： 在每回合，或更具體說，在第 t 個迭代 你照例計算導數 dW, db 我在此省略上標方括號 [l] 你在目前的小批資料上計算 dW, db 如果你用的是批次梯度下降法， 那這小批資料其實就是整個資料 這方法在批次梯度下降也有用 所以如果你的小批資料就是一整個訓練集 這也是沒問題的。 然後呢，你要做的是 計算 V_dW，讓他變成 beta * V_dW 加上 (1-beta) * dW 這個很像先前的計算，也就是 v_theta = beta * v_theta + (1-beta) * theta_t 因此，這就是在計算對W的導數的移動平均 同樣地，你計算 v_db 等於這個 ... + (1-beta) 乘 db 然後，你更新權重 W，讓他變成 W 減掉學習率乘上，這邊不用導數 dW， 你用的是 V_dW 來更新 同樣地，b 更新為 b - alpha * v_db 所以這邊做的，是讓梯度下降的步伐更平順 舉個例子，假設最近幾個導數算出來是這個 這個、這個、這個 如果你把這些梯度平均，你會發現垂直方向的震盪 大概會平均掉，變比較靠近零 所以，在你想慢慢學的垂直方向， 這會把正數和負數平均掉，會靠近零。 而對於水平方向 從水平來看，每個導數都往右指 所以水平方向上的平均還是滿大 這就是為什麼這個演算法經過幾步以後 你會發現動量梯度下降法的步伐 最後在垂直方向的震盪會變得很小 但是在水平方向上會很快、很直接地移動 所以這讓你的演算法走更直接的路徑 或說是抑制震盪，一路邁向最小值。 有個關於這動量法的直觀看法 — 有些人能接受， 但不適合每個人 — 就是你試著
在這個碗型的函數找到最小值 這其實是一個碗的等值線 我猜我不大會畫畫 我們想在這種碗狀的函數取極小值，那麼， 這個導數項，你可以想成他提供「加速度」 給一顆往下滾的球 而這個動量項，可以看作代表「速度」， 所以想像一下，你有一個碗，然後你拿一顆球， 導數賦予球「加速度」 當這球往下滾的時候 因為加速度，他會越滾越快。 然後 beta，因為他略比 1 小，他扮演著 「摩擦力」，讓你的球不會無限加速 所以不像正常的梯度下降法 所踏的每一步和之前的步伐沒有關係 現在，你的球往下滾的時候 會獲得「動量」；他能這碗內加速往下，所以獲得動量。 我發現這個球在碗裡往下滾的比喻，好像 對喜歡物理概念的人有用 不過不是所有人都能接受，所以如果球在碗滾 這個比喻不能說服你，也不用太擔心。 最後呢，讓我們看看實作的細節 這邊是演算法，所以你現在有兩個 超參數：學習率 alpha，還有這個 beta beta 控制你的指數加權平均 常見的 beta 值為 0.9 也就是最近 10 天的氣溫平均 所以這個對最近 10 次迭代的梯度做平均， 實務上，beta=0.9 會做得很好 歡迎隨意嘗試不同的值 做超參數的搜尋，不過 0.9 似乎是滿通用穩定的值。 那麼，關於「偏差矯正」呢？ (bias correction) 所以你要不要拿 V_dW 或 v_db，除以 1-beta^t 呢？ 實務上，大家通常不會這樣做，因為過了10回合 你的移動平均已經暖身完畢，估計不再有偏差 所以實務上，我沒看過大家會因為沒做矯正而在意 當實作動量梯度下降法的時候。 而當然，程序上會把 V_dW 初始化設成 0 注意到這是零矩陣，和 dW 有著相同維度 也就是和 W 有相同維度 而 v_db 也是初始化成元素為 0 的向量 和 db 有相同維度，所以和 b 維度相同。 最後我想提一下，如果你去讀動量法的文獻 你常常會看到這一項被省略 1-beta 這一項拿掉 所以你最後會有 V_dW = beta V_dW + dW 這紫色版本的最終效果就是，V_dW 最後 照 1-beta 這比例縮放，嚴格講是放大 (1-beta) 分之一 所以做梯度下降更新時，alpha 要因為 1/(1-beta) 做相對應的縮放 實務上，兩種版本都好 受影響的只有學習率 alpha 的最佳值 不過我覺得這一條式子比較不直觀 因為有個影響：如果你要調整超參數 beta 的話 你也會影響 V_dW 和 v_db 的大小尺度 所以你或許也需要重新調整學習率 alpha。 因此，我個人偏好左邊這個公式 而不是把 1-beta 拿掉。 因此，我傾向於用左邊的公式 有 1-beta、這個印刷的版本。 不過呢，對於這兩個版本，
超參數 beta=0.9 都是很常見的選擇 只不過 alpha, 學習率, 在不同的版本 會調整成不同的值。 那麼，這就是動量梯次下降法。 和正常版、沒有動量的梯度下降相比， 這個方法幾乎都會表現更好。 不過呢，我們還能做其他事情
讓你的演算法學得更快 讓我們在後面的影片繼續探討之