你現在學到了如何做出指數加權平均
(exponentially weighted averages) 技術上還有個細節，叫偏差矯正 (bias correction) 這能讓你的計算更加準確 我們來看它如何作用 在上部影片，你見過這張 beta=0.9 的圖 而這一個是 beta=0.98 但是實際上呢，你用這一個公式實作的話 例如當 beta=0.98，其實你畫不出來這條綠色的曲線 你其實會得到紫色這條線 你可以注意到，紫色這條線一開始非常低 讓我們看看怎麼解決之。 當你在實作移動平均 (moving average) 時，你從
v_0 = 0 開始 然後 v_1 = 0.98 v_0 + 0.02 theta_1 但是 v_0 是零，所以這一項就不見了 所以 v_1 只剩 0.02 乘以 theta_1 也就是假設第一天的氣溫是華氏 40 度的話 那 v_1 會是 0.02 乘以 40，也就是 8 (口誤) 所以這邊你得到一個非常低的值 對於第一天的氣溫，這並不是個好的估計 v_2 會是 0.98 v_1 + 0.02 theta_2 如果你代入 v_1，也就是這個，然後乘起來 你會發現 v_2 其實等於 0.98 乘以 0.02 再乘以 theta_1，加上 0.02 乘以 theta_2 這會是 0.0196 theta_1 + 0.02 theta_2 所以同樣的，假設 theta_1, theta_2 是正的 你算出這個 v_2，他會比 theta_1 或 theta_2 還要小的多 所以 v_2 並不會是前兩天氣溫的好估計 其實呢，用某個方法修改一下，就能讓這估計 變得更好、更準 尤其是對於估計一開始的階段 是這樣的：不拿 v_t 當估計，而是拿 v_t 除以 1 減 beta的t次方，這裡的 t 是你現在算哪一筆 讓我們舉個實際的例子 當 t=2 時， 1 - beta的t次方 是 1 - 0.98 平方 也就是 0.0396 所以，你對第二天氣溫的估計 會變成 v_2 除以 0.0396 這會是 0.0196 乘以 theta_1 加上 0.02 乘 theta_2 注意到這兩項的係數加起來，會等於分母 0.0396 所以意思是，這個變成了 theta_1 和 theta_2 的加權平均 這就把偏差弭平了。 那你會注意到當 t 變大時，beta的t次方 會趨近於 0，所以當 t 夠大的時候 這邊的偏差矯正幾乎不會有分別； 這就是為什麼 t 很大的時候 紫線和綠線幾乎重疊了 但在這一開始學習的階段，還在暖身的時候 這種偏差矯正能幫你得到比較準確的 氣溫估計 偏差矯正讓你從紫色的線變成 這條綠色的線。 在機器學習中，大部分實作 指數加權平均的時候，大家不會特別用心去做偏差矯正 因為很多人寧願等著、撐過一開始的階段 做有一點點誤差的估計，然後拿來用。 不過，如果你對這初始階段的偏差有所擔心 當你的指數加權移動平均還在暖車的時候 那麼偏差矯正能幫助你，在早期就拿到比較準的估計 現在呢，你知道怎麼實作指數移動加權平均了 讓我們繼續下去，利用它來發明一些更好的優化演算法