你見過了利用動量來加快梯度下降 有另外一個演算法叫 RMSprop 代表 Root-Mean-Square prop (方均根傳播)，
這也能加快梯度的下降 我們來看看其運作 還記得之前的例子，如果你用梯度下降法 你可能會在垂直方向有強烈的震盪 而水平方向還仍在努力取得進展 以這例子，為了提供比較直觀的看法，我們假設 垂直軸代表參數 b，水平軸代表參數 W — 其實他可以是w1, w2 或是其他的參數；這邊叫 b 和 w 只是為了直覺方便。 所以，你想讓 b 這個方向學得慢一些 或說是垂直方向。 而在水平方向上加快學習，至少不要慢下來。 為了達成這個，下面就是 RMSprop 演算法所做的 在第 t 個迭代，照例地會在小批資料上 計算導數 dW, db 和之前的指數加權平均類似 只不過不是用 V_dW，這裡我用新的符號 S_dW 所以 S_dW 等於 beta 乘以前一個值 加上 (1-beta) 乘以 dW 的平方 — 有時會寫成 **2 代表次方，不過我這邊就這樣寫。 釐清一下，這個「平方」是逐元素的平方運算 所以這邊所作的，其實是記錄導數的平方 的指數加權平均。 類似地，我們有 s_db = beta * s_db + (1-beta) * db^2 再次強調，這邊的「平方」是對每個元素的。 接下來，RMSprop 用下面的方法更新參數： W 被更新為 W 減掉學習率 雖然之前 alpha 乘的是 dW，現在的是 dW 除以 S_dW 的平方根。 而 b 被更新為 b 減學習率乘以 不是只有梯度，這個也會被 s_db (的平方根) 除。 那麼，我們來多了解一下運作概念 還記得在水平的方向 或在這個例子是 W 的方向，我們想要學習變很快 而在垂直的方向，在這個例子是 b 的方向， 我們想要慢慢來，或者是抑制垂直方向上的擺動 所以這兩項 S_dW 和 s_db， 我們希望 S_dW 相對較小 以至於我們在這邊除的是比較小的數字 而 s_db 會相對比較大，以至於在這裡除的是 比較大的數字，以減緩垂直維度的更新。 而的確，如果你看這些導數，他們 在垂直方向比較大，在水平方向比較小 在 b 方向上，這坡度是很陡峭的對吧 所以像這樣的導數，db是非常大的，dW相對比較小。 因為這一個函數的斜度在垂直方向上很陡 也就是b方向，遠比W方向也就是水平方向，還斜的多 所以，db平方會比較大 也所以 s_db 會比較大；相較之下 dW 比較小 dW 平方比較小，所以 S_dW 會比較小。 因此最終的效果是，你在垂直方向上的更新 會除以一個比較大的數字，所以有助於抑制震盪， 而在水平方向上的更新會除以比較小的數字。 所以使用 RMSprop 最終的效果會是，你的更新 最後看起來像這樣 你在垂直方向的更新被抑制， 但是在水平方向你能繼續前進。 而這個效果讓你因此也能用比較大的學習率 alpha 能更快的學習，而不會在垂直方向發散。 那麼只是釐清一下，我一直把垂直和水平方向 稱為 b 和 W，這只是為了示範， 實際上，你在一個很高維度的參數空間裡 所以或許你想抑制的垂直的維度 是某些參數 w1, w2, w17， 而水平維度可能是 w3, w4, 等等等 所以分成 w 和 b 只是為了示範 實務上 dW 是非常高維的參數向量 db 也是非常高維的參數向量 不過概念是，在那些你會有震盪的維度 你最後會算出比較大的總和 或者是導數的平方的加權平均， 所以那些有震盪的方向終會漸緩。 那麼這就是 RMSprop，
他代表 root mean square (方均根) prop，因為 這裡你把導數「平方」，而(平均)後取「平方根」 在繼續其他的之前，這演算法還有一兩個細節 在下部影片，實際上我們會把 RMSprop 和動量法合併在一起 所以對於這個超參數，與其於用動量法寫過的 beta， 我要叫這個超參數 beta_2，避免衝突 不要讓動量法和 RMSprop 超參數名字同樣。 還有為了確保你的演算法不會除以 0 你知道的，萬一 S_dW 的平方根非常靠近 0 那就爆掉了 只是為了確保運算上數值的穩定性，
在實務上你寫程式的時候 你在分母加一個非常非常小的 epsilon epsilon 實際上是多少不大重要， 用 10 的 -8 次方會是個合理的預設值，
不過這只是確保 比較好的數值穩定性，避免四捨五入還是其他原因， 讓你最後不要除以一個非常非常小的數字。 那麼，這就是 RMSprop；和動量法類似，這個有 舒緩震盪的效果，在梯度下降或是小批次梯度下降， 讓你有機會使用更大的學習率 alpha， 也一定能讓你的演算法學得更快。 那麼你知道怎麼實作 RMSprop 了，這會是另一個 加快你的學習演算法的方式。 一個關於 RMSprop 有趣的事 他一開始其實不是在學術論文裡刊登 而是多年前在 Geoffrey Hinton 的一門 Coursera 課程中提出 我猜 Coursera 本意並不是想當一個 最新學術研究的傳播平台，不過就這例子還挺不錯的 而確實是由 Coursera 課程開始，RMSprop 開始廣為人知 開始起飛。 我們談了動量法 (momentum) 我們談了 RMSprop 其實如果你把兩個加在一起，你會得到更好的 最佳化演算法 讓我們在下部影片來談談