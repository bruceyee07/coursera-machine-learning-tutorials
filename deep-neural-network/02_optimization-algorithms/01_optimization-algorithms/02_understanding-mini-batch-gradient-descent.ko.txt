이전 비디오에서는 
미니 배치 기울기 강하를 이용해서 진전있게하고, 처음에도 트레이닝 세트 중간에서 기울기 강하 step를 가질 수 있도록 하는 방법을 보았는데요, 이번 비디오에서는, 기울기 강하를 도입하는 방법과 이것이 하는 역할과 왜 잘 작동하는지에 대한 
이해도를 높히는 시간을 갖겠습니다. 전체트레이닝세트의 수행업무마다 배치 기울기 강하에서는 비용이 반복수행을 통해서 계속 내려갈 것을 기대할 것입니다. 그러면 j 비용함수를 다른 반복 업무의 함수로 가지면, 
반복을 할 때마다 비용이 줄어야 할 것입니다. 만약에 한번이라고 iteration절차에서 올라가는 경우엔, 
이상이 있는 것입니다. 아마 러닝속도가 너무 클 수도 있겠죠. 하지만 미니 배치 기울기 강하 경우에, 
여러분이 만약 진행절차를 비용함수에 그리면 반복할 때마다 감소할 수도 있습니다. 특히, 반복업무마다 여러분은 X{t}, Y{t}를 처리하는 것인데요, 그렇기 때문에 J{t}비용함수를 그리면, 이것은 X{t}, Y{t}를 이용해서 계산이 되는데요, 그러면 반복수행을 할때마다 다른 트레이닝세트에서 
트레이닝을 하는 것과 마찬가지입니다. 또는 다른 미니 배치에서 트레이닝 하는 것과 마차가지인 것이죠. 그러면 J 비용함수를 그리는데요, 이렇게 생긴 것을 볼 것입니다. 그러면 이렇게 밑으로 내려가는 경향을 보일텐데요, 
동시에 조금 더 noisy할 것입니다. 만약 J{t}를 그리면, 미니 배치 기울기 강하를 
복수의 epoch에서 트레이닝 시킬 때 말이죠, 그런 경우, 이렇게 생긴 커브를 볼 것입니다. 그렇기 때문에 iteration 마다 내려가지 않아도 괜찮습니다. 하지만 이렇게 내려가는 모양을 보일텐데요, 조금 더 noisy한 이유는 X{1}, Y{1}이 조금 더 쉬운 미니 배치여서 비용이 조금 더 낮기 때문에 
그럴 수 있는데요, 하지만 우연으로 X{2},Y{2}가 어려운 미니 배치일 수도 있죠. mislabel된 예시도 있을 수도 있겠죠, 이런 경우 비용이 조금 더 높겠습니다. 그렇기 때문에 비용을 그리면서 이와 같은 변동폭이 생기는 것인데요, 미니 배치 기울기 강하를 실행할때 말이죠. 여러분이 골라야하는 parameter중에 하나는 
바로 미니 배치의 크기입니다. 미니 배치 사이즈 가 m 인 경우, m은 one extreme에서의 
트레이닝세트 크기였습니다. 그럴 경우, 배치 기울기 강하가 남게 되는데요, 여기 extreme에서는 그냥 한개의 미니 배치
X{1},Y{1} 이 남을텐데요, 이 미니 배치는 전체 트레이닝 세트와 동일합니다. 그렇기 때문에 미니 배치 사이즈를 m으로 설정하는 것은
단순히 배치 기울기 강하를 줍니다. 다른 extreme은 미니 배치 사이즈가 1일 경우일 것입니다. 이 경우 stochastic 기울기 강하라는 알고리즘을 주는데요. 여기서 각각의 예시는 그들의 미니 배치 입니다. 이럴 경우에는, 첫번째 미니 배치를 봅니다.
즉, X{1}, Y{1}인데요, 그렇지만 미니 배치 사이즈가 1인 경우, 
첫번째 트레이닝 예시 밖에 없는데요, 즉 첫번째 트레이닝 샘플로
기울기 강하를 가져야 합니다. 다음으로 두번째 미니 배치를 봅니다. 두번째는 그냥 두번째 트레이닝 샘플인데요, 
이 값에 기울기 강하 step를 적용합니다. 그리고 이어서 세번째 트레이닝 예시도 그렇게 합니다. 하나의 트레이닝 샘플씩 보는 것입니다. 비용함수의 최적화에 있어 이런 2개의 extreme이 
어떻게 하는지 한번 보겠습니다. 이것이 바로 여러분이 최소화 시키려하는
비용함수의 곡선이라고 하면, 여기가 그 최소값이 됩니다. 그러면 배치 기울기 강하 는 여기쯤에서 시작할텐데요, 이 경우, 낮은 noise와
큰 step를 가질 수 있을 것입니다. 그러면 계속 최소값을 향할 수 있을 것입니다. stochastic 기울기 강하 와는 반대로, 다른 점을 한번 지정해보겠습니다. 그러면 한번의 iteration마다 한개의 트레이닝 예시로 gradient descent를 하는 것인데요, 
그렇기 때문에 거의 항상 global minimum 에 도달하는데요 가끔씩은 다른 방향으로 향해서, 한가지의 옛시가 나쁜 방향으로 가면, stochastic gradient descent 같은 경우에,
굉장히 noisy 해질 수 있습니다. 그리고 평균적으로 
좋은 방향으로 인도하겠지만, 가끔씩은 틀린 방향으로 갈 것입니다. stochastic 기울기 강하는 절대 수렴하지 않을 것이기 때문에, 항상 어떻게 최소값 범위를 계속 동요하고 왔다갔다할 것입니다. 하지만 이것은 절대로 최소값에 도달해 거기 멈춰있진 않을 것입니다. 실제로는, 여러분이 사용할 미니 배치 사이즈는 여기 값 사이에 있을 것입니다. 1과 m 사이와, 1과 m사이죠. 각각 2개 작은 값, 2개의 큰 값입니다. 이유는 이렇습니다. 그리고 이유를 설명드리겠습니다. 여러분이 기울기 강하를 사용하는 경우, 이것은 미니 배치 사이즈가 m 인 경우인데요, 반복 업무마다 아주 거대한 트레이닝 세트를 처리하는 것입니다. 이것의 주요 단점은, iteration마다 너무 긴 시간이 소요된다는 것입니다.
아주 긴 트레이닝 세트가 있다는 가정하에 말이죠. 만약에 작은 트레이닝 세트가 있는 경우엔, 
배치 기울기 강하는 괜찮습니다. 반대로 가면, 
stochastic 기울기 강하를 쓰는 경우엔, 하나의 예시만 처리해도 진전이 있다는 점이 좋습니다. 이것은 문제가 되지 않습니다. 그리고 noisiness는 더 작은 값의 러닝속도를 사용하여 개선시키거나 감소시킬 수 있습니다. 하지만 stochastic 기울기 강하의 큰 단점은 벡터화에서 거의 대부분의 속도를 잃는다는 것입니다. 그 이유는, 여기서는 트레이닝 샘플을
하나씩 처리하는데요, 각각의 예시를 처리하는 방식은
매우 비효율적일 것입니다. 그러므로 실제로 가장 잘 작동하는 것은 
미니 배치 사이즈의 사이즈가 너무 크지 않거나 작지 않은 경우입니다. 실제로 이런 경우에 가장 빠른 러닝을 제공합니다. 여러분도 아시겠지만 이렇게 되면 2가지 부분에서 좋습니다. 하나는 많은 벡터화를 갖게 된다는 것입니다. 이번 비디오에서 사용했던 예시를 기억하면, 여러분의 미니 배치 사이즈가 1000개의 예시였으면, 
1000개의 예시를 두고 벡터화가 가능할 것입니다. 이 경우, 예시를 하나씩 처리하는 것보다 훨씬 빠를 것입니다. 둘째로, 전체 트레이닝 세트를 처리하기 전까지 기다릴 필요없이 진전이 있게 만들 수 있습니다. 다시 한번 이전 비디오에서 다뤘던 수치를 
사용하면, 각각의 트레이닝 세트의 Epocho는 5000개의 기울기 강하 step를 밟게 해줍니다. 그렇기 때문에 실제로는 가장 잘 작동하는
중간의 미니 배치 사이즈가 있을 것입니다. 그러므로 미니 배치 기울기 강하에 대해서는
여기서 시작하겠습니다. 한번의 iteration이 이렇게 만들 수 있고, 
2개의 iteration, 3개, 4개 그리고 최소화 값을 향할 것이라는 것은 보장할 수 없습니다. 하지만 조금 더 균등하게 최소값을 향해 
consequent descent보다 가는 경향이 있습니다. 그리고 항상 정확하게 변환되거나 작은 범위에서 변동하는 것이 아닙니다. 이것이 문제라고 하면 언제든지 
러닝속도를 늦출 수 있습니다. learning rate decay에 대해선
나중의 비디오에서 러닝속도를 줄이는 방법과 같이 알아보겠습니다. 그러면 만약 미니 배치 사이즈가 
m이 아니고, 1이 아니며, 그 사이 값을 가지려면, 
어떤 것을 고를 수 있을까요? 여기 그 가이드라인이 조금 있습니다. 첫번째로, 작은 트레이닝 세트일 경우,
그냥 배치 기울기 강하를 이용하십시오. 작은 트레이닝 세트를 갖고 계시는 경우, 
미니 배치 기울기 강하를 쓰는 의미가 없습니다. 전체 트레이닝 세트를 꽤 빨리 처리할 수 있기 때문입니다. 그러므로 그냥 배치 기울기 강하를 이용하면 되겠죠. 작은 트레이닝 세트가 뜻하는 것은, 제가 생각하기에
2000보다 작을 때를 말하는 것입니다. 이런 경우, 배치 기울기 강하를 쓰는 것이 괜찮습니다. 아니면, 조금 더 큰 트레이닝 세트의 경우, 
전형적인 미니 배치 사이즈는 64에서 512가 대표적인데요, 컴퓨터 메모리가 배치되어 있는 방식과 
접속되는 방법에 따라, 가끔씩 그 코드가 2의 지수값을 가질때 
더 빨리 실행됩니다. 64는 그러면 2의 6승이구여, 
2의 7승, 2의 8승, 2의 9승, 저는 그래서 자주
미니 배치 사이즈를 어떤값의 2승으로 도입합니다. 이번 비디오에서는 제가 
미니 배치 사이즈 1000을 사용했는데요, 만약 정말로 그렇게 하고 싶은 경우엔, 
저는 여러분께서 1024를 쓰시는 것을 추천 드립니다. 이 값은 2의 10승이죠. 조금 흔하진 않지만, 미니 배치 사이즈가 1024인게 있긴 합니다. 여기 이 범위의 미니 배치 사이즈가 조금 더 흔하긴 합니다. 마지막 팁으로는, 모든 X{t}, Y{t} 값이 CPU/GPU 메모리에 들어가게 하도록 하는 것입니다. 이것은 전적으로 여러분의 어플에 달려있는데요, 또 트레이닝 샘플이 얼마나 큰지에 따라 변할 수 있습니다. 하지만 여러분이 CPU 또는 GPU에 들어가지 않는 미니 배치를 처리하게 되는 경우, process와 
데이터를 쓰는 경우에 성능이 저하되는 것을 보시면서 더 악화되는 것을 볼 것입니다. 바라건대 이 내용이 사람들이 사용하는 전형적인 미니 배치 사이즈의 범위에 대해 여러분이 이해하셨으면 좋겠습니다. 실제로는 당연히 미니 배치 사이즈가 
또 다른 하나의 하이퍼 파라미터 인데요, 여러분이 빠른 검색을 통해 어떤 것이 j 비용함수를 줄이는데 충분한지 
알아볼 수 있습니다. 저는 개인적으로 여러가지 값들을 시도해볼 것입니다. 2의 지수값을 몇개 시도해보고 그 다음에 
기울기 강하 최적화 알고리즘에 가장 효율적으로 만들어 줄 수 있는 한가지의 
값을 고를 것입니다. 바라건대 오늘 내용이 가이드라인들이 되어 하이퍼 파라미터 서치에 대한 이해도를 높혀줬길 바랍니다. 이제 여러분은 미니 배치 기울기 강하를 도입하는 방법과 알고리즘을 더 빨리 운영시키는 방법, 특히 큰 트레이닝 세트에서의 경우에 
대한 트레이닝 방법을 배웠습니다. 기울기 강하 또는 미니 배치 기울기 강하보다 훨씬 더 효율적인 알고리즘이 존재합니다. 다음 비디오로 시작하여 해당 내용을 다뤄보도록 하겠습니다.