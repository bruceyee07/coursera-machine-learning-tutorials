监督式学习的问题中，数据由输入X和输出的标签Y组成 如果检查数据集，你发现有些 输出标签Y错了 （也就是说）你的部分数据，有错误的标签 你值得花费时间去修正这些标签吗？
让我们一起看看这个问题。 在“识别猫”这个问题中 Y等于1代表图片是猫，0代表不是 假设你正在检查部分数据，这个是猫 这个不是，这个是猫 这个也是猫，这个不是，这个是 不，等等。这个实际上不是猫 所以，这就是一个错误标记的例子 我用这个术语，“错误标记” 来代表：你的学习算法，输出了一个错误的Y的值 但是我要说，错误标记的例子 是指：如果在数据集中， 不管是训练集、开发集还是测试集， Y的标签，不管人给这个数据贴的标签是什么， 实际上是错误的 这个图片实际上是个狗，所以Y实际上应该是0 但是，可能这个贴标签的人出错了 所以，如果你发现你的数据中，有一些被错误标记的例子 你应该怎么办？ 嗯，首先，让我们考虑一下训练集的情况 事实证明，深度学习算法 对训练集中的随机错误很稳健 只要你的错误，或者说错误标记的例子 只要这些错误不是那么偏离随机分布 而可能只是由标记的人偶然的疏忽造成的， 比如随机按下了错误的键 总之，如果这些错误是相当随机的 那么我们基本可以不管（这些错误） 不用花费太多的时间去纠正它们 当然了，仔细检查你的训练集和标签 并且纠正它们，肯定是无害的 有时候，这是很值得花费时间去做的， 但你也可以不做，只要总数据量够大， 而且实际错误标记的数据占比不高 我见过很多机器学习的算法
在已知包含错误标记的数据集上训练， 它们通常也表现得还可以。 这里我要提醒一下 深度学习算法对随机错误很稳健， 但它们（深度学习算法）对系统误差不那么稳健 比如说，如果你的标记员一直把白色的狗标记为猫， 那就会产生问题，因为你的分类器会 学着把所有的白色的狗分类成猫 但是随机错误，或者接近随机的错误 通常对深度学习算法来说，不算太糟糕。 现在，我们已经讨论了，如何处理在 训练集中，被错误标记的数据 那么，对于开发集和测试集中的数据呢？ 如果你担心有影响， 这些错误标记的数据（对开发集和测试集）的影响 一个比较推荐的做法是，在错误分析的过程中 增加一列，去统计 Y的标签错误的数量 比如说，可能你需要统计开发集中100个错误标记的影响 那么你要去找100个数据， 它们经过分类器的输出，与开发集中的标签不符 有时候，有少数例子 你的分类器（的结果）与标签不符，是因为标签错了 而不是你的分类器出错 所以，在这个例子中 你会发现，这个标记员漏掉了背景里的这只猫 所以，在那里打个对勾，表示第98个例子的标签错了 可能在这个例子里， 这个图片实际上是一个画的猫，而不是真的猫 可能你想要标记员标记成0，而不是1 所以在这里打个对勾 就像你计算错误率 （这些错误率）由其他类别导致的，就像在之前的视频里提及的 你也可以计算一下由这些错误标签导致的错误率 在你的开发集里，Y的值是错的 这解释了为什么你的机器学习算法 预测了一个和数据里标签不一致的结果 所以，现在的问题是 我们值得花费时间去纠正这6%的错误标记的例子吗？ 我的建议是， 如果这些错误对你评估算法在开发集上的效果
有很大的影响的话 那就继续做吧，花时间去纠正这些错误标签 但是如果没有太大影响 对你用开发集去评估模型 那你的时间最好不要花在这上面 让我举个例子来解释一下 我推荐你看三个数字，来决定是否 值得你花时间去减少错误标记的数量 我建议你看整体的开发集的错误率 在上一个视频里提到的例子中， 我们说系统的整体准确率达90% 所以错误率是10% 然后你应该看一下（另一个）错误率 由错误的标签导致的错误率 在这个例子中 6%的错误是由错误的标签导致的 10%的6%是0.6% 然后你应该看一下由其他原因导致的错误率 如果你的开发集上的错误率是10% 0.6%是由错误的标签导致的 那么剩下的，9.4% 是由其他原因导致的，比如错把狗当猫 大猫，以及它们的画像 在这个例子中，我会说9.4%的错误值得你的去纠正 而由错误的标签导致的错误 只占整体错误率的很小一部分 所以，虽然你也可以钻研进去 并纠正所有这些错误标签 但是，这大概不是当下最重要的事情 现在，我们看另一个例子 假设你在这个问题上取得了重大进步 不是10%的错误率 比如说，错误率降到了2% 但是，其中依然有0.6%的错误是由错误的标签引起的 现在，如果你想检查一下错误标记的数据集 由错误标签引起的错误集，在整体2%的错误分类中的占比 这个比例很大 0.6(%)除以2% 实际上是30%，而不是6%的标签 你的错误分类的例子，实际上是由于错误的数据标签导致的 因此，现在由其他错误导致的错误率只占1.4% 当这么高的错误率 是由你的开发集中错误的数据标签引起的时候 那么，可能（这次）更值得花时间去
纠正这些开发集中错误的数据标签 如果你记得开发集的目标的话 就会知道开发集的主要目标是 用它来帮助你在分类器A和B中作出选择 当你试用两个分类器A和B时， 在开发集上，一个错误率是2.1%，另一个错误率是1.9% 但是现在你却不能相信你的开发集了 不能相信它们会准确告知 哪个分类器比这个好，因为此时会有 0.6的错误都是由错误的标签引起的 那么，这就是一个去纠正你的开发集中的
错误标签的很好的理由 因为在右边的这个例子中，错误标签对
整体算法错误率的评估 有着非常大的影响 而在左边的例子中，影响的比例 对于你的整体算法，依然很小 现在，如果你决定探究开发集 手动重新检查标签，并且尝试纠正一些标签 这里由一些额外的指南或者说原则去考虑 首先，不管在什么情况下，我都会鼓励你去 同时应用开发集和测试集 我们之前谈论过，关于为什么你需要 开发集和测试集服从同样的分布 其中开发集是你优化的目标
当你的模型在开发集上表现良好时 你会希望这个良好的性质能推广到测试集 所以当开发集和测试集服从相同分布时 你的团队就能工作得更有效率 因此，如果你要探究并纠正开发集中的一些问题 我会建议将这个过程也应用到测试集，以确保 它们依然服从同样的分布 所以我们可以雇人来更仔细地检查这些标签 对你的开发集和测试集，重复这样的工作 第二，我强烈建议你考虑检查 你的算法准确预测和错误预测的例子 去检查你的算法错误预测的例子很简单 只要看那些需要被纠正的 不过有时可能即使你预测对了 但它却是需要被修正的 如果你只纠正那些预测错的样本 那么当你评估算法错误率时，就会有更大的偏差 这给你的算法带来一点不公平的优势 我们只是尽量仔细检查它错的部分 不过对于模型预测对的样本，也要进行检查 因为模型可能仅仅因为运气好而预测对了
此时纠正一些标签的话，就去除运气成分 并导致本来（因运气）预测对的
变成预测错误 第二个原则不总那么容易执行 所以也不常做 不常做的原因是因为，如果你的分类器很准确 那么它出错很少 比如，你的分类器准确率达98% 那么它只错误判断2%，能正确判断98% 所以，检查和验证那2%的错误标签，更容易 验证98%的数据需要花费更多的时间 所以，并不常用 这只是要考虑的一方面 最后，如果你探究开发集和数据集，去纠正一些标签 你可能应用同样的方法到训练集上，也可能不 记住我们在这个课的其他视频里说过，实际上 纠正训练集中的标签不那么重要 很可能你决定纠正开发集和 测试集中的标签，这部分数据更小 比起训练集，你可能不会把额外工作都用来 纠正那些在训练集中的标签 实际上这是可以的 本周我们会谈到一些方法 来处理训练集 和开发集、测试集服从不同分布的问题 学习算法对这个问题是非常稳健的 你的开发集和测试集服从相同的分布，这一点非常重要 但是，如果你的训练集服从稍微不同的分布 通常，这是非常合理的 在以后的课程中，我会谈更多解决办法 我想总结几个建议 首先，深度学习的研究者有时会喜欢说 我只是把数据扔进算法 我训练了，然后算法有效 在深度学习的错误中，有很多这样的例子 有很多只是把数据扔进算法，然后训练模型 做很少的工程师的工作，不加入人的观察 但是我认为，建造实用的系统时， 通常，有一些更偏向人工的错误分析和人的见解 加入到系统中，深度学习研究者更重视 第二，我见过一些工程师和 研究者不愿意做人工去检查例子 可能这不是有趣的事情 去坐下来检查 100或者几百的数据，去数错误的数量 但是这是我的做法 当我带领一个机器学期的团队时，我 希望理解这个机器在犯什么错 我会亲自去探究数据，并且 尽力去计算错误率 我认为这些时间，可能是几个 小时，来计算（错误的）数据，可以帮助你辨别下一步做什么 我认为这是非常好的利用时间，我强烈建议 考虑也这么做，如果这些机器在 你的系统里，而且你正在决定 什么想法，或者说什么方向，去区分优先级 好了，这是错误分析的方法 在下一节课汇总，我想分享一些想法
并说明错误分析是如何 与你要建造的新的机器学习项目配合的
GTC字幕组 翻译