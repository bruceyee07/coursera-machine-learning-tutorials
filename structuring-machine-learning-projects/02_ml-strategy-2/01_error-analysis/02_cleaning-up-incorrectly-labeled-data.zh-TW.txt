在監督式學習的資料中包含了輸入 X 跟輸出標籤  Ｙ 如果通過您的資料
您發現一些 輸出標籤 Y 是錯誤時怎麼辦? 您有一些標示不正確的資料 值不值得您花時間來更正這些標籤? 我們來看看 在貓咪分類器問題中 Y 等於 1 當照片是貓時
等於 0 當不是貓 所以假設當您看這些資料，認出這是貓 這不是貓，這是貓 這是貓，這不是貓，這是貓 等一下, 這實際上並不是貓 所以這是一個標籤不正確的例子 我用了這個名詞，誤標例子 (mislabeled example) 來表示如果您的學習算法輸出錯誤的 Y 值 但我會用，標籤不正確例子 (incorrectly labeled examples) 來代表如果在 您用的資料集，不管是訓練集，開發集，測試集 標籤 Y, 不管是人工標示 分派到這個資料時，實際上是不正確的 這實際上是一隻狗, 所以 Y 真的應該為零 也許標籤的人弄錯了 所以如果您發現您的資料
有一些不正確標籤例子時 你該怎麼辦？ 首先，先來考慮訓練集 實際上深度學習演算法 對於訓練集中的隨機錯誤
是不太受影響的 只要您的錯誤
或者說您的不正確標籤例子 只要這些錯誤不離隨機太遠 也許有時候標籤者只是沒有注意
或者他們不小心 隨機誤打鍵盤上的鍵 如果錯誤是合理隨機的 那麼它可能會沒事, 只是不管 這些錯誤，而不用花太多時間來糾正它們 當然如果您進入這些 訓練集逐一去改正它們也沒關係 也許有時候值得做
但如果不做應該也沒事 只要整體資料數量很大 那實際真正這些錯誤
的百分比也許不高 我看過很多機器學習演算法
訓練了即使當我們知道 有一些 X 錯誤在訓練集
通常還是可以正常工作 但這裡有一個警告，也就是 深度學習演算法是對
隨機錯誤不受影響 但對於系統化的錯誤就不見得 舉個例子，如果您的標籤者一直將白狗標為貓 那就會是一個問題，因為您的分類器 會學習將白狗分類為貓 但隨機錯誤或者幾乎隨機錯誤 通常對大多數學習演算法都可以處理 目前為止的討論都集中在 不正確標籤例子在您的訓練集 如果這些不正確標籤例子發生
在您的開發集或者測試集呢？ 如果您擔心 在您開發集或測試集的
不正確標籤例子的影響 通常建議您當在做錯誤分析時 加入另外一個欄位
讓您可以計算 標籤 Ｙ不正確標示的數目 舉例來說，或許當您計算 100 個誤標的開發集例子時 所以您用 100 個例子在 您的分類器輸出時跟您
開發集上的標籤不一致 而有時候有一些例子 您的分類器跟標籤不一致
因為您的標籤錯了 而不是您的分類器錯了 或許在這個例子中 您發現標籤者
錯過了一隻在背景的貓 所以在這裡標註一下表示
第 98 號例子不正確標籤 或許這一個 這個照片裡是畫的貓
而不是真的貓 或許您要標籤者應該標為 0 而不是標為 1 所以您放另一個
標註記號在這裡 而當您依次數這些錯誤的比例時 就像其他的類別
我們在上一段影片看過的 您也同時計算了因為
不正確標籤造成的錯誤的百分比 也就是您開發集的 Y 值 是不正確的，導致於您的學習演算法 預估的值不同於您資料上的標籤 所以現在問題是 這個 6% 的不正確標籤例子值得去糾正它們嗎？ 我的建議是 如果它是一個顯著的誤差對於
您要評估演算法在您的開發集上時 那請花時間來矯正這些錯誤的標籤 但如果沒造成 對於您用這個開發集
來評估交叉偏差時顯著不同時 那也許這並不是
最佳的時間運用 讓我用一個例子
來解釋我的意思 有三個數子我建議您使用
來決定是否 值得減低誤標例子的數字如下 我建議您看整體開發集的錯誤 在前面的影片中
我們所使用的例子 我們說或許我們的系統有 90% 的正確性 所以有 10% 的錯誤 然後您看 因為不正確的標籤造成的
錯誤數或者錯誤百分比 所以看來在這個情況下 6% 的錯誤來至於不正確的標籤 所以 10% 裡的 6% 是 0.6% 然後您應該看其他所有的原因造成的錯誤 所以如果您發生了 10% 的錯誤在開發集上 而 0.6% 因為標籤錯了 而其他的 9.4% 是來自於像誤認狗為貓 大貓跟模糊照片 這種情況下，我會說這個 9.4% 的錯誤
值得您集中精神去修復 然而這因為不正確標籤造成的錯誤 相對於整體的錯誤而言佔小的比例 所以不管怎樣 如果您要的話就去修正這些錯誤的標籤 但或許現階段
並不是最重要的事情 現在，舉另一個例子 假設您的學習問題獲得重大的進展 所以與其是 10% 的錯誤 假設您將錯誤減低至 2% 這時假設因為不正確標籤造成的
整體錯誤依然是 0.6% 現在，如果您檢驗您的誤標開發集照片 來自於只有 2% 的開發集是您誤標的 那有很大一部分 0.6% 除以 2% 所以實際上有 30% 而不是 6% 的您的標籤 來自於不正確的例子，
來自於不正確標籤的例子 所以因為其他因素
造成的錯誤現在是 1.4% 當如此大的比例 您的錯誤來自於
您開發集不正確的標籤時 或許似乎很值得修復
這些開發集上的不正確標籤 而如果您記得開發集的目的 開發集的主要目的是 您想要真的幫助您選擇
分類器 A 或 B 所以您試了兩個分類器 A 跟 B 一個是 2.1% 錯誤率，
另一個是 1.9% 的錯誤率在開發集上 但您不再相信
您的開發集能夠正確地 告訴您是否這個分類器 真的比這個好
因為您的 0.6% 的錯誤率來自於不正確的標籤 那這會是一個好理由來
更正您開發集的不正確標籤 因為在右邊的這個例子對於 演算法的整體錯誤率
評估上有很大的影響 而在左邊的例子，
那樣的百分比 對於您的演算法來講
還是很小的 現在，如果您決定在開發集上 手工重新檢驗標籤
然後試著更正一些標籤 這裡有一些指南
或者說原則要考慮 首先，我會鼓勵您應用 不管是哪一種程序
同時應用在開發跟測試集上 我們之前談過
有關您希望 開發跟測試集
來自同樣的分佈 開發集是告訴您是否正中目標
而如果您中了 您希望能夠一般化到測試集上 所以您的團隊真的 比較有效率
當開發跟測試集來自於同一個分佈 所以如果您將更正
開發集上的一些東西 我會應用相同的程序到
測試集來保證 那們來自於同一個分佈 所以我們請一個人
更小心的檢驗這些標籤 記得同時檢驗開發跟測試集 第二點，我會催促您考慮檢驗 您演算法弄正確的例子
跟不正確的例子 檢驗您的演算法 弄錯，然後只看是否
需要更正這些是很容易的 但也有可能，有一些例子您不是真的弄對的 也應該要更正 而如果您只更正
那些演算法弄錯的 您最終會有更多的偏差
對於您演算法的錯誤 這樣做會讓您的演算法
佔了一些不公平優勢 如果我們只有重新檢驗那些錯的
但不去 重新檢驗那些對的，因為那些弄對的 有可能是運氣好
而更正標籤後 舉例來說
有可能從對的變成錯的 第二點，並不那麼容易做到 所以通常都沒做 通常沒做的原因是
因為如果您的分類器已經很準了 那比起對的部分，
錯的部分變得很少 所以如果您的分類器有 98% 的正確率 那大約會有 2% 是錯的， 98% 是正確的 所以要檢驗 2% 的標籤
的資料比較容易 而要檢驗 98% 的資料
要花相對較長的時間 所以通常都沒做 只是您需要考慮做這件事 最後，如果您決定到開發及測試集
更正一些標籤資料 您或許需要決定要或不要
應用同樣的流程到訓練集上 記得我們在其他影片中說過實際上 在訓練集更正標籤
是比較不那麼重要 這是可能的，您決定去更正開發集跟 測試集的標籤，通常這些資料比起 訓練集小很多而您或許不用花額外的功夫 來更正資料大很多的訓練集 這實際上是可行的 稍後這個禮拜，我們會談到一些流程 來處理當您的訓練資料 跟開發集跟測試集的分佈是不同的 學習演算法對於這點很有辦法 您的開發跟測試集來自同樣的分佈是
超級重要的 但如果您的訓練集來自於稍微不同的分佈 通常是很合理的事 我會做這個禮拜談論
如何處理這樣的問題 所以我想總結一下一些建議 首先，深度學習研究者
有時候喜歡說 “我只是將資料餵給演算法 我訓練它，然後它就可以作用” 當然在深度學習時代
這是很真實的 比較多的是餵資料給演算法，訓練它 比較少用手工功夫跟比較少的人為洞察力 但我想在建立一個實用的系統時 通常也有更多的人為錯誤分析
跟更多人類洞察力 進入這個系統，
有時候深度學習研究者也承認這點 第二點，不知何故，我看過一些工程師 跟研究者不願意手工來看這些資料 或許這不是最有趣的事情 坐下來然後看 100 個或者幾百個例子
來數錯誤的數目 但這是我自己會做的事情 當我領導一個機器學習團隊，我 希望知道患了哪些錯誤 我會實際的自己來看這些資料 試著去數錯誤的比例 而我想因為這幾分鐘或者幾小時 來數這些資料可以幫助您
決定下一步的優先順序 我發覺這是很棒的時間利用，
我也敦促 您考慮這樣做，
如果這些機器 在您的系統而您試著決定 哪一個想法或哪一個方向
是優先事項 所以這就是誤差分析流程 在下一個影片中，
我想分享一些想法在看誤差分析 如何擺入當您開始一個新的機器學習專案