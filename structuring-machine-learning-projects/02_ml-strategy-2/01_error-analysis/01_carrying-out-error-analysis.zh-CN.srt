1
00:00:00,350 --> 00:00:02,080
欢迎回来

2
00:00:02,080 --> 00:00:06,550
如果你想得到一个训练算法<br />来做人类可以做的任务

3
00:00:06,550 --> 00:00:10,490
而且你所训练的算法<br />还没有达到人类的效果

4
00:00:10,490 --> 00:00:13,790
你需要手动地检查算法中的错误

5
00:00:13,790 --> 00:00:16,240
来得到你下一步该做什么

6
00:00:16,240 --> 00:00:19,040
这个过程叫做错误分析

7
00:00:19,040 --> 00:00:20,890
让我们从一个例子开始

8
00:00:20,890 --> 00:00:24,520
假设你正在做一个猫分类系统<br />在验证集上

9
00:00:24,520 --> 00:00:29,390
准确率达到90%的或错误率达到10%

10
00:00:29,390 --> 00:00:32,820
假设这比你想象中的结果要差很多

11
00:00:32,820 --> 00:00:36,740
也许你的一个队友<br />在看一些算法分错了的样本

12
00:00:36,740 --> 00:00:42,340
并且发现它将狗误认为猫了

13
00:00:42,340 --> 00:00:46,080
如果你看看这两只狗<br />也许它们看起来有点像猫

14
00:00:46,080 --> 00:00:47,628
至少乍看之下是这样

15
00:00:47,628 --> 00:00:51,160
所以也许你的队友会来给你一个建议

16
00:00:51,160 --> 00:00:56,110
如何使算法更好<br />特别是在狗身上 对吗

17
00:00:56,110 --> 00:01:01,080
你可以有侧重点 收集更多狗的图片

18
00:01:01,080 --> 00:01:04,680
或设计针对狗特有的特征之类的

19
00:01:04,680 --> 00:01:07,833
为了使猫分类器在狗上表现更好 所以

20
00:01:07,833 --> 00:01:11,070
它不再将狗误判为猫

21
00:01:11,070 --> 00:01:13,980
所以问题是 你是否应该继续

22
00:01:13,980 --> 00:01:18,080
并且开始一个项目侧重于狗的问题

23
00:01:19,325 --> 00:01:23,740
可能要花费好几个月来使你的算法

24
00:01:23,740 --> 00:01:25,890
在狗的照片上犯少一些错误

25
00:01:27,280 --> 00:01:29,550
而这值得你努力吗

26
00:01:29,550 --> 00:01:32,475
与其花几个月做这个

27
00:01:32,475 --> 00:01:36,175
最终却发现 这没有很大帮助。

28
00:01:36,175 --> 00:01:40,605
这个错误分析的方法<br />可以让你很快地判断

29
00:01:40,605 --> 00:01:43,055
值不值得这么做

30
00:01:43,055 --> 00:01:45,180
所以 我的建议是

31
00:01:45,180 --> 00:01:51,860
首先 拿大约100张分类错误的验证集图片<br />并进行手动检测

32
00:01:51,860 --> 00:01:56,380
只需要数一数 看有多少张

33
00:01:56,380 --> 00:01:59,338
验证集中标错的样本实际上是狗的图片

34
00:01:59,338 --> 00:02:02,160
现在 假设事实证明

35
00:02:02,160 --> 00:02:07,700
在验证集中分错的100张样本里<br />有5%是狗的图片

36
00:02:07,700 --> 00:02:12,740
也就是说 验证集中<br />分错的100张中有5张是狗

37
00:02:12,740 --> 00:02:18,231
这意味着在这100张图片中

38
00:02:18,231 --> 00:02:23,217
特指你分错的这100张

39
00:02:23,217 --> 00:02:28,807
即使完全解决狗的问题<br />也只在这100张中多分对了5张

40
00:02:28,807 --> 00:02:33,802
换言之 若只有5%的错误是狗照片

41
00:02:33,802 --> 00:02:38,076
如果你在狗的问题上花了大量时间

42
00:02:38,076 --> 00:02:43,256
最好的情况也就是 你的错误率

43
00:02:43,256 --> 00:02:46,635
从10%下降到9.5% 对吗

44
00:02:46,635 --> 00:02:53,455
这5%是错误里的相对下降值<br />因此是从10%下降到9.5%

45
00:02:53,455 --> 00:02:58,220
那么你可能可以合理地判断出<br />这样并不是最好的利用时间的方式

46
00:02:58,220 --> 00:03:02,743
也有可能是<br />但至少给了你一个上限

47
00:03:02,743 --> 00:03:08,566
通过处理狗的问题能提高多少准确率

48
00:03:08,566 --> 00:03:09,150
对吗？

49
00:03:10,800 --> 00:03:15,870
在机器学习中 有时我们把这称为表现上限

50
00:03:15,870 --> 00:03:17,818
意思是最好的情况是什么

51
00:03:17,818 --> 00:03:20,720
关注狗的问题能有多大的帮助

52
00:03:22,690 --> 00:03:25,310
但是现在 假设有别的事情发生了

53
00:03:25,310 --> 00:03:28,590
假设 在验证集里错标的100张样本中

54
00:03:28,590 --> 00:03:32,340
你发现他们中的50张实际上是狗的图像

55
00:03:32,340 --> 00:03:35,620
所以50%是狗的照片

56
00:03:35,620 --> 00:03:39,760
现在你可以更确定地把时间花在狗的问题上

57
00:03:39,760 --> 00:03:42,807
在这种情况下 如果你真的解决了狗的问题

58
00:03:42,807 --> 00:03:47,158
你的错误率可能将从这10%下降到5%

59
00:03:47,158 --> 00:03:52,260
你可能会认为错误率减半是值得付出努力的

60
00:03:52,260 --> 00:03:56,150
专注于减少被错误标识的狗

61
00:03:56,150 --> 00:04:00,446
我知道在机器学习中 有时我们会贬低

62
00:04:00,446 --> 00:04:03,660
手动操作或使用太多人工判断

63
00:04:03,660 --> 00:04:09,280
但是如果你在构建应用系统<br />那么这个简单的计数过程

64
00:04:09,280 --> 00:04:12,120
也就是错误分析 可以节省你很多时间

65
00:04:12,120 --> 00:04:14,740
在决定什么是最重要的

66
00:04:14,740 --> 00:04:17,309
或哪个方向最有希望 值得关注

67
00:04:19,739 --> 00:04:24,263
实际上 如果你想检查一下错误标记的验证集

68
00:04:24,263 --> 00:04:27,620
也许只需要花5到10分钟

69
00:04:27,620 --> 00:04:29,930
人工浏览100张图片

70
00:04:29,930 --> 00:04:32,860
并数出它们中有多少是狗

71
00:04:32,860 --> 00:04:36,212
再根据结果看 是5%

72
00:04:36,212 --> 00:04:37,570
还是50% 还是别的

73
00:04:37,570 --> 00:04:39,580
这只需要5到10分钟

74
00:04:39,580 --> 00:04:44,310
能够评估这方向是否值得花时间

75
00:04:44,310 --> 00:04:46,430
并可以帮你作更好的决定

76
00:04:46,430 --> 00:04:51,470
是否要在接下来的几个月中<br />集中精力解决

77
00:04:51,470 --> 00:04:54,180
被错误标识的狗的问题

78
00:04:54,180 --> 00:04:58,120
在这页讲义中 我们讲了使用错误分析来评估

79
00:04:58,120 --> 00:05:02,380
一个思路 这里指狗<br />是否值得实行

80
00:05:02,380 --> 00:05:08,260
有时你也可以评估多个思路<br />通过并行的错误分析

81
00:05:08,260 --> 00:05:12,920
例如 假设你有好几个<br />改进你的猫检测器的思路

82
00:05:12,920 --> 00:05:16,460
也许可以提高对狗的识别

83
00:05:16,460 --> 00:05:19,785
也许你会注意到有时候所谓的"大猫"

84
00:05:19,785 --> 00:05:22,332
如狮子、豹、猎豹等

85
00:05:22,332 --> 00:05:25,758
他们被认为是小猫或家猫

86
00:05:25,758 --> 00:05:28,031
所以你也可以尝试解决这个问题

87
00:05:28,031 --> 00:05:32,632
也许你会发现你的一些图像是模糊的

88
00:05:32,632 --> 00:05:36,489
也可以设计一些方法<br />使模糊图像能被更好的检测

89
00:05:37,560 --> 00:05:39,280
也许你对这方面有一些思路

90
00:05:41,480 --> 00:05:45,430
因此 如果用错误分析<br />来评估这三种思路

91
00:05:45,430 --> 00:05:48,430
我的做法就是创建一个这样的表

92
00:05:50,760 --> 00:05:53,940
我通常在电子表格中做这个

93
00:05:53,940 --> 00:05:56,520
但使用普通的文本文件也可以

94
00:05:57,610 --> 00:05:58,605
在左边

95
00:05:58,605 --> 00:06:02,430
这将遍历你计划手动查看的图像集

96
00:06:02,430 --> 00:06:06,010
如果你看100张图片 就从1到100

97
00:06:06,010 --> 00:06:09,910
而电子表格上的列

98
00:06:09,910 --> 00:06:12,570
对应你要评估的几个思路

99
00:06:12,570 --> 00:06:18,490
所以是 狗的问题 大猫的问题<br />以及模糊的图像

100
00:06:18,490 --> 00:06:23,870
我通常还会在电子表格中留出空间来写评论

101
00:06:23,870 --> 00:06:25,724
所以请记住 在错误分析中

102
00:06:25,724 --> 00:06:29,610
只看验证集里<br />你的算法判断错误的样本

103
00:06:30,670 --> 00:06:34,640
所以 如果你发现<br />第一个误判的图像是一张狗的图片

104
00:06:34,640 --> 00:06:36,550
然后我会在那里打个勾

105
00:06:36,550 --> 00:06:39,540
为了帮助自己记住这些图像

106
00:06:39,540 --> 00:06:41,830
有时我会在评论中做一个注解

107
00:06:41,830 --> 00:06:44,380
也许那是个斗牛犬的照片

108
00:06:44,380 --> 00:06:48,110
如果第二张图片是模糊的<br />就在那做个标记

109
00:06:48,110 --> 00:06:53,317
如果第三个误判的是一只<br />动物园雨天里的狮子

110
00:06:53,317 --> 00:06:56,030
那就是一只大猫 并且模糊的数据

111
00:06:56,030 --> 00:07:00,920
在备注里写上 在动物园的雨天

112
00:07:00,920 --> 00:07:03,620
是雨使它模糊不清等等

113
00:07:05,670 --> 00:07:08,616
最后 看完了这些图片

114
00:07:08,616 --> 00:07:11,508
我将计算出这些算法的百分比

115
00:07:11,508 --> 00:07:16,951
或者这些错误类别的百分比<br />因为狗的

116
00:07:16,951 --> 00:07:19,360
或大猫的 或模糊的

117
00:07:19,360 --> 00:07:26,484
你检测的图片中也许8%的是狗

118
00:07:26,484 --> 00:07:32,390
43%是大猫 61%是模糊的

119
00:07:32,390 --> 00:07:34,720
所以这就意味着每列下来

120
00:07:34,720 --> 00:07:39,290
计算在该列中有标记的图像的百分比

121
00:07:39,290 --> 00:07:41,567
当你在这个过程中

122
00:07:41,567 --> 00:07:44,420
有时你会发现其他类别的错误

123
00:07:44,420 --> 00:07:50,240
例如 你发现Instagram的风格滤镜

124
00:07:50,240 --> 00:07:55,420
那些花哨的图像滤镜<br />也迷惑了你的分类器

125
00:07:55,420 --> 00:07:55,940
在这时候，

126
00:07:55,940 --> 00:08:00,240
事实上没关系 在这过程中另加一列

127
00:08:00,240 --> 00:08:03,125
给颜色滤镜 Instagram滤镜

128
00:08:03,125 --> 00:08:04,650
和Snapchat滤镜

129
00:08:04,650 --> 00:08:07,900
然后也把这些数出来

130
00:08:07,900 --> 00:08:11,050
计算出这个新错误类别的百分比是多少

131
00:08:12,170 --> 00:08:16,640
这个过程的结论会给你一个估计值

132
00:08:16,640 --> 00:08:19,880
这些不同类别的错误 有多少处理价值

133
00:08:19,880 --> 00:08:23,820
这个例子里 我们在模糊图片中有非常多错误

134
00:08:23,820 --> 00:08:28,780
大猫图像上也有不少

135
00:08:28,780 --> 00:08:35,750
因此 这个分析的结果不是<br />你必须处理模糊的图像

136
00:08:35,750 --> 00:08:39,360
这不给你一个严格的数学公式<br />告诉你该怎么做

137
00:08:39,360 --> 00:08:43,140
但它给你一个最好的参考做法

138
00:08:43,140 --> 00:08:44,650
它也告诉你 例如

139
00:08:44,650 --> 00:08:50,490
不管你在狗或Instagram的图像上<br />做得有多好

140
00:08:50,490 --> 00:08:55,130
在这示例中 你最多只能提高<br />8%或12%的准确率

141
00:08:55,130 --> 00:08:57,700
而你可以针对大猫图像或

142
00:08:57,700 --> 00:09:00,246
模糊图像能有更好的结果

143
00:09:00,246 --> 00:09:03,730
现在这个能提高多少准确率的上限值

144
00:09:03,730 --> 00:09:05,390
要高得多

145
00:09:05,390 --> 00:09:09,010
根据你有多少想法<br />来提高对大猫的判断

146
00:09:09,010 --> 00:09:10,320
来处理模糊图片

147
00:09:10,320 --> 00:09:13,856
你可以选其中一个<br />如果你队伍中有足够的人手

148
00:09:13,856 --> 00:09:15,630
你可以分成两个不同的团队

149
00:09:15,630 --> 00:09:18,629
一个改善大猫的误判

150
00:09:18,629 --> 00:09:22,120
另一个团队改善模糊图片的误判

151
00:09:27,184 --> 00:09:31,280
但这个计数过程通常很快

152
00:09:31,280 --> 00:09:33,130
你最多只需要几小时的时间

153
00:09:33,130 --> 00:09:36,200
它可以真正帮你做出更好的优先决策

154
00:09:36,200 --> 00:09:39,410
并且了解不同方法的潜力

155
00:09:40,940 --> 00:09:44,670
综上所述 要进行错误分析<br />你应该找到一套

156
00:09:44,670 --> 00:09:48,731
在你验证集中错误标识的样本

157
00:09:48,731 --> 00:09:53,420
并按假阳性和假阴性来看

158
00:09:53,420 --> 00:09:56,378
并计算不同类别中的

159
00:09:56,378 --> 00:09:57,629
误判个数

160
00:09:57,629 --> 00:10:01,916
在此过程中 可能会促使你<br />提出新的错误类别

161
00:10:01,916 --> 00:10:02,597
就像我们看到的

162
00:10:02,597 --> 00:10:06,016
当你浏览样本的时候 有很多Instagram滤镜

163
00:10:06,016 --> 00:10:09,071
或者Snapchat滤镜 他们也搞乱了分类

164
00:10:09,071 --> 00:10:11,600
您可以在过程中创建新类别

165
00:10:11,600 --> 00:10:14,740
但通过对不同类中错误标识的例子计数

166
00:10:14,740 --> 00:10:17,375
通常这将有助于你判断优先级

167
00:10:17,375 --> 00:10:21,140
或给你新方向的灵感

168
00:10:21,140 --> 00:10:23,074
当你在做错误分析时

169
00:10:23,074 --> 00:10:27,600
有时你会注意到在开发集中有些是错误标签的

170
00:10:27,600 --> 00:10:29,380
那你该怎么办呢

171
00:10:29,380 --> 00:10:31,020
我们将会在下节探讨这一问题