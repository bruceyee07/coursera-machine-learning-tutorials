1
00:00:00,000 --> 00:00:06,985
监督式学习的问题中，数据由输入X和输出的标签Y组成

2
00:00:06,985 --> 00:00:09,730
如果检查数据集，你发现有些

3
00:00:09,730 --> 00:00:12,240
输出标签Y错了

4
00:00:12,240 --> 00:00:14,740
（也就是说）你的部分数据，有错误的标签

5
00:00:14,740 --> 00:00:19,540
你值得花费时间去修正这些标签吗？
让我们一起看看这个问题。

6
00:00:19,540 --> 00:00:21,640
在“识别猫”这个问题中

7
00:00:21,640 --> 00:00:25,295
Y等于1代表图片是猫，0代表不是

8
00:00:25,295 --> 00:00:28,560
假设你正在检查部分数据，这个是猫

9
00:00:28,560 --> 00:00:30,400
这个不是，这个是猫

10
00:00:30,400 --> 00:00:33,275
这个也是猫，这个不是，这个是

11
00:00:33,275 --> 00:00:35,480
不，等等。这个实际上不是猫

12
00:00:35,480 --> 00:00:41,310
所以，这就是一个错误标记的例子

13
00:00:41,310 --> 00:00:43,900
我用这个术语，“错误标记”

14
00:00:43,900 --> 00:00:48,235
来代表：你的学习算法，输出了一个错误的Y的值

15
00:00:48,235 --> 00:00:50,800
但是我要说，错误标记的例子

16
00:00:50,800 --> 00:00:53,590
是指：如果在数据集中，

17
00:00:53,590 --> 00:00:56,740
不管是训练集、开发集还是测试集，

18
00:00:56,740 --> 00:00:59,320
Y的标签，不管人给这个数据贴的标签是什么，

19
00:00:59,320 --> 00:01:02,228
实际上是错误的

20
00:01:02,228 --> 00:01:06,430
这个图片实际上是个狗，所以Y实际上应该是0

21
00:01:06,430 --> 00:01:10,115
但是，可能这个贴标签的人出错了

22
00:01:10,115 --> 00:01:14,755
所以，如果你发现你的数据中，有一些被错误标记的例子

23
00:01:14,755 --> 00:01:16,440
你应该怎么办？

24
00:01:16,440 --> 00:01:21,177
嗯，首先，让我们考虑一下训练集的情况

25
00:01:21,177 --> 00:01:24,170
事实证明，深度学习算法

26
00:01:24,170 --> 00:01:27,610
对训练集中的随机错误很稳健

27
00:01:27,610 --> 00:01:32,450
只要你的错误，或者说错误标记的例子

28
00:01:32,450 --> 00:01:35,420
只要这些错误不是那么偏离随机分布

29
00:01:35,420 --> 00:01:41,495
而可能只是由标记的人偶然的疏忽造成的，

30
00:01:41,495 --> 00:01:44,205
比如随机按下了错误的键

31
00:01:44,205 --> 00:01:46,400
总之，如果这些错误是相当随机的

32
00:01:46,400 --> 00:01:49,130
那么我们基本可以不管（这些错误）

33
00:01:49,130 --> 00:01:53,065
不用花费太多的时间去纠正它们

34
00:01:53,065 --> 00:01:55,040
当然了，仔细检查你的训练集和标签

35
00:01:55,040 --> 00:01:57,920
并且纠正它们，肯定是无害的

36
00:01:57,920 --> 00:02:02,285
有时候，这是很值得花费时间去做的，

37
00:02:02,285 --> 00:02:05,390
但你也可以不做，只要总数据量够大，

38
00:02:05,390 --> 00:02:10,470
而且实际错误标记的数据占比不高

39
00:02:10,470 --> 00:02:15,230
我见过很多机器学习的算法
在已知包含错误标记的数据集上训练，

40
00:02:15,230 --> 00:02:21,115
它们通常也表现得还可以。

41
00:02:21,115 --> 00:02:24,770
这里我要提醒一下

42
00:02:24,770 --> 00:02:28,500
深度学习算法对随机错误很稳健，

43
00:02:28,500 --> 00:02:34,955
但它们（深度学习算法）对系统误差不那么稳健

44
00:02:34,955 --> 00:02:40,555
比如说，如果你的标记员一直把白色的狗标记为猫，

45
00:02:40,555 --> 00:02:43,390
那就会产生问题，因为你的分类器会

46
00:02:43,390 --> 00:02:46,970
学着把所有的白色的狗分类成猫

47
00:02:46,970 --> 00:02:50,260
但是随机错误，或者接近随机的错误

48
00:02:50,260 --> 00:02:54,575
通常对深度学习算法来说，不算太糟糕。

49
00:02:54,575 --> 00:02:57,730
现在，我们已经讨论了，如何处理在

50
00:02:57,730 --> 00:03:00,905
训练集中，被错误标记的数据

51
00:03:00,905 --> 00:03:04,895
那么，对于开发集和测试集中的数据呢？

52
00:03:04,895 --> 00:03:07,195
如果你担心有影响，

53
00:03:07,195 --> 00:03:10,445
这些错误标记的数据（对开发集和测试集）的影响

54
00:03:10,445 --> 00:03:14,440
一个比较推荐的做法是，在错误分析的过程中

55
00:03:14,440 --> 00:03:17,920
增加一列，去统计

56
00:03:17,920 --> 00:03:22,080
Y的标签错误的数量

57
00:03:22,080 --> 00:03:29,075
比如说，可能你需要统计开发集中100个错误标记的影响

58
00:03:29,075 --> 00:03:31,300
那么你要去找100个数据，

59
00:03:31,300 --> 00:03:35,595
它们经过分类器的输出，与开发集中的标签不符

60
00:03:35,595 --> 00:03:38,440
有时候，有少数例子

61
00:03:38,440 --> 00:03:42,175
你的分类器（的结果）与标签不符，是因为标签错了

62
00:03:42,175 --> 00:03:44,220
而不是你的分类器出错

63
00:03:44,220 --> 00:03:46,030
所以，在这个例子中

64
00:03:46,030 --> 00:03:49,415
你会发现，这个标记员漏掉了背景里的这只猫

65
00:03:49,415 --> 00:03:55,810
所以，在那里打个对勾，表示第98个例子的标签错了

66
00:03:55,810 --> 00:03:57,600
可能在这个例子里，

67
00:03:57,600 --> 00:04:01,845
这个图片实际上是一个画的猫，而不是真的猫

68
00:04:01,845 --> 00:04:06,865
可能你想要标记员标记成0，而不是1

69
00:04:06,865 --> 00:04:09,940
所以在这里打个对勾

70
00:04:09,940 --> 00:04:12,585
就像你计算错误率

71
00:04:12,585 --> 00:04:15,670
（这些错误率）由其他类别导致的，就像在之前的视频里提及的

72
00:04:15,670 --> 00:04:20,800
你也可以计算一下由这些错误标签导致的错误率

73
00:04:20,800 --> 00:04:23,320
在你的开发集里，Y的值是错的

74
00:04:23,320 --> 00:04:25,940
这解释了为什么你的机器学习算法

75
00:04:25,940 --> 00:04:32,140
预测了一个和数据里标签不一致的结果

76
00:04:32,140 --> 00:04:33,835
所以，现在的问题是

77
00:04:33,835 --> 00:04:41,045
我们值得花费时间去纠正这6%的错误标记的例子吗？

78
00:04:41,045 --> 00:04:43,060
我的建议是，

79
00:04:43,060 --> 00:04:47,560
如果这些错误对你评估算法在开发集上的效果
有很大的影响的话

80
00:04:47,560 --> 00:04:50,740
那就继续做吧，花时间去纠正这些错误标签

81
00:04:50,740 --> 00:04:52,900
但是如果没有太大影响

82
00:04:52,900 --> 00:04:56,125
对你用开发集去评估模型

83
00:04:56,125 --> 00:04:58,810
那你的时间最好不要花在这上面

84
00:04:58,810 --> 00:05:02,075
让我举个例子来解释一下

85
00:05:02,075 --> 00:05:05,620
我推荐你看三个数字，来决定是否

86
00:05:05,620 --> 00:05:09,305
值得你花时间去减少错误标记的数量

87
00:05:09,305 --> 00:05:12,755
我建议你看整体的开发集的错误率

88
00:05:12,755 --> 00:05:16,570
在上一个视频里提到的例子中，

89
00:05:16,570 --> 00:05:20,680
我们说系统的整体准确率达90%

90
00:05:20,680 --> 00:05:22,995
所以错误率是10%

91
00:05:22,995 --> 00:05:26,560
然后你应该看一下（另一个）错误率

92
00:05:26,560 --> 00:05:30,495
由错误的标签导致的错误率

93
00:05:30,495 --> 00:05:32,695
在这个例子中

94
00:05:32,695 --> 00:05:35,730
6%的错误是由错误的标签导致的

95
00:05:35,730 --> 00:05:40,990
10%的6%是0.6%

96
00:05:40,990 --> 00:05:45,600
然后你应该看一下由其他原因导致的错误率

97
00:05:45,600 --> 00:05:48,280
如果你的开发集上的错误率是10%

98
00:05:48,280 --> 00:05:51,580
0.6%是由错误的标签导致的

99
00:05:51,580 --> 00:05:54,430
那么剩下的，9.4%

100
00:05:54,430 --> 00:05:58,231
是由其他原因导致的，比如错把狗当猫

101
00:05:58,231 --> 00:06:01,420
大猫，以及它们的画像

102
00:06:01,420 --> 00:06:08,380
在这个例子中，我会说9.4%的错误值得你的去纠正

103
00:06:08,380 --> 00:06:12,370
而由错误的标签导致的错误

104
00:06:12,370 --> 00:06:16,360
只占整体错误率的很小一部分

105
00:06:16,360 --> 00:06:17,860
所以，虽然你也可以钻研进去

106
00:06:17,860 --> 00:06:20,605
并纠正所有这些错误标签

107
00:06:20,605 --> 00:06:24,455
但是，这大概不是当下最重要的事情

108
00:06:24,455 --> 00:06:26,830
现在，我们看另一个例子

109
00:06:26,830 --> 00:06:30,040
假设你在这个问题上取得了重大进步

110
00:06:30,040 --> 00:06:31,896
不是10%的错误率

111
00:06:31,896 --> 00:06:35,065
比如说，错误率降到了2%

112
00:06:35,065 --> 00:06:43,300
但是，其中依然有0.6%的错误是由错误的标签引起的

113
00:06:43,300 --> 00:06:47,755
现在，如果你想检查一下错误标记的数据集

114
00:06:47,755 --> 00:06:52,600
由错误标签引起的错误集，在整体2%的错误分类中的占比

115
00:06:52,600 --> 00:06:56,065
这个比例很大

116
00:06:56,065 --> 00:06:59,315
0.6(%)除以2%

117
00:06:59,315 --> 00:07:05,235
实际上是30%，而不是6%的标签

118
00:07:05,235 --> 00:07:09,145
你的错误分类的例子，实际上是由于错误的数据标签导致的

119
00:07:09,145 --> 00:07:12,445
因此，现在由其他错误导致的错误率只占1.4%

120
00:07:12,445 --> 00:07:16,885
当这么高的错误率

121
00:07:16,885 --> 00:07:23,640
是由你的开发集中错误的数据标签引起的时候

122
00:07:23,640 --> 00:07:30,825
那么，可能（这次）更值得花时间去
纠正这些开发集中错误的数据标签

123
00:07:30,825 --> 00:07:32,800
如果你记得开发集的目标的话

124
00:07:32,800 --> 00:07:34,890
就会知道开发集的主要目标是

125
00:07:34,890 --> 00:07:39,520
用它来帮助你在分类器A和B中作出选择

126
00:07:39,520 --> 00:07:42,030
当你试用两个分类器A和B时，

127
00:07:42,030 --> 00:07:49,740
在开发集上，一个错误率是2.1%，另一个错误率是1.9%

128
00:07:49,740 --> 00:07:52,370
但是现在你却不能相信你的开发集了

129
00:07:52,370 --> 00:07:55,020
不能相信它们会准确告知

130
00:07:55,020 --> 00:07:57,440
哪个分类器比这个好，因为此时会有

131
00:07:57,440 --> 00:08:02,215
0.6的错误都是由错误的标签引起的

132
00:08:02,215 --> 00:08:06,720
那么，这就是一个去纠正你的开发集中的
错误标签的很好的理由

133
00:08:06,720 --> 00:08:10,770
因为在右边的这个例子中，错误标签对
整体算法错误率的评估

134
00:08:10,770 --> 00:08:14,784
有着非常大的影响

135
00:08:14,784 --> 00:08:17,385
而在左边的例子中，影响的比例

136
00:08:17,385 --> 00:08:21,055
对于你的整体算法，依然很小

137
00:08:21,055 --> 00:08:24,040
现在，如果你决定探究开发集

138
00:08:24,040 --> 00:08:28,285
手动重新检查标签，并且尝试纠正一些标签

139
00:08:28,285 --> 00:08:33,505
这里由一些额外的指南或者说原则去考虑

140
00:08:33,505 --> 00:08:36,850
首先，不管在什么情况下，我都会鼓励你去

141
00:08:36,850 --> 00:08:41,320
同时应用开发集和测试集

142
00:08:41,320 --> 00:08:44,110
我们之前谈论过，关于为什么你需要

143
00:08:44,110 --> 00:08:47,335
开发集和测试集服从同样的分布

144
00:08:47,335 --> 00:08:50,890
其中开发集是你优化的目标
当你的模型在开发集上表现良好时

145
00:08:50,890 --> 00:08:53,320
你会希望这个良好的性质能推广到测试集

146
00:08:53,320 --> 00:08:55,540
所以当开发集和测试集服从相同分布时

147
00:08:55,540 --> 00:08:59,195
你的团队就能工作得更有效率

148
00:08:59,195 --> 00:09:01,620
因此，如果你要探究并纠正开发集中的一些问题

149
00:09:01,620 --> 00:09:04,290
我会建议将这个过程也应用到测试集，以确保

150
00:09:04,290 --> 00:09:07,170
它们依然服从同样的分布

151
00:09:07,170 --> 00:09:10,690
所以我们可以雇人来更仔细地检查这些标签

152
00:09:10,690 --> 00:09:13,125
对你的开发集和测试集，重复这样的工作

153
00:09:13,125 --> 00:09:16,255
第二，我强烈建议你考虑检查

154
00:09:16,255 --> 00:09:20,920
你的算法准确预测和错误预测的例子

155
00:09:20,920 --> 00:09:23,400
去检查你的算法错误预测的例子很简单

156
00:09:23,400 --> 00:09:26,875
只要看那些需要被纠正的

157
00:09:26,875 --> 00:09:30,463
不过有时可能即使你预测对了

158
00:09:30,463 --> 00:09:32,000
但它却是需要被修正的

159
00:09:32,000 --> 00:09:34,560
如果你只纠正那些预测错的样本

160
00:09:34,560 --> 00:09:38,905
那么当你评估算法错误率时，就会有更大的偏差

161
00:09:38,905 --> 00:09:42,450
这给你的算法带来一点不公平的优势

162
00:09:42,450 --> 00:09:46,560
我们只是尽量仔细检查它错的部分

163
00:09:46,560 --> 00:09:50,910
不过对于模型预测对的样本，也要进行检查

164
00:09:50,910 --> 00:09:54,645
因为模型可能仅仅因为运气好而预测对了
此时纠正一些标签的话，就去除运气成分

165
00:09:54,645 --> 00:09:59,160
并导致本来（因运气）预测对的
变成预测错误

166
00:09:59,160 --> 00:10:01,995
第二个原则不总那么容易执行

167
00:10:01,995 --> 00:10:03,865
所以也不常做

168
00:10:03,865 --> 00:10:08,055
不常做的原因是因为，如果你的分类器很准确

169
00:10:08,055 --> 00:10:11,940
那么它出错很少

170
00:10:11,940 --> 00:10:15,120
比如，你的分类器准确率达98%

171
00:10:15,120 --> 00:10:19,660
那么它只错误判断2%，能正确判断98%

172
00:10:19,660 --> 00:10:24,365
所以，检查和验证那2%的错误标签，更容易

173
00:10:24,365 --> 00:10:30,345
验证98%的数据需要花费更多的时间

174
00:10:30,345 --> 00:10:31,840
所以，并不常用

175
00:10:31,840 --> 00:10:34,365
这只是要考虑的一方面

176
00:10:34,365 --> 00:10:41,275
最后，如果你探究开发集和数据集，去纠正一些标签

177
00:10:41,275 --> 00:10:46,410
你可能应用同样的方法到训练集上，也可能不

178
00:10:46,410 --> 00:10:48,600
记住我们在这个课的其他视频里说过，实际上

179
00:10:48,600 --> 00:10:51,485
纠正训练集中的标签不那么重要

180
00:10:51,485 --> 00:10:54,750
很可能你决定纠正开发集和

181
00:10:54,750 --> 00:10:58,170
测试集中的标签，这部分数据更小

182
00:10:58,170 --> 00:11:01,710
比起训练集，你可能不会把额外工作都用来

183
00:11:01,710 --> 00:11:06,025
纠正那些在训练集中的标签

184
00:11:06,025 --> 00:11:07,365
实际上这是可以的

185
00:11:07,365 --> 00:11:11,775
本周我们会谈到一些方法

186
00:11:11,775 --> 00:11:14,070
来处理训练集

187
00:11:14,070 --> 00:11:17,435
和开发集、测试集服从不同分布的问题

188
00:11:17,435 --> 00:11:20,190
学习算法对这个问题是非常稳健的

189
00:11:20,190 --> 00:11:25,175
你的开发集和测试集服从相同的分布，这一点非常重要

190
00:11:25,175 --> 00:11:28,530
但是，如果你的训练集服从稍微不同的分布

191
00:11:28,530 --> 00:11:31,170
通常，这是非常合理的

192
00:11:31,170 --> 00:11:34,060
在以后的课程中，我会谈更多解决办法

193
00:11:34,060 --> 00:11:37,705
我想总结几个建议

194
00:11:37,705 --> 00:11:41,265
首先，深度学习的研究者有时会喜欢说

195
00:11:41,265 --> 00:11:42,920
我只是把数据扔进算法

196
00:11:42,920 --> 00:11:44,897
我训练了，然后算法有效

197
00:11:44,897 --> 00:11:48,035
在深度学习的错误中，有很多这样的例子

198
00:11:48,035 --> 00:11:51,000
有很多只是把数据扔进算法，然后训练模型

199
00:11:51,000 --> 00:11:54,685
做很少的工程师的工作，不加入人的观察

200
00:11:54,685 --> 00:11:57,780
但是我认为，建造实用的系统时，

201
00:11:57,780 --> 00:12:01,965
通常，有一些更偏向人工的错误分析和人的见解

202
00:12:01,965 --> 00:12:07,270
加入到系统中，深度学习研究者更重视

203
00:12:07,270 --> 00:12:10,580
第二，我见过一些工程师和

204
00:12:10,580 --> 00:12:14,415
研究者不愿意做人工去检查例子

205
00:12:14,415 --> 00:12:16,510
可能这不是有趣的事情

206
00:12:16,510 --> 00:12:17,745
去坐下来检查

207
00:12:17,745 --> 00:12:21,465
100或者几百的数据，去数错误的数量

208
00:12:21,465 --> 00:12:23,865
但是这是我的做法

209
00:12:23,865 --> 00:12:25,485
当我带领一个机器学期的团队时，我

210
00:12:25,485 --> 00:12:27,240
希望理解这个机器在犯什么错

211
00:12:27,240 --> 00:12:29,430
我会亲自去探究数据，并且

212
00:12:29,430 --> 00:12:31,820
尽力去计算错误率

213
00:12:31,820 --> 00:12:35,535
我认为这些时间，可能是几个

214
00:12:35,535 --> 00:12:40,005
小时，来计算（错误的）数据，可以帮助你辨别下一步做什么

215
00:12:40,005 --> 00:12:42,720
我认为这是非常好的利用时间，我强烈建议

216
00:12:42,720 --> 00:12:45,480
考虑也这么做，如果这些机器在

217
00:12:45,480 --> 00:12:47,385
你的系统里，而且你正在决定

218
00:12:47,385 --> 00:12:51,585
什么想法，或者说什么方向，去区分优先级

219
00:12:51,585 --> 00:12:55,620
好了，这是错误分析的方法

220
00:12:55,620 --> 00:13:00,060
在下一节课汇总，我想分享一些想法
并说明错误分析是如何

221
00:13:00,060 --> 00:13:05,000
与你要建造的新的机器学习项目配合的
GTC字幕组 翻译