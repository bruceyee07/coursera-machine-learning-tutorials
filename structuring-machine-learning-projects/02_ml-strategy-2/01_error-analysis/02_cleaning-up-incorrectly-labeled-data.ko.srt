1
00:00:00,000 --> 00:00:06,985
지도학습문제의 데이커는 입력값 X와 결과값 Y레이블로 이루어져 있습니다.

2
00:00:06,985 --> 00:00:09,730
만약에 여러분이 더이터를 확인하는 중에

3
00:00:09,730 --> 00:00:12,240
이러한 Y의 결과값이 다르다는 것을 확인해서 

4
00:00:12,240 --> 00:00:14,740
데이터가 결과적으로 잘못되었다는 것을 찾는다면 어떻게 될까요?

5
00:00:14,740 --> 00:00:19,540
이런 레이블을 수정하는데 값어치가 있다고 할 수 있을까요? 한번 살펴보겠습니다.

6
00:00:19,540 --> 00:00:21,640
고양이 인식 문제에서는 

7
00:00:21,640 --> 00:00:25,295
고양이인 경우에, Y는 1이고 고양이가 아닌 이미지는 0의 값을 갖습니다. 

8
00:00:25,295 --> 00:00:28,560
만약 여러분이 데이터를 보고 있는 중에, 이것은 고양이고

9
00:00:28,560 --> 00:00:30,400
이것은 고양이가 아니구요, 그리고 이것은 고양이입니다.

10
00:00:30,400 --> 00:00:33,275
이것도 고양이고, 이것은 아니고, 이 사진은 고양이입니다.

11
00:00:33,275 --> 00:00:35,480
잠시만요, 이것은 다시보면 고양이가 아니죠.

12
00:00:35,480 --> 00:00:41,310
이런 example처럼 레이블이 틀린 경우가 있습니다.

13
00:00:41,310 --> 00:00:43,900
이런 경우에 mislabeled example 이라는 용어를 사용했는데요,

14
00:00:43,900 --> 00:00:48,235
러닝 알고리즘이 틀린 Y의 값을 줄 때 쓰는 용어입니다. 

15
00:00:48,235 --> 00:00:50,800
하지만 저는 이 경우에, 틀리게 레이블된 example이라고 할 것입니다.

16
00:00:50,800 --> 00:00:53,590
트레이닝 세트나 dev set 또는 테스트세트에

17
00:00:53,590 --> 00:00:56,740
있는 데이터세트에서

18
00:00:56,740 --> 00:00:59,320
Y 레이블, 여기 데이터에 부여된

19
00:00:59,320 --> 00:01:02,228
인간레벨은 사실 틀립니다.

20
00:01:02,228 --> 00:01:06,430
그리고 저건 사실 강아지이기 때문에, Y는 애초에 0이였여야 합니다.

21
00:01:06,430 --> 00:01:10,115
레이블링을 한 사람이 틀린 것 일수 있겠죠. 

22
00:01:10,115 --> 00:01:14,755
그러므로 만약 여러분의 데이터가 잘못 레이블된 example이 있으면

23
00:01:14,755 --> 00:01:16,440
어떻게 해야할까요?

24
00:01:16,440 --> 00:01:21,177
첫번째로, 트레이닝 세트를 고려해보겠습니다.

25
00:01:21,177 --> 00:01:24,170
딥러닝 알고리즘이 트레이닝세트에서 random error을 상대로

26
00:01:24,170 --> 00:01:27,610
강하다는 것이 밝혀졌습니다.

27
00:01:27,610 --> 00:01:32,450
여러분의 오류 또는 잘못 레이블된 example들이, 

28
00:01:32,450 --> 00:01:35,420
이 오류들이 완전 무작위의 수치가 아닌 이상, 

29
00:01:35,420 --> 00:01:41,495
레이블링을 진행한 사람이 전혀 신경을 안쓰거나 실수로

30
00:01:41,495 --> 00:01:44,205
키보드 작업에서 실수를 범했을 수도 있었겠죠.

31
00:01:44,205 --> 00:01:46,400
만약 오류가 비교적 random 하다고 하면,

32
00:01:46,400 --> 00:01:49,130
아마도 이 오류들을 그대로 놔둬도 

33
00:01:49,130 --> 00:01:53,065
괜찮을 것입니다. 고치는데 너무 많은 시간을 쏟을 필요 없이 말이죠.

34
00:01:53,065 --> 00:01:55,040
물론 트레이닝 세트로 가서 레이블을

35
00:01:55,040 --> 00:01:57,920
직접 검사하고 수정해서 나쁠 것은 없습니다.

36
00:01:57,920 --> 00:02:02,285
가끔씩은 그럴 값어치가 있을 수 있습니다. 하지만 수정안해도 괜찮을 수 있습니다.

37
00:02:02,285 --> 00:02:05,390
토탈 데이터 세트 사이즈가 충분이 크고

38
00:02:05,390 --> 00:02:10,470
실제 오류의 퍼센트가 너무 크지 않으면 말이죠.

39
00:02:10,470 --> 00:02:15,230
당, 트레이닝 세트 레이블에서 X개의 실수가 있음에도 정상적으로 

40
00:02:15,230 --> 00:02:21,115
작동하는 머신러닝 알고리즘을 많이 봅니다.

41
00:02:21,115 --> 00:02:24,770
한가지 단서가 있기는 합니다.

42
00:02:24,770 --> 00:02:28,500
딥러닝 알고리즘이 random error에 강하다는 조건이죠.

43
00:02:28,500 --> 00:02:34,955
딥러닝 알고리즘은 systemic error에는 덜 강합니다.

44
00:02:34,955 --> 00:02:40,555
예를 들어, 레이블 한 사람이 지속적으로 흰색의 강아지를 고양이로 레이블했다면

45
00:02:40,555 --> 00:02:43,390
이것은 문제가 됩니다. 분류기가 모든 흰색 강아지를

46
00:02:43,390 --> 00:02:46,970
고양이로 분류하도록 배웠기 때문이죠.

47
00:02:46,970 --> 00:02:50,260
하지만 randowm error 또는 near random error들은

48
00:02:50,260 --> 00:02:54,575
대부분의 딥러닝 알고리즘에 그리 나쁘지 않습니다.

49
00:02:54,575 --> 00:02:57,730
이번 토론은 트레이닝 세트에서 잘못 레이블된 

50
00:02:57,730 --> 00:03:00,905
example에 대해 집중적이로 다뤘는데요,

51
00:03:00,905 --> 00:03:04,895
잘못 레이블 된 example들이 dev set나 test set에서는 어떨까요?

52
00:03:04,895 --> 00:03:07,195
만약 여러분이 dev set나 테스트세트에서 잘못 레이블된 example

53
00:03:07,195 --> 00:03:10,445
에 대해 걱정이 되신다고 하면,

54
00:03:10,445 --> 00:03:14,440
권장드리는 것은, 오류 분석 진행 중, 추가적으로 세로줄을

55
00:03:14,440 --> 00:03:17,920
넣어서 example들의 숫자를 세는 것입니다.

56
00:03:17,920 --> 00:03:22,080
레이블 Y가 틀린부분의 총 개수를 말이죠.

57
00:03:22,080 --> 00:03:29,075
예를 들어, 100개의 잘못 레이블된 dev set example을 세는 경우, 

58
00:03:29,075 --> 00:03:31,300
여러분의 분류기의 결과값이 dev set의 레이블과

59
00:03:31,300 --> 00:03:35,595
반대하는 100개의 example을 찾을 것입니다.

60
00:03:35,595 --> 00:03:38,440
가끔씩 이런 example 중에서,

61
00:03:38,440 --> 00:03:42,175
여러분의 분류기가 레이블이 단순히 틀려서 그 레이블과 반대하는 경우가 있습니다.

62
00:03:42,175 --> 00:03:44,220
분류기가 틀려서가 아니라요.

63
00:03:44,220 --> 00:03:46,030
아마도 그렇기 때문에 이번 예제에서, 

64
00:03:46,030 --> 00:03:49,415
이렇게 레이블한 사람이 뒤배경에 있는 고양이를 못 본 경우가 있을 수 있습니다. 

65
00:03:49,415 --> 00:03:55,810
그러면 여기 체크를 표시하여 98개의 example이 잘못 레이블 됐다고 표시를 합니다.

66
00:03:55,810 --> 00:03:57,600
이것도 말이죠,

67
00:03:57,600 --> 00:04:01,845
고양이를 그린 그림입니다. 실제 고양이가 아니구요.

68
00:04:01,845 --> 00:04:06,865
레이블한 사람이 Y는 0으로 하길 바랄 수 있죠. Y는 0이라고 하지 않구요.

69
00:04:06,865 --> 00:04:09,940
여기도 그럼 체크로 표시하겠습니다. 

70
00:04:09,940 --> 00:04:12,585
그럼 이전 비디오에서 본 다른 카테고리에서 생긴 

71
00:04:12,585 --> 00:04:15,670
오류의 퍼센트를 세면서, 

72
00:04:15,670 --> 00:04:20,800
틀린 레이블링으로 생긴 오류 퍼센트의 일부를 또 셉니다. 

73
00:04:20,800 --> 00:04:23,320
dev set 에서 Y 의 값이 틀렸을 때, 

74
00:04:23,320 --> 00:04:25,940
여러분의 러일 알고리즘이 

75
00:04:25,940 --> 00:04:32,140
데이터에 있는 레이블이 제시하는 내용과 다른 예측 결과값을 준 것입니다.

76
00:04:32,140 --> 00:04:33,835
그러면 여기서 문제는, 

77
00:04:33,835 --> 00:04:41,045
여기 6퍼센트 틀리게 레이블된 샘플을 고치는 것이 과연 값어치가 있는 작업일까 입니다.

78
00:04:41,045 --> 00:04:43,060
제가 조언 드리는 것은

79
00:04:43,060 --> 00:04:47,560
만약 여러분의 알고리즘이 dev set에서 그 평가능력이 현저히 개선되어
바뀔 수 있다면

80
00:04:47,560 --> 00:04:50,740
시간을 써서 레이블이 틀린 것들을 고치라고 말씀 드릴 수 있습니다.

81
00:04:50,740 --> 00:04:52,900
하지만 dev set에서 cost buyer를 평가하는데

82
00:04:52,900 --> 00:04:56,125
그 성능이 크게 바뀌지 않는다고 하면

83
00:04:56,125 --> 00:04:58,810
시간을 가장 현명하게 쓰는 것이라고 말하기 힘듭니다.

84
00:04:58,810 --> 00:05:02,075
이것이 정확히 무슨 뜻인지 제가 예제를 통해 말씀드리겠습니다.

85
00:05:02,075 --> 00:05:05,620
저는 여러분이 잘못 레이블된 example들을 줄일지의 여부를 결정하는데

86
00:05:05,620 --> 00:05:09,305
3가지의 수치를 보고 결정하길 추천드립니다. 그 수치들을 다음과 같습니다.

87
00:05:09,305 --> 00:05:12,755
전체적인 dev set 오류를 보시길 권장드립니다.

88
00:05:12,755 --> 00:05:16,570
이전 비디오에서 보여줬던 예제를 살펴보면,

89
00:05:16,570 --> 00:05:20,680
여기서는 시스템이 90퍼센트의 정확도를 가지고 있다고 했는데요,

90
00:05:20,680 --> 00:05:22,995
그러면 10퍼센트 오류겠죠.

91
00:05:22,995 --> 00:05:26,560
그러면 여러분은 오류의 개수를 봐야할 것입니다. 또는

92
00:05:26,560 --> 00:05:30,495
잘못 레이블된 것으로 인한 오류의 퍼센트입니다.

93
00:05:30,495 --> 00:05:32,695
이번 케이스 같은 경우엔,

94
00:05:32,695 --> 00:05:35,730
6퍼센트의 오류가 잘못된 레이블로 인한 오류입니다.

95
00:05:35,730 --> 00:05:40,990
그러면 10퍼센트의 6퍼센트는 0.6퍼센트입니다.

96
00:05:40,990 --> 00:05:45,600
다른 나머지 사유로 인한 오류도 봐야합니다. 

97
00:05:45,600 --> 00:05:48,280
만약 10퍼센트 에러가 dev set에서 발생했고,

98
00:05:48,280 --> 00:05:51,580
이것의 0,6퍼센트가 틀린 레이블로 인한 오류면

99
00:05:51,580 --> 00:05:54,430
그러면 나머지 9.4퍼센트는 

100
00:05:54,430 --> 00:05:58,231
강아지를 고양이로 잘못 오인식한 경우와 같은 사유일 것입니다.

101
00:05:58,231 --> 00:06:01,420
또는 great cats 와 같은 이미지를 말이죠. 

102
00:06:01,420 --> 00:06:08,380
그러므로 이런 케이스에서는, 9.4퍼센트의 오류만큼 수정하는데 집중할 수 있습니다.

103
00:06:08,380 --> 00:06:12,370
잘못된 레이블로 인한 오류는 

104
00:06:12,370 --> 00:06:16,360
전체 오류세트의 조금한 비중을 차지합니다.

105
00:06:16,360 --> 00:06:17,860
그러므로 원하시면

106
00:06:17,860 --> 00:06:20,605
이러한 잘못된 레이블 오류를 고칠 수 있지만

107
00:06:20,605 --> 00:06:24,455
여기서 가장 중요한 부분이라고 하기 어렵습니다.

108
00:06:24,455 --> 00:06:26,830
다른 example을 살펴보겠습니다.

109
00:06:26,830 --> 00:06:30,040
만약 여러분이 러닝 문제에서 상당부분 진전이 있었다고 해봅시다.

110
00:06:30,040 --> 00:06:31,896
그래서 10퍼센트 오류대신

111
00:06:31,896 --> 00:06:35,065
오류를 줄여서 2퍼센트로 만들었다고 해보겠습니다.

112
00:06:35,065 --> 00:06:43,300
하지만 아직 전체 오류의 0.6퍼센트는 잘못된 레이블로 인한 레이블입니다.

113
00:06:43,300 --> 00:06:47,755
그러면 여러분이 잘못 레이블된 dev set 이미지를 검사하고 싶으면,

114
00:06:47,755 --> 00:06:52,600
dev set 데이터의 잘못 레이블링된 2퍼센트입니다.

115
00:06:52,600 --> 00:06:56,065
그러면 이것의 상당한 비중을 차지하는 비율인데요, 

116
00:06:56,065 --> 00:06:59,315
0.6 나누기 6퍼센트입니다.

117
00:06:59,315 --> 00:07:05,235
그러면 이것은 여러분 레이블의 6퍼센트가 아니라 30퍼센트가 되는 것이죠. 

118
00:07:05,235 --> 00:07:09,145
틀린 example은 사실 틀린 레이블 example로 인한 것입니다.

119
00:07:09,145 --> 00:07:12,445
그러면 다른 사유로 인한 오류는 이제 1.4퍼센트가 됩니다.

120
00:07:12,445 --> 00:07:16,885
그러면 dev set에서 틀리게 레이블된 

121
00:07:16,885 --> 00:07:23,640
오류가, 그 비중이 매우 높기 때문에

122
00:07:23,640 --> 00:07:30,825
이제는 dev set에서 틀린 레이블을 수정하는 작업이 값어치가 있겠습니다.

123
00:07:30,825 --> 00:07:32,800
dev set의 목표를 기억하실지 모르겠지만, 

124
00:07:32,800 --> 00:07:34,890
dev set의 주된 목적은

125
00:07:34,890 --> 00:07:39,520
classifier A와 B 사이에서 어떤 것을 고를지 선택할 수 있도록 도움을 주는 것입니다.

126
00:07:39,520 --> 00:07:42,030
그러므로 여러분은 classifier A와 B를 2개 모두 시도해 보는 것이구요.

127
00:07:42,030 --> 00:07:49,740
하나는 2.1퍼센트 오류이고, 다른 하나는 1.9퍼센트 오류입니다. dve set에서 말이죠. 

128
00:07:49,740 --> 00:07:52,370
하지만 이제 더 이상, 이 classifier가 더 이상

129
00:07:52,370 --> 00:07:55,020
여기 실수의 0.6퍼센트가 틀린 레이블로 인한 오류이기 때문에

130
00:07:55,020 --> 00:07:57,440
더 낫다고 이야기하는 것을

131
00:07:57,440 --> 00:08:02,215
신뢰할 수 없게 되는 것입니다. 더 나은 classifier인지 모르는 것이죠.

132
00:08:02,215 --> 00:08:06,720
그렇다면, 이러한 사실을 여러분이 직접 개입해서 dev set에서 틀린 레이블에 대한 부분을 고치는 것에 대한 충분한 이유일 것입니다.

133
00:08:06,720 --> 00:08:10,770
여기 오른쪽 예제를 보시면, 알고리즘에서 발생하는 오류를

134
00:08:10,770 --> 00:08:14,784
전반적으로 평가하는데서, 이것이 큰 영향을 끼치고 있습니다.

135
00:08:14,784 --> 00:08:17,385
반면에 왼쪽 예제를 보면, 알고리즘에 끼치는 

136
00:08:17,385 --> 00:08:21,055
퍼센트 영향이 더 작습니다.

137
00:08:21,055 --> 00:08:24,040
여러분이 만약 dev set에서

138
00:08:24,040 --> 00:08:28,285
레이블을 수동으로 검사하고 이런 레이블들을 직접 고치려고 한다면, 

139
00:08:28,285 --> 00:08:33,505
여기 이런 추가적인 가이드라인과 원리를 고려해보십시요. 

140
00:08:33,505 --> 00:08:36,850
첫째로, 권장드리겠습니다.

141
00:08:36,850 --> 00:08:41,320
여러분이 어떤 방식의 프로세스를 적용하던 dev set와 test set 에 동시에 적용시키라고 말이죠.

142
00:08:41,320 --> 00:08:44,110
이번에 이야기 했지만, dev set와 test set는

143
00:08:44,110 --> 00:08:47,335
같은 분포에서 와야하는지에 대해 이야기 했었는데요. 

144
00:08:47,335 --> 00:08:50,890
dev set에서 목표를 설정하여, dev set에서 만약에 목표를 달성하면, 

145
00:08:50,890 --> 00:08:53,320
이것이 test set에서도 일반화가 되게 해줘야하는데요, 

146
00:08:53,320 --> 00:08:55,540
여러분의 팀은

147
00:08:55,540 --> 00:08:59,195
dev 오 테스트세트가 똑같은 분포에서 온 경우 더 효율적으로 
업무를 할 수 있습니다.

148
00:08:59,195 --> 00:09:01,620
만약 여러분이 dev set에서 어떤 것을 고치겠다고하면,

149
00:09:01,620 --> 00:09:04,290
test set에서도 똑같은 절차를 적용할 것입니다.

150
00:09:04,290 --> 00:09:07,170
똑같은 분포에서 오게하기 위해 말이죠.

151
00:09:07,170 --> 00:09:10,690
어떤 사람을 고용해서 레이블을 신중하게 검사하도록 합니다.

152
00:09:10,690 --> 00:09:13,125
dev 와 테스트세트 2개모두 그렇게 검사합니다.

153
00:09:13,125 --> 00:09:16,255
둘째로, 여러분의 알고리즘이

154
00:09:16,255 --> 00:09:20,920
잘 맞춘 것들을 포함해서 틀린 것들의 example을 잘 살펴보도록 
하시기 바랍니다.

155
00:09:20,920 --> 00:09:23,400
여러분의 알고리즘이 틀린 example들을 보고

156
00:09:23,400 --> 00:09:26,875
그것들이 고쳐져야 한다고 판단하는 것은 쉽습니다.

157
00:09:26,875 --> 00:09:30,463
그러나 또 가능한 것은, 여러분이 잘 맞추지 못한 것도

158
00:09:30,463 --> 00:09:32,000
수정되어야 하는 것들이 있을 수 있다는 것입니다.

159
00:09:32,000 --> 00:09:34,560
여러분의 알고리즘이 틀린 것만 고치게 되면, 

160
00:09:34,560 --> 00:09:38,905
알고리즘에서 더 많은 bias estimates 와 오류가 남게됩니다.

161
00:09:38,905 --> 00:09:42,450
알고리즘에 불공평한 이점을 부여하는 셈이죠. 

162
00:09:42,450 --> 00:09:46,560
단순히 틀린것만 다시 확인하는 것입니다.

163
00:09:46,560 --> 00:09:50,910
알고리즘이 맞춘 것은 다시 확인을 안하고 말이죠. 알고리즘은 분명

164
00:09:50,910 --> 00:09:54,645
단순한 운으로 맞췄을 수도 있습니다. 이러면

165
00:09:54,645 --> 00:09:59,160
레이블이 고쳐지지 않은 상태에서는 올바른 것에서 틀린 것으로 갈수도 있습니다.

166
00:09:59,160 --> 00:10:01,995
2번째 부분은 쉬운 부분이 아닙니다.

167
00:10:01,995 --> 00:10:03,865
그래서 항상 실행되지는 않죠. 

168
00:10:03,865 --> 00:10:08,055
실행되지 않는 이유는, 만약 여러분의 classifer가 굉장히 정확하면,

169
00:10:08,055 --> 00:10:11,940
맞추는 것 대비 더 적게 틀리게 됩니다. 

170
00:10:11,940 --> 00:10:15,120
그렇게해서 만약 classifier가 98퍼센트 정확도를 갖으면,

171
00:10:15,120 --> 00:10:19,660
이것은 2퍼센트 틀리고, 98퍼센트 맞추는 것입니다.

172
00:10:19,660 --> 00:10:24,365
그러므로 2퍼센트의 데이터 레이블을 검사하고 입증하는 것이

173
00:10:24,365 --> 00:10:30,345
훨씬 더 쉽고, 98퍼센트의 데이터를 입증하는 것은 훨씬 더 오래 걸립니다.

174
00:10:30,345 --> 00:10:31,840
그렇기 때문에 잘 실행되지 않는 것이죠.

175
00:10:31,840 --> 00:10:34,365
이것은 여러분이 고려할 사항입니다.

176
00:10:34,365 --> 00:10:41,275
마지막으로, 저기있는 레이블들을 dev와 테스트세트에서 고치게하면

177
00:10:41,275 --> 00:10:46,410
이러한 동일한 절차를 트레이닝세트에서도 적용시킬 수도 있고 그렇지 않을 수도 
있습니다.

178
00:10:46,410 --> 00:10:48,600
다른 비디오에서도 이야기했지만, 

179
00:10:48,600 --> 00:10:51,485
트레이닝세트에서 레이블을 수정하는 것은 덜 중요한 편입니다.

180
00:10:51,485 --> 00:10:54,750
그렇기 때문에, dev와 테스트세트에서만 레이블을 고치려 할 수 있는 것이죠

181
00:10:54,750 --> 00:10:58,170
2개의 세트는 주로 트레이닝세트보가 크기가 작은데요,

182
00:10:58,170 --> 00:11:01,710
이렇게 훨씬 규모가 큰 트레이닝세트에서 

183
00:11:01,710 --> 00:11:06,025
레이블을 줄이기 위해 많은 노력을 투자하지 않을 수도 있습니다.

184
00:11:06,025 --> 00:11:07,365
그래도 괜찮습니다.

185
00:11:07,365 --> 00:11:11,775
나중에 이번주안으로 트레이닝 데이터가

186
00:11:11,775 --> 00:11:14,070
dev와 테스트세트와 비교하여 그 분포가 다를때

187
00:11:14,070 --> 00:11:17,435
핸들링하는 절차에 대해 이야기해보겠습니다.

188
00:11:17,435 --> 00:11:20,190
러닝 알고리즘은 이런 것에대해 꽤 탄력적인 편인데요,

189
00:11:20,190 --> 00:11:25,175
dev와 테스트세트가 같은 분포를 갖는 것이 매우 중요합니다. 

190
00:11:25,175 --> 00:11:28,530
하지만 트레이닝세트가 살짝 다른 분포를 갖게되면

191
00:11:28,530 --> 00:11:31,170
비교적 합리적인 방안일 수도 있습니다.

192
00:11:31,170 --> 00:11:34,060
이것을 어떻게 처리하는지 다음주에 더 이야기하도록 하겠습니다.

193
00:11:34,060 --> 00:11:37,705
몇가지 조언을 드리고 마치겠습니다.

194
00:11:37,705 --> 00:11:41,265
첫째로, 딥러닝 리서치 연구원들은 이렇게 말하는 것을 좋아합니다.

195
00:11:41,265 --> 00:11:42,920
"방금 데이터를 알고리즘에 삽입시켰어.

196
00:11:42,920 --> 00:11:44,897
트레이닝을 시켰는데, 잘 작동해"

197
00:11:44,897 --> 00:11:48,035
딥러닝 오류와 관련해서는 이 말이 일리가 있습니다.

198
00:11:48,035 --> 00:11:51,000
데이터를 알고리즘에 삽입시키고 트레이닝 시키면서

199
00:11:51,000 --> 00:11:54,685
수동 엔지니어링 작업 또는 인간의 인사이트가 많이 개입되지 않을 수 있죠.

200
00:11:54,685 --> 00:11:57,780
하지만 실용적인 시스템을 만드는데 있어, 

201
00:11:57,780 --> 00:12:01,965
딥러닝 리서치 연구원들이 인정하려는 부분 이상으로 수동 오류 분석이나

202
00:12:01,965 --> 00:12:07,270
인간의 인사이트가 시스템에 개입된 부분이 많습니다.

203
00:12:07,270 --> 00:12:10,580
두번째로는 어떤 이유에서인지 저는 몇몇의 엔지니어나 

204
00:12:10,580 --> 00:12:14,415
리서치 연구원들이 수동적으로 example들을 검사하는 것을 싫어하는 것을 보았습니다.

205
00:12:14,415 --> 00:12:16,510
아마 그리 흥미로운 일은 아닐 것입니다.

206
00:12:16,510 --> 00:12:17,745
가만히 앉아서 100개 또는

207
00:12:17,745 --> 00:12:21,465
몇백개의 오류의 개수를 세는 것이 말이죠. 

208
00:12:21,465 --> 00:12:23,865
이것은 제가 직접 하는 것입니다.

209
00:12:23,865 --> 00:12:25,485
제가 머신러닝팀을 리드하는 경우엔

210
00:12:25,485 --> 00:12:27,240
이것이 어떤 실수를 하고 있는지 이해하고 싶을 것입니다.

211
00:12:27,240 --> 00:12:29,430
저는 개인적으로 데이터를 직접볼 것 같습니다.

212
00:12:29,430 --> 00:12:31,820
오류의 일부를 세기 위해서 말이죠. 

213
00:12:31,820 --> 00:12:35,535
이러한 분의 단위가 또는 몇 시간 단위의 시간을 재는 데이터가

214
00:12:35,535 --> 00:12:40,005
여러분의 우선순위를 결정하는 선택권에 도움이 된다고 생각합니다. 

215
00:12:40,005 --> 00:12:42,720
이것이 시간을 잘 사용하는 방법인 것 같고

216
00:12:42,720 --> 00:12:45,480
여러분들도 만약에 이런 기계가 시스템이 있다면 

217
00:12:45,480 --> 00:12:47,385
하시길 권장드립니다. 어떤 아이디어가 좋을지 또는

218
00:12:47,385 --> 00:12:51,585
우선순위를 매기기 위해 어떤 방향을 택해야할지 고민이 된다면 말이죠.

219
00:12:51,585 --> 00:12:55,620
이 내용이 오류 분석 절차에 대한 내용 전부입니다.

220
00:12:55,620 --> 00:13:00,060
다음 비디오에서는 오류 분석이 새로운 머신 러닝 프로젝트를 시작하는 방법에 

221
00:13:00,060 --> 00:13:05,000
어떻게 적용되는지에 대한 몇가지 생각을 공유하고자 합니다.