1
00:00:00,000 --> 00:00:06,985
在監督式學習的資料中包含了輸入 X 跟輸出標籤  Ｙ

2
00:00:06,985 --> 00:00:09,730
如果通過您的資料
您發現一些

3
00:00:09,730 --> 00:00:12,240
輸出標籤 Y 是錯誤時怎麼辦?

4
00:00:12,240 --> 00:00:14,740
您有一些標示不正確的資料

5
00:00:14,740 --> 00:00:19,540
值不值得您花時間來更正這些標籤? 我們來看看

6
00:00:19,540 --> 00:00:21,640
在貓咪分類器問題中

7
00:00:21,640 --> 00:00:25,295
Y 等於 1 當照片是貓時
等於 0 當不是貓

8
00:00:25,295 --> 00:00:28,560
所以假設當您看這些資料，認出這是貓

9
00:00:28,560 --> 00:00:30,400
這不是貓，這是貓

10
00:00:30,400 --> 00:00:33,275
這是貓，這不是貓，這是貓

11
00:00:33,275 --> 00:00:35,480
等一下, 這實際上並不是貓

12
00:00:35,480 --> 00:00:41,310
所以這是一個標籤不正確的例子

13
00:00:41,310 --> 00:00:43,900
我用了這個名詞，誤標例子 (mislabeled example)

14
00:00:43,900 --> 00:00:48,235
來表示如果您的學習算法輸出錯誤的 Y 值

15
00:00:48,235 --> 00:00:50,800
但我會用，標籤不正確例子 (incorrectly labeled examples)

16
00:00:50,800 --> 00:00:53,590
來代表如果在

17
00:00:53,590 --> 00:00:56,740
您用的資料集，不管是訓練集，開發集，測試集

18
00:00:56,740 --> 00:00:59,320
標籤 Y, 不管是人工標示

19
00:00:59,320 --> 00:01:02,228
分派到這個資料時，實際上是不正確的

20
00:01:02,228 --> 00:01:06,430
這實際上是一隻狗, 所以 Y 真的應該為零

21
00:01:06,430 --> 00:01:10,115
也許標籤的人弄錯了

22
00:01:10,115 --> 00:01:14,755
所以如果您發現您的資料
有一些不正確標籤例子時

23
00:01:14,755 --> 00:01:16,440
你該怎麼辦？

24
00:01:16,440 --> 00:01:21,177
首先，先來考慮訓練集

25
00:01:21,177 --> 00:01:24,170
實際上深度學習演算法

26
00:01:24,170 --> 00:01:27,610
對於訓練集中的隨機錯誤
是不太受影響的

27
00:01:27,610 --> 00:01:32,450
只要您的錯誤
或者說您的不正確標籤例子

28
00:01:32,450 --> 00:01:35,420
只要這些錯誤不離隨機太遠

29
00:01:35,420 --> 00:01:41,495
也許有時候標籤者只是沒有注意
或者他們不小心

30
00:01:41,495 --> 00:01:44,205
隨機誤打鍵盤上的鍵

31
00:01:44,205 --> 00:01:46,400
如果錯誤是合理隨機的

32
00:01:46,400 --> 00:01:49,130
那麼它可能會沒事, 只是不管

33
00:01:49,130 --> 00:01:53,065
這些錯誤，而不用花太多時間來糾正它們

34
00:01:53,065 --> 00:01:55,040
當然如果您進入這些

35
00:01:55,040 --> 00:01:57,920
訓練集逐一去改正它們也沒關係

36
00:01:57,920 --> 00:02:02,285
也許有時候值得做
但如果不做應該也沒事

37
00:02:02,285 --> 00:02:05,390
只要整體資料數量很大

38
00:02:05,390 --> 00:02:10,470
那實際真正這些錯誤
的百分比也許不高

39
00:02:10,470 --> 00:02:15,230
我看過很多機器學習演算法
訓練了即使當我們知道

40
00:02:15,230 --> 00:02:21,115
有一些 X 錯誤在訓練集
通常還是可以正常工作

41
00:02:21,115 --> 00:02:24,770
但這裡有一個警告，也就是

42
00:02:24,770 --> 00:02:28,500
深度學習演算法是對
隨機錯誤不受影響

43
00:02:28,500 --> 00:02:34,955
但對於系統化的錯誤就不見得

44
00:02:34,955 --> 00:02:40,555
舉個例子，如果您的標籤者一直將白狗標為貓

45
00:02:40,555 --> 00:02:43,390
那就會是一個問題，因為您的分類器

46
00:02:43,390 --> 00:02:46,970
會學習將白狗分類為貓

47
00:02:46,970 --> 00:02:50,260
但隨機錯誤或者幾乎隨機錯誤

48
00:02:50,260 --> 00:02:54,575
通常對大多數學習演算法都可以處理

49
00:02:54,575 --> 00:02:57,730
目前為止的討論都集中在

50
00:02:57,730 --> 00:03:00,905
不正確標籤例子在您的訓練集

51
00:03:00,905 --> 00:03:04,895
如果這些不正確標籤例子發生
在您的開發集或者測試集呢？

52
00:03:04,895 --> 00:03:07,195
如果您擔心

53
00:03:07,195 --> 00:03:10,445
在您開發集或測試集的
不正確標籤例子的影響

54
00:03:10,445 --> 00:03:14,440
通常建議您當在做錯誤分析時

55
00:03:14,440 --> 00:03:17,920
加入另外一個欄位
讓您可以計算

56
00:03:17,920 --> 00:03:22,080
標籤 Ｙ不正確標示的數目

57
00:03:22,080 --> 00:03:29,075
舉例來說，或許當您計算 100 個誤標的開發集例子時

58
00:03:29,075 --> 00:03:31,300
所以您用 100 個例子在

59
00:03:31,300 --> 00:03:35,595
您的分類器輸出時跟您
開發集上的標籤不一致

60
00:03:35,595 --> 00:03:38,440
而有時候有一些例子

61
00:03:38,440 --> 00:03:42,175
您的分類器跟標籤不一致
因為您的標籤錯了

62
00:03:42,175 --> 00:03:44,220
而不是您的分類器錯了

63
00:03:44,220 --> 00:03:46,030
或許在這個例子中

64
00:03:46,030 --> 00:03:49,415
您發現標籤者
錯過了一隻在背景的貓

65
00:03:49,415 --> 00:03:55,810
所以在這裡標註一下表示
第 98 號例子不正確標籤

66
00:03:55,810 --> 00:03:57,600
或許這一個

67
00:03:57,600 --> 00:04:01,845
這個照片裡是畫的貓
而不是真的貓

68
00:04:01,845 --> 00:04:06,865
或許您要標籤者應該標為 0 而不是標為 1

69
00:04:06,865 --> 00:04:09,940
所以您放另一個
標註記號在這裡

70
00:04:09,940 --> 00:04:12,585
而當您依次數這些錯誤的比例時

71
00:04:12,585 --> 00:04:15,670
就像其他的類別
我們在上一段影片看過的

72
00:04:15,670 --> 00:04:20,800
您也同時計算了因為
不正確標籤造成的錯誤的百分比

73
00:04:20,800 --> 00:04:23,320
也就是您開發集的 Y 值

74
00:04:23,320 --> 00:04:25,940
是不正確的，導致於您的學習演算法

75
00:04:25,940 --> 00:04:32,140
預估的值不同於您資料上的標籤

76
00:04:32,140 --> 00:04:33,835
所以現在問題是

77
00:04:33,835 --> 00:04:41,045
這個 6% 的不正確標籤例子值得去糾正它們嗎？

78
00:04:41,045 --> 00:04:43,060
我的建議是

79
00:04:43,060 --> 00:04:47,560
如果它是一個顯著的誤差對於
您要評估演算法在您的開發集上時

80
00:04:47,560 --> 00:04:50,740
那請花時間來矯正這些錯誤的標籤

81
00:04:50,740 --> 00:04:52,900
但如果沒造成

82
00:04:52,900 --> 00:04:56,125
對於您用這個開發集
來評估交叉偏差時顯著不同時

83
00:04:56,125 --> 00:04:58,810
那也許這並不是
最佳的時間運用

84
00:04:58,810 --> 00:05:02,075
讓我用一個例子
來解釋我的意思

85
00:05:02,075 --> 00:05:05,620
有三個數子我建議您使用
來決定是否

86
00:05:05,620 --> 00:05:09,305
值得減低誤標例子的數字如下

87
00:05:09,305 --> 00:05:12,755
我建議您看整體開發集的錯誤

88
00:05:12,755 --> 00:05:16,570
在前面的影片中
我們所使用的例子

89
00:05:16,570 --> 00:05:20,680
我們說或許我們的系統有 90% 的正確性

90
00:05:20,680 --> 00:05:22,995
所以有 10% 的錯誤

91
00:05:22,995 --> 00:05:26,560
然後您看

92
00:05:26,560 --> 00:05:30,495
因為不正確的標籤造成的
錯誤數或者錯誤百分比

93
00:05:30,495 --> 00:05:32,695
所以看來在這個情況下

94
00:05:32,695 --> 00:05:35,730
6% 的錯誤來至於不正確的標籤

95
00:05:35,730 --> 00:05:40,990
所以 10% 裡的 6% 是 0.6%

96
00:05:40,990 --> 00:05:45,600
然後您應該看其他所有的原因造成的錯誤

97
00:05:45,600 --> 00:05:48,280
所以如果您發生了 10% 的錯誤在開發集上

98
00:05:48,280 --> 00:05:51,580
而 0.6% 因為標籤錯了

99
00:05:51,580 --> 00:05:54,430
而其他的 9.4%

100
00:05:54,430 --> 00:05:58,231
是來自於像誤認狗為貓

101
00:05:58,231 --> 00:06:01,420
大貓跟模糊照片

102
00:06:01,420 --> 00:06:08,380
這種情況下，我會說這個 9.4% 的錯誤
值得您集中精神去修復

103
00:06:08,380 --> 00:06:12,370
然而這因為不正確標籤造成的錯誤

104
00:06:12,370 --> 00:06:16,360
相對於整體的錯誤而言佔小的比例

105
00:06:16,360 --> 00:06:17,860
所以不管怎樣

106
00:06:17,860 --> 00:06:20,605
如果您要的話就去修正這些錯誤的標籤

107
00:06:20,605 --> 00:06:24,455
但或許現階段
並不是最重要的事情

108
00:06:24,455 --> 00:06:26,830
現在，舉另一個例子

109
00:06:26,830 --> 00:06:30,040
假設您的學習問題獲得重大的進展

110
00:06:30,040 --> 00:06:31,896
所以與其是 10% 的錯誤

111
00:06:31,896 --> 00:06:35,065
假設您將錯誤減低至 2%

112
00:06:35,065 --> 00:06:43,300
這時假設因為不正確標籤造成的
整體錯誤依然是 0.6%

113
00:06:43,300 --> 00:06:47,755
現在，如果您檢驗您的誤標開發集照片

114
00:06:47,755 --> 00:06:52,600
來自於只有 2% 的開發集是您誤標的

115
00:06:52,600 --> 00:06:56,065
那有很大一部分

116
00:06:56,065 --> 00:06:59,315
0.6% 除以 2%

117
00:06:59,315 --> 00:07:05,235
所以實際上有 30% 而不是 6% 的您的標籤

118
00:07:05,235 --> 00:07:09,145
來自於不正確的例子，
來自於不正確標籤的例子

119
00:07:09,145 --> 00:07:12,445
所以因為其他因素
造成的錯誤現在是 1.4%

120
00:07:12,445 --> 00:07:16,885
當如此大的比例

121
00:07:16,885 --> 00:07:23,640
您的錯誤來自於
您開發集不正確的標籤時

122
00:07:23,640 --> 00:07:30,825
或許似乎很值得修復
這些開發集上的不正確標籤

123
00:07:30,825 --> 00:07:32,800
而如果您記得開發集的目的

124
00:07:32,800 --> 00:07:34,890
開發集的主要目的是

125
00:07:34,890 --> 00:07:39,520
您想要真的幫助您選擇
分類器 A 或 B

126
00:07:39,520 --> 00:07:42,030
所以您試了兩個分類器 A 跟 B

127
00:07:42,030 --> 00:07:49,740
一個是 2.1% 錯誤率，
另一個是 1.9% 的錯誤率在開發集上

128
00:07:49,740 --> 00:07:52,370
但您不再相信
您的開發集能夠正確地

129
00:07:52,370 --> 00:07:55,020
告訴您是否這個分類器

130
00:07:55,020 --> 00:07:57,440
真的比這個好
因為您的

131
00:07:57,440 --> 00:08:02,215
0.6% 的錯誤率來自於不正確的標籤

132
00:08:02,215 --> 00:08:06,720
那這會是一個好理由來
更正您開發集的不正確標籤

133
00:08:06,720 --> 00:08:10,770
因為在右邊的這個例子對於

134
00:08:10,770 --> 00:08:14,784
演算法的整體錯誤率
評估上有很大的影響

135
00:08:14,784 --> 00:08:17,385
而在左邊的例子，
那樣的百分比

136
00:08:17,385 --> 00:08:21,055
對於您的演算法來講
還是很小的

137
00:08:21,055 --> 00:08:24,040
現在，如果您決定在開發集上

138
00:08:24,040 --> 00:08:28,285
手工重新檢驗標籤
然後試著更正一些標籤

139
00:08:28,285 --> 00:08:33,505
這裡有一些指南
或者說原則要考慮

140
00:08:33,505 --> 00:08:36,850
首先，我會鼓勵您應用

141
00:08:36,850 --> 00:08:41,320
不管是哪一種程序
同時應用在開發跟測試集上

142
00:08:41,320 --> 00:08:44,110
我們之前談過
有關您希望

143
00:08:44,110 --> 00:08:47,335
開發跟測試集
來自同樣的分佈

144
00:08:47,335 --> 00:08:50,890
開發集是告訴您是否正中目標
而如果您中了

145
00:08:50,890 --> 00:08:53,320
您希望能夠一般化到測試集上

146
00:08:53,320 --> 00:08:55,540
所以您的團隊真的

147
00:08:55,540 --> 00:08:59,195
比較有效率
當開發跟測試集來自於同一個分佈

148
00:08:59,195 --> 00:09:01,620
所以如果您將更正
開發集上的一些東西

149
00:09:01,620 --> 00:09:04,290
我會應用相同的程序到
測試集來保證

150
00:09:04,290 --> 00:09:07,170
那們來自於同一個分佈

151
00:09:07,170 --> 00:09:10,690
所以我們請一個人
更小心的檢驗這些標籤

152
00:09:10,690 --> 00:09:13,125
記得同時檢驗開發跟測試集

153
00:09:13,125 --> 00:09:16,255
第二點，我會催促您考慮檢驗

154
00:09:16,255 --> 00:09:20,920
您演算法弄正確的例子
跟不正確的例子

155
00:09:20,920 --> 00:09:23,400
檢驗您的演算法

156
00:09:23,400 --> 00:09:26,875
弄錯，然後只看是否
需要更正這些是很容易的

157
00:09:26,875 --> 00:09:30,463
但也有可能，有一些例子您不是真的弄對的

158
00:09:30,463 --> 00:09:32,000
也應該要更正

159
00:09:32,000 --> 00:09:34,560
而如果您只更正
那些演算法弄錯的

160
00:09:34,560 --> 00:09:38,905
您最終會有更多的偏差
對於您演算法的錯誤

161
00:09:38,905 --> 00:09:42,450
這樣做會讓您的演算法
佔了一些不公平優勢

162
00:09:42,450 --> 00:09:46,560
如果我們只有重新檢驗那些錯的
但不去

163
00:09:46,560 --> 00:09:50,910
重新檢驗那些對的，因為那些弄對的

164
00:09:50,910 --> 00:09:54,645
有可能是運氣好
而更正標籤後

165
00:09:54,645 --> 00:09:59,160
舉例來說
有可能從對的變成錯的

166
00:09:59,160 --> 00:10:01,995
第二點，並不那麼容易做到

167
00:10:01,995 --> 00:10:03,865
所以通常都沒做

168
00:10:03,865 --> 00:10:08,055
通常沒做的原因是
因為如果您的分類器已經很準了

169
00:10:08,055 --> 00:10:11,940
那比起對的部分，
錯的部分變得很少

170
00:10:11,940 --> 00:10:15,120
所以如果您的分類器有 98% 的正確率

171
00:10:15,120 --> 00:10:19,660
那大約會有 2% 是錯的， 98% 是正確的

172
00:10:19,660 --> 00:10:24,365
所以要檢驗 2% 的標籤
的資料比較容易

173
00:10:24,365 --> 00:10:30,345
而要檢驗 98% 的資料
要花相對較長的時間

174
00:10:30,345 --> 00:10:31,840
所以通常都沒做

175
00:10:31,840 --> 00:10:34,365
只是您需要考慮做這件事

176
00:10:34,365 --> 00:10:41,275
最後，如果您決定到開發及測試集
更正一些標籤資料

177
00:10:41,275 --> 00:10:46,410
您或許需要決定要或不要
應用同樣的流程到訓練集上

178
00:10:46,410 --> 00:10:48,600
記得我們在其他影片中說過實際上

179
00:10:48,600 --> 00:10:51,485
在訓練集更正標籤
是比較不那麼重要

180
00:10:51,485 --> 00:10:54,750
這是可能的，您決定去更正開發集跟

181
00:10:54,750 --> 00:10:58,170
測試集的標籤，通常這些資料比起

182
00:10:58,170 --> 00:11:01,710
訓練集小很多而您或許不用花額外的功夫

183
00:11:01,710 --> 00:11:06,025
來更正資料大很多的訓練集

184
00:11:06,025 --> 00:11:07,365
這實際上是可行的

185
00:11:07,365 --> 00:11:11,775
稍後這個禮拜，我們會談到一些流程

186
00:11:11,775 --> 00:11:14,070
來處理當您的訓練資料

187
00:11:14,070 --> 00:11:17,435
跟開發集跟測試集的分佈是不同的

188
00:11:17,435 --> 00:11:20,190
學習演算法對於這點很有辦法

189
00:11:20,190 --> 00:11:25,175
您的開發跟測試集來自同樣的分佈是
超級重要的

190
00:11:25,175 --> 00:11:28,530
但如果您的訓練集來自於稍微不同的分佈

191
00:11:28,530 --> 00:11:31,170
通常是很合理的事

192
00:11:31,170 --> 00:11:34,060
我會做這個禮拜談論
如何處理這樣的問題

193
00:11:34,060 --> 00:11:37,705
所以我想總結一下一些建議

194
00:11:37,705 --> 00:11:41,265
首先，深度學習研究者
有時候喜歡說

195
00:11:41,265 --> 00:11:42,920
“我只是將資料餵給演算法

196
00:11:42,920 --> 00:11:44,897
我訓練它，然後它就可以作用”

197
00:11:44,897 --> 00:11:48,035
當然在深度學習時代
這是很真實的

198
00:11:48,035 --> 00:11:51,000
比較多的是餵資料給演算法，訓練它

199
00:11:51,000 --> 00:11:54,685
比較少用手工功夫跟比較少的人為洞察力

200
00:11:54,685 --> 00:11:57,780
但我想在建立一個實用的系統時

201
00:11:57,780 --> 00:12:01,965
通常也有更多的人為錯誤分析
跟更多人類洞察力

202
00:12:01,965 --> 00:12:07,270
進入這個系統，
有時候深度學習研究者也承認這點

203
00:12:07,270 --> 00:12:10,580
第二點，不知何故，我看過一些工程師

204
00:12:10,580 --> 00:12:14,415
跟研究者不願意手工來看這些資料

205
00:12:14,415 --> 00:12:16,510
或許這不是最有趣的事情

206
00:12:16,510 --> 00:12:17,745
坐下來然後看

207
00:12:17,745 --> 00:12:21,465
100 個或者幾百個例子
來數錯誤的數目

208
00:12:21,465 --> 00:12:23,865
但這是我自己會做的事情

209
00:12:23,865 --> 00:12:25,485
當我領導一個機器學習團隊，我

210
00:12:25,485 --> 00:12:27,240
希望知道患了哪些錯誤

211
00:12:27,240 --> 00:12:29,430
我會實際的自己來看這些資料

212
00:12:29,430 --> 00:12:31,820
試著去數錯誤的比例

213
00:12:31,820 --> 00:12:35,535
而我想因為這幾分鐘或者幾小時

214
00:12:35,535 --> 00:12:40,005
來數這些資料可以幫助您
決定下一步的優先順序

215
00:12:40,005 --> 00:12:42,720
我發覺這是很棒的時間利用，
我也敦促

216
00:12:42,720 --> 00:12:45,480
您考慮這樣做，
如果這些機器

217
00:12:45,480 --> 00:12:47,385
在您的系統而您試著決定

218
00:12:47,385 --> 00:12:51,585
哪一個想法或哪一個方向
是優先事項

219
00:12:51,585 --> 00:12:55,620
所以這就是誤差分析流程

220
00:12:55,620 --> 00:13:00,060
在下一個影片中，
我想分享一些想法在看誤差分析

221
00:13:00,060 --> 00:13:05,000
如何擺入當您開始一個新的機器學習專案