지도학습문제의 데이커는 입력값 X와 결과값 Y레이블로 이루어져 있습니다. 만약에 여러분이 더이터를 확인하는 중에 이러한 Y의 결과값이 다르다는 것을 확인해서 데이터가 결과적으로 잘못되었다는 것을 찾는다면 어떻게 될까요? 이런 레이블을 수정하는데 값어치가 있다고 할 수 있을까요? 한번 살펴보겠습니다. 고양이 인식 문제에서는 고양이인 경우에, Y는 1이고 고양이가 아닌 이미지는 0의 값을 갖습니다. 만약 여러분이 데이터를 보고 있는 중에, 이것은 고양이고 이것은 고양이가 아니구요, 그리고 이것은 고양이입니다. 이것도 고양이고, 이것은 아니고, 이 사진은 고양이입니다. 잠시만요, 이것은 다시보면 고양이가 아니죠. 이런 example처럼 레이블이 틀린 경우가 있습니다. 이런 경우에 mislabeled example 이라는 용어를 사용했는데요, 러닝 알고리즘이 틀린 Y의 값을 줄 때 쓰는 용어입니다. 하지만 저는 이 경우에, 틀리게 레이블된 example이라고 할 것입니다. 트레이닝 세트나 dev set 또는 테스트세트에 있는 데이터세트에서 Y 레이블, 여기 데이터에 부여된 인간레벨은 사실 틀립니다. 그리고 저건 사실 강아지이기 때문에, Y는 애초에 0이였여야 합니다. 레이블링을 한 사람이 틀린 것 일수 있겠죠. 그러므로 만약 여러분의 데이터가 잘못 레이블된 example이 있으면 어떻게 해야할까요? 첫번째로, 트레이닝 세트를 고려해보겠습니다. 딥러닝 알고리즘이 트레이닝세트에서 random error을 상대로 강하다는 것이 밝혀졌습니다. 여러분의 오류 또는 잘못 레이블된 example들이, 이 오류들이 완전 무작위의 수치가 아닌 이상, 레이블링을 진행한 사람이 전혀 신경을 안쓰거나 실수로 키보드 작업에서 실수를 범했을 수도 있었겠죠. 만약 오류가 비교적 random 하다고 하면, 아마도 이 오류들을 그대로 놔둬도 괜찮을 것입니다. 고치는데 너무 많은 시간을 쏟을 필요 없이 말이죠. 물론 트레이닝 세트로 가서 레이블을 직접 검사하고 수정해서 나쁠 것은 없습니다. 가끔씩은 그럴 값어치가 있을 수 있습니다. 하지만 수정안해도 괜찮을 수 있습니다. 토탈 데이터 세트 사이즈가 충분이 크고 실제 오류의 퍼센트가 너무 크지 않으면 말이죠. 당, 트레이닝 세트 레이블에서 X개의 실수가 있음에도 정상적으로 작동하는 머신러닝 알고리즘을 많이 봅니다. 한가지 단서가 있기는 합니다. 딥러닝 알고리즘이 random error에 강하다는 조건이죠. 딥러닝 알고리즘은 systemic error에는 덜 강합니다. 예를 들어, 레이블 한 사람이 지속적으로 흰색의 강아지를 고양이로 레이블했다면 이것은 문제가 됩니다. 분류기가 모든 흰색 강아지를 고양이로 분류하도록 배웠기 때문이죠. 하지만 randowm error 또는 near random error들은 대부분의 딥러닝 알고리즘에 그리 나쁘지 않습니다. 이번 토론은 트레이닝 세트에서 잘못 레이블된 example에 대해 집중적이로 다뤘는데요, 잘못 레이블 된 example들이 dev set나 test set에서는 어떨까요? 만약 여러분이 dev set나 테스트세트에서 잘못 레이블된 example 에 대해 걱정이 되신다고 하면, 권장드리는 것은, 오류 분석 진행 중, 추가적으로 세로줄을 넣어서 example들의 숫자를 세는 것입니다. 레이블 Y가 틀린부분의 총 개수를 말이죠. 예를 들어, 100개의 잘못 레이블된 dev set example을 세는 경우, 여러분의 분류기의 결과값이 dev set의 레이블과 반대하는 100개의 example을 찾을 것입니다. 가끔씩 이런 example 중에서, 여러분의 분류기가 레이블이 단순히 틀려서 그 레이블과 반대하는 경우가 있습니다. 분류기가 틀려서가 아니라요. 아마도 그렇기 때문에 이번 예제에서, 이렇게 레이블한 사람이 뒤배경에 있는 고양이를 못 본 경우가 있을 수 있습니다. 그러면 여기 체크를 표시하여 98개의 example이 잘못 레이블 됐다고 표시를 합니다. 이것도 말이죠, 고양이를 그린 그림입니다. 실제 고양이가 아니구요. 레이블한 사람이 Y는 0으로 하길 바랄 수 있죠. Y는 0이라고 하지 않구요. 여기도 그럼 체크로 표시하겠습니다. 그럼 이전 비디오에서 본 다른 카테고리에서 생긴 오류의 퍼센트를 세면서, 틀린 레이블링으로 생긴 오류 퍼센트의 일부를 또 셉니다. dev set 에서 Y 의 값이 틀렸을 때, 여러분의 러일 알고리즘이 데이터에 있는 레이블이 제시하는 내용과 다른 예측 결과값을 준 것입니다. 그러면 여기서 문제는, 여기 6퍼센트 틀리게 레이블된 샘플을 고치는 것이 과연 값어치가 있는 작업일까 입니다. 제가 조언 드리는 것은 만약 여러분의 알고리즘이 dev set에서 그 평가능력이 현저히 개선되어
바뀔 수 있다면 시간을 써서 레이블이 틀린 것들을 고치라고 말씀 드릴 수 있습니다. 하지만 dev set에서 cost buyer를 평가하는데 그 성능이 크게 바뀌지 않는다고 하면 시간을 가장 현명하게 쓰는 것이라고 말하기 힘듭니다. 이것이 정확히 무슨 뜻인지 제가 예제를 통해 말씀드리겠습니다. 저는 여러분이 잘못 레이블된 example들을 줄일지의 여부를 결정하는데 3가지의 수치를 보고 결정하길 추천드립니다. 그 수치들을 다음과 같습니다. 전체적인 dev set 오류를 보시길 권장드립니다. 이전 비디오에서 보여줬던 예제를 살펴보면, 여기서는 시스템이 90퍼센트의 정확도를 가지고 있다고 했는데요, 그러면 10퍼센트 오류겠죠. 그러면 여러분은 오류의 개수를 봐야할 것입니다. 또는 잘못 레이블된 것으로 인한 오류의 퍼센트입니다. 이번 케이스 같은 경우엔, 6퍼센트의 오류가 잘못된 레이블로 인한 오류입니다. 그러면 10퍼센트의 6퍼센트는 0.6퍼센트입니다. 다른 나머지 사유로 인한 오류도 봐야합니다. 만약 10퍼센트 에러가 dev set에서 발생했고, 이것의 0,6퍼센트가 틀린 레이블로 인한 오류면 그러면 나머지 9.4퍼센트는 강아지를 고양이로 잘못 오인식한 경우와 같은 사유일 것입니다. 또는 great cats 와 같은 이미지를 말이죠. 그러므로 이런 케이스에서는, 9.4퍼센트의 오류만큼 수정하는데 집중할 수 있습니다. 잘못된 레이블로 인한 오류는 전체 오류세트의 조금한 비중을 차지합니다. 그러므로 원하시면 이러한 잘못된 레이블 오류를 고칠 수 있지만 여기서 가장 중요한 부분이라고 하기 어렵습니다. 다른 example을 살펴보겠습니다. 만약 여러분이 러닝 문제에서 상당부분 진전이 있었다고 해봅시다. 그래서 10퍼센트 오류대신 오류를 줄여서 2퍼센트로 만들었다고 해보겠습니다. 하지만 아직 전체 오류의 0.6퍼센트는 잘못된 레이블로 인한 레이블입니다. 그러면 여러분이 잘못 레이블된 dev set 이미지를 검사하고 싶으면, dev set 데이터의 잘못 레이블링된 2퍼센트입니다. 그러면 이것의 상당한 비중을 차지하는 비율인데요, 0.6 나누기 6퍼센트입니다. 그러면 이것은 여러분 레이블의 6퍼센트가 아니라 30퍼센트가 되는 것이죠. 틀린 example은 사실 틀린 레이블 example로 인한 것입니다. 그러면 다른 사유로 인한 오류는 이제 1.4퍼센트가 됩니다. 그러면 dev set에서 틀리게 레이블된 오류가, 그 비중이 매우 높기 때문에 이제는 dev set에서 틀린 레이블을 수정하는 작업이 값어치가 있겠습니다. dev set의 목표를 기억하실지 모르겠지만, dev set의 주된 목적은 classifier A와 B 사이에서 어떤 것을 고를지 선택할 수 있도록 도움을 주는 것입니다. 그러므로 여러분은 classifier A와 B를 2개 모두 시도해 보는 것이구요. 하나는 2.1퍼센트 오류이고, 다른 하나는 1.9퍼센트 오류입니다. dve set에서 말이죠. 하지만 이제 더 이상, 이 classifier가 더 이상 여기 실수의 0.6퍼센트가 틀린 레이블로 인한 오류이기 때문에 더 낫다고 이야기하는 것을 신뢰할 수 없게 되는 것입니다. 더 나은 classifier인지 모르는 것이죠. 그렇다면, 이러한 사실을 여러분이 직접 개입해서 dev set에서 틀린 레이블에 대한 부분을 고치는 것에 대한 충분한 이유일 것입니다. 여기 오른쪽 예제를 보시면, 알고리즘에서 발생하는 오류를 전반적으로 평가하는데서, 이것이 큰 영향을 끼치고 있습니다. 반면에 왼쪽 예제를 보면, 알고리즘에 끼치는 퍼센트 영향이 더 작습니다. 여러분이 만약 dev set에서 레이블을 수동으로 검사하고 이런 레이블들을 직접 고치려고 한다면, 여기 이런 추가적인 가이드라인과 원리를 고려해보십시요. 첫째로, 권장드리겠습니다. 여러분이 어떤 방식의 프로세스를 적용하던 dev set와 test set 에 동시에 적용시키라고 말이죠. 이번에 이야기 했지만, dev set와 test set는 같은 분포에서 와야하는지에 대해 이야기 했었는데요. dev set에서 목표를 설정하여, dev set에서 만약에 목표를 달성하면, 이것이 test set에서도 일반화가 되게 해줘야하는데요, 여러분의 팀은 dev 오 테스트세트가 똑같은 분포에서 온 경우 더 효율적으로 
업무를 할 수 있습니다. 만약 여러분이 dev set에서 어떤 것을 고치겠다고하면, test set에서도 똑같은 절차를 적용할 것입니다. 똑같은 분포에서 오게하기 위해 말이죠. 어떤 사람을 고용해서 레이블을 신중하게 검사하도록 합니다. dev 와 테스트세트 2개모두 그렇게 검사합니다. 둘째로, 여러분의 알고리즘이 잘 맞춘 것들을 포함해서 틀린 것들의 example을 잘 살펴보도록 
하시기 바랍니다. 여러분의 알고리즘이 틀린 example들을 보고 그것들이 고쳐져야 한다고 판단하는 것은 쉽습니다. 그러나 또 가능한 것은, 여러분이 잘 맞추지 못한 것도 수정되어야 하는 것들이 있을 수 있다는 것입니다. 여러분의 알고리즘이 틀린 것만 고치게 되면, 알고리즘에서 더 많은 bias estimates 와 오류가 남게됩니다. 알고리즘에 불공평한 이점을 부여하는 셈이죠. 단순히 틀린것만 다시 확인하는 것입니다. 알고리즘이 맞춘 것은 다시 확인을 안하고 말이죠. 알고리즘은 분명 단순한 운으로 맞췄을 수도 있습니다. 이러면 레이블이 고쳐지지 않은 상태에서는 올바른 것에서 틀린 것으로 갈수도 있습니다. 2번째 부분은 쉬운 부분이 아닙니다. 그래서 항상 실행되지는 않죠. 실행되지 않는 이유는, 만약 여러분의 classifer가 굉장히 정확하면, 맞추는 것 대비 더 적게 틀리게 됩니다. 그렇게해서 만약 classifier가 98퍼센트 정확도를 갖으면, 이것은 2퍼센트 틀리고, 98퍼센트 맞추는 것입니다. 그러므로 2퍼센트의 데이터 레이블을 검사하고 입증하는 것이 훨씬 더 쉽고, 98퍼센트의 데이터를 입증하는 것은 훨씬 더 오래 걸립니다. 그렇기 때문에 잘 실행되지 않는 것이죠. 이것은 여러분이 고려할 사항입니다. 마지막으로, 저기있는 레이블들을 dev와 테스트세트에서 고치게하면 이러한 동일한 절차를 트레이닝세트에서도 적용시킬 수도 있고 그렇지 않을 수도 
있습니다. 다른 비디오에서도 이야기했지만, 트레이닝세트에서 레이블을 수정하는 것은 덜 중요한 편입니다. 그렇기 때문에, dev와 테스트세트에서만 레이블을 고치려 할 수 있는 것이죠 2개의 세트는 주로 트레이닝세트보가 크기가 작은데요, 이렇게 훨씬 규모가 큰 트레이닝세트에서 레이블을 줄이기 위해 많은 노력을 투자하지 않을 수도 있습니다. 그래도 괜찮습니다. 나중에 이번주안으로 트레이닝 데이터가 dev와 테스트세트와 비교하여 그 분포가 다를때 핸들링하는 절차에 대해 이야기해보겠습니다. 러닝 알고리즘은 이런 것에대해 꽤 탄력적인 편인데요, dev와 테스트세트가 같은 분포를 갖는 것이 매우 중요합니다. 하지만 트레이닝세트가 살짝 다른 분포를 갖게되면 비교적 합리적인 방안일 수도 있습니다. 이것을 어떻게 처리하는지 다음주에 더 이야기하도록 하겠습니다. 몇가지 조언을 드리고 마치겠습니다. 첫째로, 딥러닝 리서치 연구원들은 이렇게 말하는 것을 좋아합니다. "방금 데이터를 알고리즘에 삽입시켰어. 트레이닝을 시켰는데, 잘 작동해" 딥러닝 오류와 관련해서는 이 말이 일리가 있습니다. 데이터를 알고리즘에 삽입시키고 트레이닝 시키면서 수동 엔지니어링 작업 또는 인간의 인사이트가 많이 개입되지 않을 수 있죠. 하지만 실용적인 시스템을 만드는데 있어, 딥러닝 리서치 연구원들이 인정하려는 부분 이상으로 수동 오류 분석이나 인간의 인사이트가 시스템에 개입된 부분이 많습니다. 두번째로는 어떤 이유에서인지 저는 몇몇의 엔지니어나 리서치 연구원들이 수동적으로 example들을 검사하는 것을 싫어하는 것을 보았습니다. 아마 그리 흥미로운 일은 아닐 것입니다. 가만히 앉아서 100개 또는 몇백개의 오류의 개수를 세는 것이 말이죠. 이것은 제가 직접 하는 것입니다. 제가 머신러닝팀을 리드하는 경우엔 이것이 어떤 실수를 하고 있는지 이해하고 싶을 것입니다. 저는 개인적으로 데이터를 직접볼 것 같습니다. 오류의 일부를 세기 위해서 말이죠. 이러한 분의 단위가 또는 몇 시간 단위의 시간을 재는 데이터가 여러분의 우선순위를 결정하는 선택권에 도움이 된다고 생각합니다. 이것이 시간을 잘 사용하는 방법인 것 같고 여러분들도 만약에 이런 기계가 시스템이 있다면 하시길 권장드립니다. 어떤 아이디어가 좋을지 또는 우선순위를 매기기 위해 어떤 방향을 택해야할지 고민이 된다면 말이죠. 이 내용이 오류 분석 절차에 대한 내용 전부입니다. 다음 비디오에서는 오류 분석이 새로운 머신 러닝 프로젝트를 시작하는 방법에 어떻게 적용되는지에 대한 몇가지 생각을 공유하고자 합니다.