1
00:00:00,350 --> 00:00:02,080
안녕하세요, 환영합니다.

2
00:00:02,080 --> 00:00:06,550
여러분이 만약 러닝 알고리즘이 인간이 수행가능한 업무를
할 수 있도록 만들고 싶으면, 

3
00:00:06,550 --> 00:00:10,490
또는 현재 시점에서 여러분의 러닝 알고리즘이
인간의 성능에 아직 못 미치는 경우에, 

4
00:00:10,490 --> 00:00:13,790
수동으로 알고리즘이 범하는 실수들을
점검하는 것이

5
00:00:13,790 --> 00:00:16,240
다음은 어떻게 해야할지 알려줄만한
인사이트를 제공해줄 것입니다.

6
00:00:16,240 --> 00:00:19,040
이런 절차를 오류 분석이라고 합니다. 예제로 시작해보겠습니다.

7
00:00:19,040 --> 00:00:20,890
우선 예제를 봅시다.

8
00:00:20,890 --> 00:00:24,520
고양이 분류기를 작업하고 있고 
90퍼센트 정확도를 획득했다고

9
00:00:24,520 --> 00:00:29,390
가정해봅시다. 즉, dev set에서의10퍼센트
오류라고도 할 수 있죠.

10
00:00:29,390 --> 00:00:32,820
그리고 이 수치가 여러분이 원하는 수치보다 
더 높은 수치라고 가정해봅시다. 

11
00:00:32,820 --> 00:00:36,740
이런 경우, 팀의 인원은 알고리즘의 example들을 보면서

12
00:00:36,740 --> 00:00:42,340
틀리게 분류하는 것들을 찾을 수도 있는데요,
강아지를 고양이로 잘못 카테고리화하는 경우를 찾는 것이죠. 

13
00:00:42,340 --> 00:00:46,080
이 2가지 경우의 강아지를 보면, 
2개의 사진의 경우 강아지들이 약간 고양이처럼 보일 수도 있겠죠.

14
00:00:46,080 --> 00:00:47,628
적어도 처음 볼때는 말이죠.

15
00:00:47,628 --> 00:00:51,160
여러분의 팀원이 이것을 보고 

16
00:00:51,160 --> 00:00:56,110
강아지에 대해서 알고리즘을 강화하는 방법을 
제안할 수도 있습니다. 

17
00:00:56,110 --> 00:01:01,080
focus effort를 만드는 경우를 생각하면 되는데요,
강아지 사진을 더 모은다거나

18
00:01:01,080 --> 00:01:04,680
강아지에 특화된 디자인을 만드는 방법이 있겠습니다.

19
00:01:04,680 --> 00:01:07,833
고양이 분류기에서 강아지 사진을 상대로 더 잘 작동할 수 있도록 하기 위해서,

20
00:01:07,833 --> 00:01:11,070
강아지를 고양이로 틀리게 인식하는 경우를 방지하기 위해서,

21
00:01:11,070 --> 00:01:13,980
강아지 문제에 대해서 project focus를 시작할지

22
00:01:13,980 --> 00:01:18,080
가 여러분이 질문할 수 있는 부분입니다.

23
00:01:19,325 --> 00:01:23,740
여러분이 알고리즘에서 강아지 사진을 잘못 인식하는 것을

24
00:01:23,740 --> 00:01:25,890
수정 작업하는데 수개월이 걸릴 수 있습니다.

25
00:01:27,280 --> 00:01:29,550
이런 노력이 과연 값어치가 있을까요?

26
00:01:29,550 --> 00:01:32,475
이런 과정을 진행하는데 수개월을 소비한 뒤,

27
00:01:32,475 --> 00:01:36,175
별로 수정 결과가 좋지 않고
도움이 되지 않다는 것을 발견할 수 있습니다.

28
00:01:36,175 --> 00:01:40,605
여기 이 오류분석 절차가 
여러분이 노력을 쏟을만한 값어치가 

29
00:01:40,605 --> 00:01:43,055
있는지 알려줍니다.

30
00:01:43,055 --> 00:01:45,180
여러분에게 추천드리는 부분은 이렇습니다.

31
00:01:45,180 --> 00:01:51,860
첫번째로, 대략 100개의 미스레이블된 dev set 샘플을 가지고와서
수동으로 검사합니다.

32
00:01:51,860 --> 00:01:56,380
1개씩 숫자를 세구요, 
이 중에 몇개가 미스레이블 샘플인지

33
00:01:56,380 --> 00:01:59,338
dev set에서 확인하고 강아지 사진을 걸러냅니다.

34
00:01:59,338 --> 00:02:02,160
그리고 100개의 잘못 레이블된 dev set 샘플 중

35
00:02:02,160 --> 00:02:07,700
5퍼센트가 강아지 이미지라고 해봅시다.

36
00:02:07,700 --> 00:02:12,740
즉, 100개의 잘못 레이블된 dev set 샘플 중

37
00:02:12,740 --> 00:02:18,231
5개가 강아지의 사진인 것입니다.
이 뜻은 100 개의 example중, 

38
00:02:18,231 --> 00:02:23,217
일반적인 100개의 example중, 
틀린것을 완벽히 

39
00:02:23,217 --> 00:02:28,807
해결하게 되더라도 
100개중 5개만 수정을할 수 있다는 것입니다.

40
00:02:28,807 --> 00:02:33,802
다시 말해서, 만약 오류의 5퍼센트만이
강아지 사진이라고 했을 때, 

41
00:02:33,802 --> 00:02:38,076
가장 잘할 수 있는 것은, 
강아지 문제에 많은 시간을 투자하는 것입니다.

42
00:02:38,076 --> 00:02:43,256
여러분의 오류는 
10퍼센트 오류에서

43
00:02:43,256 --> 00:02:46,635
9.5퍼센트로 내려갈 수도 있는데요,

44
00:02:46,635 --> 00:02:53,455
이것은 상대적으로 5퍼센트가 줄어든 것입니다.
10퍼센트에서 9.5퍼센트로 줄어든 것이 말이죠. 

45
00:02:53,455 --> 00:02:58,220
그러므로 여러분은 합리적으로 생각했을때,
이것이 효율적인 시간 투자가 아니라고 생각할 수도 있습니다.

46
00:02:58,220 --> 00:03:02,743
또는, 적어도 이것이 상한선을 이야기해줄 수도 있죠. 맞죠?

47
00:03:02,743 --> 00:03:08,566
강아지 문제에 대한 위의 상한선을 제시해서 얼마나 성능을 개선할 수 있는지 말이죠. 맞죠?

48
00:03:08,566 --> 00:03:09,150
그렇죠?

49
00:03:10,800 --> 00:03:15,870
머신러닝에서는, 이것을 ceiling on performance라고 합니다.

50
00:03:15,870 --> 00:03:17,818
이것은 어떤게 가장 좋은 케이스일까요? 를 뜻합니다.

51
00:03:17,818 --> 00:03:20,720
강아지 문제에 작업을 진행하는 것이 얼마나 도움이 될까요? 
등의 문제에 대한 가이드라인을 제시해줍니다.

52
00:03:22,690 --> 00:03:25,310
그럼 이제, 다른 일이 벌어진다고 생각해봅시다.

53
00:03:25,310 --> 00:03:28,590
100개의 잘못 레이블된 example을 본다고 해봅시다.

54
00:03:28,590 --> 00:03:32,340
이 중, 50장이 강아지 이미지입니다.

55
00:03:32,340 --> 00:03:35,620
즉, 50퍼센트가 강아지 사진인 것입니다.

56
00:03:35,620 --> 00:03:39,760
여러분이 이런 경우, 강아지 문제에 시간을 투자하는 것이 
조금 더 긍정적으로 다가올 것입니다.

57
00:03:39,760 --> 00:03:42,807
이 같은 케이스의 경우,
강아지 문제를 푸는 경우,

58
00:03:42,807 --> 00:03:47,158
오류가 10퍼센트에서 5퍼센트로 줄 수 있기 때문이죠.

59
00:03:47,158 --> 00:03:52,260
그러면 오류를 반으로 줄이는 것에대해 
많은 노력이 그 값어치를 한다고 생각할 수 있습니다.

60
00:03:52,260 --> 00:03:56,150
잘못 레이블된 강아지 이미지를 줄이는데 집중하는 것을 말이죠.

61
00:03:56,150 --> 00:04:00,446
머신러닝에서는 사람들이 가끔씩 hand engineering에 대해 

62
00:04:00,446 --> 00:04:03,660
폄하하거나 너무 많은 value insight를 사용한다고 생각하는데요, 

63
00:04:03,660 --> 00:04:09,280
하지만 적용시스템을 만드는 경우, 
이렇게 간단히 숫자를 세는 과정이

64
00:04:09,280 --> 00:04:12,120
, 오류 분석이 많은 시간을 절약할 수 있게 해줍니다.

65
00:04:12,120 --> 00:04:14,740
어떤 것이 가장 중요한지 여부를 결정하는데에 있어, 

66
00:04:14,740 --> 00:04:17,309
또는 가장 유망한 방향은 어떤지, 집중해햐하는 방향을 결정하는데 있어 말이죠.

67
00:04:19,739 --> 00:04:24,263
100개의 잘못 레이블된 dev set example을 본다고 하면,

68
00:04:24,263 --> 00:04:27,620
이것을 어쩌면 5 에서 10분 정도의 노력일 수 있습니다.

69
00:04:27,620 --> 00:04:29,930
수동으로 100개의 샘플을 확인해서

70
00:04:29,930 --> 00:04:32,860
수동으로 강아지 사진의 수를 세는데 소요되는 시간이 말이죠.

71
00:04:32,860 --> 00:04:36,212
결과에 따라서, 5퍼센트인지, 

72
00:04:36,212 --> 00:04:37,570
50퍼센트인지 확인도 가능합니다.

73
00:04:37,570 --> 00:04:39,580
이러한 절차를 5에서 10분내 하는 것이죠. 

74
00:04:39,580 --> 00:04:44,310
업무방향의 효용성을 예측하는데 드는 시간 말이죠.

75
00:04:44,310 --> 00:04:46,430
이렇게해서 훨씬 더 나은 결정을 내리실 수 있습니다.

76
00:04:46,430 --> 00:04:51,470
잘못 레이블된 강아지 이미지를 수개월간 수정작업할지 

77
00:04:51,470 --> 00:04:54,180
결정하는데 말이죠. 

78
00:04:54,180 --> 00:04:58,120
이번 슬라이드에서는 하나의 다루는 아이디어가, 

79
00:04:58,120 --> 00:05:02,380
이번 사례에서는 강아지가 되겠죠,
이것을 오류분석으로 평가해보겠습니다.

80
00:05:02,380 --> 00:05:08,260
가끔은 여러가지 아이디어를 parallel 방식의 오류 분석을 진행해서 
평가를 할 수도 있습니다.

81
00:05:08,260 --> 00:05:12,920
예를 들어, 고양이 이미지를 감지하는데 몇가지 아이디어가 있다고 해봅시다. 

82
00:05:12,920 --> 00:05:16,460
강아지 이미지 인식 성능을 개선하는 방법이 있겠죠? 

83
00:05:16,460 --> 00:05:19,785
또는 great cat이라고도 하는 

84
00:05:19,785 --> 00:05:22,332
사자,표범, 치타를 인식 개선하는 방법도 있습니다.

85
00:05:22,332 --> 00:05:25,758
이런 사진들이 작은 고양이나 house 고양이로 인식되는 경우를 막는거죠.

86
00:05:25,758 --> 00:05:28,031
이점을 개선하는 방법에 중점을 둘 수 있습니다.

87
00:05:28,031 --> 00:05:32,632
또는 이미지가 흐릿한 경우에 대비해, 

88
00:05:32,632 --> 00:05:36,489
선명하지 않은 이미지에서 잘 작동하는 알고리즘을 
디자인할 수도 있습니다.

89
00:05:37,560 --> 00:05:39,280
이런 방안들을 진행하기 위한 아이디어가 있으실 수도 있겠죠. 

90
00:05:41,480 --> 00:05:45,430
이런 3가지의 아이디어를 평가하기위해 
오류분석을 진행하려면

91
00:05:45,430 --> 00:05:48,430
저같은 경우, 이렇게 생긴 테이블을 
만들 것입니다.

92
00:05:50,760 --> 00:05:53,940
저는 보통 스프레드시트에서 진행하는데요, 

93
00:05:53,940 --> 00:05:56,520
일반 텍스트파일을 사용하셔도 됩니다.

94
00:05:57,610 --> 00:05:58,605
왼쪽에서는,

95
00:05:58,605 --> 00:06:02,430
이것이 여러분이 수동으로 작업하려는 이미지들로 들어가는데요,

96
00:06:02,430 --> 00:06:06,010
이게 아마 1에서 100으로 갈텐데요, 
100개의 사진을 검사하는 경우에 말이죠.

97
00:06:06,010 --> 00:06:09,910
이 테이블의 세로줄은, 스프레드시트에서. 

98
00:06:09,910 --> 00:06:12,570
평가하려는 아이디어에 해당하는 사항입니다.

99
00:06:12,570 --> 00:06:18,490
즉, 강아지 문제, great cat, 흐릿한 이미지에 해당합니다.

100
00:06:18,490 --> 00:06:23,870
저는 보통 스프레드시트에서 코멘트를 위한 공간을 남겨둡니다.

101
00:06:23,870 --> 00:06:25,724
기억하셔야할 부분은, 오류분석을 진행한다는 것은,

102
00:06:25,724 --> 00:06:29,610
알고리즘이 잘못 카테고리화한 것들에 대해서
dev set example을 보는 것이라는 것 말이죠.

103
00:06:30,670 --> 00:06:34,640
만약 첫번째로 잘못 인식된 이미지가 강아지 사진이였을 경우에,

104
00:06:34,640 --> 00:06:36,550
여기에다 체크로 표시할 것입니다.

105
00:06:36,550 --> 00:06:39,540
그리고 이 이미지를 기억하기위해,

106
00:06:39,540 --> 00:06:41,830
여기 이렇게 코멘트란에 노트를 남겨둘 것입니다.

107
00:06:41,830 --> 00:06:44,380
이것은 핏불 사진이였을 수 있죠.

108
00:06:44,380 --> 00:06:48,110
두번째 사진이 흐릿하다고하면 
여기 노트를 하십시요.

109
00:06:48,110 --> 00:06:53,317
세번째 사진이 비오는 날 동물원에서 찍은 사자의 이미지면, 
잘못 인식된 것입니다.

110
00:06:53,317 --> 00:06:56,030
이것은 great cat이고, 또 이것은 흐릿한 데이터겠죠.

111
00:06:56,030 --> 00:07:00,920
노트를 이렇게 적을 수 있겠죠. 
비오는 날 동물원, 

112
00:07:00,920 --> 00:07:03,620
비오는 날씨로 인해 흐릿하게 이미지 나옴
이라고 말이죠. 

113
00:07:05,670 --> 00:07:08,616
마지막으로, 이미지 세트를 리뷰하셨다면, 

114
00:07:08,616 --> 00:07:11,508
알고리즘의 몇 퍼센트가, 

115
00:07:11,508 --> 00:07:16,951
알고리즘의 오류 카테고리 중 몇 퍼센트가 
강아지에 관련한 상황인지,

116
00:07:16,951 --> 00:07:19,360
또는 great cat 인지 또는 흐릿한 이미지인지 개수를 셀 것입니다.

117
00:07:19,360 --> 00:07:26,484
8퍼센트에 해당하는 수치는 강아지 사진일수도 있는데요,

118
00:07:26,484 --> 00:07:32,390
43퍼센트 수치는 great cats, 61퍼센트는 흐릿한 이미지이구요.

119
00:07:32,390 --> 00:07:34,720
이 것은, 세로줄을 단계별로 내려가시면서

120
00:07:34,720 --> 00:07:39,290
몇 퍼센트의 이미지가 체크마크가 되어있는지 
개수를 세면서 확인하는 것입니다.

121
00:07:39,290 --> 00:07:41,567
이 절차를 어느정도 진행하셨으면,

122
00:07:41,567 --> 00:07:44,420
또 다른 카테고리의 실수를 발견할 수 있는데요.

123
00:07:44,420 --> 00:07:50,240
예를 들어, Instagram style filter와 같은 

124
00:07:50,240 --> 00:07:55,420
화려한 필터들이 여러분의 분류기를 망가트리는 경우가 있을 것입니다.

125
00:07:55,420 --> 00:07:55,940
그런 경우,

126
00:07:55,940 --> 00:08:00,240
괜찮습니다만, 진행 과정에서 세로줄을 이렇게 추가하셔도 됩니다. 

127
00:08:00,240 --> 00:08:03,125
멀티칼라 필터인 인스타그램 필터들과 

128
00:08:03,125 --> 00:08:04,650
스냅필터를 말이죠.

129
00:08:04,650 --> 00:08:07,900
그런 뒤에 개수를 다시 세고,

130
00:08:07,900 --> 00:08:11,050
새로운 오류 카테고리에서 몇 퍼센트의 오류가 발생하는지 
확인을 합니다.

131
00:08:12,170 --> 00:08:16,640
이런 절차를 모두 마치면, 이렇게 다른 종류의

132
00:08:16,640 --> 00:08:19,880
오류 카테고리에 대해서 수정작업을 하는 것이 얼마나
값어치가 있는지 추정할 수 있습니다. 

133
00:08:19,880 --> 00:08:23,820
예를 들어, 이 예제에서보면 분명히 알 수 있는 것은 
흐릿한 이미지에서 많은 오류가 있었고, 

134
00:08:23,820 --> 00:08:28,780
great cat에 대한 오분류도 꽤 많았습니다.

135
00:08:28,780 --> 00:08:35,750
그렇게해서, 분석의 결과는 
흐릿한 이미지를 작업해야한다는 직접적인 결과가 아닙니다.

136
00:08:35,750 --> 00:08:39,360
이런 결과는 단순한 수학 공식처럼 무엇을 어떻게 하라고 알려주는 
것이 아닙니다. 

137
00:08:39,360 --> 00:08:43,140
대신에 전반적으로 가장 선택하기 좋은 옵션에 대한 
감각적인 부분을 제시해주는 것이죠.

138
00:08:43,140 --> 00:08:44,650
또한 예를 들어 이런 내용도 말해줍니다.

139
00:08:44,650 --> 00:08:50,490
아무리 강아지에 대한 인식을 잘해도, 도는 인스타그램에서 분류를 잘해도

140
00:08:50,490 --> 00:08:55,130
8퍼센트까지 밖에 성능개선을 못한다, 또는 12퍼센트 개선 가능하다 이런식으로 
말이죠. 

141
00:08:55,130 --> 00:08:57,700
아니면 great cat 이미지 또는 흐릿한 이미지는 

142
00:08:57,700 --> 00:09:00,246
잠정적인 개선 부분이 있지만 이 부분은 이정도 밖에 개선이 안된다라는 부분을 
말해줄 수 있습니다.

143
00:09:00,246 --> 00:09:03,730
성능을 개선하고 증가시키는 부분에 있어서 

144
00:09:03,730 --> 00:09:05,390
특정 한계치가 있는데요, 

145
00:09:05,390 --> 00:09:09,010
great cat에 대해 성능개선을 하는 idea가 얼마나 있는지에 따라

146
00:09:09,010 --> 00:09:10,320
흐릿한 이미지의 idea가 얼마나 있는지에 따라서 말이죠

147
00:09:10,320 --> 00:09:13,856
둘 중 한가지를 고르는 방법도 있습니다.또는
팀원이 충분하다고 하면, 

148
00:09:13,856 --> 00:09:15,630
2개의 다른 팀으로 구성하는 방법도 있습니다.

149
00:09:15,630 --> 00:09:18,629
한팀은 great cat에 대한 오류를 개선하고,

150
00:09:18,629 --> 00:09:22,120
다른 한팀은 흐릿한 이미지를 개선하는 것입니다.

151
00:09:27,184 --> 00:09:31,280
이렇게 빠르게 수동으로 세는 작업은,

152
00:09:31,280 --> 00:09:33,130
주로 몇시간이면 처리가 가능한데요,

153
00:09:33,130 --> 00:09:36,200
그럼에도 불구하고 우선순위를 정하는데에 
많은 도움을 줍니다.

154
00:09:36,200 --> 00:09:39,410
또한, 다양한 접근 방식에 대해서 그 효용성도 측정할 수 있는 
좋은 방법이기도 합니다.

155
00:09:40,940 --> 00:09:44,670
요약하자면, 오류 분석을 실행하는데에는 먼저

156
00:09:44,670 --> 00:09:48,731
dev set나 devleopment set에서 잘못 레이블된 example을 찾고, 

157
00:09:48,731 --> 00:09:53,420
이러한 잘못 레이블된 example들을 찾아서 
false positives와 false negatives를 찾습니다.

158
00:09:53,420 --> 00:09:56,378
그리하여 다양한 카테고리에 대한 오류의 총 개수를 각각 

159
00:09:56,378 --> 00:09:57,629
카테고리별로 찾아냅니다.

160
00:09:57,629 --> 00:10:01,916
이런 진행과정에서 새로운 오류 관련 카테고리를 보신것과 같이

161
00:10:01,916 --> 00:10:02,597
생성하기 원할 수 있는데요.

162
00:10:02,597 --> 00:10:06,016
example들을 보면서 "우와, 인스타그램 필터가 

163
00:10:06,016 --> 00:10:09,071
많네, 또는 스냅쳇 필터가 많네, " 라고 하며 분류기를 망친다는 생각이 드시면, 

164
00:10:09,071 --> 00:10:11,600
진행 와중에 새로운 카테고리를 생성하실 수 있습니다.

165
00:10:11,600 --> 00:10:14,740
다양한 사유로 잘못 레이블된 example들을 직접 세면서 그 비율을 계산하면

166
00:10:14,740 --> 00:10:17,375
우선순위를 정하는데 도움이 될 것입니다.

167
00:10:17,375 --> 00:10:21,140
아니면 새로운 방향을 갖도록 자극제 역할을 해줄 수도 있구요.

168
00:10:21,140 --> 00:10:23,074
오류 분석을 하면서,

169
00:10:23,074 --> 00:10:27,600
가끔 여러분의 dev set example들이 mislabel된 경우가 
있을텐데요,

170
00:10:27,600 --> 00:10:29,380
이럴 경우 어떻게 해야될까요?

171
00:10:29,380 --> 00:10:31,020
다음 비디오에서 다루도록 하겠습니다.