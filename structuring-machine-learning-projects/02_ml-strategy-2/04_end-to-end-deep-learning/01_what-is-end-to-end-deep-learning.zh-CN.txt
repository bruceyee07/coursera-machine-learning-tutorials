近期，深度学习最令人兴奋的进展之一 是端到端深度学习的崛起 那么，什么是“端到端“的深度学习呢？ 简单地说，我们有一些数据处理系统 或者是由多个阶段组成的学习系统 端到端的深度学习做的 就是它可以捕获所有的阶段 并且，通常可以将其替代为单个神经网络 也就是说运行速度更快 以语音识别为例 其目标是接收输入音频片段X 将其转换为该音频剪辑对应的 脚本输出Y。 传统的语音识别分为多个处理阶段。 首先，需要提取音频的一些特征， 一些人工设计的音频特征。 或许你听说过MFCC 这种算法（MFCC），
用于提取一组特定的人工设计的音频特征。 提取了低级特征之后， 可以应用机器学习算法 从音频剪辑中查找音素 音素是声音的基本单位 比如说，单词"cat"由三个音构成 Cu,Ah和Tu，算法会提取出这三个音素 然后把音素串在一起，形成单词 再将这些单词串在一起，构成音频剪辑的脚本。 不同于上述由多个阶段组成的途径（管道） 端到端的深度学习 可以训练一个庞大的神经网络，只需输入音频片段， 然后直接输出脚本。 人工智能的一个有趣的社会学效应是 在端到端的深度学习开始更好地工作的同时， 有一些研究人员花费了 数年的时间设计管道的各个阶段 在不同的领域都有一些研究人员 不只是语音识别，可能是计算机视觉，或者其它领域， 已经花费了很多时间， 写了多篇论文，甚至在他们的职业生涯中创建了很多 工程特征或其它管道部件。 而端到端的深度学习只是 从最新的训练数据集中，直接学习从x到y的映射， 真的绕过了很多中间步骤， 对于一些领域来说 接受这种构建人工智能系统的替代方法是一个挑战。 因为它在某些情况下，确实淘汰了 很多年对于（管道）中间部件的研究 结果表明，端到端深度学习的一个挑战是 它需要大量的数据才能取得很好的结果 例如，如果用3000小时的 训练数据构建一个语音识别系统， 传统的方法（Pipeline） 传统的完整管道方法（Pipeline）
能取得很好的结果。 只有当你有一个非常大的数据集， 比如说10,000小时的数据， 也许增加到100,000小时的数据时， 端到端的方法才突然开始工作得很好。 因此当你的数据集较小时， 传统的管道方法实际上同样有效， 有时甚至更好。 你需要一个大的数据集以便端到端的方法真正突显其作用。 如果你有中等量的数据， 可以采用折衷的方法：输入音频， 绕过这些特征，只学习输出神经网络的音素， 然后继续其它阶段。 因此这是端到端学习的一个步骤， 不是彻底的端到端学习。 这张照片显示的是旋转闸门人脸识别， 由百度的研究者林元庆开发， 这个摄像头对着接近大门的人， 如果它识别出那个人， 旋转闸门自动让他们通过。 因此人们进门时不再需要刷RFID徽章， 在中国，越来越多的办公室使用这种方式 希望也有越来越多其它国家 你只需要接近旋转门，如果它识别出你的脸， 就会让你通过，你不需要携带RFID徽章。 那么如何构建一个这样的系统呢？ 嗯，你可以做的一件事情是看看摄像头捕捉到的图像。 对吗？我图画得不好。 设想这是一张摄像头拍下的照片。 你知道，有人接近旋转门， 因此，这可能是摄像头捕捉的图像X。 你可以试着学习一个函数， 直接建立图像X与个人Y的映射。 事实证明，这不是最好的方法。 其中一个问题是 人们可以从不同的方向接近旋转门。 因此他们可能在绿色的位置， 或者在蓝色的位置。 有时候他们离摄像头很近， 因此在图像中显得很大。 有时他们非常接近摄像头， 以至于脸显得非常大。 因此，旋转门应用实际上 不只是采集原始影像， 把它注入神经网络，试图推断一个人的身份。 相反，迄今为止最好的方法 似乎是一个多步骤的方法。首先， 运行一个软件来检测此人的脸。 所以这个第一个探测器计算这个人的脸的位置。 检测到人脸之后， 放大图片中的这部分， 并进行裁剪， 使人脸位于图像中心。 这是我图中我画的红色的部分， 然后将其送入神经网络， 试着去学习， 或者估测此人的身份。 研究者们发现 比起一步学到所有的东西更加有效的是 把这个问题拆分为两个步骤： 首先找到脸的位置， 再推断这是谁的脸。 第二种方法使得学习算法（事实上有两个学习算法） 得以解决两个比较简单的任务，从而总体上获得更好地效果。 顺便说一下，如果你想知道 我简化了讨论。 顺便说一下，如果你想知道第二步如何工作， 我简化了讨论。 实际上第二步的训练方式是 当你训练网络时， 输入两个图像。 你的网络所做的是 告诉你这两个输入图像，是不是同一个人。 所以，如果你有1万个员工的ID的文件， 你可以拿这个红色的图像， 然后将它与 1万个员工的ID比较，试图找出 这个红色的图片是否对应一万个员工之一 可以进入某个设施或你的办公楼 这是个旋转闸门限制员工出入工作场所（的场景） 那么为什么第二个方法效果更好呢？ 实际上由两个原因。 一方面是因为这两个子问题每个和原问题比都简单很多， 更重要的是，你有很多数据可供这两个子问题使用。 特别是你可以获得很多数据用于人脸检测， 即第一个子问题: 检查一张图片， 找到人脸在这个图片中的位置 所以有很多数据， 很多有标签的数据（X, Y) 其中X是一张图片，而y代表人脸在这个图片中的位置。 所以你能够建立一个神经网络很好的处理第一个子问题。 同样的，有很多数据可以用于第二个子问题。 今天，处于行业领先地位的公司拥有，比如说， 成千上万张人脸图片。 输入一张沿着脸剪裁的图片， 比如说这张红色图片或者这张下方的图片， 今天,处于行业领先地位的人脸识别团队拥有 至少数亿的图像可以使用， 从而比较两张图片然后尝试着 识别出人的身份或者两张图片是否是同一个人。 同样的，也有很多数据可以用于第二个子问题。 然而，如果你尝试着让一个模型同时学习所有的步骤， 只能获取很少数据（X，Y）。 其中X是如图所示的旋转栅图片， Y是人的身份。 因为没有足够的数据去解决端到端的学习问题， 却有足够的数据去解决两个子问题，所以在实际应用中， 把整个问题分成两个子问题来解决会 比完全端到端的深度学习方案得到更好的性能。 尽管如果你有足够的数据， 也许端到端的方案会更加好， 但是目前来说在实际应用中这不是最好的方法。 让我们来看看另一些例子 以机器翻译作为例子， 传统上机器翻译系统也是一个非常冗长和复杂的流程， 首先获取，比如说，英文的 文本然后做文本分析。 简单来说,从文本中抽取一组特征等， 然后经过很多步骤后，最终，比如说， 得到一个从英文到法文的文本翻译。 对于机器翻译来说， 你可以获取很多英文和法文对应的文本对， 所以端到端深度学习在机器翻译领域非常有效。 那是因为今天， 收集大量（X,Y）英文和法文对应的文本对的数据集 英文和法文对应的文本对的数据集是可行的。 在这个例子里 端到端的深度学习效果很好。 最后一个例子,假设你 想通过查看儿童手掌的x光图片 来估计这个儿童的年龄。 你知道吗，我第一次听说这个问题的时候， 我以为这是一个非常酷的犯罪场景调查的问题。 你可能悲剧性地发现了一个的孩子的骨架， 想分析出这个孩子的年龄。 事实上，通过手掌的x光图片估计儿童的年龄 的典型应用场景 比我想象的犯罪场景调查要普通很多。 事实上，儿科医生使用 这个工具去评估一个儿童是否健康成长。 如果使用非端到端的方法解决这个问题， 是从一个图片中分割出或识别出骨骼， 就是尝试着识别这个骨头部分在哪里， 另外一个骨头部分在哪里， 还有一个骨头部分在哪里等等。 基于不同骨骼的长度， 你可以大概从表中查找到儿童手掌的平均骨骼长度 然后用这个信息来估计这个儿童的年龄。 这样的方法实际上很有效。 相反,如果你想直接从图片联系到孩子的年龄, 你需要很多数据，而且基于我的了解， 这种方法现今不太可行，就是 因为没有足够的数据去支持端到端的训练。 相反，你能够想象其实我们可以把这个问题分成两步。 第一步是相对简单的方法， 也许你不需要特别多的数据， 也许你不需要特别多的X光图片数据
去分割出骨骼 然后第二步，收集统计儿童手掌的信息， 你也能基于不多的数据，得到比较准确的评估。 所以，这种多步的方法看起来很有前景， 可能比端到端的方法更可行 除非你可以获取支持端到端学习的更多的数据。 所以，如果端到端深度学习可行， 可以非常有效和简化系统，且 不用建立很多手工设计的单个组件。 但是它不是万能的， 它并不总是有效。 这里这个 我想与大家分享，更系统地讨论，什么时候你应该 以及什么时候也许你不应该使用端到端的深度学习，还有如何 把这些复杂的机器学习系统拼凑起来。