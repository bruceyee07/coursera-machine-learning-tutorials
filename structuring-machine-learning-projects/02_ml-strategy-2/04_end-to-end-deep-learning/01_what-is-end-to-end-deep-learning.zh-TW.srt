1
00:00:00,000 --> 00:00:02,880
一個最激動人心的最新發展
在深度學習中

2
00:00:02,880 --> 00:00:05,765
是端對端深度學習的興起

3
00:00:05,765 --> 00:00:07,570
所以什麼是端對端學習？

4
00:00:07,570 --> 00:00:10,510
簡單的說，有一些資料處理系統

5
00:00:10,510 --> 00:00:13,880
或者學習系統需要多重階段的處理

6
00:00:13,880 --> 00:00:15,330
而端對端深度學習做的是

7
00:00:15,330 --> 00:00:17,625
它可以拿所有的階段

8
00:00:17,625 --> 00:00:20,968
取代它通常只要一個
單一的神經網路

9
00:00:20,968 --> 00:00:24,170
讓我們看幾個例子

10
00:00:24,170 --> 00:00:26,460
拿語音辨識當例子

11
00:00:26,460 --> 00:00:30,975
您的目標是拿輸入 x 像是語音片段

12
00:00:30,975 --> 00:00:33,015
將它映射到輸出 Y

13
00:00:33,015 --> 00:00:37,230
也就是對照語音的腳本

14
00:00:37,230 --> 00:00:41,550
傳統上，語音辨識需要
很多階段的處理

15
00:00:41,550 --> 00:00:44,085
首先，您會提取一些特徵

16
00:00:44,085 --> 00:00:46,045
一些手工設計的語音特徵

17
00:00:46,045 --> 00:00:48,885
如果您聽過 MFCC

18
00:00:48,885 --> 00:00:53,570
那是一種演算法來提取一些
手工設計的語音特徵的集合

19
00:00:53,570 --> 00:00:55,845
而提取了一些低階的特徵後

20
00:00:55,845 --> 00:00:58,260
您或許會用上一些
機器學習的演算法

21
00:00:58,260 --> 00:01:01,530
來找出語音片段中的音素

22
00:01:01,530 --> 00:01:04,390
所以音素是聲音的基本單位

23
00:01:04,390 --> 00:01:07,810
舉個例子，"cat" 是由三個聲音組成

24
00:01:07,810 --> 00:01:10,690
也就是 Cu Ah 跟 Tu 所以可以提取這些

25
00:01:10,690 --> 00:01:13,630
然後您把音素串在一起
變成單字

26
00:01:13,630 --> 00:01:19,356
然後您將單字串在一起
變成語音片段的腳本

27
00:01:19,356 --> 00:01:23,365
相對於這種許多階段的管線

28
00:01:23,365 --> 00:01:24,940
端對端深度學習做的是

29
00:01:24,940 --> 00:01:28,735
您可以訓練大的神經網路，
只要輸入語音片段

30
00:01:28,735 --> 00:01:32,670
它會直接輸出對應的腳本

31
00:01:32,670 --> 00:01:35,800
一個有趣的社會效應在人工智慧是

32
00:01:35,800 --> 00:01:39,085
當端對端深度學習開始作用的很好

33
00:01:39,085 --> 00:01:41,545
有一些研究員，舉例來說

34
00:01:41,545 --> 00:01:44,830
花了很多年在設計單一的管線步驟

35
00:01:44,830 --> 00:01:50,249
所以有一些研究員在不同的學科，
不只是在語音辨識上

36
00:01:50,249 --> 00:01:52,360
或許在電腦視覺上，或者其他領域

37
00:01:52,360 --> 00:01:53,945
已經花了很多時間

38
00:01:53,945 --> 00:01:57,332
寫了很多論文，或許甚至大半輩子

39
00:01:57,332 --> 00:02:00,270
來手工設計這些特徵，
或者其它管線中的一部分

40
00:02:00,270 --> 00:02:02,990
而當端對端深度學習
只是拿

41
00:02:02,990 --> 00:02:06,475
最終的訓練集，學習著
如何從 x 直接映射到 y

42
00:02:06,475 --> 00:02:09,720
真的繞過了
很多這些中間步驟

43
00:02:09,720 --> 00:02:13,300
對於一些學科而言，要接受

44
00:02:13,300 --> 00:02:17,255
這種另一種方式的
建立人工智慧的方式是很大的挑戰

45
00:02:17,255 --> 00:02:20,110
因為這真的淘汰了

46
00:02:20,110 --> 00:02:23,665
很多年的研究
在一些中間的元件

47
00:02:23,665 --> 00:02:27,070
實際上，端對端深度學習的挑戰是

48
00:02:27,070 --> 00:02:30,670
在這個系統作用得很好之前
您需要很多的資料

49
00:02:30,670 --> 00:02:33,030
舉個例子，如果您訓練了 3,000

50
00:02:33,030 --> 00:02:35,935
小時的資料
來建立語音辨識系統

51
00:02:35,935 --> 00:02:37,600
那在傳統的管線

52
00:02:37,600 --> 00:02:40,675
全傳統式的管線方式作用的很好

53
00:02:40,675 --> 00:02:42,745
只是當您有很大的資料集

54
00:02:42,745 --> 00:02:45,290
假設 10,000 小時的資料

55
00:02:45,290 --> 00:02:49,000
或許到 100,000 小時的資料

56
00:02:49,000 --> 00:02:53,350
那端對端的方式
開始作用得很好

57
00:02:53,350 --> 00:02:55,000
所以當您有小的資料集

58
00:02:55,000 --> 00:02:58,990
越傳統的管線方法
實際上作用的也很好

59
00:02:58,990 --> 00:03:00,700
甚至於更好

60
00:03:00,700 --> 00:03:06,855
而您需要大量的資料
讓端對端的方式真正發光

61
00:03:06,855 --> 00:03:08,850
而如果您有中等量的資料

62
00:03:08,850 --> 00:03:12,365
而也有所謂的中等方式，或許您的輸入語音

63
00:03:12,365 --> 00:03:16,420
繞過一些特徵，
神經網路只學習如何輸出音素

64
00:03:16,420 --> 00:03:17,765
然後再接一些階段

65
00:03:17,765 --> 00:03:19,420
所以會近一步
邁向端對端學習

66
00:03:19,420 --> 00:03:29,065
但並不全然是

67
00:03:29,065 --> 00:03:34,855
所以這是一張臉部辨識的旋轉門，由

68
00:03:34,855 --> 00:03:36,600
百度研究員林元慶建立的

69
00:03:36,600 --> 00:03:41,050
這是一個攝影機，它會看著
一個人走進這個旋轉門

70
00:03:41,050 --> 00:03:43,135
如果它認識這個人

71
00:03:43,135 --> 00:03:46,645
這個旋轉門會
自動的讓這個人進入

72
00:03:46,645 --> 00:03:51,170
所以，與其使用刷一個  
RFID 的卡來進入這個設施

73
00:03:51,170 --> 00:03:53,410
這逐漸在很多

74
00:03:53,410 --> 00:03:56,270
中國大陸的辦公室使用，
希望越來越多的國家來使用

75
00:03:56,270 --> 00:03:59,485
您可以接近旋轉門，如果它認識您的臉孔

76
00:03:59,485 --> 00:04:04,155
它就會讓您進入，
不需要帶  RFID 的卡片

77
00:04:04,155 --> 00:04:07,385
所以，您要怎樣建立這種系統？

78
00:04:07,385 --> 00:04:12,590
您可以做的一件事是
只要看攝影機捕捉到的影像

79
00:04:12,590 --> 00:04:14,645
是吧，我想我畫的不好

80
00:04:14,645 --> 00:04:16,190
但或許這是攝影機的影像

81
00:04:16,190 --> 00:04:19,390
而您知道，當有人接近這個旋轉門

82
00:04:19,390 --> 00:04:23,810
所以這或許是您攝影機
捕捉的影像為影像 X

83
00:04:23,810 --> 00:04:26,950
一件您可以做的事是學習一個函數

84
00:04:26,950 --> 00:04:31,470
直接從影像 X 對應到人員 Ｙ

85
00:04:31,470 --> 00:04:34,580
實際上，這並不是最佳的方式

86
00:04:34,580 --> 00:04:36,395
一個問題是

87
00:04:36,395 --> 00:04:39,835
當人們接近旋轉門時，
可能從不同的方向接近

88
00:04:39,835 --> 00:04:41,945
所以可能在綠色的位置

89
00:04:41,945 --> 00:04:43,195
可能在藍色的位置

90
00:04:43,195 --> 00:04:45,245
有時候比較靠近攝影機

91
00:04:45,245 --> 00:04:47,020
所以看起來影像比較大

92
00:04:47,020 --> 00:04:49,225
有時候太接近攝影機

93
00:04:49,225 --> 00:04:51,600
所以臉部看起來較大

94
00:04:51,600 --> 00:04:54,205
所以它實際上
在建立這個旋轉門時

95
00:04:54,205 --> 00:04:56,350
不僅僅拿原始的影像

96
00:04:56,350 --> 00:04:59,315
餵給神經網路
試著找出一個人的身份

97
00:04:59,315 --> 00:05:02,005
取而代之，今天最佳的方式是

98
00:05:02,005 --> 00:05:05,140
似乎是多步驟的方式，第一

99
00:05:05,140 --> 00:05:09,210
您跑一個軟體來偵測人臉

100
00:05:09,210 --> 00:05:12,820
所以第一個偵測器來找出人臉

101
00:05:12,820 --> 00:05:14,785
偵測到了人臉以後

102
00:05:14,785 --> 00:05:16,930
您放大那個部分

103
00:05:16,930 --> 00:05:24,540
那個影像，然後裁剪

104
00:05:24,540 --> 00:05:29,340
所以那個人臉放在中央

105
00:05:29,340 --> 00:05:34,757
然後這個影像，我用紅色畫的部分

106
00:05:34,757 --> 00:05:36,080
這個會餵進神經網路

107
00:05:36,080 --> 00:05:38,010
然後試著學習

108
00:05:38,010 --> 00:05:40,485
或者估計這個人的身份

109
00:05:40,485 --> 00:05:42,150
而研究人員發現

110
00:05:42,150 --> 00:05:45,615
與其試著一個步驟
學習所有的東西

111
00:05:45,615 --> 00:05:48,780
將這個問題分解成兩個步驟

112
00:05:48,780 --> 00:05:51,490
首先先找出人臉

113
00:05:51,490 --> 00:05:54,890
再來在看人臉
來找出他是誰

114
00:05:54,890 --> 00:05:58,010
第二種方式讓學習演算法，或者說兩個學習演算法

115
00:05:58,010 --> 00:06:03,560
來解決兩個簡單化的任務，
結果的表現更好

116
00:06:03,560 --> 00:06:05,930
順便說一下，如果您想知道

117
00:06:05,930 --> 00:06:08,975
第二個步驟如何作用，
我已經簡化這個討論

118
00:06:08,975 --> 00:06:11,865
順便說一下，如果您想知道
第二個步驟如何作用

119
00:06:11,865 --> 00:06:13,605
我已經簡化了一點點描述

120
00:06:13,605 --> 00:06:15,470
第二個步驟實際上是訓練

121
00:06:15,470 --> 00:06:16,730
就像您訓練您的網路般

122
00:06:16,730 --> 00:06:18,920
拿著這二張影像

123
00:06:18,920 --> 00:06:22,230
您的網路的工作是

124
00:06:22,230 --> 00:06:29,553
拿這二張影像告訴您，
是否這兩個人是同一個人

125
00:06:29,553 --> 00:06:34,700
所以如果您有 10,000 個員工在檔案裡

126
00:06:34,700 --> 00:06:36,430
您可以拿紅色這個影像

127
00:06:36,430 --> 00:06:38,545
很快地比較或許所有的

128
00:06:38,545 --> 00:06:41,795
10,000 個員工的檔案，試著找出是否

129
00:06:41,795 --> 00:06:44,810
這個紅色的影像，的確是您 10,000 個員工之一

130
00:06:44,810 --> 00:06:48,640
您應該讓他進入這個設施，
應該讓他進入辦公室

131
00:06:48,640 --> 00:06:51,770
這是一個旋轉門，給員工可以進出

132
00:06:51,770 --> 00:06:55,970
這個地方，
為什麼兩個步驟的方式比較好？

133
00:06:55,970 --> 00:06:58,605
實際上有兩個原因

134
00:06:58,605 --> 00:07:02,020
其一是這兩個單獨的問題
個別解決比較簡單

135
00:07:02,020 --> 00:07:10,360
其二，您有很多的資料對於個別這兩個任務

136
00:07:10,360 --> 00:07:16,950
特別是，有很多的資料讓您可以偵測人臉

137
00:07:16,950 --> 00:07:18,720
對於任務一

138
00:07:18,720 --> 00:07:20,820
這個任務是看影像來找出

139
00:07:20,820 --> 00:07:23,415
那裡是人臉的部分

140
00:07:23,415 --> 00:07:25,695
所以有很多的資料

141
00:07:25,695 --> 00:07:27,610
有很多的標籤資料  Ｘ

142
00:07:27,610 --> 00:07:31,420
逗號 Y, 而 X 是影像， Ｙ是人臉的部分

143
00:07:31,420 --> 00:07:35,100
所以您可以建立一個
神經網路來作好這個任務

144
00:07:35,100 --> 00:07:37,440
然後分別的，有很多的資料給任務二

145
00:07:37,440 --> 00:07:41,710
在今天，領先的公司假設

146
00:07:41,710 --> 00:07:44,525
有上億張員工人臉照片

147
00:07:44,525 --> 00:07:46,845
所以給予ㄧ個裁剪的影像

148
00:07:46,845 --> 00:07:49,275
像是在這裡的紅色影像

149
00:07:49,275 --> 00:07:51,555
今天領先的人臉辨識團隊

150
00:07:51,555 --> 00:07:53,880
已經有上億張影像他們可以用來

151
00:07:53,880 --> 00:07:55,980
使用看著這兩張照片，試著去

152
00:07:55,980 --> 00:07:58,765
找出身份，或者找出是否是同一個人

153
00:07:58,765 --> 00:08:02,310
所以也是有很多的資料在任務二

154
00:08:02,310 --> 00:08:07,155
但是，相對的，如果您試著一次學習所有的事情

155
00:08:07,155 --> 00:08:10,680
在 X, Y 樣子的資料會少很多

156
00:08:10,680 --> 00:08:13,175
X 是從旋轉門得到的影像

157
00:08:13,175 --> 00:08:16,390
而
 Ｙ 是人的身份

158
00:08:16,390 --> 00:08:21,610
因為您並沒有足夠的資料
來解決端對端的學習問題

159
00:08:21,610 --> 00:08:27,410
但您的確有足夠的資料
來解決子問題一跟二

160
00:08:27,410 --> 00:08:29,740
將其分解為兩個子問題，導致

161
00:08:29,740 --> 00:08:34,260
比純粹端對端深度學習方式
更好的表現

162
00:08:34,260 --> 00:08:37,575
雖然如果對於端對端方式
您有足夠的資料

163
00:08:37,575 --> 00:08:40,470
或許端對端方式會比較好

164
00:08:40,470 --> 00:08:44,240
但在今日，這並不是最佳的方式

165
00:08:44,240 --> 00:08:46,886
讓我們再看一些例子

166
00:08:46,886 --> 00:08:49,000
看一下機器翻譯

167
00:08:49,000 --> 00:08:54,390
傳統上，機器翻譯系統
也是有很長，很複雜的管線

168
00:08:54,390 --> 00:08:56,230
首先您拿英文

169
00:08:56,230 --> 00:08:58,955
轉成文字，做文字分析

170
00:08:58,955 --> 00:09:01,990
基本上，提取一堆文字的特徵，等等

171
00:09:01,990 --> 00:09:04,630
經過許多許多的步驟，
您最後會

172
00:09:04,630 --> 00:09:07,900
有一份從英文文字翻譯成法文

173
00:09:07,900 --> 00:09:10,030
因為，對於機器翻譯

174
00:09:10,030 --> 00:09:13,990
您有很多的
英文，法文成對的語句

175
00:09:13,990 --> 00:09:17,640
端對端深度學習在
機器翻譯做得很好

176
00:09:17,640 --> 00:09:20,140
而那是因為，在今天

177
00:09:20,140 --> 00:09:24,350
獲取大量的 X-Y 資料集是可行的，

178
00:09:24,350 --> 00:09:28,780
也就是英文句子跟相對的法文翻譯

179
00:09:28,780 --> 00:09:29,955
在這個例子中

180
00:09:29,955 --> 00:09:32,320
端對端深度學習
作用得很好

181
00:09:32,320 --> 00:09:35,200
最後一個例子，假設您

182
00:09:35,200 --> 00:09:38,220
想要看著一張小孩子的手
的 Ｘ光片

183
00:09:38,220 --> 00:09:40,215
來預估小孩子的年紀

184
00:09:40,215 --> 00:09:41,830
當我第一次聽到這個問題

185
00:09:41,830 --> 00:09:45,460
我覺得這是很酷的
犯罪現場調查任務

186
00:09:45,460 --> 00:09:48,610
可能您發現了一個
悲慘的小孩子的骨架

187
00:09:48,610 --> 00:09:50,980
您希望知道
這個小孩子的資訊

188
00:09:50,980 --> 00:09:54,445
實際上，這個問題的典型應用

189
00:09:54,445 --> 00:09:57,010
從Ｘ光片預估小孩子的年紀

190
00:09:57,010 --> 00:09:59,995
比我想像中的犯罪現場調查
要非戲劇化

191
00:09:59,995 --> 00:10:02,890
實際上兒科醫生使用

192
00:10:02,890 --> 00:10:06,925
這樣來預估是否
一個小孩生長發育正不正常

193
00:10:06,925 --> 00:10:09,460
但是如果用非端對端方式來處理

194
00:10:09,460 --> 00:10:14,045
會是您先找到圖像，然後分割或者辨識骨架

195
00:10:14,045 --> 00:10:16,730
也就是找出那邊是那個骨頭部分

196
00:10:16,730 --> 00:10:17,849
那邊是那個骨頭部分

197
00:10:17,849 --> 00:10:20,290
那邊是那個骨頭部分在，等等

198
00:10:20,290 --> 00:10:22,285
知道了不同骨頭的長度

199
00:10:22,285 --> 00:10:26,380
您可以回去查閱表格來對照一下
平均骨頭長度

200
00:10:26,380 --> 00:10:30,615
在小孩子的手上，
然後來預估小孩子的年紀

201
00:10:30,615 --> 00:10:32,800
這種方式實際上
作用得很好

202
00:10:32,800 --> 00:10:37,960
相對的，如果您直接從影像來判斷小孩子的年紀

203
00:10:37,960 --> 00:10:43,030
您會需要很多的資料可以直接這樣做，據我所知

204
00:10:43,030 --> 00:10:45,850
這種方式在今天還不可行

205
00:10:45,850 --> 00:10:50,515
只因沒有足夠的資料
來做端對端的訓練方式

206
00:10:50,515 --> 00:10:56,326
而相對，您可以想像
將這個分解為兩個步驟

207
00:10:56,326 --> 00:10:58,780
第一步，是相對簡單的問題

208
00:10:58,780 --> 00:11:00,345
或許您不需要太多的資料

209
00:11:00,345 --> 00:11:03,455
或許您不需要太多的X光片
來分離出骨架來

210
00:11:03,455 --> 00:11:08,225
而第二個任務，收集一些兒童手的資料

211
00:11:08,225 --> 00:11:11,280
您也可以得到相當不錯的預估
而不需要太多資料

212
00:11:11,280 --> 00:11:14,125
所以這種多步驟的方式
似乎比較有希望

213
00:11:14,125 --> 00:11:16,420
或許比起端對端方式
更有希望

214
00:11:16,420 --> 00:11:20,635
至少直到您可以獲取更多的資料
來做端對端方式之前

215
00:11:20,635 --> 00:11:22,840
所以端對端深度學習可行

216
00:11:22,840 --> 00:11:26,650
它真的可行，且它可以簡化系統，而不需要

217
00:11:26,650 --> 00:11:30,875
您建立很多手工設計
單獨的元件

218
00:11:30,875 --> 00:11:32,773
但它不是萬能藥

219
00:11:32,773 --> 00:11:34,315
它並不總是可行

220
00:11:34,315 --> 00:11:35,650
在下一個影片中

221
00:11:35,650 --> 00:11:39,530
我想分享您更系統化的方式描述，什麼時候您應該

222
00:11:39,530 --> 00:11:42,820
跟什麼時候不該使用端對端深度學習，

223
00:11:42,820 --> 00:11:47,000
跟如何把這些複雜的機器學習
系統拼湊起來