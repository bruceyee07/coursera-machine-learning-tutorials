1
00:00:00,000 --> 00:00:02,880
심화 학습에서 최근 개발한 것중에 가장 흥미로운 중 하나는

2
00:00:02,880 --> 00:00:05,765
엔드 투 엔드 딥 러닝의 발전이었습니다.

3
00:00:05,765 --> 00:00:07,570
그렇다면 엔드 투 엔드 러닝은 무엇일까요?

4
00:00:07,570 --> 00:00:10,510
간단히 얘기하면, 여러 단계를 처리하는 데이터 프로세싱 시스템이나, 

5
00:00:10,510 --> 00:00:13,880
학습 시스템이 있습니다.

6
00:00:13,880 --> 00:00:15,330
엔드 투 엔드 딥 러닝이 하는 일은

7
00:00:15,330 --> 00:00:17,625
이런 여러 단계를 거치는 것들을 수행하고

8
00:00:17,625 --> 00:00:20,968
하나의 신경 네트워크로 변환 합니다. 몇가지 예를 보겠습니다.

9
00:00:20,968 --> 00:00:24,170
몇몇 예시를 들여다 봐 볼까요.

10
00:00:24,170 --> 00:00:26,460
음성 인식을 예로 들면,

11
00:00:26,460 --> 00:00:30,975
오디오 클립을 입력 X를 가져와서

12
00:00:30,975 --> 00:00:33,015
출력 Y에 매핑 하면

13
00:00:33,015 --> 00:00:37,230
오디오 클립이 글로 옮겨지게 되는 것 입니다.

14
00:00:37,230 --> 00:00:41,550
그래서 전통적으로 음성 인식은 많은 단계를 필요로 했습니다.

15
00:00:41,550 --> 00:00:44,085
먼저 몇가지 특징을 추출하고

16
00:00:44,085 --> 00:00:46,045
몇가지 오디오의 핸드 디자인 특징을 추출합니다. 

17
00:00:46,045 --> 00:00:48,885
MFCC 를 들어 보셨을 텐데요

18
00:00:48,885 --> 00:00:53,570
그것은 오디오를 위해 핸드 디자인 기능을 추출하고

19
00:00:53,570 --> 00:00:55,845
낮은 레벨 기능을 추출하는 알고리즘 입니다.

20
00:00:55,845 --> 00:00:58,260
기계 학습 알고리즘을 적용하여

21
00:00:58,260 --> 00:01:01,530
오디오 클립에서 음소를 찾을 수 있습니다.

22
00:01:01,530 --> 00:01:04,390
음소는 소리의 기본 단위입니다.

23
00:01:04,390 --> 00:01:07,810
예를 들면 캣은 세가지 소리로 구성되어 있습니다.

24
00:01:07,810 --> 00:01:10,690
ㅋ /ㅐ /ㅌ 으로 추출 할 수 있는것이지요.

25
00:01:10,690 --> 00:01:13,630
그리고 나서 개별적인 단어를 만들기 위해 음성들을 결합시킵니다.

26
00:01:13,630 --> 00:01:19,356
그런 다음 이 음절을 묶어서 오디오 클립의 문자 형태로 만듭니다.

27
00:01:19,356 --> 00:01:23,365
여러 단계로 이루어진 이런 파이프 라인과는 대조적으로 

28
00:01:23,365 --> 00:01:24,940
엔드 투 엔드 러닝이 하는 일은 

29
00:01:24,940 --> 00:01:28,735
거대한 신경 네트워크를 훈련시켜 오디오 클립에 입력하고

30
00:01:28,735 --> 00:01:32,670
그것이 직접 문자로 출력하도록 하는 것입니다.

31
00:01:32,670 --> 00:01:35,800
AI의 한가지 흥미로운 사회학적 영향은

32
00:01:35,800 --> 00:01:39,085
엔드 투 엔드 딥 러닝이 효과를 내기 시작함에 따라

33
00:01:39,085 --> 00:01:41,545
몇몇 연구원들은 

34
00:01:41,545 --> 00:01:44,830
많은 시간을 파이프 라인의 개별적인 단계를 설계하는데 보냈었습니다.

35
00:01:44,830 --> 00:01:50,249
몇몇의 연구원들은 단지 음성 인식만이 아니라 다른 쪽에도 연구를 하였습니다.

36
00:01:50,249 --> 00:01:52,360
어쩌면 컴퓨터 비전과 다른 분야에서

37
00:01:52,360 --> 00:01:53,945
많은 시간을 소비했을 것입니다.

38
00:01:53,945 --> 00:01:57,332
여러 논문을 쓰거나 혹은 경력 개발의 큰 부분을 차지하는 

39
00:01:57,332 --> 00:02:00,270
엔지니어링 기능들 이나 또는 파이프라인의 일부분을 개발 같은 것들을요.

40
00:02:00,270 --> 00:02:02,990
엔드 투 엔드 딥 러닝이

41
00:02:02,990 --> 00:02:06,475
마지막 훈련 세트와 직접 x와 y의 함수 매핑을 학습하면 

42
00:02:06,475 --> 00:02:09,720
이러한 많은 중간 단계를 우회하는 것 입니다.

43
00:02:09,720 --> 00:02:13,300
일부 분야에서는 인공 지능 시스템을 구축하는 대안적인 방법을 

44
00:02:13,300 --> 00:02:17,255
받아들이 기가 어려웠습니다.

45
00:02:17,255 --> 00:02:20,110
왜냐하면 어떤 경우에는 중간 구성 요소의 일부에서 

46
00:02:20,110 --> 00:02:23,665
오랜 세월의 연구가 필요하기 때문입니다.

47
00:02:23,665 --> 00:02:27,070
엔드 투 엔드 딥 러닝의 과제 중 하나는 

48
00:02:27,070 --> 00:02:30,670
잘 작동하기 위해 많은 양의 데이터가 필요합니다.

49
00:02:30,670 --> 00:02:33,030
예를 들면, 음성인식을 시스템을 위해 

50
00:02:33,030 --> 00:02:35,935
3000 시간의 데이터를 학습 하였고,

51
00:02:35,935 --> 00:02:37,600
전통적인 파이프라인과 

52
00:02:37,600 --> 00:02:40,675
완전한 전통적인 파이프 라인이 실제로 잘 작동합니다.

53
00:02:40,675 --> 00:02:42,745
큰 데이터 셋이 있는 경우에만 오직

54
00:02:42,745 --> 00:02:45,290
10, 000 시간의 데이터를 말할 수 있지만

55
00:02:45,290 --> 00:02:49,000
최대 100,000 시간의 데이터가 

56
00:02:49,000 --> 00:02:53,350
엔드 투 엔드 접근법에서 실제로 갑자기 잘 작동하기 시작합니다.

57
00:02:53,350 --> 00:02:55,000
작은 데이터 셋이 있으면

58
00:02:55,000 --> 00:02:58,990
좀더 전통적인 파이프라인 접근 방법이 실제 작동을 할 합니다.

59
00:02:58,990 --> 00:03:00,700
종종 더 낫게 작동을 합니다.

60
00:03:00,700 --> 00:03:06,855
엔드 투 엔드 접근 방식이 실제로 빛나기 위해 규모 데이터 세트가 필요합니다.

61
00:03:06,855 --> 00:03:08,850
만약 중간 정도 양의 데이터가 있으면 

62
00:03:08,850 --> 00:03:12,365
당신이 오디오를 입력할 수 있는 중간 접근법이 있습니다.

63
00:03:12,365 --> 00:03:16,420
기능을 우회하고 신경 네트워크의 음소를 출력하는 법을 배웁니다.

64
00:03:16,420 --> 00:03:17,765
다른 단계들도 만찬가지 입니다.

65
00:03:17,765 --> 00:03:19,420
이것은 완벽한 학습을 향한 한 걸음이 될 것이지만

66
00:03:19,420 --> 00:03:29,065
모두 그런 것은 아닙니다.

67
00:03:29,065 --> 00:03:34,855
실험을 해보았습니다. 이건 한 연구자가 만든 얼굴 인식 회전식 회전축 사진입니다.

68
00:03:34,855 --> 00:03:36,600
바이두의 양친링 입니다.

69
00:03:36,600 --> 00:03:41,050
이것은 카메라이고, 문에 접근하는 사람을 처다 봅니다.

70
00:03:41,050 --> 00:03:43,135
만약 사람을 인식하면

71
00:03:43,135 --> 00:03:46,645
회전식 출입문을 자동으로 통과 시켜 줍니다.

72
00:03:46,645 --> 00:03:51,170
RFID배지를 밀고 들어가서 이 시설에 들어가는 대신에

73
00:03:51,170 --> 00:03:53,410
점점 더 많은 사무실에서

74
00:03:53,410 --> 00:03:56,270
중국과 다른 나라들에서도 더욱 더,

75
00:03:56,270 --> 00:03:59,485
회전식 출입문에 접근하고 만약 당신의 얼굴을 인식된다면 

76
00:03:59,485 --> 00:04:04,155
RFID 배지를 가지고 다니지 않아도 안으로 들어갈 수 있습니다.

77
00:04:04,155 --> 00:04:07,385
그렇다면 어떻게 이런 시스템을 구축 할까요?

78
00:04:07,385 --> 00:04:12,590
자, 여러분이 할 수 있는 한가지는 그 카메라가 캡처하는 이미지를 보는 것입니다.

79
00:04:12,590 --> 00:04:14,645
알겠지요? 제 생각에 이것은 저의 엉성한 그림입니다.

80
00:04:14,645 --> 00:04:16,190
하지만 이것은 카메라 이미지 일 수도 있습니다.

81
00:04:16,190 --> 00:04:19,390
만약 당신 손님이 회전식 출입문에 다가가면

82
00:04:19,390 --> 00:04:23,810
이것이 당신이 카메라에 캡처하고 있는 이미지 X일 수도 있습니다.

83
00:04:23,810 --> 00:04:26,950
그리고 당신이 할 수 있는 한 가지는 기능 매핑을 학습 하는 것입니다.

84
00:04:26,950 --> 00:04:31,470
이미지 X에서 Y인 사람의 ID로 직접 전송됩니다.

85
00:04:31,470 --> 00:04:34,580
이것이 최선의 접근 방식이 아니라는 것이 드러났습니다.

86
00:04:34,580 --> 00:04:36,395
그리고 한가지 문제는

87
00:04:36,395 --> 00:04:39,835
회전식 출입문에 접근하는 사람은 다양한 방향에서 접근할 수 있습니다.

88
00:04:39,835 --> 00:04:41,945
녹색 위치일 수도 있어요

89
00:04:41,945 --> 00:04:43,195
파란 색 위치에 있을 수도 있어요

90
00:04:43,195 --> 00:04:45,245
때로는 카메라에 더 가까이 가서

91
00:04:45,245 --> 00:04:47,020
이미지에 더 크게 보이게 하는 거죠

92
00:04:47,020 --> 00:04:49,225
때로는 카메라에 가까이 가 있어서

93
00:04:49,225 --> 00:04:51,600
얼굴이 훨씬 크게 보이게 하려고 합니다.

94
00:04:51,600 --> 00:04:54,205
이 회전식 출입문을 만들기 위해 실제로는

95
00:04:54,205 --> 00:04:56,350
원시적인 이미지를 그대로 받아들이는 게 아니라

96
00:04:56,350 --> 00:04:59,315
사람의 신원을 알아내기 위해 신경계 망에 공급하는 것입니다.

97
00:04:59,315 --> 00:05:02,005
대신 지금까지 최선의 접근 방식으로

98
00:05:02,005 --> 00:05:05,140
처음에는 다방면의 접근 방식으로 보이지만

99
00:05:05,140 --> 00:05:09,210
얼굴을 감지하기 위해 프로그램을 하나만 돌려 봅니다.

100
00:05:09,210 --> 00:05:12,820
첫번째 감지기는 사람의 얼굴이 어디에 있는지 알아내는 것입니다

101
00:05:12,820 --> 00:05:14,785
그 사람의 얼굴을 발견하고 나서

102
00:05:14,785 --> 00:05:16,930
그 이미지 부분을 확대해서

103
00:05:16,930 --> 00:05:24,540
자르고

104
00:05:24,540 --> 00:05:29,340
얼굴이 가운데에 오게 합니다.

105
00:05:29,340 --> 00:05:34,757
이 사진은 빨간 색으로 그린 것 같네요

106
00:05:34,757 --> 00:05:36,080
그리고 이건 신경 네트워크에 공급되고

107
00:05:36,080 --> 00:05:38,010
학습을 시도하거나 

108
00:05:38,010 --> 00:05:40,485
사람의 신원을 파악할 수도 있습니다.

109
00:05:40,485 --> 00:05:42,150
그리고 연구원들이 발견한 건

110
00:05:42,150 --> 00:05:45,615
모든 걸 한 걸음에 배우려고 하는 대신에

111
00:05:45,615 --> 00:05:48,780
이 문제를 두가지 단순한 단계로 나누어서

112
00:05:48,780 --> 00:05:51,490
첫번째는 얼굴이 어디에 있는지 알아내는 것입니다.

113
00:05:51,490 --> 00:05:54,890
두번째로, 얼굴을 보고 이것이 누구인지 알아 내는것입니다.

114
00:05:54,890 --> 00:05:58,010
이 두번째 접근법은 학습 알고리즘이나 실제로 두가지 학습 알고리즘을

115
00:05:58,010 --> 00:06:03,560
두가지 훨씬 더 단순한 작업을 해결하고 전반적으로 더 나은 성능을 제공합니다.

116
00:06:03,560 --> 00:06:05,930
그런데, 혹시

117
00:06:05,930 --> 00:06:08,975
두번째 단계는 토론을 단순화시켰습니다.

118
00:06:08,975 --> 00:06:11,865
그런데 2 단계가 실제로 어떻게 작동하는지 알고 싶으시다면

119
00:06:11,865 --> 00:06:13,605
설명을 조금 단순화해서 말씀드리겠습니다.

120
00:06:13,605 --> 00:06:15,470
두번째 단계가 실제로 훈련된 방식은

121
00:06:15,470 --> 00:06:16,730
네트워크에서 훈련할 때,

122
00:06:16,730 --> 00:06:18,920
두개의 이미지를 입력하고

123
00:06:18,920 --> 00:06:22,230
당신의 네트워크가 하는 일은

124
00:06:22,230 --> 00:06:29,553
두 이미지를 입력하면 두 이미지가 같은 사람인지 아닌지를 알 수 있습니다.

125
00:06:29,553 --> 00:06:34,700
직원 1만명을 기록해 두면

126
00:06:34,700 --> 00:06:36,430
이 사진을 빨간 색으로 찍고

127
00:06:36,430 --> 00:06:38,545
빠르게 비교하여

128
00:06:38,545 --> 00:06:41,795
10000명의 직원 중 누구인지 알아내느것을 시도합니다.

129
00:06:41,795 --> 00:06:44,810
이 빨간 색 사진이 만명의 직원 중 한명이라는 알아내고

130
00:06:44,810 --> 00:06:48,640
당신 사무실 건물 안으로 들어갈 수 있을 겁니다.

131
00:06:48,640 --> 00:06:51,770
이것이 직원들이 직장에 접근 할 수있게 해주는 회전식 출입문입니다.

132
00:06:51,770 --> 00:06:55,970
직장 그러면 왜 두 단계 접근 방식이 효과가 있을까요?

133
00:06:55,970 --> 00:06:58,605
그것에 대한 두가지 이유가 있습니다.

134
00:06:58,605 --> 00:07:02,020
하나는 여러분이 해결하고 있는 두가지 문제가 실제로는 훨씬 더 단순하다는 것입니다.

135
00:07:02,020 --> 00:07:10,360
둘째로, 두개의 하위 작업에 대한 데이터가 많다는 것입니다.

136
00:07:10,360 --> 00:07:16,950
특히, 위상 검출을 위해 얻을 수 있는 데이터는 많습니다.

137
00:07:16,950 --> 00:07:18,720
하나는 여기 있고

138
00:07:18,720 --> 00:07:20,820
여기서 과제는 이미지와 수치를 보는 것입니다.

139
00:07:20,820 --> 00:07:23,415
어딘가에 그 사람의 얼굴과 이미지가 있을 겁니다

140
00:07:23,415 --> 00:07:25,695
그래서 데이터가 많습니다.

141
00:07:25,695 --> 00:07:27,610
많은 라벨 데이터 X 가 있습니다.

142
00:07:27,610 --> 00:07:31,420
쉼표 Y 여기서 X는 그림이고 y는 사람 얼굴의 위치를 나타냅니다.

143
00:07:31,420 --> 00:07:35,100
여러분은 하나의 과제를 잘 수행하기 위해 신경 조직을 만들 수 있었습니다.

144
00:07:35,100 --> 00:07:37,440
그리고 별도로, 두번째 태스크에도 많은 데이터가 있습니다.

145
00:07:37,440 --> 00:07:41,710
오늘날 주요 기업들은 이렇게 말합니다.

146
00:07:41,710 --> 00:07:44,525
수억장의 인물 사진

147
00:07:44,525 --> 00:07:46,845
그래서 가까이 잘린 사진을 보면

148
00:07:46,845 --> 00:07:49,275
이 빨간 사진이나 이 사진처럼요

149
00:07:49,275 --> 00:07:51,555
오늘날 선도적인 얼굴 인식 팀들은

150
00:07:51,555 --> 00:07:53,880
적어도 몇 억개의 이미지를 가지고 있는데

151
00:07:53,880 --> 00:07:55,980
그것들은 두개의 이미지를 보고,

152
00:07:55,980 --> 00:07:58,765
그것이 동일 인물인지 아닌지를 알아내기 위해 시도합니다.

153
00:07:58,765 --> 00:08:02,310
두번째 과제에는 많은 자료가 있습니다.

154
00:08:02,310 --> 00:08:07,155
대조적으로, 만약 여러분이 모든 것을 동시에 배우려고 시도 한다면

155
00:08:07,155 --> 00:08:10,680
X쉼표 Y형식의 데이터가 훨씬 더 적습니다.

156
00:08:10,680 --> 00:08:13,175
여기서 X는 회전식 회전식 출입문에서 찍힌 것과 같은 이미지이고,

157
00:08:13,175 --> 00:08:16,390
Y는 그 사람의 정체입니다.

158
00:08:16,390 --> 00:08:21,610
따라서 이러한 엔드 투 엔드 러닝 문제를 해결하기에 충분한 데이터는 없지만

159
00:08:21,610 --> 00:08:27,410
실제로 하위 문제를 해결하기에 충분한 데이터는 있으므로

160
00:08:27,410 --> 00:08:29,740
이 문제를 두개의 하위 문제 학습 결과보다

161
00:08:29,740 --> 00:08:34,260
더 깊이 있게 분석해야 합니다.

162
00:08:34,260 --> 00:08:37,575
엔드 투 엔드 접근 방식에 필요한 데이터가 충분했다면 

163
00:08:37,575 --> 00:08:40,470
아마도 엔드 투 엔드 접근 방식이 더 효과적일 것입니다

164
00:08:40,470 --> 00:08:44,240
하지만 오늘날 실제로 가장 효과적인 방법은 이것이 아닙니다.

165
00:08:44,240 --> 00:08:46,886
몇가지 예를 더 살펴 보겠습니다.

166
00:08:46,886 --> 00:08:49,000
기계 번역을 보면,

167
00:08:49,000 --> 00:08:54,390
전통적으로, 기계 번역 시스템은 긴 복잡한 파이프 라인을 가지고 있는데,

168
00:08:54,390 --> 00:08:56,230
우선 영어 텍스트를 말하고

169
00:08:56,230 --> 00:08:58,955
텍스트 분석을 합니다.

170
00:08:58,955 --> 00:09:01,990
기본적으로 텍스트에서 많은 형상을 추출하는 것 등이 있습니다.

171
00:09:01,990 --> 00:09:04,630
여러 단계를 거쳐

172
00:09:04,630 --> 00:09:07,900
영어 텍스트를 프랑스어로 번역하게 됩니다.

173
00:09:07,900 --> 00:09:10,030
기계 번역을 위해

174
00:09:10,030 --> 00:09:13,990
당신은 많은 영어 쉼표 프랑스어 문장이 있기 입니다.

175
00:09:13,990 --> 00:09:17,640
엔드 투 엔드 팁 러닝은 기계 번역에 매우 효과적 입니다.

176
00:09:17,640 --> 00:09:20,140
그것은 오늘날

177
00:09:20,140 --> 00:09:24,350
X-Y 쌍의 큰 데이터 세트를 모으는 것이 가능하기 때문입니다

178
00:09:24,350 --> 00:09:28,780
그것이 영어 문장이고 그것이 프랑스어 번역이기 때문이죠.

179
00:09:28,780 --> 00:09:29,955
예를 들면,

180
00:09:29,955 --> 00:09:32,320
엔드 투 엔드 딥 러닝이 작동을 잘 합니다.

181
00:09:32,320 --> 00:09:35,200
한가지 마지막 예로, 당신이

182
00:09:35,200 --> 00:09:38,220
아이 손의 X-ray 사진을 보고 싶다고 말해 보십시요.

183
00:09:38,220 --> 00:09:40,215
그리고 아이의 나이를 추정합니다.

184
00:09:40,215 --> 00:09:41,830
이런 문제를 처음 들었을 때 

185
00:09:41,830 --> 00:09:45,460
저는 이것이 매우 멋진 범죄 현장 조사의 작업이라고 생각했습니다

186
00:09:45,460 --> 00:09:48,610
아마도 비극적이게도 아이의 해골을 발견하게 될 것이고

187
00:09:48,610 --> 00:09:50,980
그 아이가 어떻게 생겼는지를 알아내고 싶을 것입니다.

188
00:09:50,980 --> 00:09:54,445
엑스 레이에 의한 아이의 나이를 추정하는 이 문제의

189
00:09:54,445 --> 00:09:57,010
전형적인 적용은 내가 상상했던

190
00:09:57,010 --> 00:09:59,995
이 범죄 현장 조사보다 덜 극적인 것으로 드러났다.

191
00:09:59,995 --> 00:10:02,890
소아과 의사는

192
00:10:02,890 --> 00:10:06,925
이것을 아이가 정상적으로 성장하는지 아니면 성장하지 않는지를 추정하기 위해 사용하는 것으로 밝혀졌다.

193
00:10:06,925 --> 00:10:09,460
하지만 이렇게 하는 데는

194
00:10:09,460 --> 00:10:14,045
골격을 구분하거나 인식할 수 있도록 영상을 찾는 것이 일반적인 방법이 될 수 있습니다.

195
00:10:14,045 --> 00:10:16,730
뼈 부분이 어디에 있는지 일단 시도해 봅시다.

196
00:10:16,730 --> 00:10:17,849
뼈 부분은 어디있는건가요? 

197
00:10:17,849 --> 00:10:20,290
뼈 조각은 어디있는건가요? 그리고 

198
00:10:20,290 --> 00:10:22,285
다른 뼈의 길이를 알면

199
00:10:22,285 --> 00:10:26,380
아이의 손에 있는 평균 뼈 길이를 보여 주는 위 표를 보면

200
00:10:26,380 --> 00:10:30,615
아이의 나이를 추정할 수 있습니다.

201
00:10:30,615 --> 00:10:32,800
그래서 이 방법은 꽤 효과가 있습니다.

202
00:10:32,800 --> 00:10:37,960
대조적으로, 만일 여러분이 이미지에서 아이들의 나이로 돌아 간다면

203
00:10:37,960 --> 00:10:43,030
여러분은 그것을 직접적으로 그리고 내가 아는 한

204
00:10:43,030 --> 00:10:45,850
이 접근법은 단지 이것이 단지 오늘날에

205
00:10:45,850 --> 00:10:50,515
충분히 잘 작동하지 않기 때문에 많은 데이터를 필요로 할 것입니다.

206
00:10:50,515 --> 00:10:56,326
대조적으로, 여러분은 이 문제를 두 단계로 나누는것으로 생각 해 볼 수 있습니다.

207
00:10:56,326 --> 00:10:58,780
1단계는 비교적 간단한 문제이다.

208
00:10:58,780 --> 00:11:00,345
그렇게 많은 데이터가 필요하지 않을 수도 있습니다.

209
00:11:00,345 --> 00:11:03,455
뼈를 분할하는 데 그렇게 많은 X선 영상이 필요하지 않을 수 있습니다.

210
00:11:03,455 --> 00:11:08,225
그리고 두번째 과제는, 많은 아이들의 손에 대한 통계를 수집함으로써,

211
00:11:08,225 --> 00:11:11,280
많은 자료를 필요로 하지 않고도 그것에 대한 상당한 추정치를 얻을 수 있다는 것입니다.

212
00:11:11,280 --> 00:11:14,125
그래서 이러한 단계별 접근 방식은 전망이 밝습니다.

213
00:11:14,125 --> 00:11:16,420
적어도 여러분이 엔드 투 엔드 러닝 접근법에 대한

214
00:11:16,420 --> 00:11:20,635
더 많은 데이터를 얻을 수 있을 때까지는 엔드 투 엔드 접근 방식보다 더 효과적일 수 있습니다.

215
00:11:20,635 --> 00:11:22,840
엔드 투 엔드 딥러닝은 작동할 수 있습니다.

216
00:11:22,840 --> 00:11:26,650
이 방법은 정말 잘 작동할 수 있고, 실제로 시스템을 단순화할 수 있기 때문에

217
00:11:26,650 --> 00:11:30,875
이렇게 많은 수작업으로 설계된 개별 구성 요소를 만들 필요가 없습니다.

218
00:11:30,875 --> 00:11:32,773
하지만 이것이 만병 통치 약도 아닙니다

219
00:11:32,773 --> 00:11:34,315
항상 효과적인것도 아닙니다. 다음 영상에서

220
00:11:34,315 --> 00:11:35,650
다음 비디오에서는

221
00:11:35,650 --> 00:11:39,530
저는 여러분이 언제 어떻게 완벽하게 딥 러닝을 하고, 

222
00:11:39,530 --> 00:11:42,820
하지 않아야 하는지, 그리고 어떻게 이런 복잡한 기계 학습 시스템들을

223
00:11:42,820 --> 00:11:47,000
결합시켜야 하는지에 한 좀 더 체계적인 설명을 나누고 싶습니다.