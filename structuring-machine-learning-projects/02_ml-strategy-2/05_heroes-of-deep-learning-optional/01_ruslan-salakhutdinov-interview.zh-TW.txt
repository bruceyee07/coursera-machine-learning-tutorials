歡迎魯斯，很高興
今天您可以加入我們的討論 >> 謝謝您 >> 今天你是蘋果公司的研究總監 你還是一個教授,
在卡內基-梅隆大學 跟大家分享一下您個人的故事 您怎麼會從事這項深度學習的工作？ 是啊，某種程度上 某種程度上是靠運氣
開始深度學習的 我在多倫多完成碩士學位, 
然後我休假了一年 實際上，
我是在金融部門工作 有點意外 在那個時候, 
我不太確定是否要去攻讀博士學位 然後發生了一些意外的事情 一天早上我要去上班, 
我碰見了 Geoff Hinton 傑夫告訴我, 嘿, 
我有一個絕妙的主意 到我辦公室來, 
我來告訴你 所以，我們一起走，
然後他開始告訴我有關 玻爾茲曼機和對比的分歧, 
和一些技巧 當時我不太明白他在說什麼 但是, 真的, 真的很興奮, 
真的讓我興奮 然後基本上, 在三月內, 
我跟隨傑夫開始了我的博士學位 所以就是這樣開始的, 
那是早在 2005年, 2006年 是一些原始的深度學習演算法 使用受限玻爾茲曼機，
非監督式預先訓練，開始出現 這就是我的開始點，真的 那個特別的早上，我遇見傑夫， 完全改變了
我的未來事業生涯 >> 實際上, 你是一個非常早的共同作者 在受限玻爾茲曼機器的論文 真的幫助了神經網路
跟深度學習的再造 告訴我們，那個時候的工作
您的感覺如何？ >> 那真的是很 令人興奮，那是我的第一年博士學位學生 傑夫跟 我試著探索使用
受限玻爾茲曼機的想法 使用預先訓練技巧來
訓練多層（深度學習） 特別是我們試著
專注於自動編碼器 我們如何有效地做非線性的 
PCA (Principle Component Analysis) 那是很令人興奮的, 
因為我們讓系統作用在 MNIST digit 很令人興奮，但下一步當我們 真的看是否可以
擴展這個模型到人臉辨識 我記得我們用 Olivetti 人臉資料集 然後我們開始看
可不可以做文件的壓縮 我們開始看所有這些不同的資料 實數，二進位，看了一年 當時我是第一年的博士生，
是我很大的學習經驗 但僅僅不到六到七個月 我們已經可以得到很有趣的結果，
我的意思是很好的結果 我想我們可以訓練
很深的自動編碼器 在當時，您無法使用 傳統的最佳化技術能夠做到的 然後，那真的真的
令人非常興奮的時期 那時真的超級興奮，
因為我學到很多 同時，那些結果也真的 非常令人印象深刻，
對於我們做的部分 >> 所以在早期這些深度學習的研究中 許多活動集中在受限玻爾茲曼機上, 然後是深度玻爾茲曼機 之後還有很多的令人興奮的研究 包含了您的小組，後來玻爾茲曼機 跟受限玻爾茲曼機怎麼了？ >> 這是一個好問題 我想 早期，我們使用受限玻爾茲曼機的方式是 您可以想像訓練
疊起來的受限玻爾茲曼機 這會讓您有效地一次訓練一層 而有好的理論在
當您加入一個特別的層的背後 在一定條件下, 它可以證明變化的約束等等 因此, 有一些理論的原因, 這些模型 可以作用得很棒在
預先訓練這些系統時 然後在大約 2009, 2010時，
一旦運算力開始展現 GPU, 我們很多人開始理解，
實際上這個運算力直接 最佳化神經網路，
給予類似的結果，甚至更好的結果 >> 所以只是標準的反向傳播，
沒有預先訓鍊或 或者受限玻爾茲曼機 >> 對對沒錯 經過三，四年後， 整個社群都很興奮，因為人們覺得，哇 您可以真的訓練這些深度模型，
使用這些預先訓練機制 然後，越多的運算力，人們開始理解您可以 基本上做標準的反向傳播，那是我們無法在 2005, 2004 的時候做，因為
會花幾個月的時間在 CPU 上做 所以那是一個很大的改變 另一件事我想
我們還沒發現到 玻爾茲曼機跟深度玻爾茲曼機要做什麼？ 我相信那是很強大的模型 因為您可以將
他們想成生成模型 他們試圖在資料中耦合分佈, 但 當我們開始看學習演算法，
現在的學習演算法 他們用到馬可夫鍊，
蒙地卡羅跟變分學習等等 它們不像反向傳播那樣可以擴充 我們還在尋找更有效的方式
來訓練這些模型 我們也用到卷積 但是很難將它融入這些模型 我記得您曾經用過機率最大池 類似建立這些不同物件的生成模型 使用卷積的概念
也是非常令人興奮 同時，還是很難來訓練這些模型 >> 可行性如何？ >> 可行性如何？是吧 我們還得弄清楚 另一方面，一些人
最近利用變分自動編碼器 舉個例子，可以看成是
玻爾茲曼機的互動版 我們已經找到方法來訓練這些模型，
Max Welling 跟 Diederik Kingma 使用重參數技巧 現在我們可以使用反向傳播
演算法在隨機系統上 現在有很多的進展 但我們還沒發現到如何
作用在玻爾茲曼機上 >> 實際上是一個非常有趣的觀點,
 我並不知道 在早期電腦比較慢，
RBM （受限玻爾茲曼機） 預先訓練是
真的很重要 只是在更快的運算力時，
驅動成為標準的反向傳播 在社群中所想的深度學習演化 換另一個主題，
我知道您花很多時間在上面 生成，非監督式跟監督式的方法 您可以分享一下您的想法
關於那個的演進 >> 是的, 我認為這是一個非常, 
我覺得是一個非常重要的話題 特別是如果我們考慮到
非監督式, 半監督式或 生成模型，因為某種程度上，最近的成功 都是在監督式學習上，回到以前 非監督式學習主要被視為
非監督式預先訓練, 因為我們不知道
如何訓練多層系統 即使在今天，如果您在設置的時候有 很多未標籤的資料跟少數標籤的例子 這些非監督式預先訓練模型 建立在這些生成模型，
可以幫助監督式 我想有很多在社群中的人，相信這樣 當我開始我的博士學位時，
都是有關於生成模型，試著學習 這些疊起來的模型，因為那是
唯一的方式我們來訓練系統 在今天，有很多的工作在生成模型 如果您看生成對抗網路 如果你看變分自動編碼器 深度能量模型是
我的實驗室正在研究的 我想都是很令人興奮的研究，
但或許我們還沒發展出來 再一次，對於很多想要
進入深度學習領域的人 這一個領域是我想我們
將會獲得重大的進展 希望在不久的將來 >> 因此, 非監督學習 >> 非監督學習, 對 或者您可以想成非監督式學習 或者半監督式學習，您會有，
我給您一些暗示或者例子 不同的東西意味著什麼, 
我拋出了很多未標籤的資料 >> 所以實際上這是一個非常重要的洞見, 
在早期的時代 對於深度學習, 電腦的速度較慢, 受限玻爾茲曼機和
深度玻爾茲曼機需要用來 初始神經網路權重，但當電腦越來越快 直接反向傳播
已經作用得比較好 換另一個主題，
我知道您花很多時間在想 監督學習與
生成模型, 非監督學習方法。 您如何 告訴我您的看法是如何
對於這種辯論，隨著時間推移而演變的？ >> 我想我們都相信我們
應該能夠在那裡取得進展 所有的工作在於玻爾茲曼機，
變分自動編碼器，GAN (生成對抗網路） 您想有很多的這些生成模型 我們只是還沒有弄清楚
如何真正讓他們可行 如何使用大量的資料 即使，我看到很多 IT 
有關的公司，有很多 大量的資料，大量非標籤資料，很多的努力 來做標註，因為那是唯一的方式 在今日讓我們可以有所進展 似乎我們應該能夠使用 非標籤資料，因為它就是很大量 而我們還沒發現如何去用它 >> 所以你提到的如果
有人想進入深度學習研究 非監督式學習
是令人興奮的領域 今天有很多人想
進入深度學習 無論是研究還是應用工作, 
對於這個全球社群 無論是研究還是應用工作, 
你會有什麼建議？ >> 是的, 我認為其中一個
關鍵的建議, 是我想 人們想進入這個領域 我會鼓勵他們
只是嘗試不同的東西, 不要害怕嘗試新事物, 
也不要害怕嘗試創新 我可以舉一個例子 當我還是個研究生的時候, 
我們正在研究神經網路 這些都是高度非凸系統, 
很難去做最佳化 我記得在最佳化社區群裡
和我的朋友聊天 和回饋總是, 嗯, 
您沒有辦法可以解決這些問題 因為這些都是非凸，
我們不知道如何去做最佳化 與做凸形函數最佳化相比, 
你還能做什麼呢？ 令人驚訝的是，
因為在我們實驗室中 從不關心這樣
特定的問題 我們只是想著
如何做最佳化 是否我們可以獲得有趣的結果 而這有效地推動社群, 使得 我們不害怕, 
也許在某種程度上, 因為我們 實際上缺乏最佳化背後的理論 但我會鼓勵人們只是嘗試 不要害怕去嘗試解決困難的問題 >> 是的, 我記得你曾經說過, 不要學高階 深度學習框架的程式，但要真的了解深度學習 >>是，對 我想這是我想嘗試的一件事是，
當我教深度學習課程時 其中一項作業，我要求學生實際去寫 反向傳播演算法的程式，
對於卷積神經網路 那是很痛苦的，但同時，
如果您做過一次 您會真的了解系統如何作用，
它們的工作方式 您可以如何有效地
建立它們在 GPU 上 我想對您而言，
當您進入研究或者應用領域 您會有相當好的理解
對於系統如何作用 所以這很重要, 我想 >> 因為你有教授的學術經驗, 跟公司的經驗, 我很好奇, 
如果有人想進入深度學習, 做博士研究跟加入公司
各有什麼優缺點？ >> 這是一個好問題 在我的實驗室中，
我有混合的學生 有些學生想要
進入學術路線 一些學生想進入產業界 這變得很挑戰，
因為您可以在產業界做驚人的研究 您也可以在
學術界做驚人的研究 但在利與弊之間，在學術界 我覺得您比較能自由地
從事長期的問題，或者您想 一些瘋狂的問題，您可以做它們，
所以您可以比較自由 同時, 你在產業界做的研究
也很令人興奮 因為在許多情況下, 你的研究可以影響 數以百萬計的使用者, 
如果你開發的是核心 AI 技術 很顯然的, 在產業界, 你有很多 資源，像是運算力，
能夠做驚人的事情 所以有優缺點, 
這取決於你想做什麼 現在變得很有趣 非常有趣的環境, 學術界轉向產業界 然後, 從產業界轉移到學術界, 
但沒有那麼多 因此, 這是非常激動人心的時刻 >> 它聽起來像學術界的機器學習是很棒的，
產業界的機器 學習也是很棒的，
最重要的是要跳進去 任何一個，只要跳進去 >> 它真的取決於你的喜好, 
因為你可以做驚人的研究 在這兩種地方都可 >> 所以你提到非監督式學習
是一個激動人心 研究的前沿 是否還有其他領域, 
你認為令人興奮的研究前沿？ >> 好啊，當然 我想現在在社群裡看到的 特別是在深度學習社群中，
有一些趨勢 一個特別的領域，我想很令人興奮 的是深度強化學習 因為我們能夠知道如何在
虛擬世界中訓練代理 這是在短短的幾年裡, 
你看到了很多, 很多進步, 我們如何擴展這些系統, 
我們如何能發展 新的演算法, 我們怎樣
才能讓代理彼此溝通 我想那個領域是，一般而言 設定來讓您與環境互動，
那是超級令人興奮的 其他領與我想也是令人興奮的是 在推理領域跟
自然語言理解部分 我們可以建立對話系統嗎？ 我們可以建立系統來做推理，
可以讀文字 然後可以
智慧地回答問題 我認為這是目前很多研究的重點 然後還有另一種子領域也是 這個領域可以從幾個例子中學習 所以一般人認為它是
一次學習或轉移學習 一種您可以從這個世界學習的設定 然後我丟給您一個任務，
您可以很快解決這個任務 像是人類在做的，不需要很多很多的標籤例子 所以這些事, 我們在社群上很多人都在試圖找出 我們如何才能做到這一點, 
我們如何能夠更接近于人的學習能力 >> 非常感謝, 魯斯, 分享這些意見、洞見和忠告 這真有趣的看到 聽到你的早期的故事, >> [歡笑]是的 感謝您的邀請