1
00:00:00,000 --> 00:00:05,250
딥러닝의 강력한 아이디어 중 한가지는 한가지 업무에서 배운 지식을

2
00:00:05,250 --> 00:00:10,560
또 다른 업무에 적용시킬 수 있다는 것입니다.

3
00:00:10,560 --> 00:00:12,815
예를 들어서, 신경망 네트워크가 

4
00:00:12,815 --> 00:00:15,720
고양이와 같은 것을 인식할 수 있도록 러니시킬 수 있고,

5
00:00:15,720 --> 00:00:18,085
그 지식을 이용해서 부분적으로

6
00:00:18,085 --> 00:00:21,300
x-ray 스캔을 읽는데 도움이 될 수 있도록 만들 수 있습니다.

7
00:00:21,300 --> 00:00:24,920
이것을 바로 트렌스퍼 러닝이라고 압니다. 한번 보겠습니다.

8
00:00:24,920 --> 00:00:30,180
이미지 인식기능을 신경망네트워크에 트레이닝시켰다고 해봅시다.

9
00:00:30,180 --> 00:00:34,395
일단 먼저 신경망을 갖고, X와 Y 쌍에 트레이닝 시킵니다. 

10
00:00:34,395 --> 00:00:37,700
X는 이미지이고, Y는 목적 대상입니다. 

11
00:00:37,700 --> 00:00:41,340
이미지는 고양이나 강아지, 새 또는 다른 것이 될 수 있을텐데요

12
00:00:41,340 --> 00:00:43,960
이 신경망 네트워크를 이용해서 조정을 하거나

13
00:00:43,960 --> 00:00:45,465
또는 트랜스퍼 한다고 표현하는데요, 

14
00:00:45,465 --> 00:00:47,670
다른 업무들을 통해서 습득한 것들이, 

15
00:00:47,670 --> 00:00:51,750
방사선학 진단같은 것들이, 

16
00:00:51,750 --> 00:00:54,780
X-ray 스캔을 읽는 것인데요, 

17
00:00:54,780 --> 00:00:59,160
신경망 네트워크의 마지막 결과값 층인 이 부분을 가지고, 

18
00:00:59,160 --> 00:01:03,885
이것은 삭제하구요, 이 마지막 결과값 층에 fedding하는 이 weight들도 삭제합니다. 

19
00:01:03,885 --> 00:01:08,880
그런 뒤에, 마직막 층을 위한 무작위로 초기화된 weight 세트를 생성합니다. 

20
00:01:08,880 --> 00:01:15,000
이렇게 생성한 것들이 방사선학 진단을 결과값으로 표출할 수 있게 하는 것이죠. 

21
00:01:15,000 --> 00:01:17,160
구체적으로 말씀드리자면, 트레이닝 첫번째 단계에서

22
00:01:17,160 --> 00:01:19,795
이미지 인식 업무 관련한 내용을 트레이닝 시키는 경우,

23
00:01:19,795 --> 00:01:23,710
익숙한 신경망 parameter들을 트레이닝 시키는데요. 모든 weight와 

24
00:01:23,710 --> 00:01:27,150
모든 층을 트레이닝 시키면 이렇게 

25
00:01:27,150 --> 00:01:32,680
이미지를 인식하고 예측하는 프로그램과 같은 것도 생기는 것입니다.

26
00:01:32,680 --> 00:01:35,370
이런 신경망을 트레이닝한 경우, 

27
00:01:35,370 --> 00:01:41,540
이제 트렌스퍼 러닝을 도입하기 위해서 데이터세트 X와 Y에서 스왑을 진행합니다.

28
00:01:41,540 --> 00:01:47,120
이것은 이제 그러면 방사선 이미지인데요. 

29
00:01:47,120 --> 00:01:50,580
Y는 예측하고 싶은 진단에 대한 부분인데요. 

30
00:01:50,580 --> 00:01:58,340
여기서 해야하는 부분은 바로 마지막 층의 weight를 초기화시키는 것입니다.

31
00:01:58,340 --> 00:02:00,250
이것을 W.L이라고 하겠습니다.

32
00:02:00,250 --> 00:02:02,360
그리고 P.L이라고 랜덤으로 이야기 하겠습니다.

33
00:02:02,360 --> 00:02:07,175
이제 새로운 데이터세트에서 신경망을 다시 트레이닝 시키는데요,

34
00:02:07,175 --> 00:02:09,320
새로운 방사선학 데이터세트에서 말이죠. 

35
00:02:09,320 --> 00:02:14,260
신경망을 방사선학 데이터로 재차 트레이닝 시키는 방법이 몇 가지 있는데요. 

36
00:02:14,260 --> 00:02:16,905
만약에 작은 양의 방사선학 데이터세트가 있는 경우,

37
00:02:16,905 --> 00:02:20,647
마지막 층의 weight만 다시 트레이닝 시킬 수 있습니다. W.L.P.L만 말이죠. 

38
00:02:20,647 --> 00:02:22,620
그리고 나머지 매개 변수는 고정시키는 것입니다.

39
00:02:22,620 --> 00:02:23,975
데이터가 충분히 있는 경우,

40
00:02:23,975 --> 00:02:27,400
나머지 신경망에 대한 부분도 모든 층을 다시 트레이닝 시킬 수 있습니다.

41
00:02:27,400 --> 00:02:32,535
경험에 의거한 규칙은, 데이터세트의 크기가 작은 경우,

42
00:02:32,535 --> 00:02:35,560
결과값 층에서 마지막 층만 retrain 시킵니다.

43
00:02:35,560 --> 00:02:37,070
마지막 층 또는 마지막 2개의 층을 말이죠. 

44
00:02:37,070 --> 00:02:38,755
하지만 만약 데이터가 많은 경우, 

45
00:02:38,755 --> 00:02:42,490
네트워크에서 있는 모든 매개 변수를 다시 트레이닝 시킬 수 있습니다.

46
00:02:42,490 --> 00:02:45,775
모든 신경망의 매개 변수를 다시 크레이닝 시키는 경우에는, 

47
00:02:45,775 --> 00:02:49,270
이러한 이미지 인식 기능에 대한 

48
00:02:49,270 --> 00:02:53,938
첫번째 단계의 트레이닝을 pre-training이라고 부릅니다.

49
00:02:53,938 --> 00:02:57,355
신경망의 weight 비중을 pre-initialize나 pre-train 하기 위해

50
00:02:57,355 --> 00:03:01,745
이미지 인식 데이터를 쓰기 때문에 그렇습니다.

51
00:03:01,745 --> 00:03:04,545
그리고 weight를 나중에 업데이트 하는 경우,

52
00:03:04,545 --> 00:03:09,885
방사선학 데이터에 트레이닝 시키는 것은 가끔 fine tuning이라고도 합니다.

53
00:03:09,885 --> 00:03:15,185
pre-training 이나 fine tuning 이라는 용어는 딥러닝 분야에서 들으실 경우가 있을텐데요, 

54
00:03:15,185 --> 00:03:17,530
트렌스퍼 러닝 소스에서 이야기하는 pre-training이나 fine tuning에

55
00:03:17,530 --> 00:03:21,050
대한 내용을 논하는 겨우, 이런 뜻이라고 생각하시면 됩니다.

56
00:03:21,050 --> 00:03:22,585
이 example에서 한 것은, 

57
00:03:22,585 --> 00:03:25,435
이미지 인석 기능에서 습득한 지식을

58
00:03:25,435 --> 00:03:31,285
방사선학 진단하는데 적용 또는 진단법에 그 지식을 트렌스퍼 시킨 것입니다.

59
00:03:31,285 --> 00:03:33,490
이것이 도움을 줄 수 있는 이유는,

60
00:03:33,490 --> 00:03:36,570
edges를 감지하는 특성, 커브 감지, poitive object를 감지하는 특성들과 같이 

61
00:03:36,570 --> 00:03:39,400
수 많은 low level 특성 때문입니다.

62
00:03:39,400 --> 00:03:43,045
이러한 아주 큰 이미지 인식 데이터세트에서 내용을 익히는 것이,

63
00:03:43,045 --> 00:03:47,736
러닝 알고리즘이 방사선학 진단에 도움이 되도록 해줄 것입니다.

64
00:03:47,736 --> 00:03:51,730
이미지의 구조가 어떻게 되는지, 이미지가 어떻게 생겼는지에 대해 많이 

65
00:03:51,730 --> 00:03:56,465
익힌 지식 내용이 유용할 수 있습니다. 

66
00:03:56,465 --> 00:03:58,545
이제 이미지를 인식하는 방법을 배웠으니,

67
00:03:58,545 --> 00:04:00,910
충분히 배웠을수 도 있습니다.

68
00:04:00,910 --> 00:04:03,135
이미지들의 어느 부분이 다른지 분간하는 방법을 말이죠. 

69
00:04:03,135 --> 00:04:05,880
즉, 이미지에서의 라인에 대한 지식,

70
00:04:05,880 --> 00:04:07,725
점들, 커브들, 등등 말이죠.

71
00:04:07,725 --> 00:04:09,555
또는 물체들의 특정 작은 부분들을 알아서

72
00:04:09,555 --> 00:04:10,950
이런 지식들은

73
00:04:10,950 --> 00:04:15,910
여러분의 네트워크가 방사선학적 판단을 내리는데 더 적은 데이터로도 
판단을 내릴 수 있게 도와줄 것입니다.
또 다른 예제를 보겠습니다. 

74
00:04:15,910 --> 00:04:17,545
또 하나의 예제를 보도록 합시다.

75
00:04:17,545 --> 00:04:20,730
여러분이 음성인식 시스템을 트레이닝 했다고 해보겠습니다.

76
00:04:20,730 --> 00:04:24,398
그러면 이제 X는 오디오의 입력값 또는 오디오 단편입니다.

77
00:04:24,398 --> 00:04:27,545
Y는 어떤 ink 기록이구요

78
00:04:27,545 --> 00:04:34,200
그러면 여러분은 음성인식 시스템을 통해 transcript를 결과값으로 만듭니다.

79
00:04:34,200 --> 00:04:39,435
이제 여러분은 "wake word" 또는 

80
00:04:39,435 --> 00:04:45,345
"trigger word" 를 감지하는 시스템을 만들고 싶다고 해보겠습니다.

81
00:04:45,345 --> 00:04:49,580
이전에 말씀드렸지만, wake word 또는 trigger word는 음성인식기기를

82
00:04:49,580 --> 00:04:54,100
깨우기 위해 또는 작동시키기 위해 말하는 단어입니다.

83
00:04:54,100 --> 00:04:58,610
예를 들어, Amazon Echo를 작동시키기 위한 "Alexa"라는 단어, 또는 
구글을 깨우기 위한 "OK Google" 이라는 단어, 

84
00:04:58,610 --> 00:05:03,590
또는 애플 기기를 깨우기 위한 "hey siri" 또는 바이두 기기를 깨우기 위한
"ni hao Baidu" 와 같은 단어가 이에 해당합니다.

85
00:05:03,590 --> 00:05:05,120
이렇게 만들기 위해서는,

86
00:05:05,120 --> 00:05:09,080
신경망 네트워크의 

87
00:05:09,080 --> 00:05:13,435
마지막 층을 꺼내서 새로운 결과값 노드를 만들어야 할 것입니다.

88
00:05:13,435 --> 00:05:18,995
가끔씩 또 할 수 있는 방법은, 1가지 새로운 결과값을 생성하는 것이 아니라, 

89
00:05:18,995 --> 00:05:23,120
여러개의 새로운 층을 신경망에서 생성시키는 것입니다.

90
00:05:23,120 --> 00:05:28,215
Y 레이블을 wake word 감지 문제에 적용시키기 위해서 말이죠. 

91
00:05:28,215 --> 00:05:30,425
여러분이 얼마나 많은 데이터를 보유하고 있는지에 따라,

92
00:05:30,425 --> 00:05:34,400
네트워크의 새로운 층을 다시 트레이닝 시키거나, 또는 

93
00:05:34,400 --> 00:05:38,925
신경망의 층들을 더 많이 트레이닝 시키는 방법도 있습니다.

94
00:05:38,925 --> 00:05:42,150
그러면 언제 transfer learning이 말이 되는 것일까요?

95
00:05:42,150 --> 00:05:46,845
transfer learning이 말이 되는 경우는, 여러분이 전송하려고 하는 곳의

96
00:05:46,845 --> 00:05:49,110
대이터가 많고, 

97
00:05:49,110 --> 00:05:52,430
전송하는 곳의 문제 관련 데이터가 적은 경우 좋습니다.

98
00:05:52,430 --> 00:05:58,030
예를 들어, 음성 인식 업무를 위한 백만개의 예제가 있다고 가정하겠습니다.

99
00:05:58,030 --> 00:06:00,605
low level 특성을 배우기 위한, 

100
00:06:00,605 --> 00:06:03,095
또는 초반 신경망 네트워크 층에서 유용한 특성들

101
00:06:03,095 --> 00:06:06,385
배우기 위한 많은 양의 데이터인데요, 

102
00:06:06,385 --> 00:06:08,240
하지만 방사선학 업무로는,

103
00:06:08,240 --> 00:06:12,005
100개의 샘플만 있을수도 있습니다.

104
00:06:12,005 --> 00:06:15,650
방사선학 진단 문제는 아주 적은 데이터가 있는 것이죠, 

105
00:06:15,650 --> 00:06:17,530
100 개의 x-ray 사진 정도요. 

106
00:06:17,530 --> 00:06:23,070
그러면 이미지 인식기능에서 배우는 지식들이 이관되어서 

107
00:06:23,070 --> 00:06:24,560
방사선학 인식에 이관되어 쓰이면

108
00:06:24,560 --> 00:06:29,360
방사선학 부문에서 많은 데이터가 없더라도 도움이 될 수 있도록 해줄 수 있겠죠. 

109
00:06:29,360 --> 00:06:31,800
음성인식 기능으로는, 여러분이 

110
00:06:31,800 --> 00:06:35,110
음성인식기능을 트레이닝하는데 10000 시간을 데이터 트레이닝하는데
소비했을 수 있습니다.

111
00:06:35,110 --> 00:06:37,700
그러면, 여러분은 인간이 어떤 유형의 소리를 갖는지 

112
00:06:37,700 --> 00:06:41,270
10000시간의 데이터 트레이닝을 통해 익숙해져 있을 수 있는데요. 
긴 시간입니다.

113
00:06:41,270 --> 00:06:43,220
하지만 trigger word 감지 기능에서는, 

114
00:06:43,220 --> 00:06:45,735
1시간 분량의 데이터만 있을 수 있습니다

115
00:06:45,735 --> 00:06:48,800
해당 시간은 많은 양의 parameter 넣기에는 불충분한 시간입니다.

116
00:06:48,800 --> 00:06:53,215
이 경우, 인간음석인식에서 인간이 어떻게 들리는지 배우는 많은 부분이,

117
00:06:53,215 --> 00:06:56,450
인간의 음성 스피치 구성요소와 관련하여 말이죠,

118
00:06:56,450 --> 00:07:00,300
이런 내용이 훌륭한 wake word 감지 기능을 만드는데 도움을 줄 수 있습니다.

119
00:07:00,300 --> 00:07:03,220
데이터세트가 작더라도 말이죠. 또는 

120
00:07:03,220 --> 00:07:08,005
적어도 wake word감지 업무로는 작은 데이터세트인 경우에 말이죠.

121
00:07:08,005 --> 00:07:09,440
이 2가지의 경우,

122
00:07:09,440 --> 00:07:11,500
많은 데이터를 보유하고 있는 문제에서

123
00:07:11,500 --> 00:07:15,610
적은 데이터를 가지고 있는 문제로 transfer 시키는 것입니다.

124
00:07:15,610 --> 00:07:19,480
transfer learning을 하는 것이 말이 안되는 케이스는

125
00:07:19,480 --> 00:07:22,330
바로 반대가 성립하는 경우입니다.

126
00:07:22,330 --> 00:07:27,560
만약 여러분이 이미지 인식 분야에서 100개의 사진을 가지고 있고,

127
00:07:27,560 --> 00:07:34,120
방사선학 진단 부문에서 100개의 이미지 또는 1000개의 이미지가 있으면,

128
00:07:34,120 --> 00:07:38,395
생각할 수 있는 것은, 방사선학 진단 부문에서 잘하기 위해서는, 

129
00:07:38,395 --> 00:07:41,830
여러분이 방사선학 진단에서 잘하는 것이

130
00:07:41,830 --> 00:07:47,670
고양이와 고양이 이미지를 갖는 것보다 훨씬 더 중요하다는 가정하에 말이죠. 

131
00:07:47,670 --> 00:07:52,060
그렇기 때문에 여기서 각각의 example이 저기 각각의 example보다 더 중요한 것입니다.

132
00:07:52,060 --> 00:07:55,935
적어도 훌륭한 방사선 시스템을 만드는 명목에서는 말이죠. 

133
00:07:55,935 --> 00:07:58,810
그러므로 여러분이 이미 방사선학 관련 데이터가 더 많은 경우,

134
00:07:58,810 --> 00:08:01,955
100개의 임의 물체의 사진,고양이,강아지 등의

135
00:08:01,955 --> 00:08:06,310
사진을 갖는 것은 도움이 별로 되지 않을 것입니다.

136
00:08:06,310 --> 00:08:12,130
그 이유는 고양이와 강아지 이미지 인식 업무에서 온 1가지의 이미지 샘플이

137
00:08:12,130 --> 00:08:15,430
x -ray 이미지의 샘플보다 덜 값지기 때문입니다. 

138
00:08:15,430 --> 00:08:19,870
좋은 방사선학 시스템을 만드는데 있어서 말이죠. 

139
00:08:19,870 --> 00:08:22,925
이것이 transfer learning이, 

140
00:08:22,925 --> 00:08:27,515
물론 써서 나쁠 것은 없지만, 그다지 의미있는 결과를 주지 않는 하나의 사례입니다.

141
00:08:27,515 --> 00:08:31,030
이와 비슷하게, 10시간 분량의 데이터로 

142
00:08:31,030 --> 00:08:34,660
음성인식 시스템을 만들었고, 실제로 10시간 보다 더 많은, 

143
00:08:34,660 --> 00:08:38,330
예를 들어, 50시간 분량의 데이터가 wake word 감지 부분에서 있다고 하면,

144
00:08:38,330 --> 00:08:40,505
그럴수도 있고, 안 그럴수도 있지만,

145
00:08:40,505 --> 00:08:44,010
해당 10시간의 데이터를 transfer learning 에 추가하는 것은 아마 그리 나쁠 것은
없을 것입니다.

146
00:08:44,010 --> 00:08:47,350
하지만 그렇다고 의미있는 결과를 주는 것도 아닐 것입니다.

147
00:08:47,350 --> 00:08:51,220
요약하자면, 언제 transfer learning을 쓰는 것이 말이 될까요?

148
00:08:51,220 --> 00:08:53,200
만약 여러분이

149
00:08:53,200 --> 00:09:00,830
A업무에서 배우고 그 배운 특정 지식을 B업무로 넘기려고하면,

150
00:09:00,830 --> 00:09:07,825
transfer learning을 사용하는 것이 말이 될 수 있죠, A업무와 B업무가 
똑같은 입력값 x로 되어있을 경우 말이죠.

151
00:09:07,825 --> 00:09:10,285
첫번째 예제에서는, 

152
00:09:10,285 --> 00:09:12,455
A와 B모두 입력값으로 이미지가 있습니다.

153
00:09:12,455 --> 00:09:13,585
두번째로는 예제는, 

154
00:09:13,585 --> 00:09:17,260
2개 모두 오디오 영상이 입력값으로 있습니다.

155
00:09:17,260 --> 00:09:22,460
업무 A의 데이터가 업무 B의 데이터보다 훨씬 더 많은 경우 말이 될텐데요. 

156
00:09:22,460 --> 00:09:27,345
이러한 모든 것은, B업무에서 더 잘하고 싶어한다는 가정하에 성립됩니다.

157
00:09:27,345 --> 00:09:32,023
B업무의 데이터가 B업무에게는 더 중요하기 때문에, 

158
00:09:32,023 --> 00:09:36,765
보통은 A업무의 데이터가 훨씬 더 많아야 합니다.

159
00:09:36,765 --> 00:09:43,605
그 이유는 각각의 A업무 샘플이 B업무 샘플보다 덜 값지기 때문입니다.

160
00:09:43,605 --> 00:09:47,740
마지막으로, transfer learning이 조금 더 말이 되는 경우는, 여러분이

161
00:09:47,740 --> 00:09:52,300
A업무의 low level 틀성들이 B업무를 배우는데 도움이 될 수 있다 판단되는 경우입니다.

162
00:09:52,300 --> 00:09:54,395
이전의 2가지 예제에서는, 

163
00:09:54,395 --> 00:09:57,010
이미지 인식 부분을 배우는 것이 이미지에 대해 충분히 학습시켜줘서

164
00:09:57,010 --> 00:09:59,800
방사선학 판단에 도움을 줄 수도 있습니다. 그리고 

165
00:09:59,800 --> 00:10:02,200
음성인식을 배우는 것이, 인간 음성에 대한

166
00:10:02,200 --> 00:10:06,000
내용을 배우게 하여, trigger word 나 wake word를 감지하는데 도움을 줄 수도 있습니다.

167
00:10:06,000 --> 00:10:08,350
요약하자면, transfer learning은 특정 B라고 하는 업무를

168
00:10:08,350 --> 00:10:11,560
잘 하려고 할 때 가장 도움이 되었습니다.

169
00:10:11,560 --> 00:10:14,480
이런 B업무는 보통 데이터가 많이 없는 경우인데요. 

170
00:10:14,480 --> 00:10:16,910
예를 들어, 방사선학에서는

171
00:10:16,910 --> 00:10:18,310
많은 양의 x-ray 이미지를

172
00:10:18,310 --> 00:10:21,990
수집하기가 어렵습니다. 좋은 방사선 판단 시스템을 만들기 위해 말이죠. 

173
00:10:21,990 --> 00:10:25,270
이런 경우, 관련된 약간은 다른 업무를 찾을 수 있습니다.

174
00:10:25,270 --> 00:10:26,645
이미지 인식 기능 과 같은 분야 말이죠.

175
00:10:26,645 --> 00:10:30,850
이 분야에서 백만개의 이미지를 가지고와서 여러 특성들을 배울 수 있겠죠.

176
00:10:30,850 --> 00:10:34,180
그렇게 배운 이후에, B업무에서 잘하려고 할 수 있겠죠.

177
00:10:34,180 --> 00:10:38,166
방사선학 업무에서 말이죠. 데이터가 많이 없어도요.

178
00:10:38,166 --> 00:10:40,305
transfer learning이 말이 되는 경우에는, 

179
00:10:40,305 --> 00:10:43,690
여러분의 러닝 학습 업무의 성능을 상당히 많이 향상시켜줍니다.

180
00:10:43,690 --> 00:10:47,865
하지만 저는 transfer learning이 B업무의 데이터 양과 비교하여 

181
00:10:47,865 --> 00:10:52,360
A업무가 더 적은 데이터를 보유하고 있는 경우에 사용된 적을 가끔 보았는데요,

182
00:10:52,360 --> 00:10:55,285
이런 경우 이득이 될 것을 기대하지 않습니다.

183
00:10:55,285 --> 00:10:57,900
자 그럼 트렌스퍼 러닝에 대한 부분은 여기까지인데요,

184
00:10:57,900 --> 00:11:00,895
하나의 작업에서 러닝을 진행 후, 다른 작업으로 넘기는 것을 보았습니다.

185
00:11:00,895 --> 00:11:02,585
또 다른 러닝의 유형이 있는데요, 

186
00:11:02,585 --> 00:11:05,080
멀티태스크 러닝이라는 복수의 작업에서 러닝을 진행하는 방식입니다.

187
00:11:05,080 --> 00:11:07,510
한가지의 작업에서 러닝을 진행하는 것이 아니라

188
00:11:07,510 --> 00:11:10,845
다수의 작업들을 동시에 러닝하여, 결과적으로

189
00:11:10,845 --> 00:11:14,170
다른 작업으로 이관하는 것입니다. 

190
00:11:14,170 --> 00:11:15,450
다음 비디오에서는 

191
00:11:15,450 --> 00:11:17,340
멀티태스킹 러닝에 대해 토론해보겠습니다.