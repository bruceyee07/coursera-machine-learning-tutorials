1
00:00:00,330 --> 00:00:03,705
transfer learning 에서는 
순차적인 절차가 있었는 반면에, 

2
00:00:03,705 --> 00:00:07,162
A업무를 배우고 B업무로 
넘어가는 절차 말이죠, 

3
00:00:07,162 --> 00:00:10,520
milti-task 러닝에서는,
동시에 시작합니다.

4
00:00:10,520 --> 00:00:13,650
신경망이 여러가지 일을 할 수 있게
만드는 것이죠. 

5
00:00:13,650 --> 00:00:17,520
그러면 바라건대 여기 각각의 업무가 
다른 업무들도 도와주는 역할을 하는 것이죠. 
예제를 보도록 하겠습니다.

6
00:00:17,520 --> 00:00:18,480
예시를 봐볼까요.

7
00:00:20,110 --> 00:00:24,140
여러분이 자율주행차를 만든다고 해보겠습니다.

8
00:00:24,140 --> 00:00:28,969
그러면 이러한 자율주행차는
보행자나 

9
00:00:28,969 --> 00:00:34,164
다른 차량, 정비 팻말등 여러가지 부분을 잘 감지해야
할텐데요, 

10
00:00:37,312 --> 00:00:42,410
또한 신호나 다른 것들도 감지해야하는 
중요한 요소가 될 것입니다.

11
00:00:43,670 --> 00:00:47,330
예를 들어, 여기 왼쪽을 보시면, 
여기 정지 sign이 있는데요,

12
00:00:47,330 --> 00:00:53,510
그리고 여기 이미지에는 챠량이 있습니다.
하지만 보행자나 신호등은 따로 없죠.

13
00:00:53,510 --> 00:00:58,200
그러면 이 이미지가 example x(i)의 입력값이라고 하면, 

14
00:00:58,200 --> 00:01:02,770
하나의 y(i)의 레이블을 갖는 것이 아니라
4개의 레이블이 필요할 것입니다.

15
00:01:02,770 --> 00:01:05,640
이 예제에서는, 
보행자는 없고, 차량은 있으며, 

16
00:01:05,640 --> 00:01:08,850
정지 sign이 있고, 신호등은 없습니다.

17
00:01:08,850 --> 00:01:10,580
그리고 여러분이 다른 요소를 감지하려고 하는 경우,

18
00:01:10,580 --> 00:01:12,634
y(i)는 더 많은 dimension을 가질 수 있겠죠.

19
00:01:12,634 --> 00:01:14,385
하지만 현재로써는 4개로 유지하도록 하겠습니다.

20
00:01:14,385 --> 00:01:18,013
그러면 y(i)는 4 x 1 벡터입니다.

21
00:01:18,013 --> 00:01:22,444
트레이닝 테스트 레이블 전체를 보시면, 

22
00:01:22,444 --> 00:01:27,370
이전과 비슷하게, 트레이닝 데이터를 

23
00:01:27,370 --> 00:01:32,116
가로로 쌓을 것입니다. 이와같이 y(1)에서 
y(m)까지 말이죠.

24
00:01:32,116 --> 00:01:39,470
하지만 이제는 y(i)는 4 x 1 벡터이고,
그러므로 여기는 긴 세로줄 벡터입니다.

25
00:01:39,470 --> 00:01:45,530
여기 y 매트릭스는 이제 
4 x m 매트릭스입니다. 

26
00:01:45,530 --> 00:01:49,810
이전에는 y가 single 실수였는데요, 
여기가 1 x m 매트릭스가 됐었었겠죠 그럼. 

27
00:01:49,810 --> 00:01:55,122
이제 그럼 여러분이 할 수 있는 것은, 
여기 y값을 예측하기 위해, 신경망을 트레이닝 시키는 것입니다.

28
00:01:55,122 --> 00:01:57,828
그러면 신경망 입력값 x를 가지고, 

29
00:01:57,828 --> 00:02:00,970
결과값은 y의 4차원의 값을 가질 수 있습니다.

30
00:02:00,970 --> 00:02:04,590
여기서 보이다시피, 결과값으로 4개의 노드를 그렸습니다.

31
00:02:04,590 --> 00:02:09,000
첫번째 노드를 통해 예측하려고 하는 것은

32
00:02:09,000 --> 00:02:10,610
여기 사진에 있는 보행자 입니다.

33
00:02:10,610 --> 00:02:13,470
두번째 결과값은 차량에 대한 예측을할 것입니다.

34
00:02:13,470 --> 00:02:18,870
이것은 정비 sign이 있는지 예측하고, 
이것은 신호등이 있는지 예측할 것입니다.

35
00:02:20,850 --> 00:02:23,950
그러므로 여기 y hat은 4차원입니다.

36
00:02:26,110 --> 00:02:30,575
여기 신경망을 트레이닝 시키기 위해서는
신경망 네트워크의 

37
00:02:30,575 --> 00:02:32,029
loss를 정의해야 합니다.

38
00:02:32,029 --> 00:02:39,190
그러므로 예측 결과값 y hat은 
4 x 1차원인데요, 

39
00:02:39,190 --> 00:02:43,939
이 값에 대해서, 전체 트레이닝세트에서의
평균 loss는

40
00:02:43,939 --> 00:02:48,209
1 나누기 m 의 합, i가 1에서 m까지와, 

41
00:02:48,209 --> 00:02:55,349
그리고 개인별 예측의 loss에 대해서 j가 1에서 4까지의 합입니다.

42
00:02:59,030 --> 00:03:03,256
그러므로 이 절차는 4가지의 요소에서, 보행자, 자동차,

43
00:03:03,256 --> 00:03:04,253
장지 sign, 신호등에 대해서 그 값을 더하는 것입니다.

44
00:03:04,253 --> 00:03:11,462
그리고 여기 L값은 보통 로지스틱 loss를 나타냅니다.

45
00:03:14,493 --> 00:03:19,404
이것을 적자면, 

46
00:03:19,404 --> 00:03:24,314
-yj i 로그 y hat ji - 

47
00:03:24,314 --> 00:03:28,349
1-y log 1 - y hat 인데요, 

48
00:03:31,706 --> 00:03:36,018
이전에 다루었던 이진분류법과 두드러지는 

49
00:03:36,018 --> 00:03:38,760
차이점은 이제 여러분은 j의 값이 1 에서 4 사이인 값을
합한다는 것입니다.

50
00:03:40,570 --> 00:03:45,260
그리고 이것과 softmax regression의 주요 차이점은, 

51
00:03:45,260 --> 00:03:50,550
softmax regression은 single example에 대해서
single label을 부여했는데요, 이런 것과는 달리,

52
00:03:50,550 --> 00:03:53,370
여기 이 이미지는 복수의 레이블을 가질 수 있습니다.

53
00:03:55,350 --> 00:04:00,162
그러므로 여러분은 이미지가 
보행자의 사진이라거나, 

54
00:04:00,162 --> 00:04:04,780
자동차의 사진이라거나, 정지 sign의 이미지라거나,
신호등 사진이라고 하는 것이 아닙니다.

55
00:04:04,780 --> 00:04:09,010
한 사진에 대해서, 보행자가 있는지, 
챠량이 있는지, stop sign이 있는지,

56
00:04:09,010 --> 00:04:11,860
신호등이 있는지, 이렇게 복수의 
물체가 같은 그림에 있을 수 있다는 것입니다.

57
00:04:11,860 --> 00:04:16,390
이전 슬라이드에서 다루었던 예제를 보면, 

58
00:04:16,390 --> 00:04:19,400
차량도 있었고, stop sign도 있었습니다.
보행자나 신호등은 없었구요. 

59
00:04:19,400 --> 00:04:22,580
그러므로 여러분은 이 이미지에
1개의 레이블을 부여하는 것이 아닙니다.

60
00:04:22,580 --> 00:04:25,800
복수 클래스들을 통해

61
00:04:25,800 --> 00:04:29,573
각각의 클래스를 상대로 물어보고,
이미지에 어떤 물체가 표출되는지 확인하는 것입니다.

62
00:04:31,420 --> 00:04:34,839
그렇기 때문에 이러한 설정을 통해

63
00:04:34,839 --> 00:04:37,313
하나의 이미지가 복수의 레이블을 가질 수 있다고 설명드리는 것입니다.

64
00:04:37,313 --> 00:04:42,281
여러분이 비용함수를 최소화 시키기위해 신경망을 트레이닝 한다면,

65
00:04:42,281 --> 00:04:45,920
여러분은 multi-task 러닝을 실행하는 것입니다.

66
00:04:45,920 --> 00:04:50,823
그럼 여러분이 하는것은 
각각의 이미지를 볼 수 있도록

67
00:04:50,823 --> 00:04:53,860
하나의 신경망을 만들고,
이것을 통해 4개의 문제를 푸는 것과 같습니다.

68
00:04:53,860 --> 00:04:58,910
이것은 하나의 이미지가 4개의 물체를 포함하고 있는지 
알려주는 역할을 합니다.

69
00:05:00,250 --> 00:05:03,850
여러분이 할 수 있는 또 다른 방법은
4개의 개별 신경망은 트레이닝 시키는 것입니다.

70
00:05:03,850 --> 00:05:06,700
하나의 네트워크가 4개를 실행하도록 하는 대신에
말이죠, 

71
00:05:06,700 --> 00:05:11,300
하지만 신경망의 초반 특성들의 일부가

72
00:05:11,300 --> 00:05:13,790
다양한 물체들과 공유될 수 있다고하면,

73
00:05:13,790 --> 00:05:17,880
한개의 신경망을 트레이닝 시켜 
4개의 일을 할 수 있도록 하는 것이 보통

74
00:05:17,880 --> 00:05:21,760
더 나은 성능을 갖게 해줍니다. 4 개의 신경망을
완전히 따로 트레이닝 시키는 것보다 말이죠. 

75
00:05:23,040 --> 00:05:25,450
이것이 바로 multi-task 러닝의 힘입니다.

76
00:05:26,716 --> 00:05:28,127
또 다른 상세 내용으로는, 

77
00:05:28,127 --> 00:05:33,440
이제까지는 알고리즘이 각각의 이미지가 모든 레이블을 
포함한 것처럼 설명했지만, 

78
00:05:33,440 --> 00:05:37,754
multi-task 러닝은 어떤 이미지가 

79
00:05:37,754 --> 00:05:39,452
일부 물체만 레이블하더라고 잘 구현됩니다.

80
00:05:39,452 --> 00:05:43,078
첫번째 트레이닝 example에서, 
어떤 사람이, 레이블하는 사람이 

81
00:05:43,078 --> 00:05:46,214
보행자가 있다고 알려주고, 차량은 없는데

82
00:05:46,214 --> 00:05:49,072
stop sign과 신호등의 유무여부는 
귀찮아서 레이블하지 않았다고 해보겠습니다.

83
00:05:49,072 --> 00:05:52,691
두번째 예제에서는, 보행자가 있고, 차량이 있는데,

84
00:05:52,691 --> 00:05:56,479
첫번째와 마찬가지로, 레이블하는 사람이 
이미지를 보았음에도, 

85
00:05:56,479 --> 00:05:59,790
stop sign이 있는지, 신호등이 있는지 등등의 정보를
레이블하지 않았다고 해보겠습니다.

86
00:05:59,790 --> 00:06:03,153
또 다른 예제에서는 완전히 레이블 처리 되었을 수 있겠죠. 

87
00:06:03,153 --> 00:06:06,117
또 다른 예제에서는, 차량에 대한 유무여부만

88
00:06:06,117 --> 00:06:08,858
레이블해서 물음표가 있는 경우도 있겠죠. 

89
00:06:08,858 --> 00:06:13,050
이런 데이터의 경우엔, 어떤 이미지들이

90
00:06:13,050 --> 00:06:16,870
일부 레이블밖에 없는 경우에도, 

91
00:06:16,870 --> 00:06:21,300
나머지 레이블은 물음표이거나 신경 안쓰는 
레이블이라더라도 알고리즘을 트레이닝 시킬 수 있습니다.

92
00:06:21,300 --> 00:06:24,808
알고리즘을 트레이닝 시키는 방식은, 

93
00:06:24,808 --> 00:06:29,520
이런 일부의 레이블이 의문점을 갖게하는 것이더라도

94
00:06:29,520 --> 00:06:34,669
또는 레이블이 전혀 안 되었더라도
여기 j값이 1에서 4인 경우,

95
00:06:34,669 --> 00:06:39,730
합이 j의 값이 0 또는 1의 레이블을 갖는 것만
합니다. 

96
00:06:41,354 --> 00:06:46,850
그러므로 물음표가 있는 경우엔, 
이 합에서 해당 항을 제외하고 

97
00:06:46,850 --> 00:06:51,480
레이블이 있는 것만 더합니다.

98
00:06:51,480 --> 00:06:54,720
그러면 이러한 데이터세트도 이용할 수 있게 해줍니다.

99
00:06:54,720 --> 00:06:57,390
그럼 언제 multi-task 러닝이 말이 될까요?

100
00:06:57,390 --> 00:06:59,471
그럼 언제 multi-task 러닝이 말이 될까요?

101
00:06:59,471 --> 00:07:03,550
3가지 경우가 성립할 때, 말이 된다고 봅니다.

102
00:07:03,550 --> 00:07:06,400
첫번째로는, shared low-level features로부터

103
00:07:06,400 --> 00:07:08,470
이득을 볼 수 있는 업무들을 트레이닝 시킬때,

104
00:07:08,470 --> 00:07:13,155
자율주행차 같은 경우엔, 신호등,보행자, 

105
00:07:13,155 --> 00:07:16,980
차량을 인식하는 것이 

106
00:07:16,980 --> 00:07:21,653
stop sign과 같은 것을 인식하는 것에 도움을 줄 수 있는 
특성과 비슷할 것입니다. 이것들은 모두 도로의 특성을 가지고 있기 때문입니다.

107
00:07:23,120 --> 00:07:28,032
두번째로, 필수 규칙은 아닌데요, 이것이 항상 옳지는 않습니다.

108
00:07:28,032 --> 00:07:31,757
제가 보는 여러개의 성공적인 milti-task 러닝
환경에서는 

109
00:07:31,757 --> 00:07:35,310
각가의 업무에 있는 데이터량은 
서로 비슷합니다.

110
00:07:35,310 --> 00:07:39,480
transfer learning에서 봤듯이, 
업무 A에서 배우고 

111
00:07:39,480 --> 00:07:41,930
업무 B로 넘기는데요, 

112
00:07:41,930 --> 00:07:46,891
만약 백만개의 A업무 example이 있고,

113
00:07:46,891 --> 00:07:51,611
1000개의 B업무 example이 있으면, 
여기 백만개의 예제에서 배운 

114
00:07:51,611 --> 00:07:56,430
지식이 훨씬 더 작은 B 업무의 데이터세트를 
증가시키는데 도움을 줄 수 있습니다.

115
00:07:56,430 --> 00:07:58,652
그러면 multi-task 러닝은 어떨까요?

116
00:07:58,652 --> 00:08:01,520
multi-task 러닝의 경우에는, 
보통 2대의 업무보다 더 많이 있습니다.

117
00:08:01,520 --> 00:08:07,678
그러면 이전에는 4개의 업무가 있었는데, 
이제 100개의 업무가 있다고 해보겠습니다.

118
00:08:07,678 --> 00:08:11,452
그리고나서 multi-task 러닝을 진행해서
100개의 다른 물체를 한번에

119
00:08:11,452 --> 00:08:12,580
인식하려고 합니다.

120
00:08:12,580 --> 00:08:17,444
이런 경우, 
한 업무당 1000개의 example이 있을 수 있기 때문에,

121
00:08:17,444 --> 00:08:20,660
하나의 업무 성능에만 집중하는 경우,

122
00:08:20,660 --> 00:08:25,775
100번째 업무에 한번 중점을 두겠습니다.
이것은 A100이라고 부르겠습니다.

123
00:08:25,775 --> 00:08:28,899
이런 최종 업무를 분리시켜 수행하려고 하면,

124
00:08:28,899 --> 00:08:32,875
이 한가지의 업무를 트레이닝 시키기 위해
1000개의 example만이 있었을 것입니다.

125
00:08:32,875 --> 00:08:37,320
이것은 100개의 업무고, 
99개의 다른 업무를 트레이닝 시킴으로꺼 나왔을 것입니다.

126
00:08:37,320 --> 00:08:42,810
이것들의 합계는 99,000개의 트레이닝 example 들로
큰 부스트 효과가 있습니다.

127
00:08:42,810 --> 00:08:46,597
그리고, 이런 비교적 작은 1000개의

128
00:08:46,597 --> 00:08:52,040
샘플을 가지고 있는 A100 업무에서 
많은 지식을 제공함으로써 증가시킬 수 있습니다.

129
00:08:52,040 --> 00:08:57,080
그리고 시스템적으로 또 다른 99개의 다른 업무들이
어떠한 데이터를 제공하거나

130
00:08:57,080 --> 00:09:01,197
지식을 제공하여 100개의 업무에게 
도움을 줄 수 있습니다.

131
00:09:02,640 --> 00:09:07,940
그렇기 때문에 두번째 부분에 대한 부분은 
엄격한 규칙이 적용되는 것은 아니지만, 

132
00:09:07,940 --> 00:09:13,150
제가 보는 것은, 어떤 업무에 집중할 때,
이것이 multi-task 러닝에서 부스트 효과가 있으려면,

133
00:09:13,150 --> 00:09:17,260
다른 업무의 총 데이터 합산 양이
다른 업무에 비해 

134
00:09:17,260 --> 00:09:18,220
훨씬 더 많아야 한다는 것입니다.

135
00:09:18,220 --> 00:09:22,730
이것을 만족시킬 수 있는 방법은
이런 오른쪽과 같은

136
00:09:22,730 --> 00:09:27,030
example에서의 경우, 그리고 각각의 업무에서의
데이터량이 비슷한 경우,

137
00:09:27,030 --> 00:09:31,558
정말로 중요한 것은, 만약 이미 1000개의 example이 
하나의 업무에서 있다고 하면,

138
00:09:31,558 --> 00:09:36,360
다른 모든 업무에서는 1000개보다 훨씬 더 많아야 할
것입니다.

139
00:09:36,360 --> 00:09:40,565
이 마지막 업무에서 성능이 잘 발휘될 수 있게
도와주려면 말이죠. 

140
00:09:40,565 --> 00:09:44,521
마지막으로 multi-task 러닝에은

141
00:09:44,521 --> 00:09:47,640
업무에서 잘 할 수 있도록 큰 신경망을 트레이닝 시키는 경우에
더 잘 되는 편입니다.

142
00:09:47,640 --> 00:09:50,259
그렇기 때문에 multi-task 러닝의 대안은

143
00:09:50,259 --> 00:09:52,767
각각의 업무에 대해서 개별적으로 신경망을 트레이닝 시키는 것입니다.

144
00:09:52,767 --> 00:09:56,084
보행자,차량,stop sign, 그리고 신호등 감지에 관해 

145
00:09:56,084 --> 00:09:59,017
1개의 신경망을 트레이닝 시키는 대신에, 

146
00:09:59,017 --> 00:10:02,528
개별적으로 보행자에 대해 1개 신경망을 트레이닝 시키고,
또 다른 망으로 챠량을 트레이닝 시키고, 

147
00:10:02,528 --> 00:10:05,630
stop sign을 트레이닝 시키고, 또 개별적인 망에서 
신호등을 트레이닝 시킵니다.

148
00:10:06,640 --> 00:10:10,895
그리하여 Rich Carona라는 리서치 연구원이 발견한 것은

149
00:10:10,895 --> 00:10:14,920
개별적으로 신경망을 트레이닝 시키는 것보다

150
00:10:14,920 --> 00:10:18,590
multi-task 러닝이 성능에 효과적이지 못한 부분은
신경망 네트워크가 충분히 크지 못한 경우입니다.

151
00:10:18,590 --> 00:10:22,898
하지만 충분히 큰 신경망을 트레이닝 시킬 수 있는 경우, 
multi-task 러닝이

152
00:10:22,898 --> 00:10:26,476
성능을 저하시키는 경우가 거의 없을 것입니다.

153
00:10:26,476 --> 00:10:29,405
바라건대, 이런 다른 업무들을 

154
00:10:29,405 --> 00:10:33,640
따로 신경망에서 트레이닝 시키는 것보다 
성능을 증가시키는 것에 도움을 줄 것입니다.

155
00:10:33,640 --> 00:10:35,860
이것이 멀티태스크 러닝에 대한 모든 내용인데요, 

156
00:10:35,860 --> 00:10:40,410
실제로는, multi-task 러닝이 
transfer 러닝보다는 훨씬 더 적게 쓰입니다.

157
00:10:40,410 --> 00:10:43,450
저는 transfer learning이 데이터량이 적은데서

158
00:10:43,450 --> 00:10:46,150
문제를 해결하기 위해 많이 어플에서 쓰이는 경우를
자주 봅니다.

159
00:10:46,150 --> 00:10:49,580
그러므로 관련된 문제에서 많은 양의 데이터가 
있는 경우, 

160
00:10:49,580 --> 00:10:51,802
그 내용을 배우고, 새로운 문제에 transfer를 시킵니다.

161
00:10:51,802 --> 00:10:56,084
그러나 multi-task 러닝은 여러분이 잘하고 싶어하는 

162
00:10:56,084 --> 00:10:57,820
업무의 양이 굉장히 큰 경우가 더 드뭅니다.

163
00:10:57,820 --> 00:11:00,390
그 모든 업무를 한번에 트레이닝 시킬 수 있습니다.

164
00:11:00,390 --> 00:11:02,254
computer vision이 그 예가 될 수 있겠죠. 

165
00:11:02,254 --> 00:11:05,778
물체 감지 분야에서, 
신경망이 많은 여러가지 물체를 한번에 

166
00:11:05,778 --> 00:11:09,533
감지하려고 하는 multi-task 어플을 봅니다

167
00:11:09,533 --> 00:11:13,700
이 경우, 물체를 감지하는데 있어, 따로 신경망을 트레이닝 시키는 것보다
더 잘 작동합니다.

168
00:11:13,700 --> 00:11:17,870
하지만 평균적으로, transfer learning이 오늘날
더 많이 쓰입니다.

169
00:11:17,870 --> 00:11:22,610
하지만 이 2개의 방법 모두 여러분이 쓸 수 있는 
도구들입니다.

170
00:11:22,610 --> 00:11:23,685
요약하자면, 

171
00:11:23,685 --> 00:11:28,270
multi-task 러닝은 여러분이 1개의 신경망이 
여러업무를 처리할 수 있도록 해줍니다.

172
00:11:28,270 --> 00:11:32,630
그리고 이러한 특성은 따로 업무를 진행하는 것보다 여러분이 더 좋은 성능을 
가질 수 있도록 해줍니다.

173
00:11:32,630 --> 00:11:37,410
주의하실 사항이 있는데요, 실제로는

174
00:11:37,410 --> 00:11:39,790
transfer learning 이 multi-task learning보다 더 자주 쓰이는 것을 
보실 것입니다.

175
00:11:39,790 --> 00:11:43,262
저는 그래서, 머신 러닝 문제를 풀고 싶은 경우에, 

176
00:11:43,262 --> 00:11:47,197
비교적 데이터세트의 크기가 작은 경우, 
transfer learning이 큰 도움을 줄 것이라 생각합니다.

177
00:11:47,197 --> 00:11:50,172
데이터세트 크기가 훨씬 더 큰 문제를 찾으면

178
00:11:50,172 --> 00:11:52,290
그 시점에서부터 신경망에서 트레이닝 시킬 수 있습니다.

179
00:11:52,290 --> 00:11:54,830
그 다음에 데이터량이 적은 문제로 transfer 시킬 수 있죠. 

180
00:11:54,830 --> 00:11:57,460
결론적으로 transfer learning은 오늘날 매우 자주 쓰입니다.

181
00:11:57,460 --> 00:12:01,785
어떤 어플에서는 transfer multi-task learning이 
쓰이는 경우도 있는데요, 

182
00:12:01,785 --> 00:12:05,730
제 생각에는 multi-task learning 은
transfer learning보다는 훨씬 덜 쓰이긴 합니다.

183
00:12:05,730 --> 00:12:09,230
예외적인 분야는 computer vision object detection인데요,

184
00:12:09,230 --> 00:12:12,180
여기서는 많은 수의 다른 물체들을 감지하는데

185
00:12:12,180 --> 00:12:13,980
신경망을 트레이닝 시키는 경우입니다.

186
00:12:13,980 --> 00:12:16,660
이런 경우에는, 신경망을 개별적으로 트레이닝 시키는 것보다

187
00:12:16,660 --> 00:12:18,150
더 잘 작동합니다.

188
00:12:18,150 --> 00:12:21,385
하지만 평균적으로 
transfer learning 과 

189
00:12:21,385 --> 00:12:26,130
multi-task learning 은 비슷하게 보여지는 경우가 
많을텐데요, 

190
00:12:26,130 --> 00:12:30,130
실제로는 multi-task learning보다 
transfer learning의 적용사례를 훨씬 더 많이 봤습니다. 

191
00:12:30,130 --> 00:12:34,250
제 생각에는 각각의 다른 업무들을 일일히

192
00:12:34,250 --> 00:12:37,120
세팅하거나 찾는 일이 굉장히 어렵기 때문에 그런 것 같습니다.

193
00:12:37,120 --> 00:12:39,050
다시 말씀드리지만, computer vision에서는

194
00:12:39,050 --> 00:12:43,000
물체 감지 예제가 가장 두드러지는 예외 적용 사례입니다.

195
00:12:43,000 --> 00:12:45,465
멀티태스크 러닝에 대한 내용은 이것으로 모두 마쳤는데요.

196
00:12:45,465 --> 00:12:46,310
여러분이 사용할 수 있는 것들 중, 

197
00:12:46,310 --> 00:12:50,350
멀티태스크 러닝과 transfer 러닝은 모두
중요한 도구입니다.

198
00:12:50,350 --> 00:12:54,730
마지막으로, end-to-end 딥러닝에 대해 
이야기하고 싶은데요.

199
00:12:54,730 --> 00:12:57,620
그러면 다음 비디오로 넘어가서, 
end-to-end에 대한 내용을 다루도록 하겠습니다.