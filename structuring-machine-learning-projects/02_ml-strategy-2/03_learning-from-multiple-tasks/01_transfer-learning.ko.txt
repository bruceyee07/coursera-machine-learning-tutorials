딥러닝의 강력한 아이디어 중 한가지는 한가지 업무에서 배운 지식을 또 다른 업무에 적용시킬 수 있다는 것입니다. 예를 들어서, 신경망 네트워크가 고양이와 같은 것을 인식할 수 있도록 러니시킬 수 있고, 그 지식을 이용해서 부분적으로 x-ray 스캔을 읽는데 도움이 될 수 있도록 만들 수 있습니다. 이것을 바로 트렌스퍼 러닝이라고 압니다. 한번 보겠습니다. 이미지 인식기능을 신경망네트워크에 트레이닝시켰다고 해봅시다. 일단 먼저 신경망을 갖고, X와 Y 쌍에 트레이닝 시킵니다. X는 이미지이고, Y는 목적 대상입니다. 이미지는 고양이나 강아지, 새 또는 다른 것이 될 수 있을텐데요 이 신경망 네트워크를 이용해서 조정을 하거나 또는 트랜스퍼 한다고 표현하는데요, 다른 업무들을 통해서 습득한 것들이, 방사선학 진단같은 것들이, X-ray 스캔을 읽는 것인데요, 신경망 네트워크의 마지막 결과값 층인 이 부분을 가지고, 이것은 삭제하구요, 이 마지막 결과값 층에 fedding하는 이 weight들도 삭제합니다. 그런 뒤에, 마직막 층을 위한 무작위로 초기화된 weight 세트를 생성합니다. 이렇게 생성한 것들이 방사선학 진단을 결과값으로 표출할 수 있게 하는 것이죠. 구체적으로 말씀드리자면, 트레이닝 첫번째 단계에서 이미지 인식 업무 관련한 내용을 트레이닝 시키는 경우, 익숙한 신경망 parameter들을 트레이닝 시키는데요. 모든 weight와 모든 층을 트레이닝 시키면 이렇게 이미지를 인식하고 예측하는 프로그램과 같은 것도 생기는 것입니다. 이런 신경망을 트레이닝한 경우, 이제 트렌스퍼 러닝을 도입하기 위해서 데이터세트 X와 Y에서 스왑을 진행합니다. 이것은 이제 그러면 방사선 이미지인데요. Y는 예측하고 싶은 진단에 대한 부분인데요. 여기서 해야하는 부분은 바로 마지막 층의 weight를 초기화시키는 것입니다. 이것을 W.L이라고 하겠습니다. 그리고 P.L이라고 랜덤으로 이야기 하겠습니다. 이제 새로운 데이터세트에서 신경망을 다시 트레이닝 시키는데요, 새로운 방사선학 데이터세트에서 말이죠. 신경망을 방사선학 데이터로 재차 트레이닝 시키는 방법이 몇 가지 있는데요. 만약에 작은 양의 방사선학 데이터세트가 있는 경우, 마지막 층의 weight만 다시 트레이닝 시킬 수 있습니다. W.L.P.L만 말이죠. 그리고 나머지 매개 변수는 고정시키는 것입니다. 데이터가 충분히 있는 경우, 나머지 신경망에 대한 부분도 모든 층을 다시 트레이닝 시킬 수 있습니다. 경험에 의거한 규칙은, 데이터세트의 크기가 작은 경우, 결과값 층에서 마지막 층만 retrain 시킵니다. 마지막 층 또는 마지막 2개의 층을 말이죠. 하지만 만약 데이터가 많은 경우, 네트워크에서 있는 모든 매개 변수를 다시 트레이닝 시킬 수 있습니다. 모든 신경망의 매개 변수를 다시 크레이닝 시키는 경우에는, 이러한 이미지 인식 기능에 대한 첫번째 단계의 트레이닝을 pre-training이라고 부릅니다. 신경망의 weight 비중을 pre-initialize나 pre-train 하기 위해 이미지 인식 데이터를 쓰기 때문에 그렇습니다. 그리고 weight를 나중에 업데이트 하는 경우, 방사선학 데이터에 트레이닝 시키는 것은 가끔 fine tuning이라고도 합니다. pre-training 이나 fine tuning 이라는 용어는 딥러닝 분야에서 들으실 경우가 있을텐데요, 트렌스퍼 러닝 소스에서 이야기하는 pre-training이나 fine tuning에 대한 내용을 논하는 겨우, 이런 뜻이라고 생각하시면 됩니다. 이 example에서 한 것은, 이미지 인석 기능에서 습득한 지식을 방사선학 진단하는데 적용 또는 진단법에 그 지식을 트렌스퍼 시킨 것입니다. 이것이 도움을 줄 수 있는 이유는, edges를 감지하는 특성, 커브 감지, poitive object를 감지하는 특성들과 같이 수 많은 low level 특성 때문입니다. 이러한 아주 큰 이미지 인식 데이터세트에서 내용을 익히는 것이, 러닝 알고리즘이 방사선학 진단에 도움이 되도록 해줄 것입니다. 이미지의 구조가 어떻게 되는지, 이미지가 어떻게 생겼는지에 대해 많이 익힌 지식 내용이 유용할 수 있습니다. 이제 이미지를 인식하는 방법을 배웠으니, 충분히 배웠을수 도 있습니다. 이미지들의 어느 부분이 다른지 분간하는 방법을 말이죠. 즉, 이미지에서의 라인에 대한 지식, 점들, 커브들, 등등 말이죠. 또는 물체들의 특정 작은 부분들을 알아서 이런 지식들은 여러분의 네트워크가 방사선학적 판단을 내리는데 더 적은 데이터로도 
판단을 내릴 수 있게 도와줄 것입니다.
또 다른 예제를 보겠습니다. 또 하나의 예제를 보도록 합시다. 여러분이 음성인식 시스템을 트레이닝 했다고 해보겠습니다. 그러면 이제 X는 오디오의 입력값 또는 오디오 단편입니다. Y는 어떤 ink 기록이구요 그러면 여러분은 음성인식 시스템을 통해 transcript를 결과값으로 만듭니다. 이제 여러분은 "wake word" 또는 "trigger word" 를 감지하는 시스템을 만들고 싶다고 해보겠습니다. 이전에 말씀드렸지만, wake word 또는 trigger word는 음성인식기기를 깨우기 위해 또는 작동시키기 위해 말하는 단어입니다. 예를 들어, Amazon Echo를 작동시키기 위한 "Alexa"라는 단어, 또는 
구글을 깨우기 위한 "OK Google" 이라는 단어, 또는 애플 기기를 깨우기 위한 "hey siri" 또는 바이두 기기를 깨우기 위한
"ni hao Baidu" 와 같은 단어가 이에 해당합니다. 이렇게 만들기 위해서는, 신경망 네트워크의 마지막 층을 꺼내서 새로운 결과값 노드를 만들어야 할 것입니다. 가끔씩 또 할 수 있는 방법은, 1가지 새로운 결과값을 생성하는 것이 아니라, 여러개의 새로운 층을 신경망에서 생성시키는 것입니다. Y 레이블을 wake word 감지 문제에 적용시키기 위해서 말이죠. 여러분이 얼마나 많은 데이터를 보유하고 있는지에 따라, 네트워크의 새로운 층을 다시 트레이닝 시키거나, 또는 신경망의 층들을 더 많이 트레이닝 시키는 방법도 있습니다. 그러면 언제 transfer learning이 말이 되는 것일까요? transfer learning이 말이 되는 경우는, 여러분이 전송하려고 하는 곳의 대이터가 많고, 전송하는 곳의 문제 관련 데이터가 적은 경우 좋습니다. 예를 들어, 음성 인식 업무를 위한 백만개의 예제가 있다고 가정하겠습니다. low level 특성을 배우기 위한, 또는 초반 신경망 네트워크 층에서 유용한 특성들 배우기 위한 많은 양의 데이터인데요, 하지만 방사선학 업무로는, 100개의 샘플만 있을수도 있습니다. 방사선학 진단 문제는 아주 적은 데이터가 있는 것이죠, 100 개의 x-ray 사진 정도요. 그러면 이미지 인식기능에서 배우는 지식들이 이관되어서 방사선학 인식에 이관되어 쓰이면 방사선학 부문에서 많은 데이터가 없더라도 도움이 될 수 있도록 해줄 수 있겠죠. 음성인식 기능으로는, 여러분이 음성인식기능을 트레이닝하는데 10000 시간을 데이터 트레이닝하는데
소비했을 수 있습니다. 그러면, 여러분은 인간이 어떤 유형의 소리를 갖는지 10000시간의 데이터 트레이닝을 통해 익숙해져 있을 수 있는데요. 
긴 시간입니다. 하지만 trigger word 감지 기능에서는, 1시간 분량의 데이터만 있을 수 있습니다 해당 시간은 많은 양의 parameter 넣기에는 불충분한 시간입니다. 이 경우, 인간음석인식에서 인간이 어떻게 들리는지 배우는 많은 부분이, 인간의 음성 스피치 구성요소와 관련하여 말이죠, 이런 내용이 훌륭한 wake word 감지 기능을 만드는데 도움을 줄 수 있습니다. 데이터세트가 작더라도 말이죠. 또는 적어도 wake word감지 업무로는 작은 데이터세트인 경우에 말이죠. 이 2가지의 경우, 많은 데이터를 보유하고 있는 문제에서 적은 데이터를 가지고 있는 문제로 transfer 시키는 것입니다. transfer learning을 하는 것이 말이 안되는 케이스는 바로 반대가 성립하는 경우입니다. 만약 여러분이 이미지 인식 분야에서 100개의 사진을 가지고 있고, 방사선학 진단 부문에서 100개의 이미지 또는 1000개의 이미지가 있으면, 생각할 수 있는 것은, 방사선학 진단 부문에서 잘하기 위해서는, 여러분이 방사선학 진단에서 잘하는 것이 고양이와 고양이 이미지를 갖는 것보다 훨씬 더 중요하다는 가정하에 말이죠. 그렇기 때문에 여기서 각각의 example이 저기 각각의 example보다 더 중요한 것입니다. 적어도 훌륭한 방사선 시스템을 만드는 명목에서는 말이죠. 그러므로 여러분이 이미 방사선학 관련 데이터가 더 많은 경우, 100개의 임의 물체의 사진,고양이,강아지 등의 사진을 갖는 것은 도움이 별로 되지 않을 것입니다. 그 이유는 고양이와 강아지 이미지 인식 업무에서 온 1가지의 이미지 샘플이 x -ray 이미지의 샘플보다 덜 값지기 때문입니다. 좋은 방사선학 시스템을 만드는데 있어서 말이죠. 이것이 transfer learning이, 물론 써서 나쁠 것은 없지만, 그다지 의미있는 결과를 주지 않는 하나의 사례입니다. 이와 비슷하게, 10시간 분량의 데이터로 음성인식 시스템을 만들었고, 실제로 10시간 보다 더 많은, 예를 들어, 50시간 분량의 데이터가 wake word 감지 부분에서 있다고 하면, 그럴수도 있고, 안 그럴수도 있지만, 해당 10시간의 데이터를 transfer learning 에 추가하는 것은 아마 그리 나쁠 것은
없을 것입니다. 하지만 그렇다고 의미있는 결과를 주는 것도 아닐 것입니다. 요약하자면, 언제 transfer learning을 쓰는 것이 말이 될까요? 만약 여러분이 A업무에서 배우고 그 배운 특정 지식을 B업무로 넘기려고하면, transfer learning을 사용하는 것이 말이 될 수 있죠, A업무와 B업무가 
똑같은 입력값 x로 되어있을 경우 말이죠. 첫번째 예제에서는, A와 B모두 입력값으로 이미지가 있습니다. 두번째로는 예제는, 2개 모두 오디오 영상이 입력값으로 있습니다. 업무 A의 데이터가 업무 B의 데이터보다 훨씬 더 많은 경우 말이 될텐데요. 이러한 모든 것은, B업무에서 더 잘하고 싶어한다는 가정하에 성립됩니다. B업무의 데이터가 B업무에게는 더 중요하기 때문에, 보통은 A업무의 데이터가 훨씬 더 많아야 합니다. 그 이유는 각각의 A업무 샘플이 B업무 샘플보다 덜 값지기 때문입니다. 마지막으로, transfer learning이 조금 더 말이 되는 경우는, 여러분이 A업무의 low level 틀성들이 B업무를 배우는데 도움이 될 수 있다 판단되는 경우입니다. 이전의 2가지 예제에서는, 이미지 인식 부분을 배우는 것이 이미지에 대해 충분히 학습시켜줘서 방사선학 판단에 도움을 줄 수도 있습니다. 그리고 음성인식을 배우는 것이, 인간 음성에 대한 내용을 배우게 하여, trigger word 나 wake word를 감지하는데 도움을 줄 수도 있습니다. 요약하자면, transfer learning은 특정 B라고 하는 업무를 잘 하려고 할 때 가장 도움이 되었습니다. 이런 B업무는 보통 데이터가 많이 없는 경우인데요. 예를 들어, 방사선학에서는 많은 양의 x-ray 이미지를 수집하기가 어렵습니다. 좋은 방사선 판단 시스템을 만들기 위해 말이죠. 이런 경우, 관련된 약간은 다른 업무를 찾을 수 있습니다. 이미지 인식 기능 과 같은 분야 말이죠. 이 분야에서 백만개의 이미지를 가지고와서 여러 특성들을 배울 수 있겠죠. 그렇게 배운 이후에, B업무에서 잘하려고 할 수 있겠죠. 방사선학 업무에서 말이죠. 데이터가 많이 없어도요. transfer learning이 말이 되는 경우에는, 여러분의 러닝 학습 업무의 성능을 상당히 많이 향상시켜줍니다. 하지만 저는 transfer learning이 B업무의 데이터 양과 비교하여 A업무가 더 적은 데이터를 보유하고 있는 경우에 사용된 적을 가끔 보았는데요, 이런 경우 이득이 될 것을 기대하지 않습니다. 자 그럼 트렌스퍼 러닝에 대한 부분은 여기까지인데요, 하나의 작업에서 러닝을 진행 후, 다른 작업으로 넘기는 것을 보았습니다. 또 다른 러닝의 유형이 있는데요, 멀티태스크 러닝이라는 복수의 작업에서 러닝을 진행하는 방식입니다. 한가지의 작업에서 러닝을 진행하는 것이 아니라 다수의 작업들을 동시에 러닝하여, 결과적으로 다른 작업으로 이관하는 것입니다. 다음 비디오에서는 멀티태스킹 러닝에 대해 토론해보겠습니다.