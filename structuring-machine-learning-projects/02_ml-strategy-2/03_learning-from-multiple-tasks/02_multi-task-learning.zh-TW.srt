1
00:00:00,330 --> 00:00:03,705
在轉移學習時，
您有一種依序的步驟

2
00:00:03,705 --> 00:00:07,162
您從任務Ａ學習，
然後轉移到任務Ｂ

3
00:00:07,162 --> 00:00:10,520
在多工任務學習裡，
您同時開始

4
00:00:10,520 --> 00:00:13,650
試著用一個神經網路，
同時一次做許多事情

5
00:00:13,650 --> 00:00:17,520
然後每一個任務，
希望都能幫助到其他的任務

6
00:00:17,520 --> 00:00:18,480
讓我們看另一個例子

7
00:00:20,110 --> 00:00:24,140
假設您建立一個自動駕駛車輛，
建立一個自駕車

8
00:00:24,140 --> 00:00:28,969
那您的自駕車需要偵測許多不同的東西

9
00:00:28,969 --> 00:00:34,164
像是行人，偵測其他車輛，
偵測停車標誌

10
00:00:37,312 --> 00:00:42,410
也要能偵測紅綠燈，
跟其他東西

11
00:00:43,670 --> 00:00:47,330
舉個例子，在左邊這個例子，
有一個停止標誌在影像中

12
00:00:47,330 --> 00:00:53,510
有一輛車在影像中，
但是沒有行人或者紅綠燈

13
00:00:53,510 --> 00:00:58,200
所以如果這個影像，舉個例子 X(i)

14
00:00:58,200 --> 00:01:02,770
那與其有一個標籤 Y(i), 
您其實有四個標籤

15
00:01:02,770 --> 00:01:05,640
在這個例子，沒有行人，有車子

16
00:01:05,640 --> 00:01:08,850
有一個停止標誌，
沒有紅綠燈

17
00:01:08,850 --> 00:01:10,580
而如果您試著偵測其他事

18
00:01:10,580 --> 00:01:12,634
或許 Y(i) 有更多維度

19
00:01:12,634 --> 00:01:14,385
但現在，讓我們只用四個

20
00:01:14,385 --> 00:01:18,013
所以 y(i) 是一個 4 乘 1 向量

21
00:01:18,013 --> 00:01:22,444
而如果您看整個訓練集

22
00:01:22,444 --> 00:01:27,370
類似之前，我們會將訓練資料的標籤

23
00:01:27,370 --> 00:01:32,116
水平疊起來像是，
y(1) 到 y(m)

24
00:01:32,116 --> 00:01:39,470
除了現在 y(i) 是 4乘1 向量，
每個都是高的列向量

25
00:01:39,470 --> 00:01:45,530
所以這個矩陣 Ｙ 現在是
 4 乘 m 的矩陣，而之前

26
00:01:45,530 --> 00:01:49,810
當 y 是一個實數，所以
會是一個 1 乘 m 矩陣

27
00:01:49,810 --> 00:01:55,122
您現在可以做的是
訓練神經網路來預測 Y 的值

28
00:01:55,122 --> 00:01:57,828
所以您可以有一個神經網路輸入 Ｘ

29
00:01:57,828 --> 00:02:00,970
輸出現在是 4 維度的 Ｙ 值

30
00:02:00,970 --> 00:02:04,590
請注意這裡的輸出
我畫了四個節點

31
00:02:04,590 --> 00:02:09,000
所以第一個節點我們
試著預測是否有行人

32
00:02:09,000 --> 00:02:10,610
在這個影像中

33
00:02:10,610 --> 00:02:13,470
第二個節點會預測
是否有其他車輛

34
00:02:13,470 --> 00:02:18,870
預測是否有停止標誌，
這會預測是否有紅綠燈

35
00:02:20,850 --> 00:02:23,950
所以這裡  y-hat 有四維度

36
00:02:26,110 --> 00:02:30,575
所以訓練這個神經網路，您現在需要定義

37
00:02:30,575 --> 00:02:32,029
神經網路的損失函數

38
00:02:32,029 --> 00:02:39,190
所以給予一個預測輸出 y-hat，是4乘1維度

39
00:02:39,190 --> 00:02:43,939
在您整個訓練集的平均損失

40
00:02:43,939 --> 00:02:48,209
會是 1 除以 m，總和從 i = 1 到 m

41
00:02:48,209 --> 00:02:55,349
總和從 j=1 到 4 的每一個
單獨的預測的損失

42
00:02:59,030 --> 00:03:03,256
所以就只是總和四個元件的行人，車子，停止標誌

43
00:03:03,256 --> 00:03:04,253
跟紅綠燈

44
00:03:04,253 --> 00:03:11,462
而這個花體的 Ｌ是
一般的羅吉斯損失

45
00:03:14,493 --> 00:03:19,404
將它直接寫下來

46
00:03:19,404 --> 00:03:24,314
這是 - y_ji log y-hat_ji

47
00:03:24,314 --> 00:03:28,349
(1 - y_ji) log (1 - y-hat_ji)

48
00:03:31,706 --> 00:03:36,018
而跟先前二元分類法
最主要不同是

49
00:03:36,018 --> 00:03:38,760
您現在要總和 J 等於 1 到 4

50
00:03:40,570 --> 00:03:45,260
而跟 softmax 迴歸分析最主要的不同是

51
00:03:45,260 --> 00:03:50,550
不像 softmax 迴歸分析要
指派一個標籤給每一個例子

52
00:03:50,550 --> 00:03:53,370
這一個影像可以有多重的標籤

53
00:03:55,350 --> 00:04:00,162
所以您並不是說每一個影像
要不是行人，

54
00:04:00,162 --> 00:04:04,780
就是一輛車，一個停止標誌的圖像
，一個紅綠燈的影像

55
00:04:04,780 --> 00:04:09,010
您問的是每一張影像裡，
有沒有行人，車子，停止標誌

56
00:04:09,010 --> 00:04:11,860
或者紅綠燈，多重物件
可以同時出現在同一個影像上

57
00:04:11,860 --> 00:04:16,390
實際上，在前面的投影片中，我們同時有車子跟

58
00:04:16,390 --> 00:04:19,400
停止標誌在影像中，
但是沒有行人跟紅綠燈

59
00:04:19,400 --> 00:04:22,580
所以您並不指派一個
單一標籤給一個影像

60
00:04:22,580 --> 00:04:25,800
您要透過不同的類別來問

61
00:04:25,800 --> 00:04:29,573
每一個類別，這個類別，有這種型態的物件
出現在影像中嗎？

62
00:04:31,420 --> 00:04:34,839
所以這是我說的，在這種設定下

63
00:04:34,839 --> 00:04:37,313
一張影像可以有多重標籤

64
00:04:37,313 --> 00:04:42,281
如果您訓練一個神經網路
來最小化這個成本函數

65
00:04:42,281 --> 00:04:45,920
您就是在進行多工任務學習

66
00:04:45,920 --> 00:04:50,823
因為您在建立一個
單一的神經網路看著

67
00:04:50,823 --> 00:04:53,860
每個影像，基本上解決四個問題

68
00:04:53,860 --> 00:04:58,910
它試著告訴您每張影像
是否有這四個物件在其中

69
00:05:00,250 --> 00:05:03,850
而另一種方式您可以做的是，
分別訓練四個的神經網路

70
00:05:03,850 --> 00:05:06,700
而非訓練一個網路來做四件事

71
00:05:06,700 --> 00:05:11,300
但如果一些在神經網路的早期特徵可以在

72
00:05:11,300 --> 00:05:13,790
不同的物件中分享的話，
那您會發現

73
00:05:13,790 --> 00:05:17,880
訓練一個神經網路來做四件事，結果比

74
00:05:17,880 --> 00:05:21,760
訓練四個完全分開的
神經網路來做這四件任務要好

75
00:05:23,040 --> 00:05:25,450
所以這是多工學習的力量

76
00:05:26,716 --> 00:05:28,127
還有一個細節

77
00:05:28,127 --> 00:05:33,440
至今我描述的演算法好像
每個影像都有一個單一標籤

78
00:05:33,440 --> 00:05:37,754
實際上，多工任務學習也可以
作用在即使一些影像

79
00:05:37,754 --> 00:05:39,452
我們只標籤一些物件

80
00:05:39,452 --> 00:05:43,078
所以在第一個訓練例子，
假設有人，您的標籤者告訴您

81
00:05:43,078 --> 00:05:46,214
有行人，沒有車子，
但他們不關心是否

82
00:05:46,214 --> 00:05:49,072
有停止標誌，或者是否有紅綠燈

83
00:05:49,072 --> 00:05:52,691
而或許在第二個例子，有行人，也有車子，但

84
00:05:52,691 --> 00:05:56,479
再一次，標籤者，他們看著這個影像，
他們並沒有將這些標籤標註

85
00:05:56,479 --> 00:05:59,790
是否有停止標誌，是否有紅綠燈等等

86
00:05:59,790 --> 00:06:03,153
或許一些例子全部都有標，或許一些例子

87
00:06:03,153 --> 00:06:06,117
他們只是標籤是否有車子

88
00:06:06,117 --> 00:06:08,858
所以有一些問號，等等

89
00:06:08,858 --> 00:06:13,050
所以用這樣的資料集，
您還是可以訓練您的學習演算法

90
00:06:13,050 --> 00:06:16,870
來一次做四件任務，
即使一些影像

91
00:06:16,870 --> 00:06:21,300
只是標籤的子集，
其他的是一些問號，或者不關心

92
00:06:21,300 --> 00:06:24,808
而您訓練您的
演算法的方式

93
00:06:24,808 --> 00:06:29,520
即使一些這樣的標籤
是問號或者

94
00:06:29,520 --> 00:06:34,669
真的未標籤，在總和從 J 從 1 到 4 時

95
00:06:34,669 --> 00:06:39,730
您會總和 j 在 0 或 1 的值

96
00:06:41,354 --> 00:06:46,850
所以當有問號時，
您只是在總和時忽略那一項

97
00:06:46,850 --> 00:06:51,480
只是總和那些有標籤部分的值

98
00:06:51,480 --> 00:06:54,720
所以這樣做
會讓您可以使用這個資料集

99
00:06:54,720 --> 00:06:57,390
所以何時使用多工學習有意義？

100
00:06:57,390 --> 00:06:59,471
所以何時使用多工學習有意義？

101
00:06:59,471 --> 00:07:03,550
我會說在以下三件事
為真時有意義

102
00:07:03,550 --> 00:07:06,400
一是如果您訓練
在一組任務上可以從

103
00:07:06,400 --> 00:07:08,470
分享低階特徵時有益

104
00:07:08,470 --> 00:07:13,155
所以對於自駕車例子而言，
是有意義的，它要辨識紅綠燈

105
00:07:13,155 --> 00:07:16,980
跟車子，行人，這些有類似的特徵

106
00:07:16,980 --> 00:07:21,653
可以幫助您辨識停止標誌，
因為這些都是路的特徵

107
00:07:23,120 --> 00:07:28,032
二，這比較不是硬性且快速的準則，
所以這並不一定永遠為真

108
00:07:28,032 --> 00:07:31,757
但我看過很多成功的
多工任務學習設定是

109
00:07:31,757 --> 00:07:35,310
每個任務的資料量
都很類似

110
00:07:35,310 --> 00:07:39,480
所以您記得在轉移學習時，
您從一些任務Ａ中學習

111
00:07:39,480 --> 00:07:41,930
轉移到任務Ｂ

112
00:07:41,930 --> 00:07:46,891
所以如果您有上百萬個例子在任務Ａ，
然後有 1,000 例子

113
00:07:46,891 --> 00:07:51,611
在任務Ｂ，那所有您從
百萬個例子學到的知識

114
00:07:51,611 --> 00:07:56,430
可以真的幫助您擴增在
任務Ｂ中小很多的資料集上

115
00:07:56,430 --> 00:07:58,652
多工任務學習呢？

116
00:07:58,652 --> 00:08:01,520
在多工任務學習中，
您通常有比兩個多的任務

117
00:08:01,520 --> 00:08:07,678
所以或許您有，之前是四個任務，
但假設您有 100 個任務

118
00:08:07,678 --> 00:08:11,452
而您試著做多工任務學習，
同時試著辨識 100 個不同

119
00:08:11,452 --> 00:08:12,580
型態的物件

120
00:08:12,580 --> 00:08:17,444
所以您或許會發現您或許
每個任務有 1,000 個例子

121
00:08:17,444 --> 00:08:20,660
如果您只關注
在一個任務的表現上

122
00:08:20,660 --> 00:08:25,775
讓我們只關注在第 100 個任務，
您稱之為 A100

123
00:08:25,775 --> 00:08:28,899
如果您試著單獨作
這個最終的任務

124
00:08:28,899 --> 00:08:32,875
您會只有 1,000 個例子
在訓練這個任務

125
00:08:32,875 --> 00:08:37,320
這個 100 個中間的一個任務，
但也使用其他 99 個任務做訓練的話

126
00:08:37,320 --> 00:08:42,810
這會總計有 99,000 個訓練例子，
這會有很大的促進

127
00:08:42,810 --> 00:08:46,597
可以給很多的知識來擴增這些

128
00:08:46,597 --> 00:08:52,040
相對小的 1,000 個例子
您用在任務 A100 的訓練集

129
00:08:52,040 --> 00:08:57,080
而對應其他 99 個任務，
也可以提供一些資料或者提供

130
00:08:57,080 --> 00:09:01,197
一些知識來幫助每一個其他任務，
在這100個清單中的任務

131
00:09:02,640 --> 00:09:07,940
第二點並不是一個硬性快速的準則，我試著這樣看

132
00:09:07,940 --> 00:09:13,150
如果您關注在任一個任務上，
要得到很大的進展

133
00:09:13,150 --> 00:09:17,260
其他任務總和下來
會是很大量的資料

134
00:09:17,260 --> 00:09:18,220
比起單一任務而言

135
00:09:18,220 --> 00:09:22,730
一個方式來滿足這一點，
如果很多的任務像我們

136
00:09:22,730 --> 00:09:27,030
在右邊這個例子，
如果您在每個任務的資料量類似

137
00:09:27,030 --> 00:09:31,558
但重點是如果您一個任務
已經有 1,000 個例子

138
00:09:31,558 --> 00:09:36,360
那其他的任務最好也會有
比 1,000 更多個例子

139
00:09:36,360 --> 00:09:40,565
那其他任務會幫助您在
最終任務上做得更好

140
00:09:40,565 --> 00:09:44,521
最後，多工任務學習傾向於有意義
當您可以訓練

141
00:09:44,521 --> 00:09:47,640
足夠大的神經網路來
在所有的任務上作用得很好

142
00:09:47,640 --> 00:09:50,259
所以多工任務學習
的另一種方式是

143
00:09:50,259 --> 00:09:52,767
在每個任務單獨
訓練神經網路

144
00:09:52,767 --> 00:09:56,084
所以與其訓練一個神經網路在
行人，車子，停止標誌跟

145
00:09:56,084 --> 00:09:59,017
紅綠燈的偵測，您可以訓練
一個神經網路對於

146
00:09:59,017 --> 00:10:02,528
行人偵測，一個神經網路做車子偵測，
一個神經網路

147
00:10:02,528 --> 00:10:05,630
做停止標誌偵測，
一個神經網路做紅綠燈偵測

148
00:10:06,640 --> 00:10:10,895
有一個研究人員，Rich Carona, 
多年前提出

149
00:10:10,895 --> 00:10:14,920
多工任務學習唯一會
傷害整體表現，比起

150
00:10:14,920 --> 00:10:18,590
單獨的神經網路而言是
如果您的神經網路不夠大

151
00:10:18,590 --> 00:10:22,898
但如果您可以訓練足夠大的神經網路，
那多工任務學習

152
00:10:22,898 --> 00:10:26,476
應該不會，或者
應該不至於傷害整體表現

153
00:10:26,476 --> 00:10:29,405
而希望會真的幫助性能，比起如果您

154
00:10:29,405 --> 00:10:33,640
訓練神經網路在單獨的
不同的任務上

155
00:10:33,640 --> 00:10:35,860
所以這是多工任務學習

156
00:10:35,860 --> 00:10:40,410
實作上，多工任務學習
使用上少於轉移學習

157
00:10:40,410 --> 00:10:43,450
我看了很多的應用在轉移學習，您

158
00:10:43,450 --> 00:10:46,150
想要解決一個
只有小量資料的問題

159
00:10:46,150 --> 00:10:49,580
所以您找一個相關的問題
有很多的資料可以學習

160
00:10:49,580 --> 00:10:51,802
轉移那個到
新的問題上

161
00:10:51,802 --> 00:10:56,084
但多工任務學習就是比較少見到，
您有大量的任務

162
00:10:56,084 --> 00:10:57,820
您想要做得很好

163
00:10:57,820 --> 00:11:00,390
您可以同時訓練所有的任務

164
00:11:00,390 --> 00:11:02,254
或許一個例子是電腦視覺

165
00:11:02,254 --> 00:11:05,778
在物件偵測上，我看到越來越多的應用使用多工任務

166
00:11:05,778 --> 00:11:09,533
在一個神經網路上，同時試著偵測整個全部物件

167
00:11:09,533 --> 00:11:13,700
比起不同的神經網路
試著單獨偵測物件更好

168
00:11:13,700 --> 00:11:17,870
但我會說平均而言，在今天，轉移學習
用的機會較多

169
00:11:17,870 --> 00:11:22,610
比起多工任務學習而言，但兩者都是
有用的工具在您的兵工廠裡

170
00:11:22,610 --> 00:11:23,685
總結一下

171
00:11:23,685 --> 00:11:28,270
多工任務學習能夠
讓您訓練一個神經網路做很多任務

172
00:11:28,270 --> 00:11:32,630
這樣會給您比較好的表現，
比起您單獨做這些任務

173
00:11:32,630 --> 00:11:37,410
一個注意點，實作上，
我看到轉移學習

174
00:11:37,410 --> 00:11:39,790
使用上比多工任務學習多

175
00:11:39,790 --> 00:11:43,262
我看過很多的任務，
如果您想要解決機器學習問題

176
00:11:43,262 --> 00:11:47,197
但相對的您的資料集比較小，
那轉移學習可以真的幫助您

177
00:11:47,197 --> 00:11:50,172
如果您找到相關的問題，
但有較大的資料集

178
00:11:50,172 --> 00:11:52,290
您可以訓練您個神經網路，從那裡

179
00:11:52,290 --> 00:11:54,830
轉移到您有
較少資料的問題上

180
00:11:54,830 --> 00:11:57,460
所以轉移學習
在今天用得很多

181
00:11:57,460 --> 00:12:01,785
有一些應用使用多工任務學習

182
00:12:01,785 --> 00:12:05,730
但我想多工任務學習
用得比轉移學習少

183
00:12:05,730 --> 00:12:09,230
或許一個例外是
電腦視覺的物件偵測

184
00:12:09,230 --> 00:12:12,180
我看到很多的應用，
訓練一個神經網路

185
00:12:12,180 --> 00:12:13,980
來偵測很多的物件

186
00:12:13,980 --> 00:12:16,660
而這比起分開
訓練神經網路要好

187
00:12:16,660 --> 00:12:18,150
跟偵測可視物件

188
00:12:18,150 --> 00:12:21,385
但平均而言，即使轉移訓練跟

189
00:12:21,385 --> 00:12:26,130
多工任務學習通常
用類似的方式表現，實作上

190
00:12:26,130 --> 00:12:30,130
看轉移學習的應用
遠多於多工任務學習

191
00:12:30,130 --> 00:12:34,250
我想因為通常比較難來做設定，
去找出不同的

192
00:12:34,250 --> 00:12:37,120
任務您會實際上
想要在一個神經網路上做訓練

193
00:12:37,120 --> 00:12:39,050
再次，只有一些電腦視覺

194
00:12:39,050 --> 00:12:43,000
物件偵測的例子
是最顯著的例外

195
00:12:43,000 --> 00:12:45,465
所以這是多工任務學習

196
00:12:45,465 --> 00:12:46,310
多工任務學習跟

197
00:12:46,310 --> 00:12:50,350
轉移學習都是同樣重要的
在您的工具袋中

198
00:12:50,350 --> 00:12:54,730
最後，我想要繼續前往
談論端對端深度學習

199
00:12:54,730 --> 00:12:57,620
讓我們前往下一段影片，
來討論端對端學習