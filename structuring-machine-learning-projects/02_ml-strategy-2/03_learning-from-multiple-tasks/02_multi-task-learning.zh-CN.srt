1
00:00:00,330 --> 00:00:03,705
迁移过程是有先后顺序的

2
00:00:03,705 --> 00:00:07,162
从任务A中学习,然后将其迁移到任务B。

3
00:00:07,162 --> 00:00:10,520
在多任务学习中,你（多个任务）一起开始

4
00:00:10,520 --> 00:00:13,650
尝试让一个神经网络同时做几件事

5
00:00:13,650 --> 00:00:17,520
然后,每个任务将会帮助完成其他任务。

6
00:00:17,520 --> 00:00:18,480
我们来看个例子让我们来看一个例子

7
00:00:20,110 --> 00:00:24,140
假设你正在建造一辆自动驾驶汽车。

8
00:00:24,140 --> 00:00:28,969
然后你的车将需要检测几个不同的

9
00:00:28,969 --> 00:00:34,164
事物如行人、其他车辆、停车标志

10
00:00:37,312 --> 00:00:42,410
还有交通信号灯和其他的东西。

11
00:00:43,670 --> 00:00:47,330
例如,在左边的例子中,图中有个停止路标

12
00:00:47,330 --> 00:00:53,510
这张照片里有一辆车,但没有行人或红绿灯。

13
00:00:53,510 --> 00:00:58,200
如果这个图像作为输入,如x(i),

14
00:00:58,200 --> 00:01:02,770
而输出并不是一个标签y(i)而是四个。

15
00:01:02,770 --> 00:01:05,640
在这个例子中,没有行人,有一辆车,

16
00:01:05,640 --> 00:01:08,850
有一个停车标志,没有红绿灯。

17
00:01:08,850 --> 00:01:10,580
如果你试着发现其他的东西

18
00:01:10,580 --> 00:01:12,634
y(i)可能会有更多的维度。

19
00:01:12,634 --> 00:01:14,385
但现在我们只用这四个。

20
00:01:14,385 --> 00:01:18,013
所以y(i)是一个4x1的向量。

21
00:01:18,013 --> 00:01:22,444
如果你把训练测试标签当成一个整体

22
00:01:22,444 --> 00:01:27,370
和之前一样,我们将训练数据的标签

23
00:01:27,370 --> 00:01:32,116
如下地进行水平堆栈，y(1)到y(m)

24
00:01:32,116 --> 00:01:39,470
y(i)是4x1向量,所以每一个都是列向量。

25
00:01:39,470 --> 00:01:45,530
所以矩阵Y现在是一个4xm矩阵,而以前,

26
00:01:45,530 --> 00:01:49,810
当y是单一实数时,是一个1xm的矩阵。

27
00:01:49,810 --> 00:01:55,122
你现在做的是训练一个神经网络来预测y。

28
00:01:55,122 --> 00:01:57,828
你可以有一个神经网络以x作为输入和

29
00:01:57,828 --> 00:02:00,970
输出为四维的y。

30
00:02:00,970 --> 00:02:04,590
请注意这里的输出,我已经绘制了四节点。

31
00:02:04,590 --> 00:02:09,000
第一个节点,我们试图检测是否有行人

32
00:02:09,000 --> 00:02:10,610
在这张图片中

33
00:02:10,610 --> 00:02:13,470
第二个输出会检测到是否有辆车

34
00:02:13,470 --> 00:02:18,870
还会检测到是否有个停车标志和红绿灯

35
00:02:20,850 --> 00:02:23,950
所以这里的y^是四维的。

36
00:02:26,110 --> 00:02:30,575
为了训练这个神经网络,你需要定义

37
00:02:30,575 --> 00:02:32,029
这个神经网络的损失函数

38
00:02:32,029 --> 00:02:39,190
预测输出的y^(i)是4x1维的。

39
00:02:39,190 --> 00:02:43,939
损失是整个训练集的平均损失

40
00:02:43,939 --> 00:02:48,209
为1除以m，乘以从i=1到m的总和

41
00:02:48,209 --> 00:02:55,349
j从1到4各自预测的损失

42
00:02:59,030 --> 00:03:03,256
它只是将4个部分行人、车、停车标志

43
00:03:03,256 --> 00:03:04,253
红绿灯进行相加

44
00:03:04,253 --> 00:03:11,462
这里的L是普通的逻辑斯蒂损失函数。

45
00:03:14,493 --> 00:03:19,404
把这写下来

46
00:03:19,404 --> 00:03:24,314
所以就是

47
00:03:24,314 --> 00:03:28,349
yj(i)logŷj(i)+(1-yj(i))log(1-ŷj(i))

48
00:03:31,706 --> 00:03:36,018
与前面的分类示例相比,主要的区别是

49
00:03:36,018 --> 00:03:38,760
现在你将j从1到4相加。

50
00:03:40,570 --> 00:03:45,260
和softmax回归区别是,不像softmax

51
00:03:45,260 --> 00:03:50,550
回归,它将单个标签分配给单个示例。

52
00:03:50,550 --> 00:03:53,370
这一个图像可以有多个标签。

53
00:03:55,350 --> 00:04:00,162
所以你不说每个图像是一个行人图片,或

54
00:04:00,162 --> 00:04:04,780
汽车图片，停车标志图片,交通信号灯图片。

55
00:04:04,780 --> 00:04:09,010
你看每张照片,它是否有行人,汽车,停车标志或

56
00:04:09,010 --> 00:04:11,860
红绿灯和多个对象出现在同一图像中。

57
00:04:11,860 --> 00:04:16,390
在上一张幻灯片的例子中,有一辆车和

58
00:04:16,390 --> 00:04:19,400
有个停车标志,但没有行人和红绿灯。

59
00:04:19,400 --> 00:04:22,580
所以你不是给图片分配一个标签

60
00:04:22,580 --> 00:04:25,800
你有不同的类别和

61
00:04:25,800 --> 00:04:29,573
查看该类别是否在该图片中？

62
00:04:31,420 --> 00:04:34,839
所以,这就是为什么我说,在这个设置下,

63
00:04:34,839 --> 00:04:37,313
一张图片可以有多个标签。

64
00:04:37,313 --> 00:04:42,281
如你在进行多任务学习需要

65
00:04:42,281 --> 00:04:45,920
训练神经网络来使损失函数最小

66
00:04:45,920 --> 00:04:50,823
因为你在建一个单一的神经网络,通过

67
00:04:50,823 --> 00:04:53,860
一张图片来解决4个问题。

68
00:04:53,860 --> 00:04:58,910
它试图告诉你每个图像中的4个对象。

69
00:05:00,250 --> 00:05:03,850
或者你可以做的是训练4个独立的神经网络

70
00:05:03,850 --> 00:05:06,700
而不是训练一个网络做4件事。

71
00:05:06,700 --> 00:05:11,300
但是在不同输出之间，神经网络

72
00:05:11,300 --> 00:05:13,790
前面的特征可以共享，那么你会发现

73
00:05:13,790 --> 00:05:17,880
训练一个神经网络做4件事的结果比

74
00:05:17,880 --> 00:05:21,760
训练4个完全独立的神经网络的结果要好。

75
00:05:23,040 --> 00:05:25,450
这就是多任务学习的力量。

76
00:05:26,716 --> 00:05:28,127
还有一个细节

77
00:05:28,127 --> 00:05:33,440
到目前为止在算法中,好像每个图像都要标签。

78
00:05:33,440 --> 00:05:37,754
其实在多任务学习中，即使一些图像

79
00:05:37,754 --> 00:05:39,452
只标记某些对象也能正常工作。

80
00:05:39,452 --> 00:05:43,078
在第一个训练例子,标注的人告诉你图片有

81
00:05:43,078 --> 00:05:46,214
行人,没有汽车,但他们标注是否

82
00:05:46,214 --> 00:05:49,072
有停车标志和红绿灯。

83
00:05:49,072 --> 00:05:52,691
在第二个例子中，有行人和汽车

84
00:05:52,691 --> 00:05:56,479
但是标注的人看到图却没有把他们标注

85
00:05:56,479 --> 00:05:59,790
有没有停车标志和有没有交通灯等等。

86
00:05:59,790 --> 00:06:03,153
也许一些例子是完全标记的,也许一些例子

87
00:06:03,153 --> 00:06:06,117
他们只是标注是否有汽车,所以

88
00:06:06,117 --> 00:06:08,858
会有些问号等。

89
00:06:08,858 --> 00:06:13,050
这样的数据集,你仍然可以训练你的算法

90
00:06:13,050 --> 00:06:16,870
进行同时完成4项任务,即使有些图像

91
00:06:16,870 --> 00:06:21,300
只有一些标志和其他问号或不关心的项。

92
00:06:21,300 --> 00:06:24,808
还有你训练算法的方式

93
00:06:24,808 --> 00:06:29,520
在j从1到4中，即使这些标签中的一

94
00:06:29,520 --> 00:06:34,669
些是问号或没有标注

95
00:06:34,669 --> 00:06:39,730
你只需要对标签为0或1的j值求和。

96
00:06:41,354 --> 00:06:46,850
每当有一个问号,你只省略该项求和,

97
00:06:46,850 --> 00:06:51,480
只对有标签的值进行求和。

98
00:06:51,480 --> 00:06:54,720
你可以这样使用数据集

99
00:06:54,720 --> 00:06:57,390
那么什么时候进行多任务学习才有意义？

100
00:06:57,390 --> 00:06:59,471
那么什么时候进行多任务学习才有意义？

101
00:06:59,471 --> 00:07:03,550
我会说它在以下三个条件下适用

102
00:07:03,550 --> 00:07:06,400
一是你要训练一系列的任务可以

103
00:07:06,400 --> 00:07:08,470
共享一些低层次的特征

104
00:07:08,470 --> 00:07:13,155
自动驾驶的例子中,在识别交通灯

105
00:07:13,155 --> 00:07:16,980
汽车和行人时,都有相似的特征

106
00:07:16,980 --> 00:07:21,653
这可以帮你识别停车标志，因为他们都是道路特征

107
00:07:23,120 --> 00:07:28,032
其次——这不是硬性的规则,所以不总是存在的——

108
00:07:28,032 --> 00:07:31,757
但我看到很多成功的多任务学习，他们

109
00:07:31,757 --> 00:07:35,310
每个单项任务的数据量非常相似。

110
00:07:35,310 --> 00:07:39,480
你会回想起迁移学习，从任务A

111
00:07:39,480 --> 00:07:41,930
迁移到任务B。

112
00:07:41,930 --> 00:07:46,891
如果任务A中100万个数据，任务B中有1000个

113
00:07:46,891 --> 00:07:51,611
数据,那么从百万个数据中训练的值

114
00:07:51,611 --> 00:07:56,430
能够帮助增强数据集较少的任务B

115
00:07:56,430 --> 00:07:58,652
那么多任务学习呢？

116
00:07:58,652 --> 00:08:01,520
多任务学习中，你一般会有多于两项的任务

117
00:08:01,520 --> 00:08:07,678
前面例子中有四项，我们假设有100个任务。

118
00:08:07,678 --> 00:08:11,452
你通过多任务学习,在同一时间内

119
00:08:11,452 --> 00:08:12,580
试图识别100个类别。

120
00:08:12,580 --> 00:08:17,444
每个任务中你有1000个例子

121
00:08:17,444 --> 00:08:20,660
如果你只关注一个任务的准确率，

122
00:08:20,660 --> 00:08:25,775
让我们看第100个任务，把它叫做A100

123
00:08:25,775 --> 00:08:28,899
如果你想单独地完成这项最后的任务,

124
00:08:28,899 --> 00:08:32,875
你只有1000个例子来训练这一项任务，

125
00:08:32,875 --> 00:08:37,320
这1个任务由其他99个任务进行训练

126
00:08:37,320 --> 00:08:42,810
有9.9万个样本是一个很大的推动,

127
00:08:42,810 --> 00:08:46,597
它们可以给很多的信息来增强,否则在第

128
00:08:46,597 --> 00:08:52,040
100个任务中只靠相对较小的1000个数据。

129
00:08:52,040 --> 00:08:57,080
同样地，其余99个任务也有同样的数据也

130
00:08:57,080 --> 00:09:01,197
得到其他任务信息来帮助训练。

131
00:09:02,640 --> 00:09:07,940
第二点不是硬性要求，但我更倾向于这样

132
00:09:07,940 --> 00:09:13,150
为了增强多任务学习,如果你集中在任一任务上,

133
00:09:13,150 --> 00:09:17,260
其他任务比单一任务合计起来

134
00:09:17,260 --> 00:09:18,220
有更多的数据。

135
00:09:18,220 --> 00:09:22,730
一个方法是如果我们例子中有很多任务

136
00:09:22,730 --> 00:09:27,030
每个任务中的数据也相当相似

137
00:09:27,030 --> 00:09:31,558
但是关键是你在一个任务中已经有1000个例子

138
00:09:31,558 --> 00:09:36,360
在其他任务中合计有远超过1000的数据，

139
00:09:36,360 --> 00:09:40,565
其他任务可帮助你在最后的任务表现更好。

140
00:09:40,565 --> 00:09:44,521
多任务学习往往会更有意义,当你训练一个

141
00:09:44,521 --> 00:09:47,640
很大的神经网络来使所有任务都有高准确度

142
00:09:47,640 --> 00:09:50,259
另一种多任务学习是

143
00:09:50,259 --> 00:09:52,767
为每个任务单独训练一个神经网络。

144
00:09:52,767 --> 00:09:56,084
与其为行人,汽车,停车标志,交通灯训练

145
00:09:56,084 --> 00:09:59,017
一个神经网络，你可以训练一个行人的神经网络

146
00:09:59,017 --> 00:10:02,528
汽车的神经网络，停车标志

147
00:10:02,528 --> 00:10:05,630
的神经网络和交通灯的神经网络。

148
00:10:06,640 --> 00:10:10,895
研究员Rich Carona,多年前发现

149
00:10:10,895 --> 00:10:14,920
如果神经网络不够大，多任务学习

150
00:10:14,920 --> 00:10:18,590
与单项训练相比会损害准确率。

151
00:10:18,590 --> 00:10:22,898
但如果你训练足够大的神经网络,那多任务学习

152
00:10:22,898 --> 00:10:26,476
应该不会或很少影响性能。

153
00:10:26,476 --> 00:10:29,405
与你分别单独训练不同任务相比，

154
00:10:29,405 --> 00:10:33,640
它实际上能够提高性能。

155
00:10:33,640 --> 00:10:35,860
这就是多任务学习。

156
00:10:35,860 --> 00:10:40,410
实际上多任务学习要比迁移学习用得少得多。

157
00:10:40,410 --> 00:10:43,450
我看到很多迁移学习的应用,你

158
00:10:43,450 --> 00:10:46,150
你想通过一个小数量的数据来解决问题。

159
00:10:46,150 --> 00:10:49,580
你找一个有大量数据的相关问题来学习

160
00:10:49,580 --> 00:10:51,802
然后转移到这个新的问题。

161
00:10:51,802 --> 00:10:56,084
多任务学习用的更少，一般在你有大量任务

162
00:10:56,084 --> 00:10:57,820
需要完成，你可以同时

163
00:10:57,820 --> 00:11:00,390
训练所有这些任务。

164
00:11:00,390 --> 00:11:02,254
可能一个例子是计算机视觉

165
00:11:02,254 --> 00:11:05,778
在对象检测中,有很多多任务学习的应用，

166
00:11:05,778 --> 00:11:09,533
一个神经网络可以同时检测到一大堆对象

167
00:11:09,533 --> 00:11:13,700
这比多个不同的神经网络单独地检测物体好。

168
00:11:13,700 --> 00:11:17,870
但我要说的是,平均来说迁移学习要比多

169
00:11:17,870 --> 00:11:22,610
任务学习用的更多，但是两者都是有用的工具。

170
00:11:22,610 --> 00:11:23,685
总结一下总结一下

171
00:11:23,685 --> 00:11:28,270
多任务学习能训练一个神经网络来完成多任务

172
00:11:28,270 --> 00:11:32,630
这可以使你的性能比单独执行任务时更好。

173
00:11:32,630 --> 00:11:37,410
请注意一点，实际上迁移学习

174
00:11:37,410 --> 00:11:39,790
比多任务学习用得更多。

175
00:11:39,790 --> 00:11:43,262
所以如果你想解决一个机器学习问题

176
00:11:43,262 --> 00:11:47,197
但你有一个相对较小得数据集，迁移学习可以帮助你。

177
00:11:47,197 --> 00:11:50,172
当你有个相关的问题有更大得数据集，

178
00:11:50,172 --> 00:11:52,290
你可以用来训练你的神经网络

179
00:11:52,290 --> 00:11:54,830
然后迁移到小数据集的问题上。

180
00:11:54,830 --> 00:11:57,460
因此,迁移学习在今天使用得很多。

181
00:11:57,460 --> 00:12:01,785
也有很多多任务学习

182
00:12:01,785 --> 00:12:05,730
但是多任务学习与迁移学习相比要少。

183
00:12:05,730 --> 00:12:09,230
但是有一个例外就是计算机视觉物体检测。

184
00:12:09,230 --> 00:12:12,180
我在那看到了很多训练神经网络

185
00:12:12,180 --> 00:12:13,980
用来检测不同物体的应用。

186
00:12:13,980 --> 00:12:16,660
这比训练单独的神经网络

187
00:12:16,660 --> 00:12:18,150
来检测物体更有效。

188
00:12:18,150 --> 00:12:21,385
但我认为迁移学习和

189
00:12:21,385 --> 00:12:26,130
多任务学习都以类似方式提出，实际上

190
00:12:26,130 --> 00:12:30,130
我看到迁移学习比多任务学习应用更多。

191
00:12:30,130 --> 00:12:34,250
我想这是因为很难找到这么多不同

192
00:12:34,250 --> 00:12:37,120
的任务要单独在单个神经网络上训练。

193
00:12:37,120 --> 00:12:39,050
再次,用计算机视觉的

194
00:12:39,050 --> 00:12:43,000
物体检测是最为显著的例外。

195
00:12:43,000 --> 00:12:45,465
这就是多任务学习。

196
00:12:45,465 --> 00:12:46,310
多任务学习与

197
00:12:46,310 --> 00:12:50,350
迁移学习是你的工具包中的重要工具。

198
00:12:50,350 --> 00:12:54,730
最后,我下次想讨论端到端的深度学习。

199
00:12:54,730 --> 00:12:57,620
让我们进入下一个视频，学习端到端学习。