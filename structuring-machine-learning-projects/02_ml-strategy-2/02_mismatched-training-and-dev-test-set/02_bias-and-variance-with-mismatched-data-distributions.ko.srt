1
00:00:00,760 --> 00:00:01,970
러닝 알고리즘의 편향과 편차의 값을 예측하는 

2
00:00:01,970 --> 00:00:06,650
것은 다음에 어떤 업무를 수행해야할지 업무 순위를
결정하는데 도움을 줍니다.

3
00:00:06,650 --> 00:00:11,220
하지만 여러분의 트레이닝세트가 dev 와 테스트세트와 비교하여 다른 분포도에서 

4
00:00:11,220 --> 00:00:14,570
오는 경우에는 편향,편차를 분석하는 방법이 달라집니다. 

5
00:00:14,570 --> 00:00:15,140
한번 살펴보겠습니다.

6
00:00:16,480 --> 00:00:19,650
계속해서 고양이 인식기능 예제로 살펴보겠습니다.

7
00:00:19,650 --> 00:00:22,880
이 기능에서 인간은 거의 완벽에 가까운 능력을 보인다고 가정해봅시다.

8
00:00:22,880 --> 00:00:28,620
그러면 Bayes error 또는 Bayes optimal error가
이 문제의 경우 0퍼센트임을 알 수 있습니다.

9
00:00:28,620 --> 00:00:33,530
오류 분석을 하기 위해서는 보통 트레이닝 오류를 보고

10
00:00:33,530 --> 00:00:37,030
dev set의 오류 또한 보게됩니다.

11
00:00:37,030 --> 00:00:41,490
그러면, 이번 예제에서 트레이닝 오류가 1퍼센트라고 해보겠습니다.

12
00:00:41,490 --> 00:00:45,040
그리고 dev error는 10퍼센트입니다.

13
00:00:45,040 --> 00:00:49,725
만약 dev 데이터가 트레이닝세트와 동일한 분포에서 왔다고하면,

14
00:00:49,725 --> 00:00:53,125
이 경우에는 아주 큰 편차를 갖는 문제가 생길 것입니다.

15
00:00:53,125 --> 00:00:56,615
트레이닝세트를 여러분의 알고리즘이 잘 일반화시키지 못하는 것이죠.

16
00:00:56,615 --> 00:01:01,795
dev set에서는 잘하는데, 갑자기 잘 못하게 되는 것입니다.

17
00:01:01,795 --> 00:01:05,335
하지만 트레이닝 데이터와 dev data가 다른 분포도에서

18
00:01:05,335 --> 00:01:09,658
오는 세팅값에서는 이렇게 쉽게 단정 지을 수 없습니다. 

19
00:01:09,658 --> 00:01:13,820
특히, dev 세트에서는 아주 잘 작동할 수도 있습니다. 

20
00:01:13,820 --> 00:01:18,250
트레이닝세트에서는 고화질의 이미지로 아주 쉬운 업무였을 수도 있습니다.

21
00:01:18,250 --> 00:01:21,880
아주 선명한 이미지일 수 있구요. 하지만 dev 세트는 훨씬 더 어렵게 되는 것이죠.

22
00:01:23,492 --> 00:01:27,610
물론 편향의 문제가 없을 수도 있고 이런 경우는

23
00:01:27,610 --> 00:01:32,030
dev 세트가 분류하기 훨씬 더 까다로운 이미지들로 이루어져 있다고 
볼 수도 있습니다.

24
00:01:33,610 --> 00:01:38,220
분석의 문제는 이렇듯이 트레이닝 오류에서

25
00:01:38,220 --> 00:01:41,980
dev 오류로 넘어갈때, 2가지가 한번에 바뀌었습니다.

26
00:01:41,980 --> 00:01:47,450
첫번째로는 알고리즘이 트레이닝세트에 있는 데이터는 보았지만
dev set에 있는 데이터는 보지 못했습니다.

27
00:01:47,450 --> 00:01:51,080
두번째로, dev set에 있는 데이터의 분포도는 다릅니다.

28
00:01:51,080 --> 00:01:55,158
그리고 여러분이 2가지를 한번에 바꾸었기 때문에,

29
00:01:55,158 --> 00:02:00,120
9 퍼센트로 증가한 오류 중, 얼마만큼이 
알고리즘이 dev set에 있는 데이터를 

30
00:02:00,120 --> 00:02:04,660
못봐서 생기는 오류인지, 이것은 편차에서 오는 문제겠죠.

31
00:02:04,660 --> 00:02:07,670
아니면 얼마만큼의 오류가 단순히 dev set 데이터가 다르기 때문에 
생기는 오류인지 구분하기가 쉽지 않습니다.

32
00:02:09,300 --> 00:02:14,150
이런 2가지의 효과를 추출하기 위해,

33
00:02:14,150 --> 00:02:17,610
만약 2가지의 효과를 잘 이해하지 못하셨으면 걱정하지 마십시요

34
00:02:17,610 --> 00:02:19,490
곧 다시한번 이야기 하겠습니다.

35
00:02:19,490 --> 00:02:23,702
이런 효과들을 추출하기 위해서는
training-dev set라고

36
00:02:23,702 --> 00:02:26,970
새로 특정 데이터를 정의하는 것이 도움이 될 것입니다.

37
00:02:26,970 --> 00:02:29,430
이것이 새로운 데이터의 부분집합인데요.

38
00:02:29,430 --> 00:02:34,080
일부 추출해서 빼낸 이 데이터는 트레이닝 세트와 
동일한 분포도를 가질 것입니다.

39
00:02:34,080 --> 00:02:37,630
하지만 여러분의 네트워크에서 따로 트레이닝 시키는 데이터는 아닙니다. 무슨 뜻인지 알려드리겠습니다.

40
00:02:37,630 --> 00:02:38,690
그래서 이것이 뜻하는 것은 다음과 같습니다.

41
00:02:40,330 --> 00:02:45,220
이전에는 일정 트레이닝세트와 

42
00:02:45,220 --> 00:02:50,920
dev set, 그리고 데스트세트들을 이렇게 세팅했었습니다.

43
00:02:50,920 --> 00:02:53,403
그리고 dev 와 테스트세트들은 똑같은 분포도를 가졌었는데요.

44
00:02:53,403 --> 00:02:56,710
트레이닝세트는 다른 분포도를 가질 것입니다.

45
00:02:56,710 --> 00:03:01,640
저희는 트레이닝세트들을 무작위로 섞어서

46
00:03:01,640 --> 00:03:09,180
일부 트레이닝세트를 추출해서 trainin-dev set라고 할 것입니다.

47
00:03:09,180 --> 00:03:14,830
그러면 dev와 테스트세트가 동일한 분포도로 되어있듯이,

48
00:03:14,830 --> 00:03:18,750
트레이닝세트와 training-dev set도 마찬가지로 동일한 분포도로 되어 있을 것입니다.

49
00:03:21,290 --> 00:03:24,940
하지만 다른점은, 이제 여러분이 

50
00:03:24,940 --> 00:03:27,920
트레이닝 세트에서만 제대로 신경망을 트레이닝 시킨다는 점입니다.

51
00:03:27,920 --> 00:03:29,330
신경망을 training-dev 부분에서는 

52
00:03:29,330 --> 00:03:34,660
따로 트레이닝 시키지 않을 것입니다.

53
00:03:34,660 --> 00:03:36,290
오류분석을 하기위해서는, 

54
00:03:36,290 --> 00:03:39,310
트레이닝세트에서 인식기의 오류를 보고,

55
00:03:39,310 --> 00:03:43,320
또 training-dev set에서 보고, 또 dev set에서도 볼 것입니다.

56
00:03:44,500 --> 00:03:51,281
그럼 이번 예제에서는 트레이닝 오류가 1퍼센트가 해봅시다.

57
00:03:53,020 --> 00:04:00,695
그리고 training-dev set에서의 오류는 9퍼센트라고 해봅시다.

58
00:04:00,695 --> 00:04:07,910
또한 dev set에서의 오류가 10퍼센트라고 해봅시다. 이전과 마찬가지로 말이죠.

59
00:04:08,910 --> 00:04:13,460
여기서 결론 내릴 수 있는 것은,

60
00:04:13,460 --> 00:04:17,680
트레이닝 데이터에서 training dev 데이터로 넘어갈 때, 
오류가 확실히 많이 증가했다는 것입니다.

61
00:04:17,680 --> 00:04:22,460
그리고 트레이닝 데이터와 training-dev 데이터의 유일한

62
00:04:22,460 --> 00:04:27,280
차이는 여러분의 신경망이 이 부분의 첫번째 부분을 정리했다는 것입니다.

63
00:04:27,280 --> 00:04:30,610
여기에서는 명백하게 트레이닝 되었는데요,

64
00:04:30,610 --> 00:04:34,840
하지만 training-dev data에서 명백히 트레이닝 되지는 않았습니다.

65
00:04:34,840 --> 00:04:38,320
이런 부분은 바로 편차문제가 있음을 말해주는데요.

66
00:04:40,006 --> 00:04:44,230
training-dev 오류가 트레이닝세트와 같은 분포도를 

67
00:04:44,230 --> 00:04:46,290
가진 데이터로 측정되었기 때문에 그렇습니다. 

68
00:04:46,290 --> 00:04:50,490
이제 여러분의 신경망이 트레이닝세트에서 잘 작동하더라도 

69
00:04:50,490 --> 00:04:53,980
training-dev의 데이터에는 잘 일반화가 되지 않는다는 점을 알게되었습니다. 

70
00:04:53,980 --> 00:04:58,280
같은 분포에서 온 training-dev 세트에서 말이죠.

71
00:04:58,280 --> 00:05:02,530
처음 보는 익숙하지 않은, 같은 분포를 갖는 데이터에 일반화가 잘 되지 않습니다. 

72
00:05:04,020 --> 00:05:07,200
이 예제에서는 그렇기 때문에 편차의 문제가 보입니다.

73
00:05:09,680 --> 00:05:11,510
또 다른 예제를 보겠습니다.

74
00:05:11,510 --> 00:05:17,613
트레이닝 오류가 1퍼센트, 
training-dev 오류가 1.5퍼센트라고 해보죠.

75
00:05:17,613 --> 00:05:21,360
그런데 dev set에서는 오류가 10퍼센트입니다.

76
00:05:21,360 --> 00:05:24,805
이 경우, 꽤 낮은 편차의 문제입니다.

77
00:05:24,805 --> 00:05:29,798
그 이유는, 이미 본 적이 있는 트레이닝 데이터에서 
신경 네트워크가 본 적이 없는 training-dev 데이터로

78
00:05:29,798 --> 00:05:34,579
가는데 오류가 조금만 오릅니다.

79
00:05:34,579 --> 00:05:37,550
그 이후, dev set로 가자 갑자기 점프하여 오릅니다.

80
00:05:37,550 --> 00:05:43,100
이것이 전형적인 데이터 미스매치 문제입니다. 데이터가 일치하지 않는 경우이죠.

81
00:05:44,810 --> 00:05:51,840
여러분의 러닝 알고리즘이 명백히

82
00:05:51,840 --> 00:05:55,838
training-dev 나 dev에서의 데이터로 
트레이닝 된 것이 아니기 때문에,

83
00:05:55,838 --> 00:06:00,610
데이터 미스매치 문제라고 볼 수 있습니다.
이 2개 데이터세트는 서로 다른 분포도를 가지고 있습니다.

84
00:06:00,610 --> 00:06:01,850
어떤 알고리즘을 학습하고 있더라도, 

85
00:06:01,850 --> 00:06:06,230
training-dev에선 잘 작동하고, 
dev에서는 잘 작동하지 않는 것입니다.

86
00:06:06,230 --> 00:06:10,407
어떻게 해서 여러분의 알고리즘이 
분포도가 다른 곳에서 

87
00:06:10,407 --> 00:06:14,462
생각하는 것보다 더 잘 작동하는 법을 배우게 된 것입니다.
우리는 이것을 데이터 미스매치 문제라고 부릅니다.

88
00:06:17,505 --> 00:06:20,112
몇개의 다른 예제를 보겠습니다.

89
00:06:20,112 --> 00:06:24,663
위에 공간이 부족하니 이 내용은 다음 줄에 적겠습니다.

90
00:06:24,663 --> 00:06:31,326
자 그럼, training error,Training-Dev error, 그리고 Dev error입니다.

91
00:06:33,618 --> 00:06:37,254
트레이닝 오류가 10퍼센트라고 해봅시다.

92
00:06:37,254 --> 00:06:42,210
training-dev 오류는 11퍼센트, 
dev 오류는 12퍼센트이구요.

93
00:06:42,210 --> 00:06:46,507
기억하시겠지만, Bayes error에 대한 인간레벨 

94
00:06:46,507 --> 00:06:50,100
프록시 값은 대략 0퍼센트입니다.

95
00:06:50,100 --> 00:06:56,020
이런 류의 성능이 있다면, 편향이 생기는데요

96
00:06:56,020 --> 00:07:02,920
avoidable bias problem이 말이죠, 그 이유는
인간레벨보다 더 못한 성능이기 때문이죠. 

97
00:07:02,920 --> 00:07:05,810
그러면 이것은 high bias setting값을 갖게 되는 것입니다.

98
00:07:07,440 --> 00:07:08,830
마지막 예입니다.

99
00:07:08,830 --> 00:07:14,211
트레이닝 오류가 10퍼센트,
training-dev 오류가 11퍼센트

100
00:07:14,211 --> 00:07:19,706
그리고 dev 오류가 20퍼센트이면
2가지 이슈가있어 보입니다.

101
00:07:19,706 --> 00:07:24,070
첫째로, avoidable bias가 꽤 높습니다.

102
00:07:24,070 --> 00:07:26,940
트레이닝세트에서 조차 그리 잘하고 있지 않기 때문이죠.

103
00:07:26,940 --> 00:07:31,860
인간은 0퍼센트 오류인 반면 여러분은 10퍼센트의 오류가
트레이닝 세트에서 발생하기 때문이죠.

104
00:07:31,860 --> 00:07:36,710
편차는 조금 작아보이는데요.

105
00:07:38,110 --> 00:07:43,910
이 데이터미스매치는 그러나 꽤 큽니다.

106
00:07:43,910 --> 00:07:48,839
이 예제에서는, 편향이 꽤 크고, 또는

107
00:07:48,839 --> 00:07:54,001
avoidable bias problem이 말이죠.
그리고 데이터미스매치 문제도 있다고 말할 것입니다.

108
00:07:56,479 --> 00:07:59,462
이 슬라이드에서 다룬 내용을 보고

109
00:07:59,462 --> 00:08:01,710
제너럴한 원리를 적어보겠습니다.

110
00:08:02,810 --> 00:08:09,909
가장 핵심적으로 볼 부분은

111
00:08:09,909 --> 00:08:14,931
인간레벨 오류, 여러분의 트레이닝 세트 오류,

112
00:08:14,931 --> 00:08:19,620
그리고 여러분의 trainin-dev set 오류 입니다.

113
00:08:21,630 --> 00:08:23,891
그것은 트레이닝 세트와 동일한 분포를 갖는데요.

114
00:08:23,891 --> 00:08:25,880
여러분이 명백히 거기서 트레이닝 시키지는 않았습니다.

115
00:08:25,880 --> 00:08:30,798
이러한 오류의 차이에 따라서, 여러분의 dev set오류가,

116
00:08:30,798 --> 00:08:35,034
avoidable bias와 편차가 얼마나 큰지 감을 잡을 수 있습니다.

117
00:08:35,034 --> 00:08:36,940
그리고 데이터 미스매치 문제도 말이죠,

118
00:08:38,840 --> 00:08:40,880
자 그럼, 인간레벨 오류가 4퍼센트라고 해봅시다.

119
00:08:40,880 --> 00:08:43,573
트레이닝 오류는 7퍼센트이구요

120
00:08:43,573 --> 00:08:46,660
training-dev 오류는 10퍼센트입니다.

121
00:08:46,660 --> 00:08:50,112
그리고 dev 오류는 12퍼센트입니다.

122
00:08:50,112 --> 00:08:54,100
이를 통해서 avoidable bias에 대한 감이 오실텐데요.

123
00:08:55,170 --> 00:08:58,032
그 이유는 여러분은 알고리즘이 인간레벨성능 
만큼 또는 그 수준과 근접하는 만큼

124
00:08:58,032 --> 00:09:01,420
트레이닝 세트에서 작동하길 바랄 것이므로 그렇습니다.

125
00:09:01,420 --> 00:09:04,460
이건은 편차의 대한 것인데요.

126
00:09:04,460 --> 00:09:08,790
얼마나 트레이닝세트에서 training-dev set로 일반화가 될까요?

127
00:09:10,540 --> 00:09:15,550
이것은 데이터 미스매치가 얼마만큼 있는지를 알려주는 척도입니다.

128
00:09:15,550 --> 00:09:18,180
엄밀히 이야기하면, 
한가지를 추가할 수 있습니다.

129
00:09:18,180 --> 00:09:21,410
바로 테스트 세트 성능입니다.
test error를 적겠습니다.

130
00:09:21,410 --> 00:09:24,790
테스트세트에서는 개발을 진행하지 않는 것이 좋습니다. 
자칫해서 테스트세트를

131
00:09:24,790 --> 00:09:25,625
overfit하는 일이 없도록 해야하니깐요.

132
00:09:25,625 --> 00:09:31,490
하지만 이것을 보면,
이 차이가 dev set에 overfit하는 

133
00:09:31,490 --> 00:09:36,212
정도를 말해줍니다.

134
00:09:36,212 --> 00:09:41,460
만약 dev set performance와 여러분의

135
00:09:41,460 --> 00:09:45,820
테스트세트 성능이 큰 차이가 있으면 
dev set를 오버튜닝 했다는 소리일 수 있습니다.

136
00:09:45,820 --> 00:09:49,450
이런 경우, 더 큰 dev set를 찾아야 하겠죠?

137
00:09:49,450 --> 00:09:53,450
여러분도 기억하시겠지만 dev set와 여러분의 테스트세트는
같은 분포를 갖고 있습니다.

138
00:09:53,450 --> 00:09:57,170
그러므로 여기 서로 큰 차이가 날 수 잇는 유일한 방법은
테스트세트에서보다 

139
00:09:57,170 --> 00:10:01,304
dev set에서 훨씬 더 잘 작동하는 경우, 
즉, 어떻게서든 dev set를 overfit했을 시 발생합니다.

140
00:10:01,304 --> 00:10:04,630
만약 이런 경우, 고려하실 수 있는 부분은

141
00:10:04,630 --> 00:10:06,650
다시 돌아가서 dev set 데이터를 더 수집하는 것입니다.

142
00:10:06,650 --> 00:10:08,760
자 여기 이렇게 숫자를 적었는데요.

143
00:10:08,760 --> 00:10:13,830
숫자 리스트를 따라 내려갈때, 
숫자는 항상 올라가십시요. 

144
00:10:13,830 --> 00:10:17,650
여기 항상 올라가지는 않는 경우의 숫자 예시입니다.

145
00:10:17,650 --> 00:10:22,166
인간레벨성능이 4퍼센트, 
트레이닝 오류가 7퍼센트,

146
00:10:22,166 --> 00:10:26,080
training-dev 오류가 10퍼센트인경우,
dve set로 간다고 해봅시다.

147
00:10:26,080 --> 00:10:30,430
놀랍게도, dev set에서 더 작 작동하는 점을 
발견했다고 해봅시다.

148
00:10:30,430 --> 00:10:34,052
이것은 6퍼센트, 이것도 6퍼센트입니다.

149
00:10:36,500 --> 00:10:41,110
이런 효과를 본 적이 있으실텐데요,

150
00:10:41,110 --> 00:10:45,430
음성인식 업무에서 트레이닝 데이터가 

151
00:10:45,430 --> 00:10:48,740
dev set와 테스트세트보다 훨씬 더 어려워진 경우 말이죠.

152
00:10:48,740 --> 00:10:53,840
이 2개는 트레이닝 세트 분포에서 평가됐고,

153
00:10:53,840 --> 00:10:57,960
여기 2개는 dev/test set 분포에서 평가됐습니다.

154
00:10:57,960 --> 00:11:02,445
그래서 가끔은 dev/test 세트 분포가 
여러분이 작업하는 어플에서 더 쉬운경우, 

155
00:11:02,445 --> 00:11:07,062
이 숫자는 실제로 내려갈 수 있습니다.

156
00:11:07,062 --> 00:11:08,768
그렇기 때문에 만약 여러분이 이런 웃기게 생긴 것을 보면,

157
00:11:08,768 --> 00:11:13,350
이런 분석에 대한 도움이 될만한 더욱 일반적인 공식이 있습니다.

158
00:11:13,350 --> 00:11:15,129
다음 슬라이드에서 간략히 이야기해보겠습니다.

159
00:11:17,420 --> 00:11:21,785
speech activated rear-view 거울(백미러)에 대한

160
00:11:21,785 --> 00:11:26,900
예제로 동기부여를 시켜드리도록 하겠습니다.

161
00:11:26,900 --> 00:11:31,575
여러분이 쓰고 있던 숫자들을 테이블화

162
00:11:31,575 --> 00:11:36,935
시킬 수 있는데요. 
가로줄에는 여러가지 이런 데이터 세트를 놓겠습니다.

163
00:11:36,935 --> 00:11:42,119
예를 들어, 일반 음성 인식 업무에서 가지고 온 데이터가 있을 수 있습니다.

164
00:11:43,570 --> 00:11:48,210
조금한 스피커를 가지고 여러가지 음성인식 문제에서 

165
00:11:48,210 --> 00:11:51,646
수집한 뭉치의 데이터가 있을 수 있는데요,

166
00:11:51,646 --> 00:11:53,740
또는 구매한 데이터 등 말이죠. 

167
00:11:53,740 --> 00:12:00,970
또한, 백미러와 관련된 특화 스피치 데이터가 있습니다.

168
00:12:00,970 --> 00:12:02,120
차 내부에 내장된 데이터 말이죠.

169
00:12:04,450 --> 00:12:09,890
그러므로 여기 테이블 x축에는
데이터세트를 변형시킬 것입니다.

170
00:12:09,890 --> 00:12:16,250
여기 다른 축에는
데이터를 검사하는 다른 방법들이나

171
00:12:16,250 --> 00:12:18,470
알고리즘을 나타낼 것입니다.

172
00:12:18,470 --> 00:12:21,350
첫번째로, 인간레벨 성능이 있습니다.

173
00:12:21,350 --> 00:12:25,980
이 데이터세트들에서 인간이 얼마나 정확한지 알아보는 방법입니다.

174
00:12:27,010 --> 00:12:31,948
또, 신경망 네트워크가 트레이닝한 

175
00:12:31,948 --> 00:12:36,210
examples의 오류가 있습니다.

176
00:12:38,870 --> 00:12:43,686
마지막으로 신경망이 트레이닝하지 않은

177
00:12:43,686 --> 00:12:47,412
example들의 오류가 있습니다.

178
00:12:50,036 --> 00:12:55,796
이전 슬라이드에서 언급했던 인간레벨에서

179
00:12:55,796 --> 00:12:59,036
여기 이 박스로 오는 숫자가 있습니다.

180
00:12:59,036 --> 00:13:03,320
이 카테고리의 데이터에서 인간이 얼마나 잘하는지에 대한
수치입니다.

181
00:13:03,320 --> 00:13:06,304
각종 음성인식 업무에서의 데이터라고 해보겠습니다.

182
00:13:06,304 --> 00:13:10,832
천개의 트레이닝세트에 넣을 수 있는
표현방식입니다.

183
00:13:10,832 --> 00:13:13,490
이전 슬라이드 예제에서는 이 수치, 4퍼센트입니다.

184
00:13:13,490 --> 00:13:20,670
여기 있는 이 숫자가 잘하면
트레이닝 오류 수치입니다.

185
00:13:23,320 --> 00:13:26,922
이전 슬라이드 예제에서는 7퍼센트였습니다.

186
00:13:29,705 --> 00:13:33,430
만약 여러분의 러닝 알고리즘이 이 예제를 보았거나

187
00:13:33,430 --> 00:13:37,315
이 예제에 대해 gradient descent를 수행했거나, 
이 예제가 여러분의 트레이닝 세트 분포도에서 왔다고 하면,

188
00:13:37,315 --> 00:13:39,800
또는 어떠한 일반 음성 인식 분포에서 왔다고 하면, 

189
00:13:39,800 --> 00:13:43,980
여러분의 알고리즘이 트레이닝한 example에서 얼마나 잘 작동할까요?

190
00:13:45,114 --> 00:13:53,122
여기는 training-dev set 오류입니다.

191
00:13:53,122 --> 00:13:58,040
보통 이것보다는 큰데요,
이 분포에서 온 데이터를 위한 것입니다.

192
00:13:58,040 --> 00:14:02,950
음성인식의 경우, 이 분포에서 온 example들로 트레이닝 진행된 
알고리즘이 아닌 경우, 

193
00:14:02,950 --> 00:14:05,870
얼마나 잘 작동할까요?

194
00:14:05,870 --> 00:14:08,520
이것을 바로 training dev 오류라고 합니다.

195
00:14:10,700 --> 00:14:14,660
그리고 오른쪽으로 이동하면, 이 박스가 보이시죠,

196
00:14:14,660 --> 00:14:19,200
이것은 dev set 오류입니다. 
또는 test set 오류입니다.

197
00:14:20,548 --> 00:14:25,310
방금 전의 예제에서는 6퍼센트였죠.

198
00:14:25,310 --> 00:14:28,260
dev 와 test 오류는, 엄밀히 이야기하면
2개의 숫자인데요,

199
00:14:28,260 --> 00:14:30,890
2개중 아무거나 1개가 여기 박스에 들어갈 수 있습니다.

200
00:14:32,870 --> 00:14:37,220
이것은 백미러에서 얻은 데이터가 있을때의 이야기입니다.

201
00:14:37,220 --> 00:14:41,270
자동차 백미러 어플에서 실제로 녹음 수집 내용이 있는 경우 말이죠.

202
00:14:41,270 --> 00:14:45,350
그렇지만 여러분의 신경망이 이 예제에 대해 back propagation 을 진행하지 않았습니다. 오류는 무엇일까요?

203
00:14:46,940 --> 00:14:51,230
이전 슬라이드에서 분석하는 것은

204
00:14:51,230 --> 00:14:55,940
이 2가지 숫자의 차이를 보는 것입니다. 그리고 이 2개 숫자 차이를 보구요,
또 이 2개 숫자의 차이를 분석하는 것입니다.

205
00:14:57,380 --> 00:15:01,880
그리고 이 차이는 avoidable bias에 대한 측정입니다.

206
00:15:03,630 --> 00:15:08,020
여기 보이는 차이는 편차의 측정입니다.

207
00:15:08,020 --> 00:15:12,580
그리고 여기서 보이는 차이는 데이터 미스매치의 측정입니다.

208
00:15:13,920 --> 00:15:17,540
그리고 남아있는 2개의 엔트리를 여기 이 테이블에

209
00:15:17,540 --> 00:15:20,010
넣는 것이 유용할 수 있다는 것을 알 수 있습니다.

210
00:15:21,340 --> 00:15:25,270
그렇게해서 만약 이 값이 6퍼센트가 되면,

211
00:15:25,270 --> 00:15:30,146
이 값이 나오는 과정은, 
사람들에게 자동차 백미러 음성 데이터를 

212
00:15:30,146 --> 00:15:33,390
레이블하라 한뒤, 사람들이 얼마나 능숙한지 
측정하면 됩니다.

213
00:15:33,390 --> 00:15:35,180
이것은 6퍼센트 일 수 있습니다.

214
00:15:35,180 --> 00:15:39,260
백미러 음성 데이터를 가지고 와서

215
00:15:39,260 --> 00:15:42,650
트레이닝 세트에 집어 넣습니다. 그리하여
신경망 네트워크가 그 내용을 배울 수 있게 말이죠.

216
00:15:42,650 --> 00:15:46,060
그런 뒤, 그 특정 일부 데이터의 오류를 측정합니다.

217
00:15:46,060 --> 00:15:50,090
그렇게 했는데 이 값이 나오면, 
이미 백미러 음성 인식 데이터 관련

218
00:15:50,090 --> 00:15:54,620
인간레벨의 성능을 보이고 있는 것 입니다.

219
00:15:54,620 --> 00:15:58,550
이 데이터 분포에서는 그러면 꽤 잘하고 있는 것으로
볼 수 있겠죠.

220
00:15:58,550 --> 00:16:03,740
부가적 분석을 하게 되는 경우,
한가지 방향을 항상 뚜렷히 제시하지는 않습니다.

221
00:16:03,740 --> 00:16:07,190
하지만 부가적인 인사이트를 제공하기도 합니다.

222
00:16:07,190 --> 00:16:12,000
예를 들어, 이 경우 2개의 숫자를 비교하여 

223
00:16:12,000 --> 00:16:16,240
인간에게, 자동차 백미러 음성 인식 데이터는 

224
00:16:16,240 --> 00:16:21,550
일반 음성인식보다 어렵다는 것을 알 수 있습니다.
그 이유는 인간이 4퍼센트가 아닌 6퍼센트의 오류값 갖기 때문입니다.

225
00:16:21,550 --> 00:16:25,840
또, 이런 차이들을 보면

226
00:16:25,840 --> 00:16:30,865
편향과 편차를 이해하고 데이터 미스매치 문제에 대한 
내용을 그 정도에 따라 볼 수 있습니다.

227
00:16:30,865 --> 00:16:35,760
이러한 일반적인 공식이 제가 몇번 사용한 방법입니다.

228
00:16:35,760 --> 00:16:41,020
이것은 직접 사용한 적은 없습니다만, 
여러 문제에 대해 

229
00:16:41,020 --> 00:16:46,040
이런 엔트리들의 subset을 검사하여, 이러한 차이를 보고,
여기 이런 차이를 보고,

230
00:16:46,040 --> 00:16:51,230
이런 차이를 보면서, 이 정도면 
유망한 쪽 방향으로 가이드해주는데 충분합니다. 

231
00:16:51,230 --> 00:16:54,840
하지만 이 테이블 전체를 채우는 것이 추가 인사이트를 얻는데 
도움이 될 수 있습니다.

232
00:16:55,910 --> 00:17:02,535
마지막으로, 이전에는 편향을 다룰 수 있는 여러가지 아이디어에 대해 
이야기 했었습니다.

233
00:17:02,535 --> 00:17:05,910
편차를 다루는 방법에 대해서도 이야기 했었는데요, 그렇다면

234
00:17:05,910 --> 00:17:08,720
데이터 미스매치는 어떻게 다룰까요?

235
00:17:08,720 --> 00:17:12,600
dev 와 테스트세트와는 다른 분포에서 온 트레이닝 데이터로

236
00:17:12,600 --> 00:17:15,330
더 많은 데이터를 획득하여

237
00:17:15,330 --> 00:17:17,760
러닝 알고리즘의 성능향상에 도움을 줄 수 있습니다.

238
00:17:17,760 --> 00:17:20,310
편향과 편차의 문제만 있는 것이 아니라

239
00:17:20,310 --> 00:17:24,210
이제 새로운 잠재적인 데이터 미스매치 문제가 생겼습니다.

240
00:17:24,210 --> 00:17:28,460
데이터 미스매치를 해결할 수 있는 
특별히 좋은 방법이 있을까요?

241
00:17:28,460 --> 00:17:30,690
솔직히 말씀드리자면 그닥 많이 있다거나,

242
00:17:30,690 --> 00:17:34,130
적어도 데이터 미스매치를 다룰만한
시스템적인 접근방식이 있다고 하기 어렵습니다.

243
00:17:34,130 --> 00:17:36,540
도움을 줄만한 몇가지 시도할 수 있는 
방법이 있습니다. 

244
00:17:36,540 --> 00:17:38,790
이 부분을 다음 비디오를 통해 보겠습니다.

245
00:17:38,790 --> 00:17:43,200
다른 분포도에서 온 dev와 test 세트와 같은
트레이닝 데이터를 이용해서

246
00:17:43,200 --> 00:17:47,690
이것이 더 많은 데이터를 주기 때문에

247
00:17:47,690 --> 00:17:50,630
러닝 알고리즘 성능향상에 도움을 줄 수 있습니다. 

248
00:17:50,630 --> 00:17:55,070
이러한 편향과 편차와 같은 2가지의 
잠재적인 문제에다가 

249
00:17:55,070 --> 00:17:58,518
이제는 3번째 문제인 데이터 미스매치가 생기게됩니다.

250
00:17:58,518 --> 00:18:02,200
만약 여러분이 오류분석을 통해 

251
00:18:02,200 --> 00:18:05,840
데이터 미스매치가 큰 오류의 원천이라고하면 어떻게 될까요?
이 부분을 어떻게 다룰 수 있을까요?

252
00:18:05,840 --> 00:18:09,730
데이터가 맞지 않는 부분을 지목하기 위한 
super systematic한 방법이 있습니다.

253
00:18:09,730 --> 00:18:14,120
그리고 여러분이 어느정도 도움을 줄 있는 
몇가지 방법 또한 있습니다. 

254
00:18:14,120 --> 00:18:15,820
이 내용은 다음 비디오를 통해 보도록 하겠습니다.