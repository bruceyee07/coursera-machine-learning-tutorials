1
00:00:00,760 --> 00:00:01,970
通过估计学习算法的偏差和方差

2
00:00:01,970 --> 00:00:06,650
能帮你确定下一步工作的优先级

3
00:00:06,650 --> 00:00:11,220
但当你的训练集 开发集 测试集 来自不同的分布时

4
00:00:11,220 --> 00:00:14,570
偏差和方差的分析方法也会相应变化

5
00:00:14,570 --> 00:00:15,140
接下来一起看看如何实现

6
00:00:16,480 --> 00:00:19,650
让我们继续使用猫分类器的例子

7
00:00:19,650 --> 00:00:22,880
假设人类在这个问题上有近乎完美的表现

8
00:00:22,880 --> 00:00:28,620
即贝叶斯误差约等于0%

9
00:00:28,620 --> 00:00:33,530
所以进行误差分析时你通常要兼顾

10
00:00:33,530 --> 00:00:37,030
训练集误差和开发集误差

11
00:00:37,030 --> 00:00:41,490
假设在这个例子中训练集误差为1%

12
00:00:41,490 --> 00:00:45,040
开发集误差为10%

13
00:00:45,040 --> 00:00:49,725
如果开发集和训练集数据 来自同一分布

14
00:00:49,725 --> 00:00:53,125
那说明问题是方差过大

15
00:00:53,125 --> 00:00:56,615
代表虽然算法的训练集表现好

16
00:00:56,615 --> 00:01:01,795
但未能较好地泛化(generalize)到开发集 即开发集表现不好

17
00:01:01,795 --> 00:01:05,335
但如果训练集与开发集的数据来自不同分布的话

18
00:01:05,335 --> 00:01:09,658
你就未必能这样肯定地下结论了

19
00:01:09,658 --> 00:01:13,820
具体来说 也许它在开发集的一般表现

20
00:01:13,820 --> 00:01:18,250
只是因为 高分辨率 非常清晰的图片

21
00:01:18,250 --> 00:01:21,880
造成训练集难度较低 但开发集较难

22
00:01:23,492 --> 00:01:27,610
所以也许不是方差的问题 它只是反映了

23
00:01:27,610 --> 00:01:32,030
开发集的图片更难精确地进行区分这个事实

24
00:01:33,610 --> 00:01:38,220
这时误差分析要注意 当你从训练集误差

25
00:01:38,220 --> 00:01:41,980
转移到开发集误差时 有两件事情变了

26
00:01:41,980 --> 00:01:47,450
一 算法看到的数据只有训练集没有开发集

27
00:01:47,450 --> 00:01:51,080
二 开发集和训练集数据分布不同

28
00:01:51,080 --> 00:01:55,158
因为同时存在两个变量 我们很难判断

29
00:01:55,158 --> 00:02:00,120
这9%的误差 有多少是因为

30
00:02:00,120 --> 00:02:04,660
算法未接触开发集 而影响了方差

31
00:02:04,660 --> 00:02:07,670
又有多少是 因为开发集的数据分布不同

32
00:02:09,300 --> 00:02:14,150
所以 为了辨识出这两个影响

33
00:02:14,150 --> 00:02:17,610
如果你对这两种影响完全不了解 别担心

34
00:02:17,610 --> 00:02:19,490
别担心 我们马上就会说到

35
00:02:19,490 --> 00:02:23,702
为了梳理出这两个影响 我们需要新定义一组数据

36
00:02:23,702 --> 00:02:26,970
叫做训练-开发集(training-dev set)

37
00:02:26,970 --> 00:02:29,430
这是一个新的数据子集

38
00:02:29,430 --> 00:02:34,080
我们要让它与训练集拥有同样的数据分布

39
00:02:34,080 --> 00:02:37,630
但你不用直接拿它来训练你的网络

40
00:02:37,630 --> 00:02:38,690
就是这样子

41
00:02:40,330 --> 00:02:45,220
之前我们已经建立了训练集

42
00:02:45,220 --> 00:02:50,920
训练集和测试集 如图所示

43
00:02:50,920 --> 00:02:53,403
开发集和测试集属于同分布

44
00:02:53,403 --> 00:02:56,710
训练集数据属于不同分布

45
00:02:56,710 --> 00:03:01,640
我们要做的是将训练集随机混淆(shuffle)

46
00:03:01,640 --> 00:03:09,180
取出一小块数据作为训练-开发集

47
00:03:09,180 --> 00:03:14,830
如同开发集与测试集分布相同

48
00:03:14,830 --> 00:03:18,750
训练集与训练-开发集也遵循相同分布

49
00:03:21,290 --> 00:03:24,940
区别在于 现在你只需要用着一部分训练集

50
00:03:24,940 --> 00:03:27,920
训练你的网络

51
00:03:27,920 --> 00:03:29,330
你用让你的神经网络

52
00:03:29,330 --> 00:03:34,660
你需要将训练-开发集用于传播算法

53
00:03:34,660 --> 00:03:36,290
要做误差分析

54
00:03:36,290 --> 00:03:39,310
你要做的是对比分类器的误差

55
00:03:39,310 --> 00:03:43,320
训练集误差 训练-开发集误差和开发集误差

56
00:03:44,500 --> 00:03:51,281
假设在这个例子中训练集误差为1%

57
00:03:53,020 --> 00:04:00,695
训练-开发集的误差是9%

58
00:04:00,695 --> 00:04:07,910
开发集误差为10% 和之前一样

59
00:04:08,910 --> 00:04:13,460
我们可以从中看出

60
00:04:13,460 --> 00:04:17,680
从训练数据到训练-开发数据 误差确实上升了很多

61
00:04:17,680 --> 00:04:22,460
训练数据和训练-开发数据的唯一差别在于

62
00:04:22,460 --> 00:04:27,280
神经网络看到了前者

63
00:04:27,280 --> 00:04:30,610
它在明确地在训练集上训练

64
00:04:30,610 --> 00:04:34,840
但并没有在训练-开发集上直接训练

65
00:04:34,840 --> 00:04:38,320
所以这表明你有方差问题

66
00:04:40,006 --> 00:04:44,230
因为训练-开发误差是在

67
00:04:44,230 --> 00:04:46,290
与训练集同分布的数据上测量的

68
00:04:46,290 --> 00:04:50,490
所以可知 虽然你的神经网络在训练集中做得很好

69
00:04:50,490 --> 00:04:53,980
但它在同分布的训练-开发集上一般化并不好

70
00:04:53,980 --> 00:04:58,280
这些数据虽然来自与训练集相同的分布

71
00:04:58,280 --> 00:05:02,530
但因为一般化得不好 神经网络没能见过

72
00:05:04,020 --> 00:05:07,200
所以这个例子实际上是高方差问题

73
00:05:09,680 --> 00:05:11,510
让我们看一个不同的例子

74
00:05:11,510 --> 00:05:17,613
假设训练集误差为1% 训练-开发集误差为1.5%

75
00:05:17,613 --> 00:05:21,360
但是开发集误差为10%

76
00:05:21,360 --> 00:05:24,805
这就是方差偏小的问题

77
00:05:24,805 --> 00:05:29,798
因为从已经见过的训练集数据

78
00:05:29,798 --> 00:05:34,579
到未见过的训练-开发集 误差只增加了一点点

79
00:05:34,579 --> 00:05:37,550
但是到开发集出现了跃增

80
00:05:37,550 --> 00:05:43,100
所以这是数据不匹配的问题

81
00:05:44,810 --> 00:05:51,840
所以这是数据不匹配的问题

82
00:05:51,840 --> 00:05:55,838
因为你的学习算法没有直接在

83
00:05:55,838 --> 00:06:00,610
训练-开发集或开发集上训练 而两者来自于不同分布

84
00:06:00,610 --> 00:06:01,850
但是无论它在学习什么算法

85
00:06:01,850 --> 00:06:06,230
它在训练-开发集上性能很好但在开发集上却不是这样

86
00:06:06,230 --> 00:06:10,407
所以某种程度上 你的算法并未在你所关心的分布上

87
00:06:10,407 --> 00:06:14,462
训练的很好 所以我们把它叫做失配问题(mismatch problem)

88
00:06:17,505 --> 00:06:20,112
让我们再看几个例子

89
00:06:20,112 --> 00:06:24,663
因为上面已经没位置了 我把这个写在下面一行

90
00:06:24,663 --> 00:06:31,326
训练集误差 训练-开发集误差 开发集误差

91
00:06:33,618 --> 00:06:37,254
假设训练集误差为10%

92
00:06:37,254 --> 00:06:42,210
训练-开发集误差为11% 开发集误差为12%

93
00:06:42,210 --> 00:06:46,507
之前提到的人类水平的

94
00:06:46,507 --> 00:06:50,100
贝叶斯误差为大约0%

95
00:06:50,100 --> 00:06:56,020
如果是这样的表现 其实是偏差问题

96
00:06:56,020 --> 00:07:02,920
即可避免偏差问题 因为性能比人类水平差远了

97
00:07:02,920 --> 00:07:05,810
这确实是个高偏差设置

98
00:07:07,440 --> 00:07:08,830
让我们看看最后一个例子

99
00:07:08,830 --> 00:07:14,211
如果训练集误差是10% 训练-开发集误差为11%

100
00:07:14,211 --> 00:07:19,706
开发集误差是20% 那么看来它存在2个问题

101
00:07:19,706 --> 00:07:24,070
第一 可避免的偏差相当高

102
00:07:24,070 --> 00:07:26,940
因为它甚至在训练集上的表现都不好

103
00:07:26,940 --> 00:07:31,860
人类误差约等于0 但算法在训练集上的误差为10%

104
00:07:31,860 --> 00:07:36,710
虽然方差看上去相当小

105
00:07:38,110 --> 00:07:43,910
但是数据失配程度相当大

106
00:07:43,910 --> 00:07:48,839
所以对于这个例子我会说

107
00:07:48,839 --> 00:07:54,001
偏差或可避免偏差问题以及数据失配问题都很严重

108
00:07:56,479 --> 00:07:59,462
让我们根据这一页的内容

109
00:07:59,462 --> 00:08:01,710
来总结一般原则

110
00:08:02,810 --> 00:08:09,909
要关注的关键数据是人类水平误差

111
00:08:09,909 --> 00:08:14,931
和你的训练集误差

112
00:08:14,931 --> 00:08:19,620
以及训练-开发集误差

113
00:08:21,630 --> 00:08:23,891
虽然它与训练集数据分布相同

114
00:08:23,891 --> 00:08:25,880
但是并没有直接用于训练

115
00:08:25,880 --> 00:08:30,798
根据开发集误差 以及这些误差间的差值

116
00:08:30,798 --> 00:08:35,034
你就能大致了解可避免偏差 方差

117
00:08:35,034 --> 00:08:36,940
以及数据失配的程度

118
00:08:38,840 --> 00:08:40,880
假设人类水平误差为4%

119
00:08:40,880 --> 00:08:43,573
训练集误差为7%

120
00:08:43,573 --> 00:08:46,660
训练-开发集误差为10%

121
00:08:46,660 --> 00:08:50,112
开发集误差为12%

122
00:08:50,112 --> 00:08:54,100
你就能估计可避免偏差

123
00:08:55,170 --> 00:08:58,032
因为你希望你的算法性能在训练集上

124
00:08:58,032 --> 00:09:01,420
能达到或接近于人类水平

125
00:09:01,420 --> 00:09:04,460
这是方差的情况

126
00:09:04,460 --> 00:09:08,790
能将训练集多好地泛化到训练-开发集

127
00:09:10,540 --> 00:09:15,550
这是数据失配的状况

128
00:09:15,550 --> 00:09:18,180
从技术上讲你还可以再加一个

129
00:09:18,180 --> 00:09:21,410
即测试集性能 这里写上test error

130
00:09:21,410 --> 00:09:24,790
你不应该在测试集上做开发 因为你并不想让

131
00:09:24,790 --> 00:09:25,625
算法在测试集上过拟合

132
00:09:25,625 --> 00:09:31,490
但是如果你看看这个差值 就能看出

133
00:09:31,490 --> 00:09:36,212
算法对开发集的过拟合

134
00:09:36,212 --> 00:09:41,460
如果开发集性能和测试集性能差太多

135
00:09:41,460 --> 00:09:45,820
也许你将神经网络调得太偏向(overtune)于开发集了

136
00:09:45,820 --> 00:09:49,450
所以也许你需要找一个更大的开发集

137
00:09:49,450 --> 00:09:53,450
记住 你的开发集和测试集服从相同分布

138
00:09:53,450 --> 00:09:57,170
因为开发集上的表现 要比测试集好太多

139
00:09:57,170 --> 00:10:01,304
所以这个巨大差异的唯一理由是对开发集的过拟合

140
00:10:01,304 --> 00:10:04,630
如果是这样的话 你可能会考虑倒回去

141
00:10:04,630 --> 00:10:06,650
取得更多的开发集数据

142
00:10:06,650 --> 00:10:08,760
我写了这些数字

143
00:10:08,760 --> 00:10:13,830
从上往下数字保持增长

144
00:10:13,830 --> 00:10:17,650
这里有另一个例子 其中数字并非一直增长

145
00:10:17,650 --> 00:10:22,166
也许人类水平性能为4% 训练集误差为7%

146
00:10:22,166 --> 00:10:26,080
训练-开发集误差为10% 但是到了开发集时

147
00:10:26,080 --> 00:10:30,430
你惊讶的发现 开发集的实际误差要小得多

148
00:10:30,430 --> 00:10:34,052
也许都是6%

149
00:10:36,500 --> 00:10:41,110
你看到的是某个语音识别任务的数据

150
00:10:41,110 --> 00:10:45,430
它是这样的效果 即训练集数据甚至

151
00:10:45,430 --> 00:10:48,740
要比开发集和测试集更难学习

152
00:10:48,740 --> 00:10:53,840
所以这两个是训练集分布上的评估

153
00:10:53,840 --> 00:10:57,960
这两个是开发集/测试集分布上的评估

154
00:10:57,960 --> 00:11:02,445
因此 如果有时基于您的应用 开发/测试集分布更容易学习

155
00:11:02,445 --> 00:11:07,062
那么这些数字实际上是会下降的

156
00:11:07,062 --> 00:11:08,768
如果你发现了这样好玩的事

157
00:11:08,768 --> 00:11:13,350
对于这种分析还有一个更通用的公式

158
00:11:13,350 --> 00:11:15,129
让我在下一张幻灯片上快速解释一下

159
00:11:17,420 --> 00:11:21,785
我用语音激活后视镜这个例子

160
00:11:21,785 --> 00:11:26,900
演示一下

161
00:11:26,900 --> 00:11:31,575
实际上 我们写下来的这些数据可以放到一个表中

162
00:11:31,575 --> 00:11:36,935
其中横轴为不同的数据集

163
00:11:36,935 --> 00:11:42,119
例如 你可能有来自常规语音识别任务的数据

164
00:11:43,570 --> 00:11:48,210
你有一堆数据

165
00:11:48,210 --> 00:11:51,646
来自于之前工作过的语音识别任务

166
00:11:51,646 --> 00:11:53,740
也许来自与小型扬声器或者买来的数据

167
00:11:53,740 --> 00:12:00,970
你也有来自后视镜的特定语音数据

168
00:12:00,970 --> 00:12:02,120
记录在车内

169
00:12:04,450 --> 00:12:09,890
所以x轴标记各种数据集

170
00:12:09,890 --> 00:12:16,250
另一个轴标记用于查验数据的

171
00:12:16,250 --> 00:12:18,470
不同方法或算法

172
00:12:18,470 --> 00:12:21,350
首先是人类水平的性能

173
00:12:21,350 --> 00:12:25,980
即在这些数据集上 人类的精确程度是多少

174
00:12:27,010 --> 00:12:31,948
然后是用于神经网络训练的

175
00:12:31,948 --> 00:12:36,210
样例的误差

176
00:12:38,870 --> 00:12:43,686
最后是没有被神经网络训练的

177
00:12:43,686 --> 00:12:47,412
样例的误差

178
00:12:50,036 --> 00:12:55,796
所以上一张幻灯片所说的人类水平

179
00:12:55,796 --> 00:12:59,036
对应于表中的这个位置

180
00:12:59,036 --> 00:13:03,320
它表示人类在这一类数据上的表现

181
00:13:03,320 --> 00:13:06,304
这一部分数据来自于各种语音识别任务

182
00:13:06,304 --> 00:13:10,832
你可以将数以10万计的话语(utterance)放入训练集

183
00:13:10,832 --> 00:13:13,490
上一页的例子中这个值为4%

184
00:13:13,490 --> 00:13:20,670
这个值也许对应训练误差

185
00:13:23,320 --> 00:13:26,922
上一页中对应值为7%

186
00:13:29,705 --> 00:13:33,430
它表示如果你的学习算法看到了这个样例

187
00:13:33,430 --> 00:13:37,315
并用于运行梯度下降法 同时这个样例来自于训练集同分布

188
00:13:37,315 --> 00:13:39,800
或者其他一般语音识别(任务)分布

189
00:13:39,800 --> 00:13:43,980
算法在这个已被训练的样例上的表现如何？

190
00:13:45,114 --> 00:13:53,122
这里是训练-开发集误差

191
00:13:53,122 --> 00:13:58,040
通常要更高一些 它代表这个分布的数据

192
00:13:58,040 --> 00:14:02,950
即一般语音识别分布中 并没有被直接用于训练

193
00:14:02,950 --> 00:14:05,870
的数据上的性能

194
00:14:05,870 --> 00:14:08,520
称作 训练-开发集误差

195
00:14:10,700 --> 00:14:14,660
移到右半边表

196
00:14:14,660 --> 00:14:19,200
这个格子代表开发集误差 也可能是测试集误差

197
00:14:20,548 --> 00:14:25,310
这个例子中对应值为6%

198
00:14:25,310 --> 00:14:28,260
开发集误差和测试集误差技术上来说是两个不同的数值

199
00:14:28,260 --> 00:14:30,890
但是任意其中之一都可以归于这个格子

200
00:14:32,870 --> 00:14:37,220
表示数据来自于后视镜 来自于车辆的真实记录

201
00:14:37,220 --> 00:14:41,270
来自于后视镜应用 但并未被神经网络

202
00:14:41,270 --> 00:14:45,350
用于反向传播训练的样例 这是它的误差

203
00:14:46,940 --> 00:14:51,230
所以我们在上一张ppt中做的分析就是

204
00:14:51,230 --> 00:14:55,940
看这两个 这两个 这两个数据的差

205
00:14:57,380 --> 00:15:01,880
这个差值用于衡量可避免的偏差

206
00:15:03,630 --> 00:15:08,020
这个差值用于衡量方差

207
00:15:08,020 --> 00:15:12,580
这个差值用于衡量数据失配

208
00:15:13,920 --> 00:15:17,540
事实表明剩下的两个表格

209
00:15:17,540 --> 00:15:20,010
也是有用的

210
00:15:21,340 --> 00:15:25,270
如果这个数据是6%

211
00:15:25,270 --> 00:15:30,146
获得这个数据的方法是 邀请一些人为他们的后视镜语音数据

212
00:15:30,146 --> 00:15:33,390
贴标签以衡量人类在这项任务的表现

213
00:15:33,390 --> 00:15:35,180
也许这个数值仍然是6%

214
00:15:35,180 --> 00:15:39,260
然后你要做的是取一些后视镜语音数据

215
00:15:39,260 --> 00:15:42,650
放入训练集中让神经网络学习

216
00:15:42,650 --> 00:15:46,060
然后测量这个数据子集上的误差

217
00:15:46,060 --> 00:15:50,090
如果这是你得到的数据 那么在这个后视镜语音的任务上

218
00:15:50,090 --> 00:15:54,620
你已经得到了人类水平的性能

219
00:15:54,620 --> 00:15:58,550
也许你在这个数据分布上已经做的很好了

220
00:15:58,550 --> 00:16:03,740
当你继续后续的分析时 并不一定总会得到

221
00:16:03,740 --> 00:16:07,190
清晰的前进方向 但是有时它能提供更多的见解

222
00:16:07,190 --> 00:16:12,000
例如 对本例这两个数据的比较可以得出

223
00:16:12,000 --> 00:16:16,240
对人类来说处理后视镜语音数据实际上比

224
00:16:16,240 --> 00:16:21,550
一般语音识别要难 因为人类误差为6%而不是4%

225
00:16:21,550 --> 00:16:25,840
但是这些差异也能帮助你

226
00:16:25,840 --> 00:16:30,865
了解不同程度的偏差和方差以及数据不匹配问题

227
00:16:30,865 --> 00:16:35,760
这个更通用的陈述我曾经用过几次

228
00:16:35,760 --> 00:16:41,020
我还不太习惯？ 但是对很多问题来说

229
00:16:41,020 --> 00:16:46,040
你会发现查验这些项对应的子集

230
00:16:46,040 --> 00:16:51,230
也就是看这个这个这个差值 就足够指出大有希望的方向了

231
00:16:51,230 --> 00:16:54,840
但是有时填充整个表将带来额外的发现

232
00:16:55,910 --> 00:17:02,535
最后 我们之前讨论了很多关于解决偏差的方法

233
00:17:02,535 --> 00:17:05,910
和处理方差的技术

234
00:17:05,910 --> 00:17:08,720
但是如何解决数据失配的问题？

235
00:17:08,720 --> 00:17:12,600
具体来说训练与开发集测试集不同分布的数据

236
00:17:12,600 --> 00:17:15,330
可以为训练提供更多的数据

237
00:17:15,330 --> 00:17:17,760
帮助学习算法获得更好的性能

238
00:17:17,760 --> 00:17:20,310
但是除了偏差和方差问题

239
00:17:20,310 --> 00:17:24,210
现在你又有了新的潜在问题 数据失配

240
00:17:24,210 --> 00:17:28,460
解决数据失配问题又那些好方法？

241
00:17:28,460 --> 00:17:30,690
老实说 实际上并没有很好的

242
00:17:30,690 --> 00:17:34,130
至少是非常系统的处理数据失配的方法

243
00:17:34,130 --> 00:17:36,540
但是有一些事情你可以试试 或者能有帮助

244
00:17:36,540 --> 00:17:38,790
我们下节再讲

245
00:17:38,790 --> 00:17:43,200
这一节我们讲的是使用来自与开发集和测试集

246
00:17:43,200 --> 00:17:47,690
不同分布的训练数据 能提供更多的数据

247
00:17:47,690 --> 00:17:50,630
帮助提高学习算法的性能

248
00:17:50,630 --> 00:17:55,070
但是除了原来仅有的偏差和方差两个潜在问题

249
00:17:55,070 --> 00:17:58,518
你又有了第三个潜在问题 数据失配

250
00:17:58,518 --> 00:18:02,200
那么如果你进行误差分析并得出结论说

251
00:18:02,200 --> 00:18:05,840
数据失配是一个巨大的误差来源 要怎么解决呢？

252
00:18:05,840 --> 00:18:09,730
不幸地 事实上还没有很系统的方法

253
00:18:09,730 --> 00:18:14,120
来解决这个问题 但是还是有一些可能有帮助的事我们可以试试

254
00:18:14,120 --> 00:18:15,820
我们下节将讲到