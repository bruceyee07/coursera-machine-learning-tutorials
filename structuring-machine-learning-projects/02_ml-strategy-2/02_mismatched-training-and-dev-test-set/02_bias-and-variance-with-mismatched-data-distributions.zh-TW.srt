1
00:00:00,760 --> 00:00:01,970
估計偏差跟

2
00:00:01,970 --> 00:00:06,650
變異在您的學習演算法上
真的能幫助您下一步的優先順序

3
00:00:06,650 --> 00:00:11,220
但分析偏差跟變異的方式需要改變
當您的訓練集

4
00:00:11,220 --> 00:00:14,570
的分佈不同於開發跟測試集

5
00:00:14,570 --> 00:00:15,140
我們來看看

6
00:00:16,480 --> 00:00:19,650
讓我們繼續使用貓分類器例子

7
00:00:19,650 --> 00:00:22,880
假設人類可以做到很完美的狀況

8
00:00:22,880 --> 00:00:28,620
所以貝葉斯誤差，或者說貝葉斯最佳化誤差，
我們知道會趨近於 0% 在這個問題

9
00:00:28,620 --> 00:00:33,530
在進行誤差分析時，您通常會看訓練誤差

10
00:00:33,530 --> 00:00:37,030
同時也會看開發集的誤差

11
00:00:37,030 --> 00:00:41,490
假設在這個例子上，您的訓練誤差是 1%

12
00:00:41,490 --> 00:00:45,040
而的開發誤差是 10%

13
00:00:45,040 --> 00:00:49,725
如果您的開發資料來自於
跟訓練集相同的分佈

14
00:00:49,725 --> 00:00:53,125
您會說這裡有大的變異問題

15
00:00:53,125 --> 00:00:56,615
您的演算法無法
很好的一般化

16
00:00:56,615 --> 00:01:01,795
從做得很好的訓練集
到做得很差的開發集

17
00:01:01,795 --> 00:01:05,335
但在設定時您的訓練資料跟開發資料來自於

18
00:01:05,335 --> 00:01:09,658
不同的分佈，
您不能很保險的說這樣的結論

19
00:01:09,658 --> 00:01:13,820
特別是或許它已經在
開發集作用得很好

20
00:01:13,820 --> 00:01:18,250
只是在訓練集上真的很容易
因為這些影像都是高解析度

21
00:01:18,250 --> 00:01:21,880
很清楚的影像，
或許開發集就是比較困難

22
00:01:23,492 --> 00:01:27,610
所以或許這不是變異的問題，而這反應了

23
00:01:27,610 --> 00:01:32,030
開發集包含的影像
是比較難正確的分類

24
00:01:33,610 --> 00:01:38,220
現在問題是在分析時，
當您從訓練誤差

25
00:01:38,220 --> 00:01:41,980
到開發誤差，
兩件事同時發生

26
00:01:41,980 --> 00:01:47,450
其一，在訓練集中演算法看到的資料，
在開發集並沒有見到

27
00:01:47,450 --> 00:01:51,080
其二，開發集的分佈不同

28
00:01:51,080 --> 00:01:55,158
而因為您同時改變了兩件事，
很難去了解這

29
00:01:55,158 --> 00:02:00,120
9% 增加的誤差，
多少來自於因為演算法

30
00:02:00,120 --> 00:02:04,660
在開發集中沒有看到資料，
這是問題中變異的部分

31
00:02:04,660 --> 00:02:07,670
多少來自於因為
開發集的資料就是不同

32
00:02:09,300 --> 00:02:14,150
所以，為了梳理出這兩項影響

33
00:02:14,150 --> 00:02:17,610
如果您還是無法理解這裡有兩項影響，
不用擔心

34
00:02:17,610 --> 00:02:19,490
我們等一下會再談一次

35
00:02:19,490 --> 00:02:23,702
但是為了梳理這兩項影響，定義一個

36
00:02:23,702 --> 00:02:26,970
新的資料集會有幫助，
我們稱之為訓練開發集

37
00:02:26,970 --> 00:02:29,430
這是一個新的資料集

38
00:02:29,430 --> 00:02:34,080
我們挖出來的資料
應該跟訓練集同一分佈

39
00:02:34,080 --> 00:02:37,630
您並不會明顯的在您的網路上訓練
這個資料集

40
00:02:37,630 --> 00:02:38,690
我們意思是

41
00:02:40,330 --> 00:02:45,220
之前，我們設定了一些訓練集，

42
00:02:45,220 --> 00:02:50,920
一些開發集，跟一些測試集如圖

43
00:02:50,920 --> 00:02:53,403
而開發跟測試集
有著同樣的分佈

44
00:02:53,403 --> 00:02:56,710
而訓練集會有一些不同的分佈

45
00:02:56,710 --> 00:03:01,640
我們要做的是隨機洗牌訓練集，
然後挖出一些

46
00:03:01,640 --> 00:03:09,180
訓練集，成為訓練開發集

47
00:03:09,180 --> 00:03:14,830
所以就像開發跟測試集有同樣的分佈，訓練集跟

48
00:03:14,830 --> 00:03:18,750
訓練開發集也有同樣的分佈

49
00:03:21,290 --> 00:03:24,940
不同的是，現在您訓練您的神經網路

50
00:03:24,940 --> 00:03:27,920
只在訓練集上

51
00:03:27,920 --> 00:03:29,330
您並不讓神經網路

52
00:03:29,330 --> 00:03:34,660
您不讓它跑在在訓練開發集上的資料

53
00:03:34,660 --> 00:03:36,290
當進行誤差分析時

54
00:03:36,290 --> 00:03:39,310
您現在應該看您的分類器

55
00:03:39,310 --> 00:03:43,320
在訓練集上，在訓練開發集上，
跟在開發集上

56
00:03:44,500 --> 00:03:51,281
假設在這個例子，您的訓練誤差是 1%

57
00:03:53,020 --> 00:04:00,695
而假設誤差在訓練開發集上是 9%

58
00:04:00,695 --> 00:04:07,910
而在開發集上的誤差是跟之前一樣 10%

59
00:04:08,910 --> 00:04:13,460
您可以下一個結論，當您從

60
00:04:13,460 --> 00:04:17,680
訓練集到訓練開發集，誤差變得很大

61
00:04:17,680 --> 00:04:22,460
而訓練資料跟訓練開發資料的不同

62
00:04:22,460 --> 00:04:27,280
是您的神經網路只在第一個部分作用

63
00:04:27,280 --> 00:04:30,610
它明顯的在這個部分訓練

64
00:04:30,610 --> 00:04:34,840
但並不在訓練開發集上訓練

65
00:04:34,840 --> 00:04:38,320
所以這個告訴您有變異問題

66
00:04:40,006 --> 00:04:44,230
因為訓練開發誤差的資料來源跟

67
00:04:44,230 --> 00:04:46,290
訓練集的分佈是一樣的

68
00:04:46,290 --> 00:04:50,490
所以您知道即使您的神經網路
在訓練集作用得很好

69
00:04:50,490 --> 00:04:53,980
它就是不能一般化得很好到

70
00:04:53,980 --> 00:04:58,280
來自於同一種分佈的訓練開發集上，它不能

71
00:04:58,280 --> 00:05:02,530
一般化得很好到
來自同一分佈的未見過的資料

72
00:05:04,020 --> 00:05:07,200
在這個問題上我們有變異的問題

73
00:05:09,680 --> 00:05:11,510
讓我們來看一個不同的問題

74
00:05:11,510 --> 00:05:17,613
假設訓練誤差是 1%，而訓練開發誤差是 1.5%

75
00:05:17,613 --> 00:05:21,360
但當您到開發集時您的誤差是 10%

76
00:05:21,360 --> 00:05:24,805
現在，您實際上有很低的變異問題

77
00:05:24,805 --> 00:05:29,798
因為當您從您見過資料的訓練資料到

78
00:05:29,798 --> 00:05:34,579
神經網路未曾見過的訓練開發集，
誤差只增加一點點

79
00:05:34,579 --> 00:05:37,550
但它真的跳上升
當您用到開發集時

80
00:05:37,550 --> 00:05:43,100
所以這是資料不匹配的問題，
資料不匹配

81
00:05:44,810 --> 00:05:51,840
所以這是一個資料不匹配的問題

82
00:05:51,840 --> 00:05:55,838
因為您的學習演算法並沒有明顯地訓練在

83
00:05:55,838 --> 00:06:00,610
訓練開發集或者開發集，
但這兩個資料來自於不同的分佈

84
00:06:00,610 --> 00:06:01,850
但不管演算法怎樣學習

85
00:06:01,850 --> 00:06:06,230
它在訓練開發集作用得很好，但在開發集不好

86
00:06:06,230 --> 00:06:10,407
所以您演算法學習得很好
在於不同於

87
00:06:10,407 --> 00:06:14,462
您真正關心的分佈，
所以我們稱之為資料不匹配問題

88
00:06:17,505 --> 00:06:20,112
讓我們再看多一些例子

89
00:06:20,112 --> 00:06:24,663
我寫在下一行，因為上面已經沒位置了

90
00:06:24,663 --> 00:06:31,326
所以訓練誤差，訓練開發誤差，跟開發誤差

91
00:06:33,618 --> 00:06:37,254
假設訓練誤差是 10%

92
00:06:37,254 --> 00:06:42,210
訓練開發誤差是 11%，而開發誤差是 12%

93
00:06:42,210 --> 00:06:46,507
記得人類的誤差，或者

94
00:06:46,507 --> 00:06:50,100
貝葉斯誤差幾乎是 0%

95
00:06:50,100 --> 00:06:56,020
所以如果您有這種表現，
那您真的有偏差問題

96
00:06:56,020 --> 00:07:02,920
一個可以避免的偏差問題，
因為您做的遠比人類做得差

97
00:07:02,920 --> 00:07:05,810
所以這真的是高偏差設定

98
00:07:07,440 --> 00:07:08,830
而最後一個例子

99
00:07:08,830 --> 00:07:14,211
如果您的訓練誤差是 10%，而您的訓練開發誤差是 11%

100
00:07:14,211 --> 00:07:19,706
您的開發誤差是 20%，
看起來您有兩個問題

101
00:07:19,706 --> 00:07:24,070
其一，可避免的偏差相當高

102
00:07:24,070 --> 00:07:26,940
因為您即便在訓練集也做得不好

103
00:07:26,940 --> 00:07:31,860
人類可以做到 0%，
但您的是 10% 的誤差在訓練集

104
00:07:31,860 --> 00:07:36,710
這邊的變異似乎比較小

105
00:07:38,110 --> 00:07:43,910
但這個資料不匹配也很高

106
00:07:43,910 --> 00:07:48,839
所以對於這個問題，我會說，
您有高的偏差或者說

107
00:07:48,839 --> 00:07:54,001
可避免的偏差，
跟資料不匹配問題

108
00:07:56,479 --> 00:07:59,462
所以讓我們拿這些
我們在這張投影片寫下的東西

109
00:07:59,462 --> 00:08:01,710
把它寫成一般的準則

110
00:08:02,810 --> 00:08:09,909
關鍵的值是，我會看人類水準的

111
00:08:09,909 --> 00:08:14,931
誤差，訓練集誤差，

112
00:08:14,931 --> 00:08:19,620
您的訓練開發集誤差，

113
00:08:21,630 --> 00:08:23,891
所以這是跟訓練集一樣的分佈

114
00:08:23,891 --> 00:08:25,880
但您沒有用它們來做訓練

115
00:08:25,880 --> 00:08:30,798
您的開發集誤差，根據這些誤差之間的關係

116
00:08:30,798 --> 00:08:35,034
您可以感覺到，
可避免的偏差，變異，

117
00:08:35,034 --> 00:08:36,940
跟資料不匹配的問題有多大

118
00:08:38,840 --> 00:08:40,880
所以假設人類的誤差是 4%

119
00:08:40,880 --> 00:08:43,573
您的訓練誤差是 7%

120
00:08:43,573 --> 00:08:46,660
您個訓練開發誤差是10%

121
00:08:46,660 --> 00:08:50,112
開發誤差是 12%

122
00:08:50,112 --> 00:08:54,100
所以這給您一些感覺
有關可避免的偏差

123
00:08:55,170 --> 00:08:58,032
因為您要您的演算法能夠做到

124
00:08:58,032 --> 00:09:01,420
至少跟人類的表現類似，
或許在訓練集上

125
00:09:01,420 --> 00:09:04,460
這是變異的感覺

126
00:09:04,460 --> 00:09:08,790
您從訓練集一般化
到訓練開發集做得如何？

127
00:09:10,540 --> 00:09:15,550
這個感覺是有關
資料不匹配的問題有多大

128
00:09:15,550 --> 00:09:18,180
技術上您可以再加上一個

129
00:09:18,180 --> 00:09:21,410
也就是測試集表現，
我們寫成測試誤差

130
00:09:21,410 --> 00:09:24,790
您不應該在測試集上做開發，因為您不要過適

131
00:09:24,790 --> 00:09:25,625
您的測試集

132
00:09:25,625 --> 00:09:31,490
但如果您看這個，那這會告訴您

133
00:09:31,490 --> 00:09:36,212
過適的等級在開發集上

134
00:09:36,212 --> 00:09:41,460
所以如果有很大的不同在於您的開發表現跟

135
00:09:41,460 --> 00:09:45,820
您的測試表現，
它的意思是您或許在開發集調過頭

136
00:09:45,820 --> 00:09:49,450
所以您或許需要大一點的開發集，是吧？

137
00:09:49,450 --> 00:09:53,450
記得您的開發跟測試集
來自於同一種分佈

138
00:09:53,450 --> 00:09:57,170
唯一的方式會造成很大的不同是，
它在開發集做得太好

139
00:09:57,170 --> 00:10:01,304
而在測試集不好，
如果您過適於開發集

140
00:10:01,304 --> 00:10:04,630
如果這樣，您或許考慮回頭

141
00:10:04,630 --> 00:10:06,650
用更多的開發資料

142
00:10:06,650 --> 00:10:08,760
現在，我寫下這些數字

143
00:10:08,760 --> 00:10:13,830
當您往下看這些數字，總是不斷上升

144
00:10:13,830 --> 00:10:17,650
這裡有一個例子，數字不一定總是上升

145
00:10:17,650 --> 00:10:22,166
或許人類誤差是 4%，訓練誤差是 7%

146
00:10:22,166 --> 00:10:26,080
訓練開發誤差是 10%，但假設當您到開發集時

147
00:10:26,080 --> 00:10:30,430
您發現實際上，令人驚訝的，
在開發集上表現很好

148
00:10:30,430 --> 00:10:34,052
或許是 6%, 這個也是 6%

149
00:10:36,500 --> 00:10:41,110
所以您看過像這樣的影響，在

150
00:10:41,110 --> 00:10:45,430
語音辨識的例子，在訓練資料

151
00:10:45,430 --> 00:10:48,740
實際上比開發跟測試集更難

152
00:10:48,740 --> 00:10:53,840
這兩個是評估在您的訓練集分佈而

153
00:10:53,840 --> 00:10:57,960
這兩個是評估在您的開發，測試集分佈

154
00:10:57,960 --> 00:11:02,445
也時候如果您的開發，測試分佈比較簡單

155
00:11:02,445 --> 00:11:07,062
不管是您做什麼應用，這些數字可能往下降

156
00:11:07,062 --> 00:11:08,768
所以如果您看到這樣有趣的數字

157
00:11:08,768 --> 00:11:13,350
甚至有更一般的公式來
做這樣的分析或許更有用

158
00:11:13,350 --> 00:11:15,129
讓我很快的在下一張投影片做解釋

159
00:11:17,420 --> 00:11:21,785
所以，讓我使用語音

160
00:11:21,785 --> 00:11:26,900
啟動後視鏡來做例子

161
00:11:26,900 --> 00:11:31,575
實際上我們寫下來的數字可以放在

162
00:11:31,575 --> 00:11:36,935
一個表格上，在橫軸，我放不同的資料集

163
00:11:36,935 --> 00:11:42,119
舉個例子，您或許有些資料
從一般語音辨識來的

164
00:11:43,570 --> 00:11:48,210
所以您或許有一堆資料是您從很多

165
00:11:48,210 --> 00:11:51,646
語音辨識問題來的，像是從小的麥克風

166
00:11:51,646 --> 00:11:53,740
或是您購買的資料等等

167
00:11:53,740 --> 00:12:00,970
然後您也有特定從後視鏡來的語音資料

168
00:12:00,970 --> 00:12:02,120
在車子裏紀錄下來的

169
00:12:04,450 --> 00:12:09,890
所以在這個表格的 x 軸，
我將放不同的資料集

170
00:12:09,890 --> 00:12:16,250
另一軸，我會放不同的

171
00:12:16,250 --> 00:12:18,470
演算法來檢驗這些資料

172
00:12:18,470 --> 00:12:21,350
第一：人類的表現水準

173
00:12:21,350 --> 00:12:25,980
也就是人類在每個資料集
的精確度

174
00:12:27,010 --> 00:12:31,948
然後是誤差發生在由

175
00:12:31,948 --> 00:12:36,210
您神經網路訓練的例子上

176
00:12:38,870 --> 00:12:43,686
最後是誤差在

177
00:12:43,686 --> 00:12:47,412
您的神經網路並沒有在上面訓練的例子上

178
00:12:50,036 --> 00:12:55,796
實際上我們在前面投影片中
稱為人類表現水準

179
00:12:55,796 --> 00:12:59,036
的數字放進這個框框

180
00:12:59,036 --> 00:13:03,320
也就是人類可以
在這類資料做得如何

181
00:13:03,320 --> 00:13:06,304
像是從不同的方式
來的語音辨識資料

182
00:13:06,304 --> 00:13:10,832
有上十萬個語音您可以
在訓練集中找出

183
00:13:10,832 --> 00:13:13,490
在前面的例子這個是 4%

184
00:13:13,490 --> 00:13:20,670
這個數字是我們的訓練誤差

185
00:13:23,320 --> 00:13:26,922
在前面投影片中的例子是7%

186
00:13:29,705 --> 00:13:33,430
對，如果您的學習演算法看了這些例子，進行了

187
00:13:33,430 --> 00:13:37,315
梯度下降法在這些例子上，
而這些例子來自於您的訓練集分佈

188
00:13:37,315 --> 00:13:39,800
或者一般語音辨識分佈

189
00:13:39,800 --> 00:13:43,980
您的演算法在這些例子
作用得如何？

190
00:13:45,114 --> 00:13:53,122
這裡是訓練開發集誤差

191
00:13:53,122 --> 00:13:58,040
它通常比較高，資料來自於這種分佈

192
00:13:58,040 --> 00:14:02,950
來自於一般語音辨識例子，
如果您的演算法沒有明顯地

193
00:14:02,950 --> 00:14:05,870
在這種分佈上訓練過，
它會做得怎樣？

194
00:14:05,870 --> 00:14:08,520
而那是我們稱之為訓練開發誤差

195
00:14:10,700 --> 00:14:14,660
然後您移到右邊，這個框框裡

196
00:14:14,660 --> 00:14:19,200
是開發集誤差，或許也是測試集誤差

197
00:14:20,548 --> 00:14:25,310
也就是在例子中的 6%

198
00:14:25,310 --> 00:14:28,260
而開發跟測試誤差，實際上是兩種數字

199
00:14:28,260 --> 00:14:30,890
但任何一個都可以放在這個框框裡

200
00:14:32,870 --> 00:14:37,220
而這是如果您的資料來自於後視鏡，真正從

201
00:14:37,220 --> 00:14:41,270
車子個後視鏡應用紀錄下來的，
但您的神經網路

202
00:14:41,270 --> 00:14:45,350
並沒有進行反向傳播在這些例子上，
誤差如何？

203
00:14:46,940 --> 00:14:51,230
所以我們在前面投影片分析中看到

204
00:14:51,230 --> 00:14:55,940
這兩個數字，這兩個數字
跟這兩個數字的不同

205
00:14:57,380 --> 00:15:01,880
而這個差距是用來評估可避免的偏差

206
00:15:03,630 --> 00:15:08,020
這個差距是評估變異

207
00:15:08,020 --> 00:15:12,580
這個差距是評估資料不匹配性

208
00:15:13,920 --> 00:15:17,540
實際上我們還可以放進

209
00:15:17,540 --> 00:15:20,010
這表格上其他兩個數字，
可能也是有用的

210
00:15:21,340 --> 00:15:25,270
如果這個實際上是 6%

211
00:15:25,270 --> 00:15:30,146
而您獲取這種資料方式是
要一些人來標籤這些從後視鏡

212
00:15:30,146 --> 00:15:33,390
語音資料，來看看
人們在這個資料表現如何

213
00:15:33,390 --> 00:15:35,180
或許這個也會是 6%

214
00:15:35,180 --> 00:15:39,260
而獲取這個數字的方式是
您拿一些後視鏡語音資料

215
00:15:39,260 --> 00:15:42,650
將它們放在訓練集，
所以神經網路也學習它們

216
00:15:42,650 --> 00:15:46,060
然後您測量在這個資料集的誤差

217
00:15:46,060 --> 00:15:50,090
但如果這是您得到的結果，實際上您已經

218
00:15:50,090 --> 00:15:54,620
表現得跟人類一樣的水準
在後視鏡的語音資料

219
00:15:54,620 --> 00:15:58,550
或許您真的在這種分佈的資料
已經做得很好了

220
00:15:58,550 --> 00:16:03,740
當您做多一點後續的分析，並不保證會給您

221
00:16:03,740 --> 00:16:07,190
明確的道路前行，
但有時候會給您一些額外的見解

222
00:16:07,190 --> 00:16:12,000
舉個例子，對照這兩個數字
在這個例子裡，告訴我們

223
00:16:12,000 --> 00:16:16,240
人們在後視鏡語音資料實際上比

224
00:16:16,240 --> 00:16:21,550
一般語音辨識資料要難，因為
人類得到 6% 誤差，而不是 4%誤差

225
00:16:21,550 --> 00:16:25,840
但看這些差距也許會幫助您

226
00:16:25,840 --> 00:16:30,865
理解不同程度的偏差，變異
跟資料不匹配問題

227
00:16:30,865 --> 00:16:35,760
所以這種比較一般化的公式，
我使用過幾次

228
00:16:35,760 --> 00:16:41,020
我沒有使用它，因為您可以發現很多的問題從檢驗

229
00:16:41,020 --> 00:16:46,040
這部份的數字，看看這個差距，這個差距

230
00:16:46,040 --> 00:16:51,230
這個差距，已經足夠指引您很好的方向

231
00:16:51,230 --> 00:16:54,840
但有時候把這個表格填滿，
可以給您一些額外的見解

232
00:16:55,910 --> 00:17:02,535
最後，我們前面談過很多有關處理偏差的想法

233
00:17:02,535 --> 00:17:05,910
談過一些處理變異的技巧

234
00:17:05,910 --> 00:17:08,720
但您要怎麼處理資料不匹配？

235
00:17:08,720 --> 00:17:12,600
特別是訓練的資料來自於跟

236
00:17:12,600 --> 00:17:15,330
開發跟測試不同的分佈，
可以給您更多的資料

237
00:17:15,330 --> 00:17:17,760
真的幫助您的學習演算法的表現

238
00:17:17,760 --> 00:17:20,310
但除了偏差跟變異的問題

239
00:17:20,310 --> 00:17:24,210
您現在有這個新的潛在的
資料不匹配問題

240
00:17:24,210 --> 00:17:28,460
有什麼好的方式來
處理資料不匹配

241
00:17:28,460 --> 00:17:30,690
誠實的說，沒有真正很棒的

242
00:17:30,690 --> 00:17:34,130
或者很系統化方式
來處理資料不匹配

243
00:17:34,130 --> 00:17:36,540
但有些方式您可以試試，可能有所幫助

244
00:17:36,540 --> 00:17:38,790
讓我們再下一段影片
看看這些方式

245
00:17:38,790 --> 00:17:43,200
我們看到使用訓練資料來自於

246
00:17:43,200 --> 00:17:47,690
跟開發，測試集不同的分佈，
可以給您很多的資料

247
00:17:47,690 --> 00:17:50,630
進而幫助您學習演算法的表現

248
00:17:50,630 --> 00:17:55,070
但除了只有偏差跟變異的兩個潛在問題

249
00:17:55,070 --> 00:17:58,518
您現在有第三種潛在的問題，資料不匹配

250
00:17:58,518 --> 00:18:02,200
所以如果做完誤差分析，
結果發現有資料不匹配問題怎麼辦？

251
00:18:02,200 --> 00:18:05,840
這是一個巨大的錯誤來源，
您如何來處理這個問題？

252
00:18:05,840 --> 00:18:09,730
實際上，不幸的沒有超級系統化方法

253
00:18:09,730 --> 00:18:14,120
來處理資料不匹配，但有一些事情
您可以試看看有沒有幫助

254
00:18:14,120 --> 00:18:15,820
我們在下一段影片
來看看這些方式