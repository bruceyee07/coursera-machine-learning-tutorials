러닝 알고리즘의 편향과 편차의 값을 예측하는 것은 다음에 어떤 업무를 수행해야할지 업무 순위를
결정하는데 도움을 줍니다. 하지만 여러분의 트레이닝세트가 dev 와 테스트세트와 비교하여 다른 분포도에서 오는 경우에는 편향,편차를 분석하는 방법이 달라집니다. 한번 살펴보겠습니다. 계속해서 고양이 인식기능 예제로 살펴보겠습니다. 이 기능에서 인간은 거의 완벽에 가까운 능력을 보인다고 가정해봅시다. 그러면 Bayes error 또는 Bayes optimal error가
이 문제의 경우 0퍼센트임을 알 수 있습니다. 오류 분석을 하기 위해서는 보통 트레이닝 오류를 보고 dev set의 오류 또한 보게됩니다. 그러면, 이번 예제에서 트레이닝 오류가 1퍼센트라고 해보겠습니다. 그리고 dev error는 10퍼센트입니다. 만약 dev 데이터가 트레이닝세트와 동일한 분포에서 왔다고하면, 이 경우에는 아주 큰 편차를 갖는 문제가 생길 것입니다. 트레이닝세트를 여러분의 알고리즘이 잘 일반화시키지 못하는 것이죠. dev set에서는 잘하는데, 갑자기 잘 못하게 되는 것입니다. 하지만 트레이닝 데이터와 dev data가 다른 분포도에서 오는 세팅값에서는 이렇게 쉽게 단정 지을 수 없습니다. 특히, dev 세트에서는 아주 잘 작동할 수도 있습니다. 트레이닝세트에서는 고화질의 이미지로 아주 쉬운 업무였을 수도 있습니다. 아주 선명한 이미지일 수 있구요. 하지만 dev 세트는 훨씬 더 어렵게 되는 것이죠. 물론 편향의 문제가 없을 수도 있고 이런 경우는 dev 세트가 분류하기 훨씬 더 까다로운 이미지들로 이루어져 있다고 
볼 수도 있습니다. 분석의 문제는 이렇듯이 트레이닝 오류에서 dev 오류로 넘어갈때, 2가지가 한번에 바뀌었습니다. 첫번째로는 알고리즘이 트레이닝세트에 있는 데이터는 보았지만
dev set에 있는 데이터는 보지 못했습니다. 두번째로, dev set에 있는 데이터의 분포도는 다릅니다. 그리고 여러분이 2가지를 한번에 바꾸었기 때문에, 9 퍼센트로 증가한 오류 중, 얼마만큼이 
알고리즘이 dev set에 있는 데이터를 못봐서 생기는 오류인지, 이것은 편차에서 오는 문제겠죠. 아니면 얼마만큼의 오류가 단순히 dev set 데이터가 다르기 때문에 
생기는 오류인지 구분하기가 쉽지 않습니다. 이런 2가지의 효과를 추출하기 위해, 만약 2가지의 효과를 잘 이해하지 못하셨으면 걱정하지 마십시요 곧 다시한번 이야기 하겠습니다. 이런 효과들을 추출하기 위해서는
training-dev set라고 새로 특정 데이터를 정의하는 것이 도움이 될 것입니다. 이것이 새로운 데이터의 부분집합인데요. 일부 추출해서 빼낸 이 데이터는 트레이닝 세트와 
동일한 분포도를 가질 것입니다. 하지만 여러분의 네트워크에서 따로 트레이닝 시키는 데이터는 아닙니다. 무슨 뜻인지 알려드리겠습니다. 그래서 이것이 뜻하는 것은 다음과 같습니다. 이전에는 일정 트레이닝세트와 dev set, 그리고 데스트세트들을 이렇게 세팅했었습니다. 그리고 dev 와 테스트세트들은 똑같은 분포도를 가졌었는데요. 트레이닝세트는 다른 분포도를 가질 것입니다. 저희는 트레이닝세트들을 무작위로 섞어서 일부 트레이닝세트를 추출해서 trainin-dev set라고 할 것입니다. 그러면 dev와 테스트세트가 동일한 분포도로 되어있듯이, 트레이닝세트와 training-dev set도 마찬가지로 동일한 분포도로 되어 있을 것입니다. 하지만 다른점은, 이제 여러분이 트레이닝 세트에서만 제대로 신경망을 트레이닝 시킨다는 점입니다. 신경망을 training-dev 부분에서는 따로 트레이닝 시키지 않을 것입니다. 오류분석을 하기위해서는, 트레이닝세트에서 인식기의 오류를 보고, 또 training-dev set에서 보고, 또 dev set에서도 볼 것입니다. 그럼 이번 예제에서는 트레이닝 오류가 1퍼센트가 해봅시다. 그리고 training-dev set에서의 오류는 9퍼센트라고 해봅시다. 또한 dev set에서의 오류가 10퍼센트라고 해봅시다. 이전과 마찬가지로 말이죠. 여기서 결론 내릴 수 있는 것은, 트레이닝 데이터에서 training dev 데이터로 넘어갈 때, 
오류가 확실히 많이 증가했다는 것입니다. 그리고 트레이닝 데이터와 training-dev 데이터의 유일한 차이는 여러분의 신경망이 이 부분의 첫번째 부분을 정리했다는 것입니다. 여기에서는 명백하게 트레이닝 되었는데요, 하지만 training-dev data에서 명백히 트레이닝 되지는 않았습니다. 이런 부분은 바로 편차문제가 있음을 말해주는데요. training-dev 오류가 트레이닝세트와 같은 분포도를 가진 데이터로 측정되었기 때문에 그렇습니다. 이제 여러분의 신경망이 트레이닝세트에서 잘 작동하더라도 training-dev의 데이터에는 잘 일반화가 되지 않는다는 점을 알게되었습니다. 같은 분포에서 온 training-dev 세트에서 말이죠. 처음 보는 익숙하지 않은, 같은 분포를 갖는 데이터에 일반화가 잘 되지 않습니다. 이 예제에서는 그렇기 때문에 편차의 문제가 보입니다. 또 다른 예제를 보겠습니다. 트레이닝 오류가 1퍼센트, 
training-dev 오류가 1.5퍼센트라고 해보죠. 그런데 dev set에서는 오류가 10퍼센트입니다. 이 경우, 꽤 낮은 편차의 문제입니다. 그 이유는, 이미 본 적이 있는 트레이닝 데이터에서 
신경 네트워크가 본 적이 없는 training-dev 데이터로 가는데 오류가 조금만 오릅니다. 그 이후, dev set로 가자 갑자기 점프하여 오릅니다. 이것이 전형적인 데이터 미스매치 문제입니다. 데이터가 일치하지 않는 경우이죠. 여러분의 러닝 알고리즘이 명백히 training-dev 나 dev에서의 데이터로 
트레이닝 된 것이 아니기 때문에, 데이터 미스매치 문제라고 볼 수 있습니다.
이 2개 데이터세트는 서로 다른 분포도를 가지고 있습니다. 어떤 알고리즘을 학습하고 있더라도, training-dev에선 잘 작동하고, 
dev에서는 잘 작동하지 않는 것입니다. 어떻게 해서 여러분의 알고리즘이 
분포도가 다른 곳에서 생각하는 것보다 더 잘 작동하는 법을 배우게 된 것입니다.
우리는 이것을 데이터 미스매치 문제라고 부릅니다. 몇개의 다른 예제를 보겠습니다. 위에 공간이 부족하니 이 내용은 다음 줄에 적겠습니다. 자 그럼, training error,Training-Dev error, 그리고 Dev error입니다. 트레이닝 오류가 10퍼센트라고 해봅시다. training-dev 오류는 11퍼센트, 
dev 오류는 12퍼센트이구요. 기억하시겠지만, Bayes error에 대한 인간레벨 프록시 값은 대략 0퍼센트입니다. 이런 류의 성능이 있다면, 편향이 생기는데요 avoidable bias problem이 말이죠, 그 이유는
인간레벨보다 더 못한 성능이기 때문이죠. 그러면 이것은 high bias setting값을 갖게 되는 것입니다. 마지막 예입니다. 트레이닝 오류가 10퍼센트,
training-dev 오류가 11퍼센트 그리고 dev 오류가 20퍼센트이면
2가지 이슈가있어 보입니다. 첫째로, avoidable bias가 꽤 높습니다. 트레이닝세트에서 조차 그리 잘하고 있지 않기 때문이죠. 인간은 0퍼센트 오류인 반면 여러분은 10퍼센트의 오류가
트레이닝 세트에서 발생하기 때문이죠. 편차는 조금 작아보이는데요. 이 데이터미스매치는 그러나 꽤 큽니다. 이 예제에서는, 편향이 꽤 크고, 또는 avoidable bias problem이 말이죠.
그리고 데이터미스매치 문제도 있다고 말할 것입니다. 이 슬라이드에서 다룬 내용을 보고 제너럴한 원리를 적어보겠습니다. 가장 핵심적으로 볼 부분은 인간레벨 오류, 여러분의 트레이닝 세트 오류, 그리고 여러분의 trainin-dev set 오류 입니다. 그것은 트레이닝 세트와 동일한 분포를 갖는데요. 여러분이 명백히 거기서 트레이닝 시키지는 않았습니다. 이러한 오류의 차이에 따라서, 여러분의 dev set오류가, avoidable bias와 편차가 얼마나 큰지 감을 잡을 수 있습니다. 그리고 데이터 미스매치 문제도 말이죠, 자 그럼, 인간레벨 오류가 4퍼센트라고 해봅시다. 트레이닝 오류는 7퍼센트이구요 training-dev 오류는 10퍼센트입니다. 그리고 dev 오류는 12퍼센트입니다. 이를 통해서 avoidable bias에 대한 감이 오실텐데요. 그 이유는 여러분은 알고리즘이 인간레벨성능 
만큼 또는 그 수준과 근접하는 만큼 트레이닝 세트에서 작동하길 바랄 것이므로 그렇습니다. 이건은 편차의 대한 것인데요. 얼마나 트레이닝세트에서 training-dev set로 일반화가 될까요? 이것은 데이터 미스매치가 얼마만큼 있는지를 알려주는 척도입니다. 엄밀히 이야기하면, 
한가지를 추가할 수 있습니다. 바로 테스트 세트 성능입니다.
test error를 적겠습니다. 테스트세트에서는 개발을 진행하지 않는 것이 좋습니다. 
자칫해서 테스트세트를 overfit하는 일이 없도록 해야하니깐요. 하지만 이것을 보면,
이 차이가 dev set에 overfit하는 정도를 말해줍니다. 만약 dev set performance와 여러분의 테스트세트 성능이 큰 차이가 있으면 
dev set를 오버튜닝 했다는 소리일 수 있습니다. 이런 경우, 더 큰 dev set를 찾아야 하겠죠? 여러분도 기억하시겠지만 dev set와 여러분의 테스트세트는
같은 분포를 갖고 있습니다. 그러므로 여기 서로 큰 차이가 날 수 잇는 유일한 방법은
테스트세트에서보다 dev set에서 훨씬 더 잘 작동하는 경우, 
즉, 어떻게서든 dev set를 overfit했을 시 발생합니다. 만약 이런 경우, 고려하실 수 있는 부분은 다시 돌아가서 dev set 데이터를 더 수집하는 것입니다. 자 여기 이렇게 숫자를 적었는데요. 숫자 리스트를 따라 내려갈때, 
숫자는 항상 올라가십시요. 여기 항상 올라가지는 않는 경우의 숫자 예시입니다. 인간레벨성능이 4퍼센트, 
트레이닝 오류가 7퍼센트, training-dev 오류가 10퍼센트인경우,
dve set로 간다고 해봅시다. 놀랍게도, dev set에서 더 작 작동하는 점을 
발견했다고 해봅시다. 이것은 6퍼센트, 이것도 6퍼센트입니다. 이런 효과를 본 적이 있으실텐데요, 음성인식 업무에서 트레이닝 데이터가 dev set와 테스트세트보다 훨씬 더 어려워진 경우 말이죠. 이 2개는 트레이닝 세트 분포에서 평가됐고, 여기 2개는 dev/test set 분포에서 평가됐습니다. 그래서 가끔은 dev/test 세트 분포가 
여러분이 작업하는 어플에서 더 쉬운경우, 이 숫자는 실제로 내려갈 수 있습니다. 그렇기 때문에 만약 여러분이 이런 웃기게 생긴 것을 보면, 이런 분석에 대한 도움이 될만한 더욱 일반적인 공식이 있습니다. 다음 슬라이드에서 간략히 이야기해보겠습니다. speech activated rear-view 거울(백미러)에 대한 예제로 동기부여를 시켜드리도록 하겠습니다. 여러분이 쓰고 있던 숫자들을 테이블화 시킬 수 있는데요. 
가로줄에는 여러가지 이런 데이터 세트를 놓겠습니다. 예를 들어, 일반 음성 인식 업무에서 가지고 온 데이터가 있을 수 있습니다. 조금한 스피커를 가지고 여러가지 음성인식 문제에서 수집한 뭉치의 데이터가 있을 수 있는데요, 또는 구매한 데이터 등 말이죠. 또한, 백미러와 관련된 특화 스피치 데이터가 있습니다. 차 내부에 내장된 데이터 말이죠. 그러므로 여기 테이블 x축에는
데이터세트를 변형시킬 것입니다. 여기 다른 축에는
데이터를 검사하는 다른 방법들이나 알고리즘을 나타낼 것입니다. 첫번째로, 인간레벨 성능이 있습니다. 이 데이터세트들에서 인간이 얼마나 정확한지 알아보는 방법입니다. 또, 신경망 네트워크가 트레이닝한 examples의 오류가 있습니다. 마지막으로 신경망이 트레이닝하지 않은 example들의 오류가 있습니다. 이전 슬라이드에서 언급했던 인간레벨에서 여기 이 박스로 오는 숫자가 있습니다. 이 카테고리의 데이터에서 인간이 얼마나 잘하는지에 대한
수치입니다. 각종 음성인식 업무에서의 데이터라고 해보겠습니다. 천개의 트레이닝세트에 넣을 수 있는
표현방식입니다. 이전 슬라이드 예제에서는 이 수치, 4퍼센트입니다. 여기 있는 이 숫자가 잘하면
트레이닝 오류 수치입니다. 이전 슬라이드 예제에서는 7퍼센트였습니다. 만약 여러분의 러닝 알고리즘이 이 예제를 보았거나 이 예제에 대해 gradient descent를 수행했거나, 
이 예제가 여러분의 트레이닝 세트 분포도에서 왔다고 하면, 또는 어떠한 일반 음성 인식 분포에서 왔다고 하면, 여러분의 알고리즘이 트레이닝한 example에서 얼마나 잘 작동할까요? 여기는 training-dev set 오류입니다. 보통 이것보다는 큰데요,
이 분포에서 온 데이터를 위한 것입니다. 음성인식의 경우, 이 분포에서 온 example들로 트레이닝 진행된 
알고리즘이 아닌 경우, 얼마나 잘 작동할까요? 이것을 바로 training dev 오류라고 합니다. 그리고 오른쪽으로 이동하면, 이 박스가 보이시죠, 이것은 dev set 오류입니다. 
또는 test set 오류입니다. 방금 전의 예제에서는 6퍼센트였죠. dev 와 test 오류는, 엄밀히 이야기하면
2개의 숫자인데요, 2개중 아무거나 1개가 여기 박스에 들어갈 수 있습니다. 이것은 백미러에서 얻은 데이터가 있을때의 이야기입니다. 자동차 백미러 어플에서 실제로 녹음 수집 내용이 있는 경우 말이죠. 그렇지만 여러분의 신경망이 이 예제에 대해 back propagation 을 진행하지 않았습니다. 오류는 무엇일까요? 이전 슬라이드에서 분석하는 것은 이 2가지 숫자의 차이를 보는 것입니다. 그리고 이 2개 숫자 차이를 보구요,
또 이 2개 숫자의 차이를 분석하는 것입니다. 그리고 이 차이는 avoidable bias에 대한 측정입니다. 여기 보이는 차이는 편차의 측정입니다. 그리고 여기서 보이는 차이는 데이터 미스매치의 측정입니다. 그리고 남아있는 2개의 엔트리를 여기 이 테이블에 넣는 것이 유용할 수 있다는 것을 알 수 있습니다. 그렇게해서 만약 이 값이 6퍼센트가 되면, 이 값이 나오는 과정은, 
사람들에게 자동차 백미러 음성 데이터를 레이블하라 한뒤, 사람들이 얼마나 능숙한지 
측정하면 됩니다. 이것은 6퍼센트 일 수 있습니다. 백미러 음성 데이터를 가지고 와서 트레이닝 세트에 집어 넣습니다. 그리하여
신경망 네트워크가 그 내용을 배울 수 있게 말이죠. 그런 뒤, 그 특정 일부 데이터의 오류를 측정합니다. 그렇게 했는데 이 값이 나오면, 
이미 백미러 음성 인식 데이터 관련 인간레벨의 성능을 보이고 있는 것 입니다. 이 데이터 분포에서는 그러면 꽤 잘하고 있는 것으로
볼 수 있겠죠. 부가적 분석을 하게 되는 경우,
한가지 방향을 항상 뚜렷히 제시하지는 않습니다. 하지만 부가적인 인사이트를 제공하기도 합니다. 예를 들어, 이 경우 2개의 숫자를 비교하여 인간에게, 자동차 백미러 음성 인식 데이터는 일반 음성인식보다 어렵다는 것을 알 수 있습니다.
그 이유는 인간이 4퍼센트가 아닌 6퍼센트의 오류값 갖기 때문입니다. 또, 이런 차이들을 보면 편향과 편차를 이해하고 데이터 미스매치 문제에 대한 
내용을 그 정도에 따라 볼 수 있습니다. 이러한 일반적인 공식이 제가 몇번 사용한 방법입니다. 이것은 직접 사용한 적은 없습니다만, 
여러 문제에 대해 이런 엔트리들의 subset을 검사하여, 이러한 차이를 보고,
여기 이런 차이를 보고, 이런 차이를 보면서, 이 정도면 
유망한 쪽 방향으로 가이드해주는데 충분합니다. 하지만 이 테이블 전체를 채우는 것이 추가 인사이트를 얻는데 
도움이 될 수 있습니다. 마지막으로, 이전에는 편향을 다룰 수 있는 여러가지 아이디어에 대해 
이야기 했었습니다. 편차를 다루는 방법에 대해서도 이야기 했었는데요, 그렇다면 데이터 미스매치는 어떻게 다룰까요? dev 와 테스트세트와는 다른 분포에서 온 트레이닝 데이터로 더 많은 데이터를 획득하여 러닝 알고리즘의 성능향상에 도움을 줄 수 있습니다. 편향과 편차의 문제만 있는 것이 아니라 이제 새로운 잠재적인 데이터 미스매치 문제가 생겼습니다. 데이터 미스매치를 해결할 수 있는 
특별히 좋은 방법이 있을까요? 솔직히 말씀드리자면 그닥 많이 있다거나, 적어도 데이터 미스매치를 다룰만한
시스템적인 접근방식이 있다고 하기 어렵습니다. 도움을 줄만한 몇가지 시도할 수 있는 
방법이 있습니다. 이 부분을 다음 비디오를 통해 보겠습니다. 다른 분포도에서 온 dev와 test 세트와 같은
트레이닝 데이터를 이용해서 이것이 더 많은 데이터를 주기 때문에 러닝 알고리즘 성능향상에 도움을 줄 수 있습니다. 이러한 편향과 편차와 같은 2가지의 
잠재적인 문제에다가 이제는 3번째 문제인 데이터 미스매치가 생기게됩니다. 만약 여러분이 오류분석을 통해 데이터 미스매치가 큰 오류의 원천이라고하면 어떻게 될까요?
이 부분을 어떻게 다룰 수 있을까요? 데이터가 맞지 않는 부분을 지목하기 위한 
super systematic한 방법이 있습니다. 그리고 여러분이 어느정도 도움을 줄 있는 
몇가지 방법 또한 있습니다. 이 내용은 다음 비디오를 통해 보도록 하겠습니다.