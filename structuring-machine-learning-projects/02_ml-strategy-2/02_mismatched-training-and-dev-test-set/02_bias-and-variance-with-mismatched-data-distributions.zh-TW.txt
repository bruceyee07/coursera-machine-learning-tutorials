估計偏差跟 變異在您的學習演算法上
真的能幫助您下一步的優先順序 但分析偏差跟變異的方式需要改變
當您的訓練集 的分佈不同於開發跟測試集 我們來看看 讓我們繼續使用貓分類器例子 假設人類可以做到很完美的狀況 所以貝葉斯誤差，或者說貝葉斯最佳化誤差，
我們知道會趨近於 0% 在這個問題 在進行誤差分析時，您通常會看訓練誤差 同時也會看開發集的誤差 假設在這個例子上，您的訓練誤差是 1% 而的開發誤差是 10% 如果您的開發資料來自於
跟訓練集相同的分佈 您會說這裡有大的變異問題 您的演算法無法
很好的一般化 從做得很好的訓練集
到做得很差的開發集 但在設定時您的訓練資料跟開發資料來自於 不同的分佈，
您不能很保險的說這樣的結論 特別是或許它已經在
開發集作用得很好 只是在訓練集上真的很容易
因為這些影像都是高解析度 很清楚的影像，
或許開發集就是比較困難 所以或許這不是變異的問題，而這反應了 開發集包含的影像
是比較難正確的分類 現在問題是在分析時，
當您從訓練誤差 到開發誤差，
兩件事同時發生 其一，在訓練集中演算法看到的資料，
在開發集並沒有見到 其二，開發集的分佈不同 而因為您同時改變了兩件事，
很難去了解這 9% 增加的誤差，
多少來自於因為演算法 在開發集中沒有看到資料，
這是問題中變異的部分 多少來自於因為
開發集的資料就是不同 所以，為了梳理出這兩項影響 如果您還是無法理解這裡有兩項影響，
不用擔心 我們等一下會再談一次 但是為了梳理這兩項影響，定義一個 新的資料集會有幫助，
我們稱之為訓練開發集 這是一個新的資料集 我們挖出來的資料
應該跟訓練集同一分佈 您並不會明顯的在您的網路上訓練
這個資料集 我們意思是 之前，我們設定了一些訓練集， 一些開發集，跟一些測試集如圖 而開發跟測試集
有著同樣的分佈 而訓練集會有一些不同的分佈 我們要做的是隨機洗牌訓練集，
然後挖出一些 訓練集，成為訓練開發集 所以就像開發跟測試集有同樣的分佈，訓練集跟 訓練開發集也有同樣的分佈 不同的是，現在您訓練您的神經網路 只在訓練集上 您並不讓神經網路 您不讓它跑在在訓練開發集上的資料 當進行誤差分析時 您現在應該看您的分類器 在訓練集上，在訓練開發集上，
跟在開發集上 假設在這個例子，您的訓練誤差是 1% 而假設誤差在訓練開發集上是 9% 而在開發集上的誤差是跟之前一樣 10% 您可以下一個結論，當您從 訓練集到訓練開發集，誤差變得很大 而訓練資料跟訓練開發資料的不同 是您的神經網路只在第一個部分作用 它明顯的在這個部分訓練 但並不在訓練開發集上訓練 所以這個告訴您有變異問題 因為訓練開發誤差的資料來源跟 訓練集的分佈是一樣的 所以您知道即使您的神經網路
在訓練集作用得很好 它就是不能一般化得很好到 來自於同一種分佈的訓練開發集上，它不能 一般化得很好到
來自同一分佈的未見過的資料 在這個問題上我們有變異的問題 讓我們來看一個不同的問題 假設訓練誤差是 1%，而訓練開發誤差是 1.5% 但當您到開發集時您的誤差是 10% 現在，您實際上有很低的變異問題 因為當您從您見過資料的訓練資料到 神經網路未曾見過的訓練開發集，
誤差只增加一點點 但它真的跳上升
當您用到開發集時 所以這是資料不匹配的問題，
資料不匹配 所以這是一個資料不匹配的問題 因為您的學習演算法並沒有明顯地訓練在 訓練開發集或者開發集，
但這兩個資料來自於不同的分佈 但不管演算法怎樣學習 它在訓練開發集作用得很好，但在開發集不好 所以您演算法學習得很好
在於不同於 您真正關心的分佈，
所以我們稱之為資料不匹配問題 讓我們再看多一些例子 我寫在下一行，因為上面已經沒位置了 所以訓練誤差，訓練開發誤差，跟開發誤差 假設訓練誤差是 10% 訓練開發誤差是 11%，而開發誤差是 12% 記得人類的誤差，或者 貝葉斯誤差幾乎是 0% 所以如果您有這種表現，
那您真的有偏差問題 一個可以避免的偏差問題，
因為您做的遠比人類做得差 所以這真的是高偏差設定 而最後一個例子 如果您的訓練誤差是 10%，而您的訓練開發誤差是 11% 您的開發誤差是 20%，
看起來您有兩個問題 其一，可避免的偏差相當高 因為您即便在訓練集也做得不好 人類可以做到 0%，
但您的是 10% 的誤差在訓練集 這邊的變異似乎比較小 但這個資料不匹配也很高 所以對於這個問題，我會說，
您有高的偏差或者說 可避免的偏差，
跟資料不匹配問題 所以讓我們拿這些
我們在這張投影片寫下的東西 把它寫成一般的準則 關鍵的值是，我會看人類水準的 誤差，訓練集誤差， 您的訓練開發集誤差， 所以這是跟訓練集一樣的分佈 但您沒有用它們來做訓練 您的開發集誤差，根據這些誤差之間的關係 您可以感覺到，
可避免的偏差，變異， 跟資料不匹配的問題有多大 所以假設人類的誤差是 4% 您的訓練誤差是 7% 您個訓練開發誤差是10% 開發誤差是 12% 所以這給您一些感覺
有關可避免的偏差 因為您要您的演算法能夠做到 至少跟人類的表現類似，
或許在訓練集上 這是變異的感覺 您從訓練集一般化
到訓練開發集做得如何？ 這個感覺是有關
資料不匹配的問題有多大 技術上您可以再加上一個 也就是測試集表現，
我們寫成測試誤差 您不應該在測試集上做開發，因為您不要過適 您的測試集 但如果您看這個，那這會告訴您 過適的等級在開發集上 所以如果有很大的不同在於您的開發表現跟 您的測試表現，
它的意思是您或許在開發集調過頭 所以您或許需要大一點的開發集，是吧？ 記得您的開發跟測試集
來自於同一種分佈 唯一的方式會造成很大的不同是，
它在開發集做得太好 而在測試集不好，
如果您過適於開發集 如果這樣，您或許考慮回頭 用更多的開發資料 現在，我寫下這些數字 當您往下看這些數字，總是不斷上升 這裡有一個例子，數字不一定總是上升 或許人類誤差是 4%，訓練誤差是 7% 訓練開發誤差是 10%，但假設當您到開發集時 您發現實際上，令人驚訝的，
在開發集上表現很好 或許是 6%, 這個也是 6% 所以您看過像這樣的影響，在 語音辨識的例子，在訓練資料 實際上比開發跟測試集更難 這兩個是評估在您的訓練集分佈而 這兩個是評估在您的開發，測試集分佈 也時候如果您的開發，測試分佈比較簡單 不管是您做什麼應用，這些數字可能往下降 所以如果您看到這樣有趣的數字 甚至有更一般的公式來
做這樣的分析或許更有用 讓我很快的在下一張投影片做解釋 所以，讓我使用語音 啟動後視鏡來做例子 實際上我們寫下來的數字可以放在 一個表格上，在橫軸，我放不同的資料集 舉個例子，您或許有些資料
從一般語音辨識來的 所以您或許有一堆資料是您從很多 語音辨識問題來的，像是從小的麥克風 或是您購買的資料等等 然後您也有特定從後視鏡來的語音資料 在車子裏紀錄下來的 所以在這個表格的 x 軸，
我將放不同的資料集 另一軸，我會放不同的 演算法來檢驗這些資料 第一：人類的表現水準 也就是人類在每個資料集
的精確度 然後是誤差發生在由 您神經網路訓練的例子上 最後是誤差在 您的神經網路並沒有在上面訓練的例子上 實際上我們在前面投影片中
稱為人類表現水準 的數字放進這個框框 也就是人類可以
在這類資料做得如何 像是從不同的方式
來的語音辨識資料 有上十萬個語音您可以
在訓練集中找出 在前面的例子這個是 4% 這個數字是我們的訓練誤差 在前面投影片中的例子是7% 對，如果您的學習演算法看了這些例子，進行了 梯度下降法在這些例子上，
而這些例子來自於您的訓練集分佈 或者一般語音辨識分佈 您的演算法在這些例子
作用得如何？ 這裡是訓練開發集誤差 它通常比較高，資料來自於這種分佈 來自於一般語音辨識例子，
如果您的演算法沒有明顯地 在這種分佈上訓練過，
它會做得怎樣？ 而那是我們稱之為訓練開發誤差 然後您移到右邊，這個框框裡 是開發集誤差，或許也是測試集誤差 也就是在例子中的 6% 而開發跟測試誤差，實際上是兩種數字 但任何一個都可以放在這個框框裡 而這是如果您的資料來自於後視鏡，真正從 車子個後視鏡應用紀錄下來的，
但您的神經網路 並沒有進行反向傳播在這些例子上，
誤差如何？ 所以我們在前面投影片分析中看到 這兩個數字，這兩個數字
跟這兩個數字的不同 而這個差距是用來評估可避免的偏差 這個差距是評估變異 這個差距是評估資料不匹配性 實際上我們還可以放進 這表格上其他兩個數字，
可能也是有用的 如果這個實際上是 6% 而您獲取這種資料方式是
要一些人來標籤這些從後視鏡 語音資料，來看看
人們在這個資料表現如何 或許這個也會是 6% 而獲取這個數字的方式是
您拿一些後視鏡語音資料 將它們放在訓練集，
所以神經網路也學習它們 然後您測量在這個資料集的誤差 但如果這是您得到的結果，實際上您已經 表現得跟人類一樣的水準
在後視鏡的語音資料 或許您真的在這種分佈的資料
已經做得很好了 當您做多一點後續的分析，並不保證會給您 明確的道路前行，
但有時候會給您一些額外的見解 舉個例子，對照這兩個數字
在這個例子裡，告訴我們 人們在後視鏡語音資料實際上比 一般語音辨識資料要難，因為
人類得到 6% 誤差，而不是 4%誤差 但看這些差距也許會幫助您 理解不同程度的偏差，變異
跟資料不匹配問題 所以這種比較一般化的公式，
我使用過幾次 我沒有使用它，因為您可以發現很多的問題從檢驗 這部份的數字，看看這個差距，這個差距 這個差距，已經足夠指引您很好的方向 但有時候把這個表格填滿，
可以給您一些額外的見解 最後，我們前面談過很多有關處理偏差的想法 談過一些處理變異的技巧 但您要怎麼處理資料不匹配？ 特別是訓練的資料來自於跟 開發跟測試不同的分佈，
可以給您更多的資料 真的幫助您的學習演算法的表現 但除了偏差跟變異的問題 您現在有這個新的潛在的
資料不匹配問題 有什麼好的方式來
處理資料不匹配 誠實的說，沒有真正很棒的 或者很系統化方式
來處理資料不匹配 但有些方式您可以試試，可能有所幫助 讓我們再下一段影片
看看這些方式 我們看到使用訓練資料來自於 跟開發，測試集不同的分佈，
可以給您很多的資料 進而幫助您學習演算法的表現 但除了只有偏差跟變異的兩個潛在問題 您現在有第三種潛在的問題，資料不匹配 所以如果做完誤差分析，
結果發現有資料不匹配問題怎麼辦？ 這是一個巨大的錯誤來源，
您如何來處理這個問題？ 實際上，不幸的沒有超級系統化方法 來處理資料不匹配，但有一些事情
您可以試看看有沒有幫助 我們在下一段影片
來看看這些方式