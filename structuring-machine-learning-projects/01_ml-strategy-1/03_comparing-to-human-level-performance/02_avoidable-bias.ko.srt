1
00:00:02,400 --> 00:00:07,760
우리는 여러분이 어떻게 러닝 알고리즘이 트레이닝세트에서 잘 되기를 바라는지에 대해 이야기 했었는데요.

2
00:00:07,760 --> 00:00:10,085
가끔씩은 너무 잘하는 것이 별로 좋지 않을 수도 있습니다.

3
00:00:10,085 --> 00:00:12,765
인간레벨성능을 알면 그것에 따라

4
00:00:12,765 --> 00:00:15,070
얼마나 성능이 발휘되야 하는지

5
00:00:15,070 --> 00:00:18,250
너무 잘하면 좋지 않을 수도 있으니 적당한 레벨로 알고리즘이 트레이닝세트에서 발휘할 수 있도록 가능케 할 것입니다.

6
00:00:18,250 --> 00:00:19,392
어떤 말인지 자세히 설명해드리도록 하겠습니다.

7
00:00:19,392 --> 00:00:24,320
고양이 인식 프로그램을 봤었는데요, 이 사진을 보면

8
00:00:24,320 --> 00:00:32,195
인간은 거의 완벽에 가까운 정확도를 가지고 있고 인간오류는 1퍼센트라고 해봅시다.

9
00:00:32,195 --> 00:00:34,475
이 경우, 러닝 알고리즘이

10
00:00:34,475 --> 00:00:38,915
8퍼센트 트레이닝 오류, 10퍼센트 dev 오류

11
00:00:38,915 --> 00:00:44,500
그리소 트레이닝세트에서는 조금 잘 하고 싶으셨을 수도 있죠.

12
00:00:44,500 --> 00:00:49,510
그러므로 트레이닝 세트에서의 알고리즘의 성능과 인간의 차이가

13
00:00:49,510 --> 00:00:52,010
매우 크기 때문에

14
00:00:52,010 --> 00:00:55,625
이것은 해당 알고리즘이 트레이닝세트에 잘 피팅되지 않고 있음을 보여줍니다.

15
00:00:55,625 --> 00:00:59,210
그러므로, 바이어스 와 편차를 줄이는 방면에서,

16
00:00:59,210 --> 00:01:03,835
이번 경우에는 바이어스를 줄이는데 중점을 둘 것 같습니다.

17
00:01:03,835 --> 00:01:09,410
더 큰 신경망을 트레이닝 한다거나 더 오랜 시간 동안 트레이닝세트를 운영하는 방법이 있겠습니다.

18
00:01:09,410 --> 00:01:12,003
트레이닝세트에서 더 잘하기 위함이죠.

19
00:01:12,003 --> 00:01:15,050
이번에는 동일한 트레이닝 오류와 dev error를 봅시다.

20
00:01:15,050 --> 00:01:19,340
그리고 인간레벨성능이 1퍼센트가 아니라고 가정해봅시다.

21
00:01:19,340 --> 00:01:22,120
이것을 이쪽으로 복사해보겠습니다,

22
00:01:22,120 --> 00:01:25,170
다른 어플 또는 다른 데이터세트에서는

23
00:01:25,170 --> 00:01:30,180
인간 오류가 7.5퍼센트라고 해봅시다.

24
00:01:30,180 --> 00:01:33,890
데이터세트에 있는 이미지가 너무 흐려서 사람이 판단하기에도

25
00:01:33,890 --> 00:01:37,917
고양이인지 여부를 알 수 없는 경우가 있을 수 있겠죠.

26
00:01:37,917 --> 00:01:41,090
이 사례는 약간 부자연스러운 사례일 수 있긴 합니다.

27
00:01:41,090 --> 00:01:44,525
왜냐면, 인간은 사진을 보고 고양이인지 이미지를 분간하는 게 굉장히 뛰어나기 때문입니다.

28
00:01:44,525 --> 00:01:46,490
하지만 예시인 만큼, 한번 보도록 하겠습니다.

29
00:01:46,490 --> 00:01:48,270
그럼 데이터세트에 있는 이미지가

30
00:01:48,270 --> 00:01:54,680
너무 흐리거나 화질이 너무 좋지 않아서 인간도 7.5퍼센트의 오류를 범한다고 가정해봅시다.

31
00:01:54,680 --> 00:01:56,720
이런 경우,

32
00:01:56,720 --> 00:02:00,305
트레이닝 오류와 dev error가 다른 예제들과 동일하긴 하지만,

33
00:02:00,305 --> 00:02:04,016
트레이닝세트에서는 잘 하고 있는 것을 보실 수 있습니다.

34
00:02:04,016 --> 00:02:07,980
인간레벨성능에서 조금 못 미치는 수준을 보이고 있습니다.

35
00:02:07,980 --> 00:02:10,010
두 번째는,

36
00:02:10,010 --> 00:02:14,295
이 부분을 조금 줄이고 싶을 수 있겠죠.

37
00:02:14,295 --> 00:02:19,390
러닝 알고리즘의 편차를 줄이는 겁니다.

38
00:02:19,390 --> 00:02:21,650
그렇게 하기 위해 Regularization (일반화)를 시도하여

39
00:02:21,650 --> 00:02:25,600
dev error를 트레이닝 오류와 비슷한 수준으로 만드는 것이죠.

40
00:02:25,600 --> 00:02:29,790
이전 코스에서 다루었던 바이어스와 편차에 대한 내용에서는,

41
00:02:29,790 --> 00:02:36,900
주로 Bayes error가 0에 가까운 업무를 다루었습니다.

42
00:02:36,900 --> 00:02:39,280
그러므로 여기서 일어난 것을 설명 드리자면,

43
00:02:39,280 --> 00:02:42,150
고양이인식 프로그램 예로 들자면,

44
00:02:42,150 --> 00:02:47,510
인간레벨 오류를

45
00:02:47,510 --> 00:02:56,030
Bayes error의 추정치로 생각하거나 Bayes optimal error의 추정 수치로 생각합니다.

46
00:02:56,030 --> 00:02:58,660
컴퓨터의 인식 영역에서는,

47
00:02:58,660 --> 00:03:02,450
꽤 합리적인 프록시 값입니다. 이유인 즉 슨,

48
00:03:02,450 --> 00:03:08,750
사람은 computer vision영역에서 굉장히 능숙하고 사람이 할 수 있는 부분이 Bayes error와 크게 다르지 않기 때문입니다.

49
00:03:08,750 --> 00:03:11,930
인간레벨 오류는 정의로만 봤을 때,

50
00:03:11,930 --> 00:03:14,840
Bayes error보다 못합니다. 그 이유는 그 어떤 것도

51
00:03:14,840 --> 00:03:19,665
Bayes error보다 더 나을 순 없기 때문이죠. 하지만 인간레벨 오류는 Bayes error에서 크게 떨어지지 않을 수 있습니다.

52
00:03:19,665 --> 00:03:25,145
여기서 놀라운 사실을 발견했는데요, 인간레벨오류가 얼마인지에 따라

53
00:03:25,145 --> 00:03:31,214
또는, 이 값은 사실 Bayes error와 동일합니다만,

54
00:03:31,214 --> 00:03:35,273
어떤 것을 이룰 수 있느냐에 따라 다르지만,

55
00:03:35,273 --> 00:03:40,970
동일한 트레이닝 오류와 dev error인 경우, 이 2가지의 사례와 같이,

56
00:03:40,970 --> 00:03:47,510
바이어스를 줄이는 기술이나 편차를 줄이는 방법에 중점을 두기로 했습니다.

57
00:03:47,510 --> 00:03:51,710
왼쪽 예제에서는,

58
00:03:51,710 --> 00:03:55,850
8퍼센트의 트레이닝은 1퍼센트까지 줄일 수 있다고 하면 굉장히 큰 값입니다.

59
00:03:55,850 --> 00:04:01,310
바이어스를 줄이는 기술이 가능케 하죠.

60
00:04:01,310 --> 00:04:02,885
오른쪽 예시는,

61
00:04:02,885 --> 00:04:07,140
Bayes error가 7.5퍼센트입니다.

62
00:04:07,140 --> 00:04:12,265
여기서는 인간레벨오류를 Bayes error를 프로시로 사용합니다.

63
00:04:12,265 --> 00:04:13,622
만약 Bayes error가

64
00:04:13,622 --> 00:04:15,860
7.5퍼세트와 가깝다고 생각되는 경우,

65
00:04:15,860 --> 00:04:20,195
트레이닝 오류를 더 이상 줄일 수 있는 공간이 많지 않습니다.

66
00:04:20,195 --> 00:04:24,710
7.5퍼센트보다 더 많이 뛰어나길 바라지 않습니다.

67
00:04:24,710 --> 00:04:29,780
어차피 그렇게 되기 위해선 교육 량을 늘려야 할 것이기 때문이죠. 

68
00:04:29,780 --> 00:04:32,910
대신에, 여기 2퍼센트 갭을 줄이는 방안을

69
00:04:32,910 --> 00:04:36,380
생각해보면, 일반화 과 같은 또는

70
00:04:36,380 --> 00:04:38,660
트레이닝 데이터를 더 수집하는 방안으로

71
00:04:38,660 --> 00:04:43,370
편차를 줄이는 기술을 생각해 볼 것입니다.

72
00:04:43,370 --> 00:04:47,463
몇 가지 이름을 부여하자면,

73
00:04:47,463 --> 00:04:50,490
자주 쓰이는 용어는 아니지만,

74
00:04:50,490 --> 00:04:54,075
개인적으로 유용한 용어였는데요, 생각하는 사고방식이 유용합니다.

75
00:04:54,075 --> 00:04:58,380
Bayes error 또는 Bayes error의 근사치와

76
00:04:58,380 --> 00:05:05,670
트레이닝 오류의 차이를 avoidable bias라고 할 것입니다.

77
00:05:05,670 --> 00:05:11,830
여러분이 할 수 잇는 것은 트레이닝 성능을

78
00:05:11,830 --> 00:05:14,020
Bayes error 값으로 내려갈 때까지 계속 개선시키는 것입니다.

79
00:05:14,020 --> 00:05:16,565
하지만 Bayes error보다 잘하면 안되겠죠.

80
00:05:16,565 --> 00:05:20,740
사실 overfitting을 하지 않는 이상 Bayes error보다 잘할 수는 없습니다.

81
00:05:20,740 --> 00:05:24,879
그리고 이것, 트레이닝 오류와 dev error의 차이는

82
00:05:24,879 --> 00:05:29,775
알고리즘 편차 문제의 수치입니다.

83
00:05:29,775 --> 00:05:35,350
‘avoidable bias’라는 용어는 최소의 오류 값이나 특정 오류가 있다는 것을

84
00:05:35,350 --> 00:05:38,140
인정하는 셈이고,

85
00:05:38,140 --> 00:05:42,975
Bayes error가 7.5퍼센트인 경우 이 이하로 내려갈 수 없다는 뜻도 내포하고 있습니다.

86
00:05:42,975 --> 00:05:46,885
이 오류 수치 밑으로는 내려가면 좋지 않습니다.

87
00:05:46,885 --> 00:05:50,650
그러므로, 트레이닝 오류가 8퍼센트라고 이야기하기 보다는,

88
00:05:50,650 --> 00:05:53,427
8퍼센트는 바이어스의 측정수치이며,

89
00:05:53,427 --> 00:06:01,520
해당 예시에서는 avoidable bias가 0.5퍼센트이거나,

90
00:06:01,520 --> 00:06:06,220
2퍼센트는 편차 수치입니다.

91
00:06:06,220 --> 00:06:11,378
그러므로 2퍼센트를 줄일 수 있는 공간은 0.5퍼센트 줄이는 공간보다 훨씬 더 많습니다.

92
00:06:11,378 --> 00:06:14,384
반대로 왼쪽 예시는,

93
00:06:14,384 --> 00:06:20,055
7퍼센트는 avoidable bias 이고,

94
00:06:20,055 --> 00:06:24,275
2퍼센트가 편차입니다.

95
00:06:24,275 --> 00:06:25,960
왼쪽 사례에서는,

96
00:06:25,960 --> 00:06:31,789
avoidable bias를 줄이면 더욱 큰 효과를 얻을 수 있겠죠.

97
00:06:31,789 --> 00:06:33,310
이번 예시에서는,

98
00:06:33,310 --> 00:06:35,845
인간레벨 오류에 대해 다뤘는데요,

99
00:06:35,845 --> 00:06:38,220
Bayes error에 대한 추정치를 이해하면

100
00:06:38,220 --> 00:06:42,420
시나리오마다 각각 다른 전술로 접근하여,

101
00:06:42,420 --> 00:06:45,970
bias avoidance 기술을 이용하거나, variance avoidance 기술을 이용할 수 있습니다.

102
00:06:45,970 --> 00:06:48,820
본인이 어느 곳에 중점을 둘지 여부와 관련하여 의사결정을 내리는데 있어,

103
00:06:48,820 --> 00:06:53,800
인간레벨성능이 미묘하게 관여하는 부분이 있는데요,

104
00:06:53,800 --> 00:06:55,970
다음 비디오에선,

105
00:06:55,970 --> 00:06:59,460
인간레벨성능이 구체적으로 어떤 것을 이야기하는지 자세히 알아보겠습니다.