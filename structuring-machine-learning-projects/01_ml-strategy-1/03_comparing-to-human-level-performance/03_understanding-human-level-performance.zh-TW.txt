"human-level performance" (人類水準的表現)這個詞 有時會非正式地用在研究文獻 不過讓我來告訴你，
該怎麼更精確去定義它 甚至如何善用「人類水準的表現」的定義 來推動你的機器學習計畫 那麼，還記得上部影片談到這個詞「人類水準的錯誤」 (human-level error)，是用在估計 Bayes error 也就是世界上所有函數竭盡所能 能夠達到的最佳錯誤率 先記著這點，讓我們來看一個醫療上圖片辨識的例子 假設你想要看一張 X 光片 做出診斷、決定分類 假設一般人、沒經過訓練的人 在這個任務有 3% 錯誤率 一般醫生，可能普通的放射科醫生，有 1% 錯誤率 一個很有經驗的醫生做更好，0.7% 錯誤 一個有經驗的團隊，也就是
你找來一群經驗豐富的醫生 讓他們全都看這張圖片、討論、辯論 最後達成共識 — 這樣是 0.5% 錯誤率 那麼我想問你的是：要怎麼定義「人類水準的錯誤」？ 是 3%, 1%, 0.7% 或 0.5%? 想暫停影片想想的
可以先暫停 要回答這個問題，
我強力建議你記得這一點： 「人類錯誤」最有用的地方，
是視作 Bayes error 的近似、估計 想要的話請隨時暫停影片，思考一下 不過我自己會這樣定義人類水準的錯誤率： 如果你想要近似、估計出 Bayes error 那麼當你有一組經驗豐富的醫生，討論、 辯論後能達到 0.5% 錯誤率時 我們就知道 Bayes error 會比 0.5% 小 因為存在某個系統，
也就是這群醫生，能達到 0.5% 錯誤率 所以根據定義，
理論上的最佳錯誤一定比 0.5% 低 我們不知道會低多少，
搞不好找更多人 或更有經驗的醫生可以做更好 所以或許會比 0.5% 好一些 不過我們知道，最佳的錯誤率不會比 0.5% 高 所以在這樣的情況下，
我會拿 0.5% 當作 Bayes error 的估計值 我會把「人類水準的表現」定義成 0.5% 錯誤率 — 至少，當你想拿人類水準來做上部影片的 偏差/變異的分析的時候 然而，為了發論文 或為了推出系統，
你可能對「人類水準」 有不同的定義： 只要比一位普通的醫生好就算 如果真的達成，或許也很有用有貢獻 在某些情境下，
或許比一位放射科醫生厲害 就表示這系統夠好，可以推出了 因此，也許重點在於，當定義人類水準時 釐清你的目的為何 如果你想表示在某種情況下，
因為你能超越一個人的表現 所以可以推出你的系統，
這樣或許這一個是好的定義 可是，如果你的目的是估計 Bayes error 那這一個才是好的定義 為什麼這很重要呢？
讓我們看一個錯誤分析的例子 假設對於醫療圖片診斷 你的訓練錯誤是 5%，
而開發錯誤是 6% 拿前一張投影片當例子，
我們的人類水準表現 我要把他看成是 Bayes error 的近似值 根據你怎麼定義它：
是一位一般醫生的表現 或是有經驗的醫生、有經驗的團隊，
這邊可能是 1%、 0.7% 或 0.5% 還有在上部影片提到的定義 這邊的差距，在 Bayes error 或其近似值，
與訓練錯誤之間的 叫做可避免的偏差 而這邊，是這個問題的變異 對於你的演算法而言 因此，在第一個例子，無論你選擇那個定義 可避免的偏差大約是 4% 這邊應該是約莫介在 4% 如果用這個，和 4.5% 之間，如果用這個。而這邊差距是 1% 所以以這個例子，我會說 你用哪種人類水準的定義
並不會有太大的影響 無論是用一位普通醫生的錯誤率 或用經驗豐富的醫師、或團隊 無論這邊是 4% 還是 4.5%，
很明顯這問題比變異還大 所以在這種情況 你應該要減少偏差，
例如訓練比較大的網路 那麼，我們看第二個例子 假設你的訓練錯誤是 1%，
而開發錯誤是 5% 同樣地，無論把人類水準定義成 1%, 0.7% 或 0.5% 也都不大重要 因為無論你用哪種定義，你的 可避免的偏差會介在 0% 到 0.5% 之間，對吧 也就是人類的表現和你的訓練錯誤之間的差距 然而這邊的差距是 4% 所以 4% 無論如何都比可避免的偏差大很多 這意味著你必須專心減少變異 例如正則化，或蒐集更多的訓練資料 可是，這種情況下就很重要了：如果訓練錯誤為 0.7% 所以你已經很厲害了，然後你的開發錯誤是 0.8% 在這種情況下，你必須要拿 0.5% 當作 Bayes error 的估計值 因為這樣的話，可避免的偏差會是 0.2% 也就是你的變異，0.1%，的兩倍大 這表示偏差和變異都會是問題所在 但也許可避免的偏差問題比較大 在這個例子，前一張投影片說的 0.5% 會是最好的 Bayes error 估計值，
因為一組醫生的團隊可以達到這樣 如果你拿 0.7% 當作估計值，你會認為 可避免的偏差大概就是 0%，你會忽略了 你其實的確要在訓練集上加把勁 我希望這也能給你一點感覺，
了解為什麼在機器學習中 你越逼近人類表現的水準時，
問題會越來越難 以這個例子來說，當你達到 0.7% 錯誤率 除非你很小心地估計出 Bayes error 否則你不知道你離 Bayes error 還多遠 也就是不知道要花多少心力，去減少可避免的偏差 實際上，萬一你唯一知道的是，
一位普通醫生有 1% 的錯誤率 你還滿難知道要不要去更加配合 (fit) 你的 訓練資料 而這種煩惱，只會在你已經做得很好的時候才會發生 當你達到 0.7%, 0.8% 很靠近人類水平的時候 而在左邊的這兩個例子，
當你離人類水準還很遠的時候 要分辨該處理偏差還是變異，會比較容易點 這或許也告訴了你，當你逼近人類水準的表現時 會很難洞察出偏差和變異的效果 所以在機器學習的任務裡，當你做得越來越好 會越來越難 那麼，統整一下剛剛所說的 如果你想了解一個問題的偏差和變異 而那個問題，人類做得好，你也有人類水準的錯誤率估計 那你可以拿人類水準當作 Bayes error 的估計、近似值 距離你估計的 Bayes error 還差多少，能讓你知道 「可避免的偏差」有多少，問題大不大 而訓練錯誤和開發錯誤之間的差距 讓你知道你在「變異」方面的問題大不大；你的演算法 能不能從訓練集推廣 (generalize) 到開發集上 我們在這裡所討論的，與之前的課程 最大的不同在，我們不是拿 0% 和訓練錯誤做比較 並稱之為「偏差」的估計 相反地，我們在這部影片做了更細膩的分析 我們並不期待你應該做到 0% 錯誤 因為 Bayes error 有時候不是零；
可能沒有任何一個東西 能夠做得比某個錯誤值還要低 那麼，在先前的課程，我們量出訓練錯誤後 看它比零大多少 就依此評估我們的偏差大小 其實在 Bayes error 幾乎是零的時候，這還不錯 例如辨認貓貓 人類做這個近乎完美，所以 Bayes error 也近乎完美 所以當 Bayes error 幾乎是零的時候，這樣評估還 OK 可是，對資料很亂的問題，
例如語音辨識，如果 音檔噪音很雜，有時根本聽不出來在說什麼 無法得到正確語音 對於這種問題，有比較精準的Bayes error 估計 能幫你估計「可避免的偏差」和「變異」比較準確 所以對於要不要專心在減少偏差或減少變異 就能做比較好的決定 總結一下：估計人類水平的表現，就能給你 Bayes error 的估計 這能讓你更快下決定：是否應該 減少你的演算法的偏差還是變異 這些技巧還滿有用的 — 直到你超越了人類水準 超越了以後，對於 Bayes error 可能就沒有一個好的估計了 所以無法幫你做出決定 然而，深度學習其中令人興奮的進展在 有越來越多的任務我們能夠
超越人類水平的表現 在下一個影片中 讓我們談談關於超越人類水準的進展