Öğrenme algoritmalarınızın eğitim setinde ne kadar iyi performans sergilemesi gerektiğini konuşmuştuk fakat bazen çok fazla iyi olmasını istemezsiniz ve insan seviyesi performansını bilmek size eğitim setinde tam olarak ne kadar iyi bir performans sergilemeniz gerektiği konusunda yardımcı olur Size ne demek istediğimi göstereyim. Kedi sınıflandırmasını daha önce birçok kez kullandık, bir kedi resmini ele alalım, diyelim ki insanlar mükemmele yakın doğruluk oranına sahip ve bu oran %1 olsun bu durumda aynı zamanda eğer öğrenme algoritmanız %8 eğitim hatasına ve %10 geliştirme hatasına sahipse, belki de eğitim setinde daha iyi bir sonuç elde etmek istersiniz bu durumda algoritmanızın ne kadar iyi yaptığı ile insanların ne kadar iyi yaptığı arasında büyük bir fark olması algoritmanızın eğitim setinde çok iyi oturmadığını gösterir. Dolayısıyla, yanlılık ve değişintiyi azaltmayı sağlayan araçlar bakımından bu durumda, odağınızı yanlılığı azaltmaya yönlendirin derim bunun için yapmak isteyeceğiniz şeylere daha büyük bir ağ eğitmek veya eğitim setinde daha fazla eğitmek örnek olarak verilebilir, yani bu durumda eğitim setinde daha iyi yapmaya odaklanın Şimdi ise aynı eğitim hatasına ve geliştirme hatasında, insan seviyesi performansının yüzde 1 olmadığını düşünelim dolayısıyla aynı değerleri farklı bir uygulamaya veya farklı bir veri setine kopyalayalım fakat bu sefer insan seviyesi hatası %7.5 olsun belki sağ taraftaki verilerinizdeki görüntüler fazla miktarda bulanık ve insanlar bile bunun kedi mi değil mi olduğunu ayırt etmekte güçlük çekiyor bu örnek aslında bir miktar tasarlanmış bir örnek çünkü aslında insanlar resime bakıp bunun bir kedi olup olmadığını söylemekte oldukça başarılıdırlar fakat bu örneği vermek adına bu rakamlarla devam edelim, diyelim ki veri setlerinin görüntüleri bulanık ya da düşük çözünürlüğe sahip ve insanlar %7.5 hataya sahipler, bu durumda, eğitim hatanız ve geliştirme hatanız diğer durumdaki ile(sol taraftaki durum) aynı olsa bile, yine de eğitim setinde iyi bir sonuç elde etmiş olursunuz burada(sağda) insan seviyesi performansından biraz daha kötü bir performans sergiliyor ve bu örnekte, belki bu bileşeni azaltmaya odaklanmayı isteyebilirsiniz yani algoritmanızdaki değişintiyi azaltmaya, dolayısıyla geliştirme hatanızı eğitim hatanıza yaklaştırmak için normalleştirme deneyebilirsiniz örneğin. Önceki kurslarda, yanlılık ve değişinti konusunda, çoğunlukla olarak bayes hatasının neredeyse 0 olduğu görevler olduğunu varsayıyorduk, dolayısıyla burada ne olduğunu açıklamak için, kedi sınıflandırma örneğimizde, insan seviyesi hatasını, vekil(Bayes hatası için yerine) ya da tahmini Bayes hatası ya da optimum Bayes hatası olarak düşünün ve bilgisayarlı görü işlemleri için, bu çok mantıklı bir vekildir çünkü insanlar aslında bilgisayarlı görüde oldukça iyidirler ve belki de insanın aldığı sonuç Bayes hatasından çokta uzakta değildir Tanımsal olarak, insan seviyesi hatası Bayes hatasından daha kötüdür, çünkü hiçbir şey Bayes hatasından daha iyi olamaz fakat insan seviyesi hatası Bayes hatasından çokta uzakta olmayabilir. dolayısıyla burada gördüğünüz şaşırtıcı şey, insan seviyesi hatasının ne olduğuna bağlı olarak, -ki bu hata(insan seviyesi hatası) Bayes hatasına çok yakın veya biz öyle olduğunu varsayıyoruz- aynı eğitim ve geliştirme hatasıyla bu iki örnekte, başarılı olacağını düşündüğümüz, yanlılık azaltma taktiklerine veya değişinti azaltma taktiklerine odaklanmayı seçiyoruz ve soldaki örnekte olan şey ise, %8 eğitim hatası bunu %1'e kadar düşürebileceğinizi düşündüğünüz zaman çok yüksek olarak karşımıza çıkıyor ve yanlılık azaltma taktikleri bu konuda yardımcı olabilir bunun yanısıra sağdaki örneğe baktığımız zaman, eğer bayes hatasının %7.5 olduğunu düşünürseniz, -ki burada insan seviyesi hatasını tahmin ya da bayes hatası yerine vekil olarak kullanıyoruz- bu durumda eğitim hatanızı daha fazla azaltacak çok fazla boşluk ya da oynama alanı kalmamış demektir. Bu hatayı(eğitim seti hatasını) %7.5'tan daha fazla azaltmak istemezsiniz çünkü bu durumda aşırı öğrenmeye başlatabilirsiniz bunun yerine aradaki %2 farkı azaltmak için çok daha fazla imkan mevcuttur ve bunu değişinti azaltma taktikleri kullanarak örneğin normalleştirme yaparak veya belki de daha fazla eğitim verisi kullanarak yapabilirsiniz Dolayısıyla, bunlara birkaç isim vermek gerekirse, bu kullanacağım isim çok sık kullanılan bir terminoloji değil fakat bunu faydalı bulduğum için söylemek istiyorum, bu da bayes hatasıyla ya da bayes hatasının yaklaşık değeriyle eğitim hatasının farkının önlenebilir yanlılığın yaklaşık değeri olduğudur. Dolayısıyla, istediğiniz şey eğitim hatanızı Bayes hatasına varıncaya kadar geliştirmeye devam ettirmenizdir fakat Bayes hatasından daha iyi yapmak istemezsiniz çünkü aşırı öğrenme'ye maruz kalmadan Bayes hatasından daha iyi bir sonuç alamazsınız Bu bahsettiğimiz , eğitim seti ile geliştirme hatası arasındaki fark , algoritmanızdaki değişinti probleminin miktarıdır ve önlenebilir yanlılık terimi size şu bilgiyi verir; minimum yanlılık ya da minimum hata olan ve daha aşağısına geçemeyeceğiniz bir değer vardır ki bu değer Bayes değeridir bu değerin altına geçebilecek geliştirmeler yapmak istemezsiniz. Dolayısıyla, eğitim hatanız yüzde 8 ise, %8 yanlılık miktarıdır demek yerine önlenebilir yanlılık %0.5'tir(bu örnekte) ve bu örnekte %2 değişinti ölçüsüdür ve %2'yi azaltmak için %0.5'i azaltmaya çalışmaktan çok daha fazla aralık mevcuttur diyebilirsiniz. Tam tersine, soldaki örnekte, % 7 önlenebilir yanlılığın miktarıdır aynı şekilde %2 ise ne kadar değişintiye sahip olduğunuzun ölçüsüdür ve dolayısıyla, soldaki örnekte, önlenebilir yanlılığı azaltmak için çok daha fazla potansiyel vardır Bu yüzden bu örnekte, insan seviyesi hatasını anlamak ve Bayes hatasını anlamak gerçekten sizi farklı durumlarda yanlılık önleme taktikleri ya da değişinti önleme taktikleri gibi farklı taktikler uygulamaya yönlendirir. Neye odaklanmak istediğinizi seçerken insan seviyesi hatayı nasıl olaya dahil ettiğiniz ile ilgili çok daha fazla ayrıntı vardır Hadi, bir sonraki videoda, insan seviyesi hatanın ne anlama geldiğini daha derinden anlamaya çalışalım.