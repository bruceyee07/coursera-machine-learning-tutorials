你们已经学过正交化 如何设置开发集和测试集<br />用人类水平代表贝叶斯误差 以及如何估计可避免偏差和方差 让我们把这些结合成一套准则 用于改进你的学习算法 我认为一个有监督学习算法能发挥作用 基本上意味着<br />希望或者预设你可以做到两件事 第一是你可以很好地拟合训练集 你可以大致认为你能得到较低的可避免偏差 需要做好的第二点是 训练集的结果可以很好地<br />推广到开发集或者测试集 这就是说 方差不太大 从正交化角度来说 你看到的是 存在一组旋钮<br />可以修正可避免偏差的问题 比如训练更大的神经网络<br />或者训练更长时间 并且有另一组独立的方法<br />可以用来处理方差的问题 比如正则化或者获取更多训练数据 总结一下之前几个视频里展示的方法 如果想要改善你的机器学习系统 我建议看看你的训练误差<br />和贝叶斯误差估计值间的差距 这能让你估计可避免偏差 换句话说 就是你需要试着<br />在训练集优化到什么程度 然后再看看你的开发集误差 和训练集误差间的差距 来估计你的方差问题有多大 换句话说 你需要付出多大的努力 来把你训练集的结果推广到开发集<br />那些没有直接用于训练的数据上 无论你想把可避免偏差<br />降低到什么程度 我会尝试用一些策略<br />比如 训练一个更大的模型 这样你的训练集结果会更好<br />又或者 训练更长的时间 用更好的优化算法 比如 加入Momentum或者RMS Prop 或者用更好的算法 比如Adam算法 又或者 你可以试试寻找 更好的神经网络架构<br />或者更准确来说 超参数 这可能包括从改变激活函数 到<br />改变层数或者隐含单元数的各个方面 虽然你这么做可能会增大模型的规模 因为要训练其他模型 或者模型架构 比如循环神经网络(RNN)或者卷积神经网络(CNN)<br />我们会在之后的课程里学到 一个新的神经网络架构<br />能否更好地拟合你的训练集 有时候很难提前判断 但有时候用一个更好的架构<br />可以得到好得多的结果 下一步你会发现方差是主要问题 有很多方法你可以尝试 包括 尝试获得更多的数据<br />因为用更多的数据来训练 可以帮助你更好地把结果推广到<br />开发集那些你没有遇到过的数据上 你可以试试正则化 包括L2正则化 随机失活法(dropout) 或者我们之前讲过的数据集扩增 又或者 同样地<br />你还可以试试不同的神经网络架构 或者超参数搜索 看看是否能帮你 找到一个更好的构架<br />更适合这个问题 我想这些偏差或者说可避免偏差<br />以及方差的概念 是很容易学但很难精通的东西 在这周的视频中<br />我们系统地应用了这些概念 你实际上已经比很多机器学习团队 更高效 更系统 更有策略了 从系统地改善他们<br />机器学习系统的角度来说 这周的作业会让你练习实践 你对这些概念的理解 祝你们好运 并且期待在下周的视频中<br />继续见到你们 方差