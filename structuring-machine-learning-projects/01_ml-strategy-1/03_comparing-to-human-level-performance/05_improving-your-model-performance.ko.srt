1
00:00:00,360 --> 00:00:01,805
여러분은 직교화에 대해 들어 본 적이 있으실 텐데요.

2
00:00:01,805 --> 00:00:06,561
dev set와 테스트세트를 설정하는 방법 인간레벨성능을 Bayers error에 대한 프록시로

3
00:00:06,561 --> 00:00:11,110
사용하는 방법 및 avoidable bias 및 분산을 추정하는 방법.

4
00:00:11,110 --> 00:00:14,121
이제 모든 것들을 가이드라인으로 취합해보겠습니다.

5
00:00:14,121 --> 00:00:17,473
여러분의 러닝 알고리즘 성능을 향상시키는 방안에 대해서 말이죠.

6
00:00:17,473 --> 00:00:22,149
그러니까, 제가 생각하기에 러닝 알고리즘이 효과가 있기 위해선 근본적으로

7
00:00:22,149 --> 00:00:24,656
2가지의 전제조건이 있다고 봅니다.

8
00:00:24,656 --> 00:00:30,015
첫 번째로는 트레이닝세트를 잘 대입할 수 있다는 것이고,

9
00:00:30,015 --> 00:00:37,670
이것은 대략적으로 말해서 낮은 avoidable bias를
 획득할 수 있다는 것으로 이해하시면 됩니다.

10
00:00:38,830 --> 00:00:42,992
두 번째로는, 트레이닝 세트에서 잘하는 것은

11
00:00:42,992 --> 00:00:47,369
보통 dev set나 테스트 세트로 잘 
이어서 잘되는 경우가 많습니다.

12
00:00:47,369 --> 00:00:50,488
이것은 편차가 나쁘지 않다는 것이죠.

13
00:00:50,488 --> 00:00:53,717
Thought organization 영역에서 비추어볼 때,

14
00:00:53,717 --> 00:00:58,779
손잡이의 세트가 트레이닝 시킨다던 지

15
00:00:58,779 --> 00:01:03,245
더욱 긴 시간 트레이닝을 
진행하면서 문제를 해결해주는 경우가 있습니다.

16
00:01:03,245 --> 00:01:08,635
또한, 또 다른 세트가 Damien’s problems과 
연관된 문제들을 해결해줄 수 있습니다.

17
00:01:08,635 --> 00:01:12,369
일반화 이나 더 많은 데이터 수집을 하는 방법으로 말이죠.

18
00:01:12,369 --> 00:01:16,543
지난 몇 개의 비디오를 통해 배운 내용을 요약하자면,

19
00:01:16,543 --> 00:01:21,190
시스템에 있는 여러분의 머신 성능을 향상시키고 싶으시면

20
00:01:21,190 --> 00:01:26,234
트레이닝 에러와 Bayers error의 프록시 차이를 보시고,

21
00:01:26,234 --> 00:01:31,163
avoidable bias에 대한 이해도를 높이시길 바랍니다.

22
00:01:31,163 --> 00:01:35,297
다시 말해, 트레이닝 세트에서 얼마나 더 잘해야 할지

23
00:01:35,297 --> 00:01:39,366
보시고 그 이후로, dev error와

24
00:01:39,366 --> 00:01:41,382
트레이닝 에러의 차이를 이해하시면 됩니다.

25
00:01:41,382 --> 00:01:43,871
결국에는 편차/변동의 문제입니다.

26
00:01:43,871 --> 00:01:44,711
달리 말하면,

27
00:01:44,711 --> 00:01:48,671
바로 대놓고 트레이닝 시키지 못한 부분에 대해서

28
00:01:48,671 --> 00:01:52,392
얼마나 더 일을 수행해야 하는지가 관건인 것인데요, 트레이닝세트에서 dev set로 넘어갈 때 말이죠.

29
00:02:04,393 --> 00:02:09,201
얼마나 avoidable bias를 줄이고 싶은지 간에

30
00:02:09,201 --> 00:02:13,386
더 큰 모델을 트레이닝 시키는 방법을 고려할 것 같습니다.

31
00:02:13,386 --> 00:02:18,124
그렇게하여 트레이닝세트에서 더 잘 하거나, 트레이닝 시간을 늘리는 방안을 생각해보십시오.

32
00:02:18,124 --> 00:02:21,196
더욱 향상된 최적화 알고리즘 또한 사용하십시오.

33
00:02:24,005 --> 00:02:27,433
Adds momentum, RMS prop 이나

34
00:02:27,433 --> 00:02:32,060
ADAM 같은 것을 사용하십시오.

35
00:02:34,874 --> 00:02:39,894
또 다른 방법으로는 더 나은 구조를 찾는 것인데요,

36
00:02:39,894 --> 00:02:45,220
구체적으로, 더 좋은 하이퍼 파라미터를 사용하거나

37
00:02:45,220 --> 00:02:50,187
활성함수 사용 및, 층의 개수나 숨겨진 
유닛의 개수를 바꾸는 방법이 있겠습니다.

38
00:02:50,187 --> 00:02:55,341
이렇게 하더라도 model size를 China로 
또는 다른 모델 구조를 바꾸는 방향으로 할 것입니다.

39
00:02:55,341 --> 00:03:00,654
재발되는 신경망이나 컨볼루션 신경망에서처럼 말이죠.

40
00:03:00,654 --> 00:03:06,500
이런 내용은 나중에 다른 코스에서 다루도록 하겠습니다.

41
00:03:06,500 --> 00:03:09,520
새로운 신경망 구조가 트레이닝세트에 더 좋게

42
00:03:09,520 --> 00:03:12,800
반영될 지 여부는 이벤트에 따라 분간하기 어려울 수 있습니다만,

43
00:03:12,800 --> 00:03:16,570
더 향상된 구조로는 조금 쉬울 수도 있습니다.

44
00:03:18,500 --> 00:03:20,941
편차가 문제라는 것 가정하에,

45
00:03:20,941 --> 00:03:26,417
시도할 수 있는 여러 자기 기술들이 있는데요. 몇 개 말씀 드리죠.

46
00:03:26,417 --> 00:03:30,762
더 많은 데이터를 수집하는 방안이 있는데요,

47
00:03:30,762 --> 00:03:35,437
트레이닝 하는 곳에 더 많은 데이터가 
있으면 dev set에 더욱 잘 이관할 수 있습니다.

48
00:03:35,437 --> 00:03:37,759
일반화를 시도해 볼 수도 있습니다.

49
00:03:37,759 --> 00:03:43,000
dropout이라는 것과,

50
00:03:43,000 --> 00:03:50,501
data augmentation이라는 것이죠. 이것은 이전 코스에서 다루어 졌었던 내용이기도 합니다.

51
00:03:50,501 --> 00:03:55,187
아니면 또 다시 한번, 다른 여러 가지 신경망 구조에 대한 방법을 모색할 수도 있습니다.

52
00:03:55,187 --> 00:03:58,467
하이퍼 파라미터 와 같은 것을 통해,

53
00:03:58,467 --> 00:04:02,390
문제에 더 적합한 새로운 구조를 찾는 것이죠.

54
00:04:03,810 --> 00:04:07,430
제 생각에는 바이어스 나 avoidable bias에 대한 개념은,

55
00:04:07,430 --> 00:04:12,150
쉽게 배울 수는 있지만, 마스터하기 어려운 내용인 것 같습니다.

56
00:04:12,150 --> 00:04:16,090
이런 내용에 대해서 이번 주에 시스템적인 측면에서 기본 컨셉을 다루어 보았는데요.

57
00:04:16,090 --> 00:04:20,244
이제는 여러분이 현재 있는 많은 머신러닝팀보다

58
00:04:20,244 --> 00:04:24,734
더욱 효율적이고 시스템적인 접근을 하실 수 있을 겁니다.

59
00:04:24,734 --> 00:04:28,567
어떻게 하면 머신러닝을 통해 성능을 향상시킬 것인지에 대한 부분을 말이죠.

60
00:04:28,567 --> 00:04:32,982
이 번주 강의 내용은 여러분이 연습하고

61
00:04:32,982 --> 00:04:36,832
컨셉에 대해 이해하기 충분할 것입니다.

62
00:04:36,832 --> 00:04:38,950
숙제를 잘 마치시기 바라며,

63
00:04:38,950 --> 00:04:42,463
다음주에 뵙도록 하겠습니다.

64
00:06:19,757 --> 00:06:20,701
[무음]