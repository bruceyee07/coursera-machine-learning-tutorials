1
00:00:00,008 --> 00:00:03,400
인간레벨성능 이라는 표현은 리서치

2
00:00:03,400 --> 00:00:05,820
기사에서 심심찮게 쓰이는 단어인데요.

3
00:00:05,820 --> 00:00:09,070
조금 더 정확히 이 부분에 대해 설명 드리도록 하겠습니다.

4
00:00:09,070 --> 00:00:13,350
특히, human-level performance의 문구를 정의하도록 해보겠습니다.

5
00:00:13,350 --> 00:00:17,430
이 부분이 머신러닝 프로젝트에서 진전이 있을 수 있도록 촉진제 역할을 할 수 있는 문구죠.

6
00:00:19,370 --> 00:00:23,455
이전 비디오 내용을 기억하시겠지만, human-level error 이라는 문구가 사용되는 부분에서

7
00:00:23,455 --> 00:00:28,820
알다시피 Bayes error를 추정하는 길을 마련해줍니다.

8
00:00:28,820 --> 00:00:31,914
어떠한 함수가 최선의 에러를 가질 수 있도록

9
00:00:31,914 --> 00:00:35,380
하는 값은, 현재 시점 또는 특정 미래 시점에 대하, 어떤 값일까요?

10
00:00:35,380 --> 00:00:40,190
이러한 점들을 염두 하면서, 의학이미지 분류를 사례로 보도록 하겠습니다.

11
00:00:40,190 --> 00:00:43,900
여러분들이 이런 방사선 사진을 본다고 해봅시다.

12
00:00:43,900 --> 00:00:48,010
이 이미지를 바탕으로 분류하는 업무를 맡았다고 해보죠.

13
00:00:49,155 --> 00:00:52,541
전형적인 인간은, 트레이닝 경험이 있지 않은 사람은

14
00:00:52,541 --> 00:00:55,350
3퍼센트의 오류를 범합니다.

15
00:00:55,350 --> 00:01:02,460
일반적인 의사는, 방사선학 전문 의사 경우, 1퍼센트의 오류를 범하고요.

16
00:01:02,460 --> 00:01:06,330
경험이 많은 의사는 더 잘하겠죠. 0.7퍼센트 오류가 있을 수 있습니다.

17
00:01:06,330 --> 00:01:11,370
경험이 많은 의사로 구성된 팀은,

18
00:01:11,370 --> 00:01:14,790
이미지를 모두 분석하고 그 내용에 대하여 토론하여

19
00:01:14,790 --> 00:01:20,085
통합적으로 의견을 취합하여 0.5퍼센트 오류가 있습니다.

20
00:01:20,085 --> 00:01:25,247
제가 여러분께 질문하고 싶은 부분은, 어떻게 인간레벨 오류를 정의할 수 있는 것일까요?

21
00:01:25,247 --> 00:01:31,080
인간의 오류는 3퍼센트? 1퍼센트? 0.7퍼센트? 0.5퍼센트? 어떤 게 맞는 것일까요?

22
00:01:31,080 --> 00:01:34,910
비디오를 잠시 멈추고 생각해보셔도 됩니다.

23
00:01:34,910 --> 00:01:39,690
이 질문에 답하기 위해서 한가지 알려드리자면 인간오류를 생각하기 가장 좋은

24
00:01:39,690 --> 00:01:45,990
부분은 프록시로 또는, Bayes error로 접근을 하는 방식입니다.

25
00:01:45,990 --> 00:01:50,360
자 그럼 비디오를 멈추시고 한번 생각해보시기 바랍니다.

26
00:01:50,360 --> 00:01:55,300
저는 인간레벨 오류를 이렇게 정의할 것 같습니다.

27
00:01:55,300 --> 00:02:00,014
프록시나 Bayes error의 추정 값을 원하는 경우,

28
00:02:00,014 --> 00:02:04,924
경험이 많은 의사 팀이 토론에 거쳐

29
00:02:04,924 --> 00:02:08,102
0.5퍼센트의 오류를 범할 수 있다고 하면

30
00:02:08,102 --> 00:02:12,649
Bayes error는 0.5퍼센트이거나 그 이하일 것입니다.

31
00:02:12,649 --> 00:02:17,801
어떠한 시스템은 이런 팀들이 0.5퍼센트 오류를 범할 수 있기 때문에,

32
00:02:17,801 --> 00:02:23,366
정의를 하자면, 직접적으로 최적 오류는 0.5퍼센트이거나 낮다고 할 수 있습니다.

33
00:02:23,366 --> 00:02:26,680
얼마나 그 오류가 작을지 모르지만, 경험 있는 의사 팀의 규모가

34
00:02:26,680 --> 00:02:29,488
더 클 수도 있고, 의사의 경험레벨이 더 높을 수도 있습니다,

35
00:02:29,488 --> 00:02:32,087
그러므로 0.5퍼센트보다 당연히 낮을 수 있겠죠.

36
00:02:32,087 --> 00:02:36,325
그렇지만 최적 오류는 0.5퍼센트보다 높을 수 없습니다.

37
00:02:36,325 --> 00:02:43,265
그래서 이런 설정에서, 저 같은 경우엔 0.5퍼센트를 Bayes error의 추정치로 지정할 것입니다.

38
00:02:43,265 --> 00:02:48,548
그렇게 해서 0.5퍼센트를 인간레벨성능으로 정의하는 것이죠.

39
00:02:48,548 --> 00:02:52,928
적어도 이전 비디오에서 본 것과 같이 바이어스와 편차 분석 목적으로

40
00:02:52,928 --> 00:02:55,300
인간레벨성능을 이용하는 경우엔 말이죠.

41
00:02:56,330 --> 00:02:59,370
논문 목적이나

42
00:02:59,370 --> 00:03:03,535
시스템 도입이 목적인 경우엔 사용할 수 있는

43
00:03:03,535 --> 00:03:06,725
인간레벨성능의 정의가 다를 수 있는데요

44
00:03:06,725 --> 00:03:10,675
일반적인 의사의 능력 이상은 되어야 할 것입니다.

45
00:03:10,675 --> 00:03:13,865
성공하면 굉장히 유용할 수 있는데요,

46
00:03:13,865 --> 00:03:18,002
일반 방사선학 의사의 능력과, 의사 개인 역량을 뛰어넘은 시스템이라고 하면,

47
00:03:18,002 --> 00:03:21,312
도입이 가능할 수도 있는 시스템일 수도 있습니다.

48
00:03:22,342 --> 00:03:26,412
그렇기 때문에 이번 학습에서 명심하실 부분은 어떤 목적으로

49
00:03:26,412 --> 00:03:28,902
인간레벨 오류를 정의할 것인지에 대해 정확하게 설정하는 것입니다.

50
00:03:28,902 --> 00:03:34,006
이런 목적이 어느 분야에서 특정 사람을 능가하여 시스템을 도입시키는 것에

51
00:03:34,006 --> 00:03:39,126
그 의의를 두고 있는 것이라고 하면 경우에 따라 이것이 적합한 정의라고 할 수 있겠죠.

52
00:03:39,126 --> 00:03:41,642
하지만 Bayes error의 프록시가 목표인 경우,

53
00:03:41,642 --> 00:03:44,976
이것이 적합한 정의라고 할 수 있습니다.

54
00:03:44,976 --> 00:03:48,662
이게 왜 중요한지, 오류 분석 사례를 통해 한번 알아보도록 하겠습니다.

55
00:03:51,642 --> 00:03:55,830
의학 이미지 진단 사례를 예로 들겠습니다.

56
00:03:55,830 --> 00:04:00,320
트레이닝 오류가 5퍼센트이고, dev error가 6퍼센트 입니다.

57
00:04:00,320 --> 00:04:05,260
이전 슬라이드 예시에서 봤듯이, 인간레벨성능 슬라이드요,

58
00:04:05,260 --> 00:04:08,688
이것을 Bayes error의 프록시라고 생각할 것입니다.

59
00:04:12,460 --> 00:04:17,577
여러분이 이것을 일반적인 의사 능력으로 했거나

60
00:04:17,577 --> 00:04:22,362
경험 있는 의사 또는 의사 팀으로 정의했는지에 따라 각각 1퍼센트,

61
00:04:22,362 --> 00:04:24,599
0.7퍼센트, 0.5퍼센트의 값을 가질 것입니다.

62
00:04:24,599 --> 00:04:28,476
이전 비디오에서 정의 내린 것과 같이,

63
00:04:28,476 --> 00:04:32,504
Bayes error또는 Bayes error 추정 값과

64
00:04:32,504 --> 00:04:36,625
training error의 차이는 avoidable bias 측정 값입니다.

65
00:04:36,625 --> 00:04:40,633
이것은 여러분의 러닝 알고리즘에서 얼마나

66
00:04:40,633 --> 00:04:42,067
편차가 있는지를 측정하는 수치입니다.

67
00:04:44,417 --> 00:04:49,008
첫 번째 사례에서 여러분이 어떤 결정을 내리던,

68
00:04:49,008 --> 00:04:53,271
avoidable bias의 값은 4퍼센트 정도 될 것입니다.

69
00:04:53,271 --> 00:04:56,784
아마도 4퍼센트에서

70
00:04:56,784 --> 00:05:02,526
이것을 4.5퍼센트까지로 하면, 0.5퍼센트 이용하면, 반면에 이것은 1퍼센트입니다.

71
00:05:06,108 --> 00:05:08,013
이번 사례에서는,

72
00:05:08,013 --> 00:05:12,780
인간레벨 오류를 어떻게 정의하는지는 그리 중요하지 않습니다.

73
00:05:12,780 --> 00:05:15,435
일반적인 의사 오류로 지정하거나

74
00:05:15,435 --> 00:05:20,361
의사 개인 오류로 지정하거나, 의사 팀의 오류로 지정하거나 말이죠.

75
00:05:20,361 --> 00:05:27,520
이 값이 4퍼센트 또는 4.5퍼센트이면 편차문제보다 더 큰 값이 되죠.

76
00:05:27,520 --> 00:05:29,020
이런 경우엔,

77
00:05:29,020 --> 00:05:34,490
바이어스를 줄이는 테크닉에 중점을 두어야 합니다. 더 큰 네트워크를 트레이닝 시키는 테크닉 말이죠.

78
00:05:34,490 --> 00:05:36,970
두 번째 사례를 보겠습니다.

79
00:05:36,970 --> 00:05:42,880
트레이닝 오류가 1퍼센트, dev 오류가 5퍼센트입니다.

80
00:05:42,880 --> 00:05:45,386
하지만 별로 중요하지 않습니다.

81
00:05:45,386 --> 00:05:49,617
인간레벨성능이 1퍼센트, 0.7퍼센트.0.5퍼센트인지 말이죠.

82
00:05:49,617 --> 00:05:54,599
어떠한 것을 사용하더라도, avoidable bias값이

83
00:05:54,599 --> 00:05:59,517
모두 0에서 0.5퍼센트일테니 말이죠. 맞죠?

84
00:05:59,517 --> 00:06:03,268
이것은 인간레벨성능과 트레이닝 오류 사이의 차이입니다.

85
00:06:03,268 --> 00:06:04,516
반면에 이 차이는 4퍼센트입니다.

86
00:06:04,516 --> 00:06:08,976
그렇기 때문에 이 4퍼센트가 어떻게 하던 간에 avoidable bias보다 더 클 것입니다.

87
00:06:08,976 --> 00:06:13,355
그러므로 편차를 줄이는 테크닉을 쓰길 권장할 것입니다.

88
00:06:13,355 --> 00:06:16,571
일반화 이나 더 튼 트레이닝세트를 사용하는 것처럼 말이죠.

89
00:06:16,571 --> 00:06:20,946
하지만 정말로 중요한 부분은 트레이닝 오류가 0.7퍼센트인지 여부입니다.

90
00:06:20,946 --> 00:06:26,830
여러분이 정말 잘해서 dev error가 0.8퍼센트가 되었습니다.

91
00:06:26,830 --> 00:06:33,597
만약 이런 경우엔, Bayes error의 추정치가 0.5퍼센트가 되도록 지정하는 것이 매우 중요합니다.

92
00:06:36,027 --> 00:06:41,303
이 경우, avoidable bias의 값이 0.2퍼센트가 되기 때문입니다.

93
00:06:41,303 --> 00:06:46,512
편차가 0.1퍼센트이기 때문에 avoidable bias가 2배로 더 큰 값입니다.

94
00:06:48,592 --> 00:06:52,226
이렇게 되면 바이어스와 편차 2가지 모두 문제인데요,

95
00:06:52,226 --> 00:06:54,880
avoidable bias가 조금 더 큰 문제라고 볼 수 있습니다.

96
00:06:54,880 --> 00:07:00,000
이번 사례는, 0.5퍼센트, 이번 슬라이드에서 다뤘듯이

97
00:07:00,000 --> 00:07:04,130
Bayes error에서 가장 좋게 나온 값입니다. 의사 팀이 가장 좋은 성과를 가져올 수 있기 때문이죠,

98
00:07:04,130 --> 00:07:08,711
만약 0.7을 Bayes error의 추정치로 하고,

99
00:07:08,711 --> 00:07:13,200
avoidable bias를 거의 0퍼센트로 했을 것입니다. 이것을 아마 놓쳤을 텐데요.

100
00:07:13,200 --> 00:07:15,870
트레이닝 세트에서 더 잘 할 수 있도록 해야 될 것입니다.

101
00:07:18,085 --> 00:07:22,640
머신러닝 문제에서 인간레벨성능에 도달해가는 시점에서

102
00:07:22,640 --> 00:07:27,660
발전을 이루기 왜 어려운지 어느 정도 감이 왔기를 바라는데요.

103
00:07:27,660 --> 00:07:31,600
이번 사례는, 0.7퍼센트 오류에 도달했을 때,

104
00:07:31,600 --> 00:07:35,300
Bayes error를 추정하는데 굉장히 신경 쓰지 않는 이상,

105
00:07:35,300 --> 00:07:38,620
Bayes error에서 얼마나 떨어져 있는지 알기 어려울 것입니다.

106
00:07:38,620 --> 00:07:42,999
그러므로 avoidable bias를 얼마나 줄여야 할지도 모를 것이고요.

107
00:07:42,999 --> 00:07:47,691
여러분이 알 수 있는 것은 사실 일반적인 의사의 오류가 0.1퍼센트라는 것,

108
00:07:47,691 --> 00:07:52,247
이것이 전부이기 때문에 트레이닝 세트를 피팅하기 매우

109
00:07:52,247 --> 00:07:53,070
까다로울 것입니다.

110
00:07:54,860 --> 00:07:58,720
더군다나 이러한 문제가 이미 잘하고 있는 상황에서 생긴 것이기 때문에 더 힘들죠.

111
00:07:58,720 --> 00:08:02,764
0.7퍼센트, 0.8퍼센트와 같이 인간레벨성능과 거의 비슷한 시점에서 말이죠.

112
00:08:04,430 --> 00:08:09,254
반면에, 왼쪽의 2가지 사례는 인간레벨성능에서 멀리

113
00:08:09,254 --> 00:08:13,530
떨어져 있는 상황이기 때문에 바이어스와 편차에 중점을 두기 쉬운 부분이 있었습니다.

114
00:08:13,530 --> 00:08:17,209
이러한 사례들이 보여주듯이, 인간라벨성능과 가까운 선상에 있는 경우,

115
00:08:17,209 --> 00:08:20,071
바이어스와 편차효과를 제거하기가 굉장히 더 어렵습니다.

116
00:08:20,071 --> 00:08:23,555
그러므로 결과적으로는 더 잘하면 잘할수록

117
00:08:23,555 --> 00:08:24,810
머신러닝에서 발전을 이루기가 점진적으로 어려워지는 것입니다.

118
00:08:25,930 --> 00:08:28,590
이야기했던 내용을 요약하자면

119
00:08:28,590 --> 00:08:31,863
인간이 이미 잘 수행하는 업무에 대하여

120
00:08:31,863 --> 00:08:36,734
바이어스와 편차를 이해하기 위해선,

121
00:08:36,734 --> 00:08:41,419
인간레벨 오류의 프록시 또는 Bayes error의 추정 값을 사용할 수 있습니다.

122
00:08:47,130 --> 00:08:51,917
Bayes error의 추정 값 차이를 통해

123
00:08:51,917 --> 00:08:56,568
얼마만큼이나 avoidable bias가 문제가 되는지 알 수 있습니다.

124
00:08:56,568 --> 00:08:59,767
그리고, 트레이닝 오류와 dev error의 차이를 통해

125
00:08:59,767 --> 00:09:04,075
편차의 문제를 파악할 수 있는데요.

126
00:09:04,075 --> 00:09:07,500
트레이닝세트에서 dev set로 해당 알고리즘이 이관될 수 있는지를 파악할 수 있습니다.

127
00:09:07,500 --> 00:09:10,708
이번 토론 내용과

128
00:09:10,708 --> 00:09:15,740
이전 코스에서 다뤘던 내용의 큰 차이는, 트레이닝 오류를 0퍼센트와 비교하기 보다는,

129
00:09:18,471 --> 00:09:23,553
그것을 바이어스의 추정 그 자체로 보는 것입니다.

130
00:09:23,553 --> 00:09:28,400
반대로, 이번 비디오에선 딱히 0퍼센트로 예측하는 것이 없다는

131
00:09:28,400 --> 00:09:31,999
조금 미묘한 분석이 있는데요

132
00:09:31,999 --> 00:09:36,269
이유인 즉 슨, Bayes error가 0이 아닌 경우가 있고,

133
00:09:36,269 --> 00:09:39,198
가끔씩은 단순히 특정 한계치보다 더 좋은 결과가 나오는 것이 불가능하기 때문이죠.

134
00:09:41,723 --> 00:09:46,305
이전 코스에서, 트레이닝 오류를 계산하고,

135
00:09:46,305 --> 00:09:49,895
0보다 얼마나 더 큰지 비교해보았는데요,

136
00:09:49,895 --> 00:09:53,720
이렇게 해서 바이어스가 얼마나 큰지 알아봤습니다.

137
00:09:53,720 --> 00:09:58,458
Bayes error가 0에 가까운 경우엔 잘 된다는 사실을 알았는데요,

138
00:09:58,458 --> 00:10:00,085
고양이 인식 프로그램 같은 경우 말이죠.

139
00:10:00,085 --> 00:10:04,005
이 경우, 인간이 거의 완벽하기 때문에, Bayes error도 거의 완벽하다고 볼 수 있습니다.

140
00:10:04,005 --> 00:10:07,525
그러므로, Bayes error가 0에 가까울 경우 잘 작동하는데요,

141
00:10:07,525 --> 00:10:11,441
데이터가 음성인식기기처럼 혼잡하거나,

142
00:10:11,441 --> 00:10:14,831
오디오가 시끄러운 경우 여러분이 말한 것을 인식하기 어려운 경우가 있습니다.

143
00:10:14,831 --> 00:10:16,594
이런 경우, 표기화가 불가능하죠.

144
00:10:16,594 --> 00:10:19,239
이런 문제의 경우, Bayes error에 대한 추정치를

145
00:10:19,239 --> 00:10:22,787
더 정확하게 알면, avoidable bias와 편차를 더 정확히 추정할 수 있습니다.

146
00:10:22,787 --> 00:10:26,569
그러므로 결과적으로 바이어스를 줄이는데 중점을 둘 것인지,

147
00:10:26,569 --> 00:10:28,955
편차를 줄이는데 초점을 맞출 것인지 결정을 내릴 수 있습니다.

148
00:10:30,915 --> 00:10:34,855
복습하자면, 인간레벨성능의 추정치를 알면

149
00:10:34,855 --> 00:10:36,442
Bayes error의 예상 값을 알 수 있습니다.

150
00:10:36,442 --> 00:10:40,468
그 이후, 여러분의 알고리즘에서 바이어스의 값을 줄일지,

151
00:10:40,468 --> 00:10:44,390
편차 값을 줄일지 의사결정을 내릴 수 있습니다.

152
00:10:45,690 --> 00:10:50,190
이런 테크닉은 인간레벨성능을 도달하기 전까지는

153
00:10:50,190 --> 00:10:54,750
잘 작동할 것입니다. 그 이후로는 Bayes error 추정 값이 구하기 어렵기 때문에

154
00:10:54,750 --> 00:10:57,420
의사결정을 내리는데 어려움이 있을 수 있습니다.

155
00:10:58,470 --> 00:11:01,980
딥러닝의 흥미로운 발달 부문은

156
00:11:01,980 --> 00:11:06,360
바로 더 많은 수행업무들이 인간레벨성능을 능가할 수 있다는 점입니다.

157
00:11:06,360 --> 00:11:07,630
다음 비디오에서는

158
00:11:07,630 --> 00:11:11,394
인간레벨성능 능가하는 절차에 대해 더 자세히 이야기해보도록 하겠습니다.