여러분은 직교화에 대해 들어 본 적이 있으실 텐데요. dev set와 테스트세트를 설정하는 방법 인간레벨성능을 Bayers error에 대한 프록시로 사용하는 방법 및 avoidable bias 및 분산을 추정하는 방법. 이제 모든 것들을 가이드라인으로 취합해보겠습니다. 여러분의 러닝 알고리즘 성능을 향상시키는 방안에 대해서 말이죠. 그러니까, 제가 생각하기에 러닝 알고리즘이 효과가 있기 위해선 근본적으로 2가지의 전제조건이 있다고 봅니다. 첫 번째로는 트레이닝세트를 잘 대입할 수 있다는 것이고, 이것은 대략적으로 말해서 낮은 avoidable bias를
 획득할 수 있다는 것으로 이해하시면 됩니다. 두 번째로는, 트레이닝 세트에서 잘하는 것은 보통 dev set나 테스트 세트로 잘 
이어서 잘되는 경우가 많습니다. 이것은 편차가 나쁘지 않다는 것이죠. Thought organization 영역에서 비추어볼 때, 손잡이의 세트가 트레이닝 시킨다던 지 더욱 긴 시간 트레이닝을 
진행하면서 문제를 해결해주는 경우가 있습니다. 또한, 또 다른 세트가 Damien’s problems과 
연관된 문제들을 해결해줄 수 있습니다. 일반화 이나 더 많은 데이터 수집을 하는 방법으로 말이죠. 지난 몇 개의 비디오를 통해 배운 내용을 요약하자면, 시스템에 있는 여러분의 머신 성능을 향상시키고 싶으시면 트레이닝 에러와 Bayers error의 프록시 차이를 보시고, avoidable bias에 대한 이해도를 높이시길 바랍니다. 다시 말해, 트레이닝 세트에서 얼마나 더 잘해야 할지 보시고 그 이후로, dev error와 트레이닝 에러의 차이를 이해하시면 됩니다. 결국에는 편차/변동의 문제입니다. 달리 말하면, 바로 대놓고 트레이닝 시키지 못한 부분에 대해서 얼마나 더 일을 수행해야 하는지가 관건인 것인데요, 트레이닝세트에서 dev set로 넘어갈 때 말이죠. 얼마나 avoidable bias를 줄이고 싶은지 간에 더 큰 모델을 트레이닝 시키는 방법을 고려할 것 같습니다. 그렇게하여 트레이닝세트에서 더 잘 하거나, 트레이닝 시간을 늘리는 방안을 생각해보십시오. 더욱 향상된 최적화 알고리즘 또한 사용하십시오. Adds momentum, RMS prop 이나 ADAM 같은 것을 사용하십시오. 또 다른 방법으로는 더 나은 구조를 찾는 것인데요, 구체적으로, 더 좋은 하이퍼 파라미터를 사용하거나 활성함수 사용 및, 층의 개수나 숨겨진 
유닛의 개수를 바꾸는 방법이 있겠습니다. 이렇게 하더라도 model size를 China로 
또는 다른 모델 구조를 바꾸는 방향으로 할 것입니다. 재발되는 신경망이나 컨볼루션 신경망에서처럼 말이죠. 이런 내용은 나중에 다른 코스에서 다루도록 하겠습니다. 새로운 신경망 구조가 트레이닝세트에 더 좋게 반영될 지 여부는 이벤트에 따라 분간하기 어려울 수 있습니다만, 더 향상된 구조로는 조금 쉬울 수도 있습니다. 편차가 문제라는 것 가정하에, 시도할 수 있는 여러 자기 기술들이 있는데요. 몇 개 말씀 드리죠. 더 많은 데이터를 수집하는 방안이 있는데요, 트레이닝 하는 곳에 더 많은 데이터가 
있으면 dev set에 더욱 잘 이관할 수 있습니다. 일반화를 시도해 볼 수도 있습니다. dropout이라는 것과, data augmentation이라는 것이죠. 이것은 이전 코스에서 다루어 졌었던 내용이기도 합니다. 아니면 또 다시 한번, 다른 여러 가지 신경망 구조에 대한 방법을 모색할 수도 있습니다. 하이퍼 파라미터 와 같은 것을 통해, 문제에 더 적합한 새로운 구조를 찾는 것이죠. 제 생각에는 바이어스 나 avoidable bias에 대한 개념은, 쉽게 배울 수는 있지만, 마스터하기 어려운 내용인 것 같습니다. 이런 내용에 대해서 이번 주에 시스템적인 측면에서 기본 컨셉을 다루어 보았는데요. 이제는 여러분이 현재 있는 많은 머신러닝팀보다 더욱 효율적이고 시스템적인 접근을 하실 수 있을 겁니다. 어떻게 하면 머신러닝을 통해 성능을 향상시킬 것인지에 대한 부분을 말이죠. 이 번주 강의 내용은 여러분이 연습하고 컨셉에 대해 이해하기 충분할 것입니다. 숙제를 잘 마치시기 바라며, 다음주에 뵙도록 하겠습니다. [무음]