인간레벨성능 이라는 표현은 리서치 기사에서 심심찮게 쓰이는 단어인데요. 조금 더 정확히 이 부분에 대해 설명 드리도록 하겠습니다. 특히, human-level performance의 문구를 정의하도록 해보겠습니다. 이 부분이 머신러닝 프로젝트에서 진전이 있을 수 있도록 촉진제 역할을 할 수 있는 문구죠. 이전 비디오 내용을 기억하시겠지만, human-level error 이라는 문구가 사용되는 부분에서 알다시피 Bayes error를 추정하는 길을 마련해줍니다. 어떠한 함수가 최선의 에러를 가질 수 있도록 하는 값은, 현재 시점 또는 특정 미래 시점에 대하, 어떤 값일까요? 이러한 점들을 염두 하면서, 의학이미지 분류를 사례로 보도록 하겠습니다. 여러분들이 이런 방사선 사진을 본다고 해봅시다. 이 이미지를 바탕으로 분류하는 업무를 맡았다고 해보죠. 전형적인 인간은, 트레이닝 경험이 있지 않은 사람은 3퍼센트의 오류를 범합니다. 일반적인 의사는, 방사선학 전문 의사 경우, 1퍼센트의 오류를 범하고요. 경험이 많은 의사는 더 잘하겠죠. 0.7퍼센트 오류가 있을 수 있습니다. 경험이 많은 의사로 구성된 팀은, 이미지를 모두 분석하고 그 내용에 대하여 토론하여 통합적으로 의견을 취합하여 0.5퍼센트 오류가 있습니다. 제가 여러분께 질문하고 싶은 부분은, 어떻게 인간레벨 오류를 정의할 수 있는 것일까요? 인간의 오류는 3퍼센트? 1퍼센트? 0.7퍼센트? 0.5퍼센트? 어떤 게 맞는 것일까요? 비디오를 잠시 멈추고 생각해보셔도 됩니다. 이 질문에 답하기 위해서 한가지 알려드리자면 인간오류를 생각하기 가장 좋은 부분은 프록시로 또는, Bayes error로 접근을 하는 방식입니다. 자 그럼 비디오를 멈추시고 한번 생각해보시기 바랍니다. 저는 인간레벨 오류를 이렇게 정의할 것 같습니다. 프록시나 Bayes error의 추정 값을 원하는 경우, 경험이 많은 의사 팀이 토론에 거쳐 0.5퍼센트의 오류를 범할 수 있다고 하면 Bayes error는 0.5퍼센트이거나 그 이하일 것입니다. 어떠한 시스템은 이런 팀들이 0.5퍼센트 오류를 범할 수 있기 때문에, 정의를 하자면, 직접적으로 최적 오류는 0.5퍼센트이거나 낮다고 할 수 있습니다. 얼마나 그 오류가 작을지 모르지만, 경험 있는 의사 팀의 규모가 더 클 수도 있고, 의사의 경험레벨이 더 높을 수도 있습니다, 그러므로 0.5퍼센트보다 당연히 낮을 수 있겠죠. 그렇지만 최적 오류는 0.5퍼센트보다 높을 수 없습니다. 그래서 이런 설정에서, 저 같은 경우엔 0.5퍼센트를 Bayes error의 추정치로 지정할 것입니다. 그렇게 해서 0.5퍼센트를 인간레벨성능으로 정의하는 것이죠. 적어도 이전 비디오에서 본 것과 같이 바이어스와 편차 분석 목적으로 인간레벨성능을 이용하는 경우엔 말이죠. 논문 목적이나 시스템 도입이 목적인 경우엔 사용할 수 있는 인간레벨성능의 정의가 다를 수 있는데요 일반적인 의사의 능력 이상은 되어야 할 것입니다. 성공하면 굉장히 유용할 수 있는데요, 일반 방사선학 의사의 능력과, 의사 개인 역량을 뛰어넘은 시스템이라고 하면, 도입이 가능할 수도 있는 시스템일 수도 있습니다. 그렇기 때문에 이번 학습에서 명심하실 부분은 어떤 목적으로 인간레벨 오류를 정의할 것인지에 대해 정확하게 설정하는 것입니다. 이런 목적이 어느 분야에서 특정 사람을 능가하여 시스템을 도입시키는 것에 그 의의를 두고 있는 것이라고 하면 경우에 따라 이것이 적합한 정의라고 할 수 있겠죠. 하지만 Bayes error의 프록시가 목표인 경우, 이것이 적합한 정의라고 할 수 있습니다. 이게 왜 중요한지, 오류 분석 사례를 통해 한번 알아보도록 하겠습니다. 의학 이미지 진단 사례를 예로 들겠습니다. 트레이닝 오류가 5퍼센트이고, dev error가 6퍼센트 입니다. 이전 슬라이드 예시에서 봤듯이, 인간레벨성능 슬라이드요, 이것을 Bayes error의 프록시라고 생각할 것입니다. 여러분이 이것을 일반적인 의사 능력으로 했거나 경험 있는 의사 또는 의사 팀으로 정의했는지에 따라 각각 1퍼센트, 0.7퍼센트, 0.5퍼센트의 값을 가질 것입니다. 이전 비디오에서 정의 내린 것과 같이, Bayes error또는 Bayes error 추정 값과 training error의 차이는 avoidable bias 측정 값입니다. 이것은 여러분의 러닝 알고리즘에서 얼마나 편차가 있는지를 측정하는 수치입니다. 첫 번째 사례에서 여러분이 어떤 결정을 내리던, avoidable bias의 값은 4퍼센트 정도 될 것입니다. 아마도 4퍼센트에서 이것을 4.5퍼센트까지로 하면, 0.5퍼센트 이용하면, 반면에 이것은 1퍼센트입니다. 이번 사례에서는, 인간레벨 오류를 어떻게 정의하는지는 그리 중요하지 않습니다. 일반적인 의사 오류로 지정하거나 의사 개인 오류로 지정하거나, 의사 팀의 오류로 지정하거나 말이죠. 이 값이 4퍼센트 또는 4.5퍼센트이면 편차문제보다 더 큰 값이 되죠. 이런 경우엔, 바이어스를 줄이는 테크닉에 중점을 두어야 합니다. 더 큰 네트워크를 트레이닝 시키는 테크닉 말이죠. 두 번째 사례를 보겠습니다. 트레이닝 오류가 1퍼센트, dev 오류가 5퍼센트입니다. 하지만 별로 중요하지 않습니다. 인간레벨성능이 1퍼센트, 0.7퍼센트.0.5퍼센트인지 말이죠. 어떠한 것을 사용하더라도, avoidable bias값이 모두 0에서 0.5퍼센트일테니 말이죠. 맞죠? 이것은 인간레벨성능과 트레이닝 오류 사이의 차이입니다. 반면에 이 차이는 4퍼센트입니다. 그렇기 때문에 이 4퍼센트가 어떻게 하던 간에 avoidable bias보다 더 클 것입니다. 그러므로 편차를 줄이는 테크닉을 쓰길 권장할 것입니다. 일반화 이나 더 튼 트레이닝세트를 사용하는 것처럼 말이죠. 하지만 정말로 중요한 부분은 트레이닝 오류가 0.7퍼센트인지 여부입니다. 여러분이 정말 잘해서 dev error가 0.8퍼센트가 되었습니다. 만약 이런 경우엔, Bayes error의 추정치가 0.5퍼센트가 되도록 지정하는 것이 매우 중요합니다. 이 경우, avoidable bias의 값이 0.2퍼센트가 되기 때문입니다. 편차가 0.1퍼센트이기 때문에 avoidable bias가 2배로 더 큰 값입니다. 이렇게 되면 바이어스와 편차 2가지 모두 문제인데요, avoidable bias가 조금 더 큰 문제라고 볼 수 있습니다. 이번 사례는, 0.5퍼센트, 이번 슬라이드에서 다뤘듯이 Bayes error에서 가장 좋게 나온 값입니다. 의사 팀이 가장 좋은 성과를 가져올 수 있기 때문이죠, 만약 0.7을 Bayes error의 추정치로 하고, avoidable bias를 거의 0퍼센트로 했을 것입니다. 이것을 아마 놓쳤을 텐데요. 트레이닝 세트에서 더 잘 할 수 있도록 해야 될 것입니다. 머신러닝 문제에서 인간레벨성능에 도달해가는 시점에서 발전을 이루기 왜 어려운지 어느 정도 감이 왔기를 바라는데요. 이번 사례는, 0.7퍼센트 오류에 도달했을 때, Bayes error를 추정하는데 굉장히 신경 쓰지 않는 이상, Bayes error에서 얼마나 떨어져 있는지 알기 어려울 것입니다. 그러므로 avoidable bias를 얼마나 줄여야 할지도 모를 것이고요. 여러분이 알 수 있는 것은 사실 일반적인 의사의 오류가 0.1퍼센트라는 것, 이것이 전부이기 때문에 트레이닝 세트를 피팅하기 매우 까다로울 것입니다. 더군다나 이러한 문제가 이미 잘하고 있는 상황에서 생긴 것이기 때문에 더 힘들죠. 0.7퍼센트, 0.8퍼센트와 같이 인간레벨성능과 거의 비슷한 시점에서 말이죠. 반면에, 왼쪽의 2가지 사례는 인간레벨성능에서 멀리 떨어져 있는 상황이기 때문에 바이어스와 편차에 중점을 두기 쉬운 부분이 있었습니다. 이러한 사례들이 보여주듯이, 인간라벨성능과 가까운 선상에 있는 경우, 바이어스와 편차효과를 제거하기가 굉장히 더 어렵습니다. 그러므로 결과적으로는 더 잘하면 잘할수록 머신러닝에서 발전을 이루기가 점진적으로 어려워지는 것입니다. 이야기했던 내용을 요약하자면 인간이 이미 잘 수행하는 업무에 대하여 바이어스와 편차를 이해하기 위해선, 인간레벨 오류의 프록시 또는 Bayes error의 추정 값을 사용할 수 있습니다. Bayes error의 추정 값 차이를 통해 얼마만큼이나 avoidable bias가 문제가 되는지 알 수 있습니다. 그리고, 트레이닝 오류와 dev error의 차이를 통해 편차의 문제를 파악할 수 있는데요. 트레이닝세트에서 dev set로 해당 알고리즘이 이관될 수 있는지를 파악할 수 있습니다. 이번 토론 내용과 이전 코스에서 다뤘던 내용의 큰 차이는, 트레이닝 오류를 0퍼센트와 비교하기 보다는, 그것을 바이어스의 추정 그 자체로 보는 것입니다. 반대로, 이번 비디오에선 딱히 0퍼센트로 예측하는 것이 없다는 조금 미묘한 분석이 있는데요 이유인 즉 슨, Bayes error가 0이 아닌 경우가 있고, 가끔씩은 단순히 특정 한계치보다 더 좋은 결과가 나오는 것이 불가능하기 때문이죠. 이전 코스에서, 트레이닝 오류를 계산하고, 0보다 얼마나 더 큰지 비교해보았는데요, 이렇게 해서 바이어스가 얼마나 큰지 알아봤습니다. Bayes error가 0에 가까운 경우엔 잘 된다는 사실을 알았는데요, 고양이 인식 프로그램 같은 경우 말이죠. 이 경우, 인간이 거의 완벽하기 때문에, Bayes error도 거의 완벽하다고 볼 수 있습니다. 그러므로, Bayes error가 0에 가까울 경우 잘 작동하는데요, 데이터가 음성인식기기처럼 혼잡하거나, 오디오가 시끄러운 경우 여러분이 말한 것을 인식하기 어려운 경우가 있습니다. 이런 경우, 표기화가 불가능하죠. 이런 문제의 경우, Bayes error에 대한 추정치를 더 정확하게 알면, avoidable bias와 편차를 더 정확히 추정할 수 있습니다. 그러므로 결과적으로 바이어스를 줄이는데 중점을 둘 것인지, 편차를 줄이는데 초점을 맞출 것인지 결정을 내릴 수 있습니다. 복습하자면, 인간레벨성능의 추정치를 알면 Bayes error의 예상 값을 알 수 있습니다. 그 이후, 여러분의 알고리즘에서 바이어스의 값을 줄일지, 편차 값을 줄일지 의사결정을 내릴 수 있습니다. 이런 테크닉은 인간레벨성능을 도달하기 전까지는 잘 작동할 것입니다. 그 이후로는 Bayes error 추정 값이 구하기 어렵기 때문에 의사결정을 내리는데 어려움이 있을 수 있습니다. 딥러닝의 흥미로운 발달 부문은 바로 더 많은 수행업무들이 인간레벨성능을 능가할 수 있다는 점입니다. 다음 비디오에서는 인간레벨성능 능가하는 절차에 대해 더 자세히 이야기해보도록 하겠습니다.