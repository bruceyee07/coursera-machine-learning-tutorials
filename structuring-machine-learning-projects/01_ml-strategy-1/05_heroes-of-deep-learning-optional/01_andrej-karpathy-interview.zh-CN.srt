1
00:00:02,977 --> 00:00:06,068
欢迎你 Andrej 非常荣幸今天能邀请到你

2
00:00:06,068 --> 00:00:08,180
谢谢你的邀请

3
00:00:08,180 --> 00:00:12,170
很多人都知道你在深度学习方面的工作

4
00:00:12,170 --> 00:00:14,600
但并不是每个人都了解你的个人经历

5
00:00:14,600 --> 00:00:17,100
那么 你能先讲讲

6
00:00:17,100 --> 00:00:20,510
你是如何走上深度学习的研究道路吗

7
00:00:20,510 --> 00:00:21,590
— 当然可以 

8
00:00:21,590 --> 00:00:25,100
我记得 我第一次接触深度学习

9
00:00:25,100 --> 00:00:26,520
是在多伦多大学读本科的时候

10
00:00:26,520 --> 00:00:28,696
当时Geoff Hinton在那儿开设了一门深度学习课程

11
00:00:28,696 --> 00:00:32,346
当时使用MNIST数字集训练<br />受限玻尔兹曼机(Restricted Boltzmann Machine) 

12
00:00:32,346 --> 00:00:35,966
我很喜欢Geoff所说的训练网络的方式

13
00:00:35,966 --> 00:00:38,999
他当时用的术语是 网络的心智

14
00:00:38,999 --> 00:00:42,333
我当时觉得 在使用这些数据进行训练时

15
00:00:42,333 --> 00:00:46,870
会发生某些神奇的事情

16
00:00:46,870 --> 00:00:50,130
这就是我第一次接触深度学习时的情况

17
00:00:50,130 --> 00:00:52,440
尽管当时我没有了解很多细节

18
00:00:52,440 --> 00:00:55,540
后来 当我在英属哥伦比亚大学<br />攻读硕士学位时

19
00:00:57,000 --> 00:00:59,850
我再次修了一门机器学习课程

20
00:00:59,850 --> 00:01:03,665
那时 我第一次对这些网络有了更深入的了解

21
00:01:03,665 --> 00:01:07,790
有意思的是 当时我对人工智能非常感兴趣

22
00:01:07,790 --> 00:01:10,430
所以我修了不少人工智能的课程

23
00:01:10,430 --> 00:01:12,690
不过我当时看到的很多东西 都不够令人满意

24
00:01:12,690 --> 00:01:16,277
有大量的深度优先搜索<br />广度优先搜索 Alpha-Beta剪枝

25
00:01:16,277 --> 00:01:17,220
等等这些东西

26
00:01:17,220 --> 00:01:20,190
我当时并不满意

27
00:01:20,190 --> 00:01:23,700
当我第一次碰到机器学习中的神经网络时

28
00:01:23,700 --> 00:01:25,720
我觉得这是个更偏技术的术语

29
00:01:25,720 --> 00:01:29,280
并不像大家都谈论的人工智能那样出名

30
00:01:29,280 --> 00:01:32,550
我几乎可以这样说<br />机器学习在当时更像是一个技术术语

31
00:01:32,550 --> 00:01:34,940
我对人工智能并不满意

32
00:01:34,940 --> 00:01:36,520
当我看到机器学习时 感觉就像

33
00:01:36,520 --> 00:01:41,498
这就是我想花时间研究的人工智能<br />这是真正有趣的东西

34
00:01:41,498 --> 00:01:45,200
于是我就走上了这个方向

35
00:01:45,200 --> 00:01:47,000
我觉得这几乎一个新的计算范式

36
00:01:48,210 --> 00:01:50,730
因为通常情况下 由人来编写代码

37
00:01:50,730 --> 00:01:54,263
但是在这种情况下 由优化程序编写代码

38
00:01:54,263 --> 00:01:56,260
你只是创建输入输出规范

39
00:01:56,260 --> 00:01:59,460
准备很多很多的样本 然后优化程序编写代码

40
00:01:59,460 --> 00:02:01,370
有时候它写的代码比你还要好

41
00:02:01,370 --> 00:02:06,300
所以我觉得这是一种非常新的编程思想

42
00:02:06,300 --> 00:02:08,150
这让我着迷

43
00:02:08,150 --> 00:02:11,580
在你的工作成果中 最令人称道的一件事

44
00:02:11,580 --> 00:02:18,030
是你现在成为了ImageNet图像分类大赛的人类基准

45
00:02:18,030 --> 00:02:19,280
这是怎么一回事呢

46
00:02:19,280 --> 00:02:23,620
大体来说 人们常把ImageNet比赛看做

47
00:02:23,620 --> 00:02:24,870
计算机视觉领域的世界杯

48
00:02:24,870 --> 00:02:27,820
所以无论人们是否关注这个基准和数字

49
00:02:27,820 --> 00:02:29,330
我们的错误率都会随时间越来越低

50
00:02:29,330 --> 00:02:33,390
在我看来 人类在这个评分标准上<br />能达到什么程度并不明显

51
00:02:33,390 --> 00:02:37,054
我曾使用CIFAR-10数据集进行了<br />类似的较小规模的实验

52
00:02:37,054 --> 00:02:40,437
当时使用CIFAR-10数据集时<br />我只是看着这些32乘32的图像

53
00:02:40,437 --> 00:02:42,290
然后自己尝试进行归类

54
00:02:42,290 --> 00:02:43,751
那时候 只有十个分类

55
00:02:43,751 --> 00:02:45,371
所以很容易为它创建一个界面

56
00:02:45,371 --> 00:02:48,341
我觉得 当时我的错误率大约是6%

57
00:02:48,341 --> 00:02:52,057
基于我了解的情况 以及任务本身的难度

58
00:02:52,057 --> 00:02:56,634
我预测了我们可以达到的最低错误率是

59
00:02:56,634 --> 00:02:58,812
好吧 我记不起来确切的数字了

60
00:02:58,812 --> 00:03:03,530
我猜是10%<br />现在我们达到了3%或2% 甚至更了不起的水平

61
00:03:03,530 --> 00:03:09,113
这就是我第一次开展人类基准实验的情况

62
00:03:09,113 --> 00:03:11,870
而且我觉得这是非常重要

63
00:03:11,870 --> 00:03:13,950
你在课上也指出了这一点

64
00:03:13,950 --> 00:03:18,790
我的意思是 这个数字对于了解<br />人类的所能达到的水平非常重要

65
00:03:18,790 --> 00:03:20,868
然后我们就可以拿机器学习算法和它进行比较

66
00:03:20,868 --> 00:03:24,610
对于ImageNet来说 在这个基准的重要性

67
00:03:24,610 --> 00:03:27,600
与应该花多大精力来降低错误率之间<br />似乎存在一些分歧

68
00:03:27,600 --> 00:03:31,800
我们甚至都不知道 人类在这个基准上的表现如何

69
00:03:31,800 --> 00:03:35,770
所以我编写了这个JavaScript界面<br />然后我自己看图片

70
00:03:35,770 --> 00:03:38,340
ImageNet的问题在于 不只有10个分类

71
00:03:38,340 --> 00:03:39,340
比如有1000个分类

72
00:03:39,340 --> 00:03:41,085
这几乎成了用户界面上的挑战

73
00:03:41,085 --> 00:03:44,443
很明显 我记不住这1000个分类都是什么<br />那么我怎么做才能

74
00:03:44,443 --> 00:03:45,708
保证公平呢

75
00:03:45,708 --> 00:03:48,955
于是我把所有的分类都列了出来<br />让自己看了一些样本

76
00:03:48,955 --> 00:03:52,679
对于每张图片 我向下滚动 浏览过1000个分类

77
00:03:52,679 --> 00:03:56,401
尝试根据我看到的每个分类里的样本

78
00:03:56,401 --> 00:03:57,739
来判断这张图片的分类可能是什么

79
00:03:57,739 --> 00:04:01,880
我觉得这个练习非常有启发

80
00:04:01,880 --> 00:04:06,539
我的意思是 我之前并不知道<br />ImageNet有三分之一是狗和狗的品种

81
00:04:06,539 --> 00:04:10,125
当我看到网络花了大量的时间来处理狗

82
00:04:10,125 --> 00:04:12,800
我觉得很有意思

83
00:04:12,800 --> 00:04:14,588
它三分之一的性能来源于狗

84
00:04:14,588 --> 00:04:20,809
这些工作可能花了我 一到两周的时间

85
00:04:20,809 --> 00:04:21,837
我放下了其他的事物

86
00:04:21,837 --> 00:04:24,250
我觉得这是个非常有意思的练习

87
00:04:24,250 --> 00:04:26,703
最终我得到了一个数字 然后我觉得一个人不够

88
00:04:26,703 --> 00:04:28,770
我需要更多的人

89
00:04:28,770 --> 00:04:32,275
所以我想办法在实验室内部<br />组织其他人也参与进来

90
00:04:32,275 --> 00:04:36,544
我觉得人们并不那么愿意 奉献一两周

91
00:04:36,544 --> 00:04:41,402
来做这么辛苦的工作 坐上五个小时

92
00:04:41,402 --> 00:04:44,222
想办法确定一条狗的品种是什么

93
00:04:44,222 --> 00:04:47,876
所以在这方面 我没法得到足够的数据

94
00:04:47,876 --> 00:04:53,430
但至少对人类的表现得到了一些近似的估计<br />我觉得这很有趣

95
00:04:53,430 --> 00:04:57,530
然后大家知道了这件事 但我当时并没有察觉

96
00:04:57,530 --> 00:04:59,946
我只是想知道这个数字 然后就成了这样

97
00:04:59,946 --> 00:05:03,800
大家都很高兴有人做了这件事

98
00:05:03,800 --> 00:05:06,140
还开玩笑地把我称为参考人类

99
00:05:06,140 --> 00:05:10,775
当然 我也觉得很有趣

100
00:05:10,775 --> 00:05:15,892
当软件 也就是深度网络

101
00:05:15,892 --> 00:05:18,785
最后超过你的表现时 你吃惊吗

102
00:05:18,785 --> 00:05:19,787
当然

103
00:05:19,787 --> 00:05:21,968
当然 非常吃惊

104
00:05:21,968 --> 00:05:26,851
我的意思是 有时候真的很难<br />看出一张图片到底是什么

105
00:05:26,851 --> 00:05:30,125
有的图片就像一团黑点

106
00:05:30,125 --> 00:05:31,335
我也看不出来是什么

107
00:05:31,335 --> 00:05:34,897
我只能猜测它大概属于20个分类中的某一个<br />但网络直接就找出来了

108
00:05:34,897 --> 00:05:37,420
我不明白这是怎么回事

109
00:05:37,420 --> 00:05:39,506
有点超出人类的范畴

110
00:05:39,506 --> 00:05:44,040
此外 我觉得网络非常擅长<br />识别诸如地砖图案和纹理

111
00:05:44,040 --> 00:05:45,050
的统计规律

112
00:05:46,090 --> 00:05:49,950
我觉得在那方面 网络可以更好地

113
00:05:49,950 --> 00:05:53,680
提取大量图片中的精细的统计信息<br />这点我并不吃惊

114
00:05:53,680 --> 00:05:57,720
在很多情况下 我觉得惊讶的是<br />有些图片需要你读取文字

115
00:05:57,720 --> 00:05:59,544
图片中只是一个瓶子 光看你不知道它是什么

116
00:05:59,544 --> 00:06:00,904
但它上面有文字 告诉你它是什么

117
00:06:00,904 --> 00:06:04,382
作为人类 我能读懂 这没什么问题<br />但对网络来说

118
00:06:04,382 --> 00:06:07,292
它必须学习阅读才能识别这个物体<br />因为从外形看并不明显

119
00:06:07,292 --> 00:06:10,204
让你出名的一件事

120
00:06:10,204 --> 00:06:13,557
也是让深度学习社区感谢你的一件事是

121
00:06:13,557 --> 00:06:17,115
你开展教学并把它放到了网上

122
00:06:17,115 --> 00:06:20,049
能讲讲这件事的经过吗

123
00:06:20,049 --> 00:06:20,740
— 当然可以

124
00:06:20,740 --> 00:06:26,160
我有一种强烈的感觉 总的来说

125
00:06:26,160 --> 00:06:29,490
这种技术是一种变革 很多人想用它

126
00:06:29,490 --> 00:06:30,700
它就像一个锤子

127
00:06:30,700 --> 00:06:31,490
我想做的事情是

128
00:06:31,490 --> 00:06:36,170
能够把这个锤子随机地交给很多人

129
00:06:36,170 --> 00:06:37,785
我只是觉得这非常急迫

130
00:06:37,785 --> 00:06:40,501
从博士研究生的角度来说 这不一定可取

131
00:06:40,501 --> 00:06:42,280
因为你放下了你的研究

132
00:06:42,280 --> 00:06:44,940
我的意思 这占用了我120%的时间

133
00:06:44,940 --> 00:06:46,480
我必须放下所有的研究 

134
00:06:46,480 --> 00:06:50,140
我的意思是 这门课我教了两次<br />每次大概都要花四个月时间

135
00:06:50,140 --> 00:06:52,880
那段时间基本都花在上课上

136
00:06:52,880 --> 00:06:56,570
所以从这个角度来看并不太建议<br />但是总体来说这是我博士阶段的亮点

137
00:06:56,570 --> 00:06:57,838
它甚至与研究无关

138
00:06:57,838 --> 00:07:01,110
我认为教课 绝对是我博士阶段的亮点

139
00:07:01,110 --> 00:07:02,350
只要看到那些学生

140
00:07:02,350 --> 00:07:06,360
就能感觉到他们有多兴奋 这门课与众不同

141
00:07:06,360 --> 00:07:08,518
通常 课程讲的是19世纪左右

142
00:07:08,518 --> 00:07:09,167
发现的东西

143
00:07:09,167 --> 00:07:12,614
但是我们可以在课堂跟大家说<br />看 这是一周之前发表的论文

144
00:07:12,614 --> 00:07:13,453
甚至昨天发表的论文

145
00:07:13,453 --> 00:07:16,112
有新的结论 我觉得本科生和

146
00:07:16,112 --> 00:07:18,904
其他的学生 真的很喜欢课堂的这一面

147
00:07:18,904 --> 00:07:20,496
而且他们真的能理解这些内容

148
00:07:20,496 --> 00:07:25,868
这不是核子物理或火箭科学

149
00:07:25,868 --> 00:07:28,454
你只需了解微积分 代数

150
00:07:28,454 --> 00:07:31,860
你就能够理解背后的所有原理

151
00:07:31,860 --> 00:07:36,465
我这个领域非常强大 日新月异

152
00:07:36,465 --> 00:07:39,395
人们觉得自己站在浪潮前沿 这感觉很棒

153
00:07:39,395 --> 00:07:42,395
我觉得这是人们真正喜欢这门课的原因

154
00:07:42,395 --> 00:07:47,695
而且你确实帮了很多人 递出去了很多锤子

155
00:07:47,695 --> 00:07:48,892
— 没错

156
00:07:48,892 --> 00:07:52,182
作为一个对深度学习有着长期研究的人

157
00:07:52,182 --> 00:07:56,712
这个领域还在迅速发展

158
00:07:56,712 --> 00:07:59,222
我很想知道 你自己是怎样想的

159
00:07:59,222 --> 00:08:02,889
这些年来 你对深度学习的理解有什么变化

160
00:08:02,889 --> 00:08:06,444
大体来讲 当我第一次见到受限玻尔兹曼机

161
00:08:06,444 --> 00:08:07,599
处理数字时

162
00:08:08,620 --> 00:08:11,360
对我来说 这种技术的应用前景并不明朗

163
00:08:11,360 --> 00:08:12,240
也不知道它将来有多重要

164
00:08:12,240 --> 00:08:15,270
当我开始研究 计算机视觉 卷积网络的时候

165
00:08:15,270 --> 00:08:18,240
这些概念也已经存在了 但很多计算机视觉领域的人

166
00:08:18,240 --> 00:08:21,770
觉得短时间内用不上

167
00:08:21,770 --> 00:08:25,400
我觉得大家当时的观点是 在少量的场景下有用

168
00:08:25,400 --> 00:08:27,210
但无法扩展到处理更大的图像

169
00:08:27,210 --> 00:08:28,820
这种观点完全错误

170
00:08:28,820 --> 00:08:34,283
所以总体来说 我对这个技术的通用程度感到惊讶

171
00:08:34,283 --> 00:08:36,139
也没想到能取得这么好的结果

172
00:08:36,139 --> 00:08:39,234
这是最大的惊喜 而且不仅如此

173
00:08:39,234 --> 00:08:42,780
一方面 它的表现非常好 比如说ImageNet

174
00:08:42,780 --> 00:08:45,100
另一方面 我觉得出乎所有人预料的是

175
00:08:45,100 --> 00:08:48,310
至少出乎我的意料的是 你可以对训练好的网络

176
00:08:48,310 --> 00:08:49,290
进行迁移

177
00:08:49,290 --> 00:08:51,390
你可以在任意的其他任务中对网络进行微调

178
00:08:51,390 --> 00:08:52,806
因为现在 你不仅解决了需要数百万样本的

179
00:08:52,806 --> 00:08:53,648
ImageNet的问题

180
00:08:53,648 --> 00:08:56,748
这个网络还成为了非常通用的特征提取器

181
00:08:56,748 --> 00:09:00,349
我觉得很少有人能预料到这第二个方面

182
00:09:00,349 --> 00:09:04,340
在这方面的论文中

183
00:09:04,340 --> 00:09:06,840
人们一直在研究计算机视觉

184
00:09:06,840 --> 00:09:10,900
场景分类 动作识别 对象识别

185
00:09:10,900 --> 00:09:13,070
基本属性 等等

186
00:09:13,070 --> 00:09:16,900
人们只是通过微调网络 就解决了每个任务

187
00:09:16,900 --> 00:09:21,136
这让我觉得非常惊讶

188
00:09:21,136 --> 00:09:25,665
是的 我觉得监督学习占据了大部分的版面

189
00:09:25,665 --> 00:09:30,564
虽然微调训练好的模型 或是迁移学习的效果很好

190
00:09:30,564 --> 00:09:34,528
但由于某些原因 人们谈论的比较少

191
00:09:34,528 --> 00:09:35,460
是的 正是如此

192
00:09:36,560 --> 00:09:39,670
是的 我觉得有些方面的研究不多<br />大家对无监督学习抱有很高的期望

193
00:09:39,670 --> 00:09:44,680
这才是吸引很多研究人员在2007年左右

194
00:09:44,680 --> 00:09:48,310
投身这一领域的原因

195
00:09:48,310 --> 00:09:52,350
我觉得这方面的前景 还没有实现

196
00:09:52,350 --> 00:09:56,090
让我意外的是 监督学习的效果那么好

197
00:09:56,090 --> 00:09:59,350
而无监督学习仍然处于

198
00:09:59,350 --> 00:10:03,600
不明朗的状态 它的运作原理和应用前景尚不明确

199
00:10:03,600 --> 00:10:05,570
虽然这个领域仍然有

200
00:10:05,570 --> 00:10:10,525
很多忠实信徒

201
00:10:10,525 --> 00:10:14,495
我知道你属于一直思考人工智能<br />长远发展的那种人

202
00:10:14,495 --> 00:10:16,175
你能跟我们分享下这方面的想法吗

203
00:10:16,175 --> 00:10:18,902
我在OpenAI用了大约一年半的时间

204
00:10:18,902 --> 00:10:23,548
思考这些问题

205
00:10:23,548 --> 00:10:29,410
在我看来 这个领域会分成两条道路

206
00:10:29,410 --> 00:10:34,010
一条是应用人工智能 就是创建和训练神经网络

207
00:10:34,010 --> 00:10:37,450
主要使用监督学习 也可能用无监督学习

208
00:10:37,450 --> 00:10:40,296
然后逐步提升性能 比如图像识别器或类似的东西

209
00:10:40,296 --> 00:10:45,210
我觉得另一个方向是 人工通用智能

210
00:10:45,210 --> 00:10:50,191
也就是 怎么让神经网络成为一个完全动态的系统

211
00:10:50,191 --> 00:10:54,990
它能思考 说话 可以做人能做的任何事情<br />在这些方面具有智能

212
00:10:54,990 --> 00:10:58,550
我一直以来都觉得有趣的是 比如在计算机视觉中

213
00:10:58,550 --> 00:10:59,990
我认为 我们一开始使用的方法是错误的

214
00:10:59,990 --> 00:11:02,990
我们想把它分解成不同的部分

215
00:11:02,990 --> 00:11:05,862
就像是 人类可以认出人 人类可以认出场景

216
00:11:05,862 --> 00:11:06,910
人类可以认出物体

217
00:11:06,910 --> 00:11:09,318
所以我们只是关注人类能做的各种事

218
00:11:09,318 --> 00:11:12,740
一旦完成了这些独立的目标<br />就分成了不同的领域

219
00:11:12,740 --> 00:11:13,850
有了这些独立的成果

220
00:11:13,850 --> 00:11:16,080
我们再考虑如何把它们拼在一起

221
00:11:16,080 --> 00:11:17,710
我觉得这个方法不对

222
00:11:17,710 --> 00:11:21,120
我们已经见证了历史给出的结果

223
00:11:21,120 --> 00:11:24,173
所以我觉得在更高级的人工智能领域

224
00:11:24,173 --> 00:11:24,737
历史正在重演

225
00:11:24,737 --> 00:11:28,363
人类会问问题 会做计划

226
00:11:28,363 --> 00:11:32,463
会通过实验来了解世界的运行原理<br />人类需要互相交谈 所以发明了语言

227
00:11:32,463 --> 00:11:35,684
人们试图把人类的能力分解成各种功能<br />然后逐一实现

228
00:11:35,684 --> 00:11:37,522
再把它们一起放进某种大脑

229
00:11:37,522 --> 00:11:40,490
我觉得这种方法不对

230
00:11:40,490 --> 00:11:45,111
所以我更倾向于不按照那样分解

231
00:11:45,111 --> 00:11:50,041
而是使用一种完全动态的神经网络

232
00:11:50,041 --> 00:11:53,690
这样你总是与完全的代理人程序打交道

233
00:11:53,690 --> 00:11:54,760
然后的问题是

234
00:11:54,760 --> 00:11:58,990
应该如何构建目标 使得当你在优化

235
00:11:58,990 --> 00:12:02,330
大脑的权重时 能得到智能的行为

236
00:12:02,330 --> 00:12:05,610
这是我在OpenAI里一直深入思考的东西

237
00:12:05,610 --> 00:12:08,330
我认为人们已经想出了很多不同的方法

238
00:12:08,330 --> 00:12:10,320
来处理这个问题

239
00:12:11,550 --> 00:12:12,050
比如

240
00:12:12,050 --> 00:12:15,510
在监督学习方向 我在网上发过一篇文章

241
00:12:15,510 --> 00:12:17,750
不算是论文 只是我写的一个小故事

242
00:12:17,750 --> 00:12:20,960
这个小故事试图设想出一个假想的世界

243
00:12:20,960 --> 00:12:25,350
我们只通过扩大监督学习的规模的方式<br />来发展人工通用智能

244
00:12:25,350 --> 00:12:27,270
我们知道这是可行的

245
00:12:27,270 --> 00:12:32,135
然后就会得到 像亚马逊土耳其机器人这样的东西

246
00:12:32,135 --> 00:12:35,310
人们让数量众多的机器人执行任务

247
00:12:35,310 --> 00:12:38,640
然后以此为监督学习的数据集进行训练 来模仿人类

248
00:12:38,640 --> 00:12:39,790
这样的东西会是什么样的 等等

249
00:12:39,790 --> 00:12:41,924
还有其他的方向

250
00:12:41,924 --> 00:12:46,511
比如源于算法信息论的无监督学习 像AIXI那样

251
00:12:46,511 --> 00:12:50,872
或者源于人工生命 这更像是人工进化

252
00:12:50,872 --> 00:12:54,804
这就是我花了很多时间所思考的东西

253
00:12:54,804 --> 00:12:57,882
我觉得我找到了正确的答案 但是我不想在这儿说

254
00:12:57,882 --> 00:13:01,109
至少我可以通过读你的博客

255
00:13:01,109 --> 00:13:02,050
学到更多的东西

256
00:13:02,050 --> 00:13:02,550
— 是的 当然

257
00:13:03,670 --> 00:13:08,520
你已经给了很多建议

258
00:13:08,520 --> 00:13:13,280
现在 仍有很多人想进入人工智能和深度学习领域

259
00:13:13,280 --> 00:13:17,340
你能给这些人一些建议吗

260
00:13:17,340 --> 00:13:18,390
— 没问题

261
00:13:18,390 --> 00:13:22,225
我觉得当人们和我谈起CS231n课程<br />以及他们认为

262
00:13:22,225 --> 00:13:25,947
这门课程非常有用的原因时 我反复听到的是

263
00:13:25,947 --> 00:13:29,054
人们喜欢我们一直深入底层细节

264
00:13:29,054 --> 00:13:31,946
他们不是在用什么库 而是看到了真正的代码

265
00:13:31,946 --> 00:13:34,415
他们看到了一切是如何实现的

266
00:13:34,415 --> 00:13:36,750
自己也实现了其中的大部分

267
00:13:36,750 --> 00:13:40,550
要一直深入底层 理解背后的所有原理

268
00:13:42,140 --> 00:13:44,020
不把事物过于抽象简化也很重要

269
00:13:44,020 --> 00:13:46,890
你需要充分了解全栈

270
00:13:46,890 --> 00:13:49,390
当我学习这些知识的时候 这种做法收获最大

271
00:13:49,390 --> 00:13:52,470
我只是从头开始把它实现了 这是很重要的

272
00:13:52,470 --> 00:13:57,880
从理解知识的角度来看 这样做

273
00:13:57,880 --> 00:13:59,450
性价比最高

274
00:13:59,450 --> 00:14:00,107
我写了自己的库

275
00:14:00,107 --> 00:14:01,438
叫做ConvNetJS

276
00:14:01,438 --> 00:14:03,663
它是用JavaScript写的 实现了卷积神经网络

277
00:14:03,663 --> 00:14:06,410
那就是我学习反向传播的方法

278
00:14:06,410 --> 00:14:11,238
所以我一直建议人们 不要一开始就使用

279
00:14:11,238 --> 00:14:12,671
TensorFlow这样的东西

280
00:14:12,671 --> 00:14:15,763
当你能自己编写最底层的代码后 再去使用

281
00:14:15,763 --> 00:14:19,066
你知道了底层的所有原理后

282
00:14:19,066 --> 00:14:21,985
再使用这些框架 框架为你抽象掉了一些细节

283
00:14:21,985 --> 00:14:23,766
但你必须知道背后的原理

284
00:14:23,766 --> 00:14:26,444
所以这点对我帮助最大

285
00:14:26,444 --> 00:14:29,174
这是人们上CS231n课程时最喜欢的一点

286
00:14:29,174 --> 00:14:30,691
这也是我给大家的建议

287
00:14:30,691 --> 00:14:35,540
所以不是去运行神经网络 然后顺其自然

288
00:14:35,540 --> 00:14:38,390
对 在某些层的序列中 我知道当我加一些

289
00:14:38,390 --> 00:14:41,500
Dropout层 效果会更好 但那并不是你想要的

290
00:14:41,500 --> 00:14:45,320
在这种情况下 你就无法进行有效的调试

291
00:14:45,320 --> 00:14:47,610
也无法有效地改进模型

292
00:14:48,630 --> 00:14:52,184
是的 听你这么说<br />我很高兴在deeplearning.ai的课程中

293
00:14:52,184 --> 00:14:56,235
开课的时候首先讲了很多个星期的Python编程

294
00:14:56,235 --> 00:14:57,625
是的 很好

295
00:14:57,625 --> 00:15:00,947
非常感谢你分享这些见解和建议

296
00:15:00,947 --> 00:15:04,355
在深度学习的世界里<br />你已经是许多人心目中的英雄

297
00:15:04,355 --> 00:15:07,598
我很高兴 也很感谢你<br />今天能在这里与我们分享

298
00:15:07,598 --> 00:15:09,585
谢谢你的邀请<br />GTC字幕组翻译