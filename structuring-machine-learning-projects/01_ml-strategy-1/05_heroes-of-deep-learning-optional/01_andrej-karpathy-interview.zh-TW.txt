歡迎 Andrej，很高興您今天能加入我們的討論 >> 謝謝你的邀請 >> 那麼，很多人已經知道你在深度學習的研究 但不是每個人都知道你個人的故事 請先告訴我們 你如何能有這些深度學習的成果呢？ >> 好啊，當然 那...我第一次接觸深度學習應該是大學的時候 在多倫多大學 Geoff Hinton 在那裡，他在教深度學習的課 講的是用受限玻爾茲曼機 (RBM) 訓練 MNIST 數字 我很喜歡 Geoff 講述訓練網路的方式 例如「網路的心靈」，他用這樣子的詞彙 當我在訓練辨認那些數字時， 我感覺有某種魔力。 這算是我的第一次接觸 雖然那時候我還沒深入研究 然後當我在英屬哥倫比亞大學讀碩士的時候 我上了另一堂關於機器學習的課 這算是我第一次深入研究神經網路之類的。 有趣的是，我對人工智慧很有興趣 所以我上了些 AI 的課 不過有很多我當時並不滿意 因為講了很多深度優先搜尋、廣度優先搜尋、Alpha-beta剪枝 如此之類 我不大了解為什麼... 我就是不滿意 所以當我第一次接觸神經網路，在「機器學習」的領域 — 我覺得這個詞比較專業 而不浮濫... 大部分的人都在講人工智慧 「機器學習」是一個比較技術的詞彙，可以這樣說 所以我當時對人工智慧並不滿意 當我接觸了機器學習，我覺得 這，才是我想研究的 AI，這才是真正有趣的 這讓我繼續往這方向邁進 你可以說這是嶄新的運算模式 因為一般來說，是人在寫程式 但在這裡，是「最佳化」(optimization) 在寫程式 你定好了輸入輸出的規則 然後你有很多的資料範例，然後「最佳化」來寫程式 有時寫的比你還好 所以我認為這是非常新穎的程式思維 這讓我很感興趣 >> 就你的成就來說，你其中最著名的是 您現在是圖片分類競賽的人類基準了 這是怎麼開始的？ >> 基本上，ImageNet 挑戰有時被視作某種 電腦視覺的世界杯 所以很多人很在意這個基準 我們的錯誤率逐漸降低 對於這種規模的問題，在當時我不確定人類能作到多好 我在更之前在做過比較小規模的實驗、CIFAR-10 資料集 我在 CIFAR-10 所作的是，我看那些 32x32 的圖片 我試著自己做分類 當時只有十個類別 所以弄個介面頗簡單 我記得我達到了 6% 的錯誤率 根據我看到的、還有這任務的困難度 我猜我預測我們能達到最好的錯誤率是... 嗯，我現在不記得確切數字 應該是 10% 吧：而我們現在來到了 3% 2% 或某個驚奇的數字 那就是我身為「人類基準」的第一個有趣的實驗 我認為這非常重要 原因和你在課堂提到的一樣 你真的會需要那些數字來了解人類能做多好 我們就能和機器學習演算法做比較 而當時 ImageNet 則有種落差：這種基準的重要性 但大家花了很多心力在把錯誤率降低， 而我們甚至還不知道人類到底能做多好。 所以我用 Javascript 做了一個界面，秀給我圖片 然而 ImageNet 的問題在於他不只有 10 個類別 他有 1000 個 這算是個 UI 的難題 顯然我無法記得所有 1000 類，那我該如何進行 確保不是來亂的呢？ 所以我列出所有的類別，給每類一張範例 然後對於每張圖片，我就滾過一千個類別 根據剛剛每個類別的範例圖，對比看看 這張圖片大概是哪類。 我發現這件事本身還滿有教育意義 我的意思是，我之前不知道原來 ImageNet 有三分之一是狗類 這還滿好玩的，發現這網路花了很多時間 來在意狗狗 成效有三分之一都來自狗 嗯...對，所以這件事我大概花了一兩個禮拜 我把其他事都擱著 我覺得這種練習還滿有趣的 最後我得到了數據，然後覺得只有一個人並不夠 我想要有其他人的 所以我試著召集實驗室的大家做同樣的事 我猜大家不太想貢獻；大概一兩個禮拜 非常刻苦的工作，坐在那邊五個小時 試著分辨這是哪一種狗的種類 所以這方面來說，我沒能拿到足夠的資料 不過至少還能估計出成效，我覺得還滿好玩的。 後來這引起大家注意了... 其實我當時並沒有料到 我只是想要知道數據而已，可是就變成個大事了 (笑) 而且大家很開心有人做了這樣的事 還開玩笑稱我為肉體基準 當然我覺得這滿好笑的 >> 你當時會驚訝有軟體 終於超越你了嗎？ >> 沒錯 嗯當然 特別是有時候圖片裡面那是啥真的很難看出來 就一坨黑點在那邊 而我看不出來... 你看我還要在20個中猜一個，而神經網路就知道答案 我不知道這怎麼辦到的 所以有種超人類感。 而且我覺得，神經網路對樣式和材質的這種統計歸納 非常在行。 我覺得從這方面來看，我並不意外，神經網路更能 從一大堆圖片量測到細膩的統計資料 而在很多例子我還滿訝異的，因為有些圖片需要「讀」 例如他就是個瓶子，外觀看不出是什麼 可是其實上面的文字就告訴你這是什麼了 所以身為人類，我能夠用讀的，但網路必須學習 用讀的方式來辨識物品，因為外觀並不明顯 >> 你其中最著名的事 也是深度學習社群很感激你的 就是你的課堂教學，還放在網路上 請和我們分享一下緣由 >> 好啊，當然 基本上我強烈覺得 這是很革命性的科技，而且很多人都想用 就像個鐵鎚 而我想要做的是 我可以將這把鐵鎚傳授給很多人 我覺得這很有吸引力 從一個博士生的角度來說，這不一定很明智 因為你等於是放下你的研究 我的意思是，這佔了我大概 120% 的心力 我必須把所有研究工作先擱著 我看看，我教了兩次課，每次大概四個月 那段時間算是全心全意在課堂上 所以從這角度來看並不是很明智，不過這算是我博士生涯的亮點 這甚至和研究無關 我覺得教書絕對是我博士生涯最重要的部份 光是看到學生 光是看到他們很興奮... 這門課真的很不一樣 平常大家教你的，是早在 1800 年就發現的 諸如此類 但是我們可以到課堂上說，你看，這論文前個禮拜才出來 甚至是昨天出的 又有嶄新結果。我覺得那些大學生和其他同學 他們非常喜愛這種特點 甚至他們還能讀懂理解之 這並不是什麼非常深奧的學問 只要你懂微積分、還有線性代數 你就能了解每件事、了解背後道理 所以我覺得因為這是如此強大、每天不斷演化 大家覺得自己身處於革命性的尖端 我認為這是大家很喜歡那門課的原因 >> 你真的幫助了很多人，交出去了很多鐵鎚 >> 沒錯 >> 身為一直在從事深度學習 也做了很久了，而這領域演化非常迅速 我很好奇你的看法 在這些年，你對深度學習的理解有何改變？ >> 嗯嗯，例如當我剛開始接觸受限玻爾茲曼機 (RBM) 第一次用在數字辨認 我並不確定要怎麼使用這項技術 也不確定這多重要 還有當我一開始研究電腦視覺時， 卷積網路(CNN)已經有了，但是 還沒被很多電腦視覺的人使用 我想當時的氛圍是，這在小資料有用 但不可能擴展到非常多圖片 這其實錯很大 (笑) 總之基本上，我很訝異這技術是如此地泛用 而且如此有效 我會說這是我最訝異的。更有甚者... 所以其中一件是成效非常有用，例如 ImageNet 不過另一件大家沒預期到的 至少我沒預期到的，是你可以拿預先訓練好的網路 拿來轉移學習 你可以微調後用在任何其他的問題上 因為你現在並不是在解 ImageNet 而需要數百萬的資料 這網路本身，剛好也能很泛用地抽取特徵 我想這是另一個比較少人預期到的特質。 當時出現了很多論文 各種電腦視覺的領域都有： 我看過場景辨認、行為辨認、物體辨認、 臉部特徵、諸如此類的 大家只要微調網路，就能在每個問題通關 這讓我感覺非常驚奇 >> 沒錯，而且我覺得不知為何，監督學習比較受注目 就算預先訓練的網路或轉移學習其實非常有用 感覺大家也比較少談到這一塊 >> 是的，沒錯。 我想有些沒那麼出色，也就是對於非監督學習的期待 我猜這大概是為什麼很多研究員踏入了這領域 大概在2007年之類的 而我覺得這邊的成績還沒繳出來 我感到訝異的是監督學習的部份成效很好 而非監督學習的部份還在... 要怎麼使用之或怎麼成功，這還不明顯 就算很多人還深深地相信 在這個領域上。 >> 那麼，我知道 你一直在思考 AI 長遠的未來 你想分享一下嗎？ >> 那麼，在過去一年半 我在 OpenAI 想了很多相關的主題 對我來說，這領域會分成兩條路 一條是「應用 AI」，就只是做神經網路，訓練之 大部都是監督學習，也可能是非監督的 然後不斷進步，例如圖片辨認器之類的。 而我想另一條路會是「強人工智慧」(AGI) 也就是把神經網路變成完全動態的系統、 能像人類一樣思考、說話、做所有人類能做的，這樣子地有智慧 我一直覺得有趣的是，以電腦視覺為例 我認為我們一開始解決問題的方法是錯的： 我們嘗試把問題分成不同領域 就好像，人類能辨認人、人類能辨認場景 人類能辨認物品 所以我們去做每件人類能做的 然後我們有了這些 — 現在有了不同的領域 然後有了這些後 我們要想想怎麼把這些整合在一起。 我覺得這方法不對 能看到過去這樣的後果如何。 我覺得這趨勢在 AI 比較高階的領域 也類似 就是大家在問：人類能計畫、人類能做實驗 了解世界怎麼運作、人類要交談所以需要語言 大家想根據功能性來分解問題，解決每一個 然後再整合成某種腦。 我認為這方法不對 我一直比較傾向... 不是那樣各個擊破，而是有某個單一的神經網路 一個完整的動態系統、總是用整個系統來運作， 那麼問題就變成： 要怎麼去定義目標，使得你在最佳化 這腦袋的權重時，你能得到有智慧的行為 我在 OpenAI 一直想了很多這方面的事 我想大家對於這個問題 想了很多不同的方法 例如 走監督學習的方向，我在網路有篇論述 不算是論述，那是我寫的短篇故事 這故事試著假設、編織出一個世界的模樣 — 如果達到「強人工智慧」僅是大規模的監督學習 — 我們知道有這可能。 所以這看起來會像 Amazon Mechanical Turk 將功能加進許多執行作業的機器人當中 然後我們訓練監督式學習資料集使其模仿人類 可能是什麼樣子, 等等。 還有其他的方向, 像是演算法資訊理論的非監督式學習, 像是AIXI 或者是人工生命, 那些看起來更像是人工進化的東西 所以這就是我花時間思考的事情 我心中有個正確答案, 但我不會在這裡透露給大家 [笑] > > 我至少可以透過閱讀 你的部落格瞭解更多 >> 好啊, 當然 您已經給出了相當多的意見, 而今日 仍有很多人想進入人工智慧深度學習的領域 你有沒有甚麼建議可以幫助他們呢? >> 好啊, 當然 所以我認為當人們跟我談論 CS231n, 為什麼他們認為這是一個非常 有用的課程, 我不斷聽到 學生感謝我們帶領他們學習這些基礎的細節 他們並不是直接使用框架, 必須先讀這些程式碼 親自去看看這些程式是如何實踐 然後自己再去一步步寫出這些函式 透過這個過程真正將其內化成自己的知識 不要只看那些最後的重點 你必須要充分了解整個原貌 這也是為什麼當我通常透過自學學習這些知識 徒手從無到有實踐一切是最重要的 這是我學習過程當中 真正使我理解這些知識的方式 所以我自己寫了一個函式庫 叫做ConvNetJS 用Javascript實踐了卷積神經網路 這是我學習反向傳播的方式 這是我一直建議人們不要一開始就用 Tensorflow或其他框架 除非你曾經徒手實踐過最基礎的函式 並真正了解所有功能 這時才去使用這些框架，去更清楚表達你的程式 而你已經知道其中的意涵了 這是一直以來幫助我做多的東西 這是來上231n的人們最欣賞的學習方式 也是我會建議多數人的做法 >> 所以不要只是運行神經網路，看他會發生甚麼事 對, 不要只是看到你在特定某隱藏層加上dropout 就讓結果變好，這不是你要做的 在這種情況下，你無法有效地進行除錯 也無法有效地改進模型 同樣的, 我很高興我們的深度學習課程 是從數周Python語言開始的 對, 很好 非常感謝您分享的洞見與建議。 您已經是很多人心目中深度學習領域的英雄 我非常高興也非常感謝今天你能加入我們 >> 謝謝你的邀請