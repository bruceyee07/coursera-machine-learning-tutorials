1
00:00:02,977 --> 00:00:06,068
歡迎 Andrej，很高興您今天能加入我們的討論

2
00:00:06,068 --> 00:00:08,180
>> 謝謝你的邀請

3
00:00:08,180 --> 00:00:12,170
>> 那麼，很多人已經知道你在深度學習的研究

4
00:00:12,170 --> 00:00:14,600
但不是每個人都知道你個人的故事

5
00:00:14,600 --> 00:00:17,100
請先告訴我們

6
00:00:17,100 --> 00:00:20,510
你如何能有這些深度學習的成果呢？

7
00:00:20,510 --> 00:00:21,590
>> 好啊，當然

8
00:00:21,590 --> 00:00:25,100
那...我第一次接觸深度學習應該是大學的時候

9
00:00:25,100 --> 00:00:26,520
在多倫多大學

10
00:00:26,520 --> 00:00:28,696
Geoff Hinton 在那裡，他在教深度學習的課

11
00:00:28,696 --> 00:00:32,346
講的是用受限玻爾茲曼機 (RBM) 訓練 MNIST 數字

12
00:00:32,346 --> 00:00:35,966
我很喜歡 Geoff 講述訓練網路的方式

13
00:00:35,966 --> 00:00:38,999
例如「網路的心靈」，他用這樣子的詞彙

14
00:00:38,999 --> 00:00:42,333
當我在訓練辨認那些數字時，

15
00:00:42,333 --> 00:00:46,870
我感覺有某種魔力。

16
00:00:46,870 --> 00:00:50,130
這算是我的第一次接觸

17
00:00:50,130 --> 00:00:52,440
雖然那時候我還沒深入研究

18
00:00:52,440 --> 00:00:55,540
然後當我在英屬哥倫比亞大學讀碩士的時候

19
00:00:57,000 --> 00:00:59,850
我上了另一堂關於機器學習的課

20
00:00:59,850 --> 00:01:03,665
這算是我第一次深入研究神經網路之類的。

21
00:01:03,665 --> 00:01:07,790
有趣的是，我對人工智慧很有興趣

22
00:01:07,790 --> 00:01:10,430
所以我上了些 AI 的課

23
00:01:10,430 --> 00:01:12,690
不過有很多我當時並不滿意

24
00:01:12,690 --> 00:01:16,277
因為講了很多深度優先搜尋、廣度優先搜尋、Alpha-beta剪枝

25
00:01:16,277 --> 00:01:17,220
如此之類

26
00:01:17,220 --> 00:01:20,190
我不大了解為什麼... 我就是不滿意

27
00:01:20,190 --> 00:01:23,700
所以當我第一次接觸神經網路，在「機器學習」的領域

28
00:01:23,700 --> 00:01:25,720
— 我覺得這個詞比較專業

29
00:01:25,720 --> 00:01:29,280
而不浮濫... 大部分的人都在講人工智慧

30
00:01:29,280 --> 00:01:32,550
「機器學習」是一個比較技術的詞彙，可以這樣說

31
00:01:32,550 --> 00:01:34,940
所以我當時對人工智慧並不滿意

32
00:01:34,940 --> 00:01:36,520
當我接觸了機器學習，我覺得

33
00:01:36,520 --> 00:01:41,498
這，才是我想研究的 AI，這才是真正有趣的

34
00:01:41,498 --> 00:01:45,200
這讓我繼續往這方向邁進

35
00:01:45,200 --> 00:01:47,000
你可以說這是嶄新的運算模式

36
00:01:48,210 --> 00:01:50,730
因為一般來說，是人在寫程式

37
00:01:50,730 --> 00:01:54,263
但在這裡，是「最佳化」(optimization) 在寫程式

38
00:01:54,263 --> 00:01:56,260
你定好了輸入輸出的規則

39
00:01:56,260 --> 00:01:59,460
然後你有很多的資料範例，然後「最佳化」來寫程式

40
00:01:59,460 --> 00:02:01,370
有時寫的比你還好

41
00:02:01,370 --> 00:02:06,300
所以我認為這是非常新穎的程式思維

42
00:02:06,300 --> 00:02:08,150
這讓我很感興趣

43
00:02:08,150 --> 00:02:11,580
>> 就你的成就來說，你其中最著名的是

44
00:02:11,580 --> 00:02:18,030
您現在是圖片分類競賽的人類基準了

45
00:02:18,030 --> 00:02:19,280
這是怎麼開始的？

46
00:02:19,280 --> 00:02:23,620
>> 基本上，ImageNet 挑戰有時被視作某種

47
00:02:23,620 --> 00:02:24,870
電腦視覺的世界杯

48
00:02:24,870 --> 00:02:27,820
所以很多人很在意這個基準

49
00:02:27,820 --> 00:02:29,330
我們的錯誤率逐漸降低

50
00:02:29,330 --> 00:02:33,390
對於這種規模的問題，在當時我不確定人類能作到多好

51
00:02:33,390 --> 00:02:37,054
我在更之前在做過比較小規模的實驗、CIFAR-10 資料集

52
00:02:37,054 --> 00:02:40,437
我在 CIFAR-10 所作的是，我看那些 32x32 的圖片

53
00:02:40,437 --> 00:02:42,290
我試著自己做分類

54
00:02:42,290 --> 00:02:43,751
當時只有十個類別

55
00:02:43,751 --> 00:02:45,371
所以弄個介面頗簡單

56
00:02:45,371 --> 00:02:48,341
我記得我達到了 6% 的錯誤率

57
00:02:48,341 --> 00:02:52,057
根據我看到的、還有這任務的困難度

58
00:02:52,057 --> 00:02:56,634
我猜我預測我們能達到最好的錯誤率是...

59
00:02:56,634 --> 00:02:58,812
嗯，我現在不記得確切數字

60
00:02:58,812 --> 00:03:03,530
應該是 10% 吧：而我們現在來到了 3% 2% 或某個驚奇的數字

61
00:03:03,530 --> 00:03:09,113
那就是我身為「人類基準」的第一個有趣的實驗

62
00:03:09,113 --> 00:03:11,870
我認為這非常重要

63
00:03:11,870 --> 00:03:13,950
原因和你在課堂提到的一樣

64
00:03:13,950 --> 00:03:18,790
你真的會需要那些數字來了解人類能做多好

65
00:03:18,790 --> 00:03:20,868
我們就能和機器學習演算法做比較

66
00:03:20,868 --> 00:03:24,610
而當時 ImageNet 則有種落差：這種基準的重要性

67
00:03:24,610 --> 00:03:27,600
但大家花了很多心力在把錯誤率降低，

68
00:03:27,600 --> 00:03:31,800
而我們甚至還不知道人類到底能做多好。

69
00:03:31,800 --> 00:03:35,770
所以我用 Javascript 做了一個界面，秀給我圖片

70
00:03:35,770 --> 00:03:38,340
然而 ImageNet 的問題在於他不只有 10 個類別

71
00:03:38,340 --> 00:03:39,340
他有 1000 個

72
00:03:39,340 --> 00:03:41,085
這算是個 UI 的難題

73
00:03:41,085 --> 00:03:44,443
顯然我無法記得所有 1000 類，那我該如何進行

74
00:03:44,443 --> 00:03:45,708
確保不是來亂的呢？

75
00:03:45,708 --> 00:03:48,955
所以我列出所有的類別，給每類一張範例

76
00:03:48,955 --> 00:03:52,679
然後對於每張圖片，我就滾過一千個類別

77
00:03:52,679 --> 00:03:56,401
根據剛剛每個類別的範例圖，對比看看

78
00:03:56,401 --> 00:03:57,739
這張圖片大概是哪類。

79
00:03:57,739 --> 00:04:01,880
我發現這件事本身還滿有教育意義

80
00:04:01,880 --> 00:04:06,539
我的意思是，我之前不知道原來 ImageNet 有三分之一是狗類

81
00:04:06,539 --> 00:04:10,125
這還滿好玩的，發現這網路花了很多時間

82
00:04:10,125 --> 00:04:12,800
來在意狗狗

83
00:04:12,800 --> 00:04:14,588
成效有三分之一都來自狗

84
00:04:14,588 --> 00:04:20,809
嗯...對，所以這件事我大概花了一兩個禮拜

85
00:04:20,809 --> 00:04:21,837
我把其他事都擱著

86
00:04:21,837 --> 00:04:24,250
我覺得這種練習還滿有趣的

87
00:04:24,250 --> 00:04:26,703
最後我得到了數據，然後覺得只有一個人並不夠

88
00:04:26,703 --> 00:04:28,770
我想要有其他人的

89
00:04:28,770 --> 00:04:32,275
所以我試著召集實驗室的大家做同樣的事

90
00:04:32,275 --> 00:04:36,544
我猜大家不太想貢獻；大概一兩個禮拜

91
00:04:36,544 --> 00:04:41,402
非常刻苦的工作，坐在那邊五個小時

92
00:04:41,402 --> 00:04:44,222
試著分辨這是哪一種狗的種類

93
00:04:44,222 --> 00:04:47,876
所以這方面來說，我沒能拿到足夠的資料

94
00:04:47,876 --> 00:04:53,430
不過至少還能估計出成效，我覺得還滿好玩的。

95
00:04:53,430 --> 00:04:57,530
後來這引起大家注意了... 其實我當時並沒有料到

96
00:04:57,530 --> 00:04:59,946
我只是想要知道數據而已，可是就變成個大事了

97
00:04:59,946 --> 00:05:03,800
(笑) 而且大家很開心有人做了這樣的事

98
00:05:03,800 --> 00:05:06,140
還開玩笑稱我為肉體基準

99
00:05:06,140 --> 00:05:10,775
當然我覺得這滿好笑的

100
00:05:10,775 --> 00:05:15,892
>> 你當時會驚訝有軟體

101
00:05:15,892 --> 00:05:18,785
終於超越你了嗎？

102
00:05:18,785 --> 00:05:19,787
>> 沒錯

103
00:05:19,787 --> 00:05:21,968
嗯當然

104
00:05:21,968 --> 00:05:26,851
特別是有時候圖片裡面那是啥真的很難看出來

105
00:05:26,851 --> 00:05:30,125
就一坨黑點在那邊

106
00:05:30,125 --> 00:05:31,335
而我看不出來...

107
00:05:31,335 --> 00:05:34,897
你看我還要在20個中猜一個，而神經網路就知道答案

108
00:05:34,897 --> 00:05:37,420
我不知道這怎麼辦到的

109
00:05:37,420 --> 00:05:39,506
所以有種超人類感。

110
00:05:39,506 --> 00:05:44,040
而且我覺得，神經網路對樣式和材質的這種統計歸納

111
00:05:44,040 --> 00:05:45,050
非常在行。

112
00:05:46,090 --> 00:05:49,950
我覺得從這方面來看，我並不意外，神經網路更能

113
00:05:49,950 --> 00:05:53,680
從一大堆圖片量測到細膩的統計資料

114
00:05:53,680 --> 00:05:57,720
而在很多例子我還滿訝異的，因為有些圖片需要「讀」

115
00:05:57,720 --> 00:05:59,544
例如他就是個瓶子，外觀看不出是什麼

116
00:05:59,544 --> 00:06:00,904
可是其實上面的文字就告訴你這是什麼了

117
00:06:00,904 --> 00:06:04,382
所以身為人類，我能夠用讀的，但網路必須學習

118
00:06:04,382 --> 00:06:07,292
用讀的方式來辨識物品，因為外觀並不明顯

119
00:06:07,292 --> 00:06:10,204
>> 你其中最著名的事

120
00:06:10,204 --> 00:06:13,557
也是深度學習社群很感激你的

121
00:06:13,557 --> 00:06:17,115
就是你的課堂教學，還放在網路上

122
00:06:17,115 --> 00:06:20,049
請和我們分享一下緣由

123
00:06:20,049 --> 00:06:20,740
>> 好啊，當然

124
00:06:20,740 --> 00:06:26,160
基本上我強烈覺得

125
00:06:26,160 --> 00:06:29,490
這是很革命性的科技，而且很多人都想用

126
00:06:29,490 --> 00:06:30,700
就像個鐵鎚

127
00:06:30,700 --> 00:06:31,490
而我想要做的是

128
00:06:31,490 --> 00:06:36,170
我可以將這把鐵鎚傳授給很多人

129
00:06:36,170 --> 00:06:37,785
我覺得這很有吸引力

130
00:06:37,785 --> 00:06:40,501
從一個博士生的角度來說，這不一定很明智

131
00:06:40,501 --> 00:06:42,280
因為你等於是放下你的研究

132
00:06:42,280 --> 00:06:44,940
我的意思是，這佔了我大概 120% 的心力

133
00:06:44,940 --> 00:06:46,480
我必須把所有研究工作先擱著

134
00:06:46,480 --> 00:06:50,140
我看看，我教了兩次課，每次大概四個月

135
00:06:50,140 --> 00:06:52,880
那段時間算是全心全意在課堂上

136
00:06:52,880 --> 00:06:56,570
所以從這角度來看並不是很明智，不過這算是我博士生涯的亮點

137
00:06:56,570 --> 00:06:57,838
這甚至和研究無關

138
00:06:57,838 --> 00:07:01,110
我覺得教書絕對是我博士生涯最重要的部份

139
00:07:01,110 --> 00:07:02,350
光是看到學生

140
00:07:02,350 --> 00:07:06,360
光是看到他們很興奮... 這門課真的很不一樣

141
00:07:06,360 --> 00:07:08,518
平常大家教你的，是早在 1800 年就發現的

142
00:07:08,518 --> 00:07:09,167
諸如此類

143
00:07:09,167 --> 00:07:12,614
但是我們可以到課堂上說，你看，這論文前個禮拜才出來

144
00:07:12,614 --> 00:07:13,453
甚至是昨天出的

145
00:07:13,453 --> 00:07:16,112
又有嶄新結果。我覺得那些大學生和其他同學

146
00:07:16,112 --> 00:07:18,904
他們非常喜愛這種特點

147
00:07:18,904 --> 00:07:20,496
甚至他們還能讀懂理解之

148
00:07:20,496 --> 00:07:25,868
這並不是什麼非常深奧的學問

149
00:07:25,868 --> 00:07:28,454
只要你懂微積分、還有線性代數

150
00:07:28,454 --> 00:07:31,860
你就能了解每件事、了解背後道理

151
00:07:31,860 --> 00:07:36,465
所以我覺得因為這是如此強大、每天不斷演化

152
00:07:36,465 --> 00:07:39,395
大家覺得自己身處於革命性的尖端

153
00:07:39,395 --> 00:07:42,395
我認為這是大家很喜歡那門課的原因

154
00:07:42,395 --> 00:07:47,695
>> 你真的幫助了很多人，交出去了很多鐵鎚

155
00:07:47,695 --> 00:07:48,892
>> 沒錯

156
00:07:48,892 --> 00:07:52,182
>> 身為一直在從事深度學習

157
00:07:52,182 --> 00:07:56,712
也做了很久了，而這領域演化非常迅速

158
00:07:56,712 --> 00:07:59,222
我很好奇你的看法

159
00:07:59,222 --> 00:08:02,889
在這些年，你對深度學習的理解有何改變？

160
00:08:02,889 --> 00:08:06,444
>> 嗯嗯，例如當我剛開始接觸受限玻爾茲曼機 (RBM)

161
00:08:06,444 --> 00:08:07,599
第一次用在數字辨認

162
00:08:08,620 --> 00:08:11,360
我並不確定要怎麼使用這項技術

163
00:08:11,360 --> 00:08:12,240
也不確定這多重要

164
00:08:12,240 --> 00:08:15,270
還有當我一開始研究電腦視覺時，

165
00:08:15,270 --> 00:08:18,240
卷積網路(CNN)已經有了，但是

166
00:08:18,240 --> 00:08:21,770
還沒被很多電腦視覺的人使用

167
00:08:21,770 --> 00:08:25,400
我想當時的氛圍是，這在小資料有用

168
00:08:25,400 --> 00:08:27,210
但不可能擴展到非常多圖片

169
00:08:27,210 --> 00:08:28,820
這其實錯很大

170
00:08:28,820 --> 00:08:34,283
(笑) 總之基本上，我很訝異這技術是如此地泛用

171
00:08:34,283 --> 00:08:36,139
而且如此有效

172
00:08:36,139 --> 00:08:39,234
我會說這是我最訝異的。更有甚者...

173
00:08:39,234 --> 00:08:42,780
所以其中一件是成效非常有用，例如 ImageNet

174
00:08:42,780 --> 00:08:45,100
不過另一件大家沒預期到的

175
00:08:45,100 --> 00:08:48,310
至少我沒預期到的，是你可以拿預先訓練好的網路

176
00:08:48,310 --> 00:08:49,290
拿來轉移學習

177
00:08:49,290 --> 00:08:51,390
你可以微調後用在任何其他的問題上

178
00:08:51,390 --> 00:08:52,806
因為你現在並不是在解 ImageNet

179
00:08:52,806 --> 00:08:53,648
而需要數百萬的資料

180
00:08:53,648 --> 00:08:56,748
這網路本身，剛好也能很泛用地抽取特徵

181
00:08:56,748 --> 00:09:00,349
我想這是另一個比較少人預期到的特質。

182
00:09:00,349 --> 00:09:04,340
當時出現了很多論文

183
00:09:04,340 --> 00:09:06,840
各種電腦視覺的領域都有：

184
00:09:06,840 --> 00:09:10,900
我看過場景辨認、行為辨認、物體辨認、

185
00:09:10,900 --> 00:09:13,070
臉部特徵、諸如此類的

186
00:09:13,070 --> 00:09:16,900
大家只要微調網路，就能在每個問題通關

187
00:09:16,900 --> 00:09:21,136
這讓我感覺非常驚奇

188
00:09:21,136 --> 00:09:25,665
>> 沒錯，而且我覺得不知為何，監督學習比較受注目

189
00:09:25,665 --> 00:09:30,564
就算預先訓練的網路或轉移學習其實非常有用

190
00:09:30,564 --> 00:09:34,528
感覺大家也比較少談到這一塊

191
00:09:34,528 --> 00:09:35,460
>> 是的，沒錯。

192
00:09:36,560 --> 00:09:39,670
我想有些沒那麼出色，也就是對於非監督學習的期待

193
00:09:39,670 --> 00:09:44,680
我猜這大概是為什麼很多研究員踏入了這領域

194
00:09:44,680 --> 00:09:48,310
大概在2007年之類的

195
00:09:48,310 --> 00:09:52,350
而我覺得這邊的成績還沒繳出來

196
00:09:52,350 --> 00:09:56,090
我感到訝異的是監督學習的部份成效很好

197
00:09:56,090 --> 00:09:59,350
而非監督學習的部份還在...

198
00:09:59,350 --> 00:10:03,600
要怎麼使用之或怎麼成功，這還不明顯

199
00:10:03,600 --> 00:10:05,570
就算很多人還深深地相信

200
00:10:05,570 --> 00:10:10,525
在這個領域上。 >> 那麼，我知道

201
00:10:10,525 --> 00:10:14,495
你一直在思考 AI 長遠的未來

202
00:10:14,495 --> 00:10:16,175
你想分享一下嗎？

203
00:10:16,175 --> 00:10:18,902
>> 那麼，在過去一年半

204
00:10:18,902 --> 00:10:23,548
我在 OpenAI 想了很多相關的主題

205
00:10:23,548 --> 00:10:29,410
對我來說，這領域會分成兩條路

206
00:10:29,410 --> 00:10:34,010
一條是「應用 AI」，就只是做神經網路，訓練之

207
00:10:34,010 --> 00:10:37,450
大部都是監督學習，也可能是非監督的

208
00:10:37,450 --> 00:10:40,296
然後不斷進步，例如圖片辨認器之類的。

209
00:10:40,296 --> 00:10:45,210
而我想另一條路會是「強人工智慧」(AGI)

210
00:10:45,210 --> 00:10:50,191
也就是把神經網路變成完全動態的系統、

211
00:10:50,191 --> 00:10:54,990
能像人類一樣思考、說話、做所有人類能做的，這樣子地有智慧

212
00:10:54,990 --> 00:10:58,550
我一直覺得有趣的是，以電腦視覺為例

213
00:10:58,550 --> 00:10:59,990
我認為我們一開始解決問題的方法是錯的：

214
00:10:59,990 --> 00:11:02,990
我們嘗試把問題分成不同領域

215
00:11:02,990 --> 00:11:05,862
就好像，人類能辨認人、人類能辨認場景

216
00:11:05,862 --> 00:11:06,910
人類能辨認物品

217
00:11:06,910 --> 00:11:09,318
所以我們去做每件人類能做的

218
00:11:09,318 --> 00:11:12,740
然後我們有了這些 — 現在有了不同的領域

219
00:11:12,740 --> 00:11:13,850
然後有了這些後

220
00:11:13,850 --> 00:11:16,080
我們要想想怎麼把這些整合在一起。

221
00:11:16,080 --> 00:11:17,710
我覺得這方法不對

222
00:11:17,710 --> 00:11:21,120
能看到過去這樣的後果如何。

223
00:11:21,120 --> 00:11:24,173
我覺得這趨勢在 AI 比較高階的領域

224
00:11:24,173 --> 00:11:24,737
也類似

225
00:11:24,737 --> 00:11:28,363
就是大家在問：人類能計畫、人類能做實驗

226
00:11:28,363 --> 00:11:32,463
了解世界怎麼運作、人類要交談所以需要語言

227
00:11:32,463 --> 00:11:35,684
大家想根據功能性來分解問題，解決每一個

228
00:11:35,684 --> 00:11:37,522
然後再整合成某種腦。

229
00:11:37,522 --> 00:11:40,490
我認為這方法不對

230
00:11:40,490 --> 00:11:45,111
我一直比較傾向...

231
00:11:45,111 --> 00:11:50,041
不是那樣各個擊破，而是有某個單一的神經網路

232
00:11:50,041 --> 00:11:53,690
一個完整的動態系統、總是用整個系統來運作，

233
00:11:53,690 --> 00:11:54,760
那麼問題就變成：

234
00:11:54,760 --> 00:11:58,990
要怎麼去定義目標，使得你在最佳化

235
00:11:58,990 --> 00:12:02,330
這腦袋的權重時，你能得到有智慧的行為

236
00:12:02,330 --> 00:12:05,610
我在 OpenAI 一直想了很多這方面的事

237
00:12:05,610 --> 00:12:08,330
我想大家對於這個問題

238
00:12:08,330 --> 00:12:10,320
想了很多不同的方法

239
00:12:11,550 --> 00:12:12,050
例如

240
00:12:12,050 --> 00:12:15,510
走監督學習的方向，我在網路有篇論述

241
00:12:15,510 --> 00:12:17,750
不算是論述，那是我寫的短篇故事

242
00:12:17,750 --> 00:12:20,960
這故事試著假設、編織出一個世界的模樣

243
00:12:20,960 --> 00:12:25,350
— 如果達到「強人工智慧」僅是大規模的監督學習

244
00:12:25,350 --> 00:12:27,270
— 我們知道有這可能。

245
00:12:27,270 --> 00:12:32,135
所以這看起來會像 Amazon Mechanical Turk

246
00:12:32,135 --> 00:12:35,310
將功能加進許多執行作業的機器人當中

247
00:12:35,310 --> 00:12:38,640
然後我們訓練監督式學習資料集使其模仿人類

248
00:12:38,640 --> 00:12:39,790
可能是什麼樣子, 等等。

249
00:12:39,790 --> 00:12:41,924
還有其他的方向,

250
00:12:41,924 --> 00:12:46,511
像是演算法資訊理論的非監督式學習, 像是AIXI

251
00:12:46,511 --> 00:12:50,872
或者是人工生命, 那些看起來更像是人工進化的東西

252
00:12:50,872 --> 00:12:54,804
所以這就是我花時間思考的事情

253
00:12:54,804 --> 00:12:57,882
我心中有個正確答案, 但我不會在這裡透露給大家

254
00:12:57,882 --> 00:13:01,109
[笑] > > 我至少可以透過閱讀

255
00:13:01,109 --> 00:13:02,050
你的部落格瞭解更多

256
00:13:02,050 --> 00:13:02,550
>> 好啊, 當然

257
00:13:03,670 --> 00:13:08,520
您已經給出了相當多的意見, 而今日

258
00:13:08,520 --> 00:13:13,280
仍有很多人想進入人工智慧深度學習的領域

259
00:13:13,280 --> 00:13:17,340
你有沒有甚麼建議可以幫助他們呢?

260
00:13:17,340 --> 00:13:18,390
>> 好啊, 當然

261
00:13:18,390 --> 00:13:22,225
所以我認為當人們跟我談論 CS231n, 為什麼他們認為這是一個非常

262
00:13:22,225 --> 00:13:25,947
有用的課程, 我不斷聽到

263
00:13:25,947 --> 00:13:29,054
學生感謝我們帶領他們學習這些基礎的細節

264
00:13:29,054 --> 00:13:31,946
他們並不是直接使用框架, 必須先讀這些程式碼

265
00:13:31,946 --> 00:13:34,415
親自去看看這些程式是如何實踐

266
00:13:34,415 --> 00:13:36,750
然後自己再去一步步寫出這些函式

267
00:13:36,750 --> 00:13:40,550
透過這個過程真正將其內化成自己的知識

268
00:13:42,140 --> 00:13:44,020
不要只看那些最後的重點

269
00:13:44,020 --> 00:13:46,890
你必須要充分了解整個原貌

270
00:13:46,890 --> 00:13:49,390
這也是為什麼當我通常透過自學學習這些知識

271
00:13:49,390 --> 00:13:52,470
徒手從無到有實踐一切是最重要的

272
00:13:52,470 --> 00:13:57,880
這是我學習過程當中

273
00:13:57,880 --> 00:13:59,450
真正使我理解這些知識的方式

274
00:13:59,450 --> 00:14:00,107
所以我自己寫了一個函式庫

275
00:14:00,107 --> 00:14:01,438
叫做ConvNetJS

276
00:14:01,438 --> 00:14:03,663
用Javascript實踐了卷積神經網路

277
00:14:03,663 --> 00:14:06,410
這是我學習反向傳播的方式

278
00:14:06,410 --> 00:14:11,238
這是我一直建議人們不要一開始就用

279
00:14:11,238 --> 00:14:12,671
Tensorflow或其他框架

280
00:14:12,671 --> 00:14:15,763
除非你曾經徒手實踐過最基礎的函式

281
00:14:15,763 --> 00:14:19,066
並真正了解所有功能

282
00:14:19,066 --> 00:14:21,985
這時才去使用這些框架，去更清楚表達你的程式

283
00:14:21,985 --> 00:14:23,766
而你已經知道其中的意涵了

284
00:14:23,766 --> 00:14:26,444
這是一直以來幫助我做多的東西

285
00:14:26,444 --> 00:14:29,174
這是來上231n的人們最欣賞的學習方式

286
00:14:29,174 --> 00:14:30,691
也是我會建議多數人的做法

287
00:14:30,691 --> 00:14:35,540
>> 所以不要只是運行神經網路，看他會發生甚麼事

288
00:14:35,540 --> 00:14:38,390
對, 不要只是看到你在特定某隱藏層加上dropout

289
00:14:38,390 --> 00:14:41,500
就讓結果變好，這不是你要做的

290
00:14:41,500 --> 00:14:45,320
在這種情況下，你無法有效地進行除錯

291
00:14:45,320 --> 00:14:47,610
也無法有效地改進模型

292
00:14:48,630 --> 00:14:52,184
同樣的, 我很高興我們的深度學習課程

293
00:14:52,184 --> 00:14:56,235
是從數周Python語言開始的

294
00:14:56,235 --> 00:14:57,625
對, 很好

295
00:14:57,625 --> 00:15:00,947
非常感謝您分享的洞見與建議。

296
00:15:00,947 --> 00:15:04,355
您已經是很多人心目中深度學習領域的英雄

297
00:15:04,355 --> 00:15:07,598
我非常高興也非常感謝今天你能加入我們

298
00:15:07,598 --> 00:15:09,585
>> 謝謝你的邀請